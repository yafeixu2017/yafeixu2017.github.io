<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta http-equiv="Content-Style-Type" content="text/css" />
  <meta name="generator" content="pandoc" />
  <title></title>
  <style type="text/css">code{white-space: pre;}</style>
</head>
<body>
<blockquote>
<p><img src="./automlgithubpagesimages//media/image2.png" width="64" height="34" /><strong>The</strong> <strong>Springer</strong> <strong>Series</strong> <strong>on</strong> <strong>Challenges</strong> <strong>in</strong> <strong>Machine</strong> <strong>Learning</strong></p>
<p>Frank Hutter</p>
<p>Lars Kotthoff</p>
<p>Joaquin Vanschoren Edit0rs</p>
<p>Automated Machine Learning</p>
<p>Methods, Systems, Challenges</p>
</blockquote>
<p><img src="./automlgithubpagesimages//media/image3.png" width="144" height="39" /></p>
<blockquote>
<p><strong>The</strong> <strong>Springer</strong> <strong>Series</strong> <strong>on</strong> <strong>Challenges</strong> <strong>in</strong> <strong>Machine</strong> <strong>Learning</strong></p>
<p><strong>Series</strong> <strong>editors</strong></p>
</blockquote>
<p>Hugo Jair Escalante, Astroﬁsica Optica y Electronica, INAOE, Puebla, Mexico Isabelle Guyon, ChaLearn, Berkeley, CA, USA</p>
<blockquote>
<p>Sergio Escalera <a href="https://orcid.org/0000-0003-0617-8873"><img src="./automlgithubpagesimages//media/image4.png" width="13" height="11" /></a>, University of Barcelona, Barcelona, Spain</p>
</blockquote>
<p>The books in this innovative series collect papers written in the context of successful competitions in machine learning. They also include analyses of the challenges, tutorial material, dataset descriptions, and pointers to data and software. Together with the websites of the challenge competitions, they offer a complete teaching toolkit and a valuable resource for engineers and scientists.</p>
<p>More information about this series at <a href="http://www.springer.com/series/15602" class="uri">http://www.springer.com/series/15602</a></p>
<blockquote>
<p>Frank Hutter • Lars Kotthoff • Joaquin Vanschoren</p>
<p>Editors</p>
<p>Automated Machine</p>
<p>Learning</p>
<p>Methods, Systems, Challenges</p>
</blockquote>
<p><em>Editors</em></p>
<blockquote>
<p>Frank Hutter</p>
<p>Department of Computer Science</p>
<p>University of Freiburg</p>
<p>Freiburg, Germany</p>
<p>Joaquin Vanschoren <a href="https://orcid.org/0000-0001-7044-9805"><img src="./automlgithubpagesimages//media/image6.png" width="13" height="10" /></a></p>
<p>Eindhoven University of Technology</p>
<p>Eindhoven, The Netherlands</p>
</blockquote>
<p>Lars Kotthoff</p>
<p>University of Wyoming</p>
<p>Laramie, WY, USA</p>
<p><img src="./automlgithubpagesimages//media/image7.png" width="75" height="26" /></p>
<blockquote>
<p>ISSN 2520- 131X ISSN 2520- 1328 (electronic)</p>
<p>The Springer Series on Challenges in Machine Learning</p>
<p>ISBN 978-3-030-05317-8 ISBN 978-3-030-05318-5 (eBook)</p>
<p><a href="https://doi.org/10.1007/978-3-030-05318-5" class="uri">https://doi.org/10.1007/978-3-030-05318-5</a></p>
<p>© The Editor(s) (if applicable) and The Author(s) 2019. This book is an open access publication. <strong>Open</strong> <strong>Access</strong> This book is licensed under the terms of the Creative Commons Attribution 4.0 International License <a href="http://creativecommons.org/licenses/by/4.0/">(http://creativecommons.org/licenses/by/4.0/</a>), which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence and indicate if changes were made.</p>
</blockquote>
<p>The images or other third party material in this book are included in the book’s Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the book’s Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder.</p>
<p>The use of general descriptive names, registered names, trademarks, service marks, etc. in this publication does not imply, even in the absence of a speciﬁc statement, that such names are exempt from the relevant protective laws and regulations and therefore free for general use.</p>
<blockquote>
<p>The publisher, the authors, and the editors are safe to assume that the advice and information in this book are believed to be true and accurate at the date of publication. Neither the publisher nor the authors or the editors give a warranty, express or implied, with respect to the material contained herein or for any errors or omissions that may have been made. The publisher remains neutral with regard to jurisdictional claims in published maps and institutional afﬁliations.</p>
<p>This Springer imprint is published by the registered company Springer Nature Switzerland AG. The registered company address is: Gewerbestrasse 11, 6330 Cham, Switzerland</p>
<p>To Sophia and Tashia. – F.H.</p>
<p>To Kobe, Elias, Ada, and Veerle. – J.V.</p>
<p>To the AutoML community, for being awesome. – F.H., L.K., and J.V.</p>
<p><strong>Foreword</strong></p>
</blockquote>
<p>“<em>I’d</em> <em>like</em> <em>to</em> <em>use</em> <em>machine</em> <em>learning,</em> <em>but</em> <em>I</em> <em>can’t</em> <em>invest</em> <em>much</em> <em>time.</em>” That is something you hear all too often in industry and from researchers in other disciplines. The resulting demand for hands-free solutions to machine learning has recently given rise to the ﬁeld of automated machine learning (AutoML), and I’m delighted that with this book, there is now the ﬁrst comprehensive guide to this ﬁeld.</p>
<blockquote>
<p>I have been very passionate about automating machine learning myself ever since our Automatic Statistician project started back in 2014. I want us to be really ambitious in this endeavor; we should try to automate all aspects of the entire machine learning and data analysis pipeline. This includes automating data collection and experiment design; automating data cleanup and missing data imputa- tion; automating feature selection and transformation; automating model discovery, criticism, and explanation; automating the allocation of computational resources; automating hyperparameter optimization; automating inference; and automating model monitoring and anomaly detection. This is a huge list of things, and we’d optimally like to automate all of it.</p>
<p>There is a caveat of course. While <em>full</em> automation can motivate scientiﬁc research and provide a long-term engineering goal, in practice, we probably want to <em>semiautomate</em> most of these and gradually remove the human in the loop as needed. Along the way, what is going to happen if we try to do all this automation is that we are likely to develop powerful tools that will help make the practice of machine learning, ﬁrst of all, <em>more</em> <em>systematic</em> (since it’s very ad hoc these days) and also <em>more</em> <em>efﬁcient</em>.</p>
<p>These are worthy goals even if we did not succeed in the ﬁnal goal of automation, but as this book demonstrates, current AutoML methods can already surpass human machine learning experts in several tasks. This trend is likely only going to intensify as we’re making progress and as computation becomes ever cheaper, and AutoML is therefore clearly one of the topics that is here to stay. It is a great time to get involved in AutoML, and this book is an excellent starting point.</p>
<p>This book includes very up-to-date overviews of the bread-and-butter techniques we need in AutoML (hyperparameter optimization, meta-learning, and neural architecture search), provides in-depth discussions of existing AutoML systems, and</p>
<p>viii Foreword</p>
</blockquote>
<p>thoroughly evaluates the state of the art in AutoML in a series of competitions that ran since 2015. As such, I highly recommend this book to any machine learning researcher wanting to get started in the ﬁeld and to any practitioner looking to</p>
<p>understand the methods behind all the AutoML tools out there.</p>
<blockquote>
<p>San Francisco, USA Zoubin Ghahramani Professor, University of Cambridge and</p>
<p>Chief Scientist, Uber</p>
<p>October 2018</p>
<p><strong>Preface</strong></p>
</blockquote>
<p>The past decade has seen an explosion of machine learning research and appli- cations; especially, deep learning methods have enabled key advances in many application domains, such as computer vision, speech processing, and game playing. However, the performance of many machine learning methods is very sensitive to a plethora of design decisions, which constitutes a considerable barrier for new users. This is particularly true in the booming ﬁeld of deep learning, where human engineers need to select the right neural architectures, training procedures, regularization methods, and hyperparameters of all of these components in order to make their networks do what they are supposed to do with sufﬁcient performance. This process has to be repeated for every application. Even experts are often left with tedious episodes of trial and error until they identify a good set of choices for a particular dataset.</p>
<p>The ﬁeld of automated machine learning (AutoML) aims to make these decisions in a data-driven, objective, and automated way: the user simply provides data, and the AutoML system automatically determines the approach that performs best for this particular application. Thereby, AutoML makes state-of-the-art machine learning approaches accessible to domain scientists who are interested in applying machine learning but do not have the resources to learn about the technologies behind it in detail. This can be seen as a <em>democratization</em> of machine learning: with AutoML, customized state-of-the-art machine learning is at everyone’s ﬁngertips.</p>
<p>As we show in this book, AutoML approaches are already mature enough to rival and sometimes even outperform human machine learning experts. Put simply, AutoML can lead to improved performance while saving substantial amounts of time and money, as machine learning experts are both hard to ﬁnd and expensive. As a result, commercial interest in AutoML has grown dramatically in recent years, and several major tech companies are now developing their own AutoML systems. We note, though, that the purpose of democratizing machine learning is served much better by open-source AutoML systems than by proprietary paid black-box services. This book presents an overview of the fast-moving ﬁeld of AutoML. Due to the community’s current focus on deep learning, some researchers nowadays mistakenly equate AutoML with the topic of neural architecture search (NAS);</p>
<p>Preface</p>
<p>but of course, if you’re reading this book, you know that – while NAS is an excellent example of AutoML – there is a lot more to AutoML than NAS. This book is intended to provide some background and starting points for researchers interested in developing their own AutoML approaches, highlight available systems for practitioners who want to apply AutoML to their problems, and provide an overview of the state of the art to researchers already working in AutoML. The book is divided into three parts on these different aspects of AutoML.</p>
<blockquote>
<p>Part <a href="#_bookmark1">I</a> presents an overview of AutoML methods. This part gives both a solid overview for novices and serves as a reference to experienced AutoML researchers.</p>
<p>Chap.<a href="#_bookmark2">1</a> discusses the problem of hyperparameter optimization, the simplest and most common problem that AutoML considers, and describes the wide variety of different approaches that are applied, with a particular focus on the methods that are currently most efﬁcient.</p>
</blockquote>
<p>Chap. <a href="#_bookmark3">2</a> shows how to <em>learn</em> <em>to</em> <em>learn</em>, i.e., how to use experience from evaluating machine learning models to inform how to approach new learning tasks with new data. Such techniques mimic the processes going on as a human transitions from a machine learning novice to an expert and can tremendously decrease the time required to get good performance on completely new machine learning tasks.</p>
<blockquote>
<p>Chap. <a href="#_bookmark4">3</a>provides a comprehensive overview of methods for NAS. This is one of the most challenging tasks in AutoML, since the design space is extremely large and a single evaluation of a neural network can take a very long time. Nevertheless, the area is very active, and new exciting approaches for solving NAS appear regularly.</p>
<p>Part <a href="#_bookmark5">II</a>focuses on actual AutoML systems that even novice users can use. If you are most interested in applying AutoML to your machine learning problems, this is the part you should start with. All of the chapters in this part evaluate the systems they present to provide an idea of their performance in practice.</p>
</blockquote>
<p>Chap. <a href="#_bookmark6">4</a> describes Auto-WEKA, one of the ﬁrst AutoML systems. It is based on the well-known WEKA machine learning toolkit and searches over different classiﬁcation and regression methods, their hyperparameter settings, and data preprocessing methods. All of this is available through WEKA’s graphical user interface at the click of a button, without the need for a single line of code.</p>
<blockquote>
<p>Chap. <a href="#_bookmark7">5</a> gives an overview of Hyperopt-Sklearn, an AutoML framework based on the popular scikit-learn framework. It also includes several hands-on examples for how to use system.</p>
<p>Chap. <a href="#_bookmark8">6</a> describes Auto-sklearn, which is also based on scikit-learn. It applies similar optimization techniques as Auto-WEKA and adds several improvements over other systems at the time, such as meta-learning for warmstarting the opti- mization and automatic ensembling. The chapter compares the performance of Auto-sklearn to that of the two systems in the previous chapters, Auto-WEKA and Hyperopt-Sklearn. In two different versions, Auto-sklearn is the system that won the challenges described in Part <a href="#_bookmark9">III</a>of this book.</p>
<p>Chap. <a href="#_bookmark10">7</a> gives an overview of Auto-Net, a system for automated deep learning that selects both the architecture and the hyperparameters of deep neural networks. An early version of Auto-Net produced the ﬁrst automatically tuned neural network that won against human experts in a competition setting.</p>
<p>Preface xi</p>
<p>Chap. <a href="#_bookmark11">8</a> describes the TPOT system, which automatically constructs and opti- mizes tree-based machine learning pipelines. These pipelines are more ﬂexible than approaches that consider only a set of ﬁxed machine learning components that are connected in predeﬁned ways.</p>
</blockquote>
<p>Chap. <a href="#_bookmark12">9</a> presents the Automatic Statistician, a system to automate data science by generating fully automated reports that include an analysis of the data, as well as predictive models and a comparison of their performance. A unique feature of the Automatic Statistician is that it provides natural-language descriptions of the results, suitable for non-experts in machine learning.</p>
<blockquote>
<p>Finally, Part <a href="#_bookmark9">III</a>and Chap.<a href="#_bookmark13">10</a>give an overview of the AutoML challenges, which have been running since 2015. The purpose of these challenges is to spur the development of approaches that perform well on practical problems and determine the best overall approach from the submissions. The chapter details the ideas and concepts behind the challenges and their design, as well as results from past challenges.</p>
</blockquote>
<p>To the best of our knowledge, this is the ﬁrst comprehensive compilation of all aspects of AutoML: the methods behind it, available systems that implement AutoML in practice, and the challenges for evaluating them. This book provides practitioners with background and ways to get started developing their own AutoML systems and details existing state-of-the-art systems that can be applied immediately to a wide range of machine learning tasks. The ﬁeld is moving quickly, and with this book, we hope to help organize and digest the many recent advances. We hope you enjoy this book and join the growing community of AutoML enthusiasts.</p>
<blockquote>
<p><strong>Acknowledgments</strong></p>
</blockquote>
<p>We wish to thank all the chapter authors, without whom this book would not have been possible. We are also grateful to the European Union’s Horizon 2020 research and innovation program for covering the open access fees for this book through Frank’s ERC Starting Grant (grant no. 716721).</p>
<blockquote>
<p>Freiburg, Germany</p>
<p>Laramie, WY, USA</p>
<p>Eindhoven, The Netherlands</p>
<p>October 2018</p>
</blockquote>
<p>Frank Hutter Lars Kotthoff Joaquin Vanschoren</p>
<blockquote>
<p><strong>Contents</strong></p>
<p><a href="#_bookmark2">Matthias Feurer and Frank Hutter</a></p>
<p><a href="#_bookmark3"><strong>2</strong> <strong>Meta-Learning</strong></a> .......................................... .................... 35</p>
<p><a href="#_bookmark3">Joaquin Vanschoren</a></p>
<p><strong>4</strong> <strong>Auto-WEKA:</strong> <strong>Automatic</strong> <strong>Model</strong> <strong>Selection</strong> <strong>and</strong> <strong>Hyperparameter</strong></p>
<p><a href="#_bookmark7">Brent Komer, James Bergstra, and Chris Eliasmith</a></p>
<p><strong>6</strong> <strong>Auto-sklearn:</strong> <strong>Efﬁcient</strong> <strong>and</strong> <strong>Robust</strong> <strong>Automated</strong> <strong>Machine</strong></p>
<p>Hector Mendoza, Aaron Klein, Matthias Feurer, Jost Tobias Springenberg, Matthias Urban, Michael Burkart, Maximilian Dippel, Marius Lindauer, and Frank Hutter</p>
<p><strong>8</strong> <strong>TPOT:</strong> <strong>A</strong> <strong>Tree-Based</strong> <strong>Pipeline</strong> <strong>Optimization</strong> <strong>Tool</strong></p>
</blockquote>
<p>xiv Contents</p>
<blockquote>
<p><a href="#_bookmark12"><strong>9</strong> <strong>The</strong> <strong>Automatic</strong> <strong>Statistician</strong></a> ............................ .................... 161</p>
<p>Christian Steinruecken, Emma Smith, David Janz, James Lloyd, and Zoubin Ghahramani</p>
</blockquote>
<p><a href="#_bookmark9"><strong>Part</strong> <strong>III</strong> <strong>AutoML</strong> <strong>Challenges</strong></a></p>
<blockquote>
<p><a href="#_bookmark13"><strong>10</strong> <strong>Analysis</strong> <strong>of</strong> <strong>the</strong> <strong>AutoML</strong> <strong>Challenge</strong> <strong>Series</strong> <strong>2015–2018</strong></a> .................. 177</p>
<p>Isabelle Guyon, Lisheng Sun-Hosoya, Marc Boullé,</p>
<p>Hugo Jair Escalante, Sergio Escalera, Zhengying Liu, Damir Jajetic, Bisakha Ray, Mehreen Saeed, Michèle Sebag, Alexander Statnikov, Wei-Wei Tu, and Evelyne Viegas</p>
</blockquote>
<p><span id="_bookmark1" class="anchor"></span><strong>Part</strong> <strong>I</strong></p>
<p><strong>AutoML</strong> <strong>Methods</strong></p>
<p><img src="./automlgithubpagesimages//media/image8.png" width="41" height="41" /><img src="./automlgithubpagesimages//media/image9.jpeg" width="136" /></p>
<blockquote>
<p><span id="_bookmark2" class="anchor"></span><strong>Chapter</strong> <strong>1</strong></p>
<p><strong>Hyperparameter</strong> <strong>Optimization</strong></p>
</blockquote>
<p><img src="./automlgithubpagesimages//media/image10.png" /></p>
<blockquote>
<p><strong>Matthias</strong> <strong>Feurer</strong> <strong>and</strong> <strong>Frank</strong> <strong>Hutter</strong></p>
<p><strong>Abstract</strong> Recent interest in complex and computationally expensive machine learning models with many hyperparameters, such as automated machine learning (AutoML) frameworks and deep neural networks, has resulted in a resurgence of research on hyperparameter optimization (HPO). In this chapter, we give an overview of the most prominent approaches for HPO. We ﬁrst discuss blackbox function optimization methods based on model-free methods and Bayesian opti- mization. Since the high computational demand of many modern machine learning applications renders pure blackbox optimization extremely costly, we next focus on modern multi-ﬁdelity methods that use (much) cheaper variants of the blackbox function to approximately assess the quality of hyperparameter settings. Lastly, we point to open problems and future research directions.</p>
<p><strong>1.1</strong> <strong>Introduction</strong></p>
<p>Every machine learning system has hyperparameters, and the most basic task in automated machine learning (AutoML) is to automatically set these hyperparam- eters to optimize performance. Especially recent deep neural networks crucially depend on a wide range of hyperparameter choices about the neural network’s archi- tecture, regularization, and optimization. Automated hyperparameter optimization (HPO) has several important use cases; it can</p>
<p>• reduce the human effort necessary for applying machine learning. This is particularly important in the context of AutoML.</p>
<p>M. Feurer (凶)</p>
<p>Department of Computer Science, University of Freiburg, Freiburg, Baden-Württemberg, Germany</p>
<p>e-mail: <a href="mailto:feurerm@informatik.uni-freiburg.de ">feurerm@informatik.uni-freiburg.de</a></p>
<p>F. Hutter</p>
<p>Department of Computer Science, University of Freiburg, Freiburg, Germany</p>
<p>© The Author(s) 2019</p>
<p>F. Hutter et al. (eds.), <em>Automated</em> <em>Machine</em> <em>Learning</em>, The Springer Series on Challenges in Machine Learning, <a href="https://doi.org/10.1007/978-3-030-05318-5_1" class="uri">https://doi.org/10.1007/978-3-030-05318-5_1</a></p>
<p>4 M. Feurer and F. Hutter</p>
<p>• improve the performance of machine learning algorithms (by tailoring them to the problem at hand); this has led to new state-of-the-art performances for important machine learning benchmarks in several studies (e.g. [<a href="#_bookmark21">105</a>, <a href="#_bookmark22">140</a>]).</p>
<p>• improve the reproducibility and fairness of scientiﬁc studies. Automated HPO is clearly more reproducible than manual search. It facilitates fair comparisons since different methods can only be compared fairly if they all receive the same level of tuning for the problem at hand [<a href="#_bookmark23">14</a>, <a href="#_bookmark24">133</a>].</p>
<p>The problem of HPO has a long history, dating back to the 1990s (e.g., [<a href="#_bookmark25">77</a>, <a href="#_bookmark26">82</a>, <a href="#_bookmark27">107</a>, <a href="#_bookmark28">126</a>]), and it was also established early that different hyperparameter conﬁgurations tend to work best for different datasets [<a href="#_bookmark26">82</a>]. In contrast, it is a rather new insight that HPO can be used to adapt general-purpose pipelines to speciﬁc application domains [<a href="#_bookmark29">30</a>]. Nowadays, it is also widely acknowledged that tuned hyperparameters improve over the default setting provided by common machine learning libraries [<a href="#_bookmark30">100</a>, <a href="#_bookmark31">116</a>, <a href="#_bookmark32">130</a>, <a href="#_bookmark33">149</a>].</p>
</blockquote>
<p>Because of the increased usage of machine learning in companies, HPO is also of substantial commercial interest and plays an ever larger role there, be it in company- internal tools [<a href="#_bookmark34">45</a>], as part of machine learning cloud services [<a href="#_bookmark35">6</a>, <a href="#_bookmark36">89</a>], or as a service by itself [<a href="#_bookmark37">137</a>].</p>
<blockquote>
<p>HPO faces several challenges which make it a hard problem in practice:</p>
<p>• Function evaluations can be extremely expensive for large models (e.g., in deep learning), complex machine learning pipelines, or large datesets.</p>
<p>• The conﬁguration space is often complex (comprising a mix of continuous, cat- egorical and conditional hyperparameters) and high-dimensional. Furthermore, it is not always clear which of an algorithm’s hyperparameters need to be optimized, and in which ranges.</p>
<p>• We usually don’t have access to a gradient of the loss function with respect to the hyperparameters. Furthermore, other properties of the target function often used in classical optimization do not typically apply, such as convexity and smoothness.</p>
<p>• One cannot directly optimize for generalization performance as training datasets are of limited size.</p>
</blockquote>
<p>We refer the interested reader to other reviews of HPO for further discussions on</p>
<blockquote>
<p>this topic [<a href="#_bookmark38">64</a>, <a href="#_bookmark39">94</a>].</p>
<p>This chapter is structured as follows. First, we deﬁne the HPO problem for- mally and discuss its variants (Sect.<a href="#_bookmark40">1.2</a>). Then, we discuss blackbox optimization algorithms for solving HPO (Sect.<a href="#_bookmark41">1.3</a>). Next, we focus on modern multi-ﬁdelity methods that enable the use of HPO even for very expensive models, by exploiting approximate performance measures that are cheaper than full model evaluations (Sect.<a href="#_bookmark42">1.4</a>). We then provide an overview of the most important hyperparameter optimization systems and applications to AutoML (Sect.<a href="#_bookmark43">1.5</a>) and end the chapter with a discussion of open problems (Sect.<a href="#_bookmark44">1.6</a>).</p>
<p>1 Hyperparameter Optimization 5</p>
<p><span id="_bookmark40" class="anchor"></span><strong>1.2</strong> <strong>Problem</strong> <strong>Statement</strong></p>
</blockquote>
<p>Let A denote a machine learning algorithm with N hyperparameters. We denote the domain of the n-th hyperparameter by ^n and the overall <em>hyperparameter</em> <em>conﬁguration</em> <em>space</em> as <strong>A</strong> = ^1 × ^2 × . . . ^N . A vector of hyperparameters is denoted by <strong>λ</strong> ∈ <strong>A</strong>, and A with its hyperparameters instantiated to <strong>λ</strong> is denoted by A<strong>λ</strong> .</p>
<blockquote>
<p>The domain of a hyperparameter can be real-valued (e.g., learning rate), integer- valued (e.g., number of layers), binary (e.g., whether to use early stopping or not), or categorical (e.g., choice of optimizer). For integer and real-valued hyperparameters, the domains are mostly bounded for practical reasons, with only a few excep- tions [<a href="#_bookmark45">12</a>, <a href="#_bookmark46">113</a>, <a href="#_bookmark47">136</a>].</p>
</blockquote>
<p>Furthermore, the conﬁguration space can contain <em>conditionality</em>, i.e., a hyper- parameter may only be relevant if another hyperparameter (or some combination of hyperparameters) takes on a certain value. Conditional spaces take the form of directed acyclic graphs. Such conditional spaces occur, e.g., in the automated tuning of machine learning pipelines, where the choice between different preprocessing and machine learning algorithms is modeled as a categorical hyperparameter, a problem known as <em>Full</em> <em>Model</em> <em>Selection</em> (FMS) or <em>Combined</em> <em>Algorithm</em> <em>Selection</em> <em>and</em> <em>Hyperparameter</em> <em>optimization</em> <em>problem</em> (CASH) [<a href="#_bookmark29">30</a>, <a href="#_bookmark48">34</a>, <a href="#_bookmark49">83</a>, <a href="#_bookmark33">149</a>]. They also occur when optimizing the architecture of a neural network: e.g., the number of layers can be an integer hyperparameter and the per-layer hyperparameters of layer i are only active if the network depth is at least i [<a href="#_bookmark45">12</a>, <a href="#_bookmark23">14</a>, <a href="#_bookmark50">33</a>].</p>
<blockquote>
<p>Given a data set D, our goal is to ﬁnd</p>
<p><span id="_bookmark51" class="anchor"></span><strong>λ</strong>* = argmin E(Dtrain,Dvalid)∼D<strong>V</strong>(L, A<strong>λ</strong>,Dtrain,Dvalid),</p>
<p><strong>λ</strong>∈<strong>A</strong></p>
<p>(1. 1)</p>
</blockquote>
<p>where <strong>V</strong>(L, A<strong>λ</strong>,Dtrain,Dvalid) measures the loss of a model generated by algo- rithm A with hyperparameters <strong>λ</strong> on training data Dtrain and evaluated on validation data Dvalid . In practice, we only have access to ﬁnite data D ∼ D and thus need to approximate the expectation in Eq.<a href="#_bookmark51">1.1</a>.</p>
<p>Popular choices for the validation protocol <strong>V</strong>(·, · , · , ·) are the holdout and cross- validation error for a user-given loss function (such as misclassiﬁcation rate); see Bischl et al. [<a href="#_bookmark52">16</a>] for an overview of validation protocols. Several strategies for reducing the evaluation time have been proposed: It is possible to only test machine learning algorithms on a subset of folds [<a href="#_bookmark33">149</a>], only on a subset of data [<a href="#_bookmark53">78</a>, <a href="#_bookmark54">102</a>, <a href="#_bookmark55">147</a>], or for a small amount of iterations; we will discuss some of these strategies in more detail in Sect.<a href="#_bookmark42">1.4</a>. Recent work on multi-task [<a href="#_bookmark55">147</a>] and multi-source [<a href="#_bookmark56">121</a>] optimization introduced further cheap, auxiliary tasks, which can be queried instead of Eq.<a href="#_bookmark51">1.1</a>. These can provide cheap information to help HPO, but do not necessarily train a machine learning model on the dataset of interest and therefore do not yield a usable model as a side product.</p>
<blockquote>
<p>6 M. Feurer and F. Hutter</p>
</blockquote>
<p><span id="_bookmark57" class="anchor"></span><em><strong>1.2.1</strong></em> <em><strong>Alternatives</strong></em> <em><strong>to</strong></em> <em><strong>Optimization:</strong></em> <em><strong>Ensembling</strong></em> <em><strong>and</strong></em></p>
<blockquote>
<p><em><strong>Marginalization</strong></em></p>
</blockquote>
<p>Solving Eq.<a href="#_bookmark51">1.1</a> with one of the techniques described in the rest of this chapter usually requires ﬁtting the machine learning algorithm A with multiple hyperpa- rameter vectors <strong>λ</strong>t . Instead of using the argmin-operator over these, it is possible to either construct an ensemble (which aims to minimize the loss for a given validation protocol) or to integrate out all the hyperparameters (if the model under consideration is a probabilistic model). We refer to Guyon et al. [<a href="#_bookmark58">50</a>] and the references therein for a comparison of frequentist and Bayesian model selection.</p>
<blockquote>
<p>Only choosing a single hyperparameter conﬁguration can be wasteful when many good conﬁgurations have been identiﬁed by HPO, and combining them in an ensemble can improve performance [<a href="#_bookmark59">109</a>]. This is particularly useful in AutoML systems with a large conﬁguration space (e.g., in <em>FMS</em> or <em>CASH</em>), where good conﬁgurations can be very diverse, which increases the potential gains from ensembling [<a href="#_bookmark60">4</a>, <a href="#_bookmark61">19</a>, <a href="#_bookmark62">31</a>, <a href="#_bookmark48">34</a>]. To further improve performance, <em>Automatic</em> <em>Franken-</em> <em>steining</em> [<a href="#_bookmark63">155</a>] uses HPO to train a stacking model [<a href="#_bookmark64">156</a>] on the outputs of the models found with HPO; the 2nd level models are then combined using a traditional ensembling strategy.</p>
</blockquote>
<p>The methods discussed so far applied ensembling after the HPO procedure. While they improve performance in practice, the base models are not optimized for ensembling. It is, however, also possible to directly optimize for models which would maximally improve an existing ensemble [<a href="#_bookmark65">97</a>].</p>
<blockquote>
<p>Finally, when dealing with Bayesian models it is often possible to integrate out the hyperparameters of the machine learning algorithm, for example using <em>evidence</em> <em>maximization</em> [<a href="#_bookmark66">98</a>], <em>Bayesian</em> <em>model</em> <em>averaging</em> [<a href="#_bookmark67">56</a>], <em>slice</em> <em>sampling</em> [<a href="#_bookmark68">111</a>] or <em>empirical</em> <em>Bayes</em> [<a href="#_bookmark69">103</a>].</p>
</blockquote>
<p><em><strong>1.2.2</strong></em> <em><strong>Optimizingfor</strong></em> <em><strong>Multiple</strong></em> <em><strong>Objectives</strong></em></p>
<blockquote>
<p>In practical applications it is often necessary to trade off two or more objectives, such as the performance of a model and resource consumption [<a href="#_bookmark70">65</a>] (see also Chap.<a href="#_bookmark4">3</a>) or multiple loss functions [<a href="#_bookmark71">57</a>]. Potential solutions can be obtained in two ways.</p>
<p>First, if a limit on a secondary performance measure is known (such as the maximal memory consumption), the problem can be formulated as a constrained optimization problem. We will discuss constraint handling in Bayesian optimization in Sect.<a href="#_bookmark72">1.3.2.4</a>.</p>
</blockquote>
<p>Second, and more generally, one can apply multi-objective optimization to search for the Pareto front, a set of conﬁgurations which are optimal tradeoffs between the objectives in the sense that, for each conﬁguration on the Pareto front, there is no other conﬁguration which performs better for at least one and at least as well for all other objectives. The user can then choose a conﬁguration from the Pareto front. We refer the interested reader to further literature on this topic [<a href="#_bookmark73">53</a>, <a href="#_bookmark71">57</a>, <a href="#_bookmark70">65</a>, <a href="#_bookmark74">134</a>].</p>
<p><img src="./automlgithubpagesimages//media/image11.png" /><img src="./automlgithubpagesimages//media/image12.jpeg" width="136" /><img src="./automlgithubpagesimages//media/image13.png" /><img src="./automlgithubpagesimages//media/image14.png" /><img src="./automlgithubpagesimages//media/image15.png" /><img src="./automlgithubpagesimages//media/image16.png" /><img src="./automlgithubpagesimages//media/image17.png" /><img src="./automlgithubpagesimages//media/image18.png" /><img src="./automlgithubpagesimages//media/image22.png" height="113" /><img src="./automlgithubpagesimages//media/image23.png" width="104" height="35" /><img src="./automlgithubpagesimages//media/image24.png" width="35" height="104" /><img src="./automlgithubpagesimages//media/image25.png" height="113" /><img src="./automlgithubpagesimages//media/image26.png" width="104" height="35" /><img src="./automlgithubpagesimages//media/image27.png" width="35" height="104" /><img src="./automlgithubpagesimages//media/image28.png" /><img src="./automlgithubpagesimages//media/image29.png" /><img src="./automlgithubpagesimages//media/image30.png" /><img src="./automlgithubpagesimages//media/image31.png" /><img src="./automlgithubpagesimages//media/image32.png" /><img src="./automlgithubpagesimages//media/image33.png" width="23" /><img src="./automlgithubpagesimages//media/image34.png" /><img src="./automlgithubpagesimages//media/image35.png" width="100" /><img src="./automlgithubpagesimages//media/image36.png" width="12" /><img src="./automlgithubpagesimages//media/image37.png" width="23" /></p>
<blockquote>
<p>1 Hyperparameter Optimization 7</p>
<p><span id="_bookmark41" class="anchor"></span><strong>1.3</strong> <strong>Blackbox</strong> <strong>Hyperparameter</strong> <strong>Optimization</strong></p>
<p>In general, every blackbox optimization method can be applied to HPO. Due to the non-convex nature of the problem, global optimization algorithms are usually preferred, but some locality in the optimization process is useful in order to make progress within the few function evaluations that are usually available. We ﬁrst discuss model-free blackbox HPO methods and then describe blackbox Bayesian optimization methods.</p>
<p><em><strong>1.3.1</strong></em> <em><strong>Model-Free</strong></em> <em><strong>Blackbox</strong></em> <em><strong>Optimization</strong></em> <em><strong>Methods</strong></em></p>
<p>Grid search is the most basic HPO method, also known as full factorial design [<a href="#_bookmark75">110</a>]. The user speciﬁes a ﬁnite set of values for each hyperparameter, and grid search evaluates the Cartesian product of these sets. This suffers from the curse of dimen- sionality since the required number of function evaluations grows exponentially with the dimensionality of the conﬁguration space. An additional problem of grid search is that increasing the resolution of discretization substantially increases the required number of function evaluations.</p>
<p>A simple alternative to grid search is random search [<a href="#_bookmark76">13</a>].<a href="#_bookmark77">1</a>As the name suggests, random search samples conﬁgurations at random until a certain budget for the search is exhausted. This works better than grid search when some hyperparameters are much more important than others (a property that holds in many cases [<a href="#_bookmark76">13</a>, <a href="#_bookmark78">61</a>]). Intuitively, when run with a ﬁxed budget of B function evaluations, the number of different values grid search can afford to evaluate for each of the N hyperparameters is only B1/N, whereas random search will explore B different values for each; see Fig.<a href="#_bookmark79">1.1</a> for an illustration.</p>
</blockquote>
<p><img src="./automlgithubpagesimages//media/image38.png" width="89" /></p>
<p><img src="./automlgithubpagesimages//media/image39.png" /></p>
<table>
<tbody>
<tr class="odd">
<td><p><img src="./automlgithubpagesimages//media/image40.png" /><img src="./automlgithubpagesimages//media/image41.png" /><img src="./automlgithubpagesimages//media/image42.png" /></p>
<p><img src="./automlgithubpagesimages//media/image43.png" /></p>
<p><img src="./automlgithubpagesimages//media/image44.png" /></p>
<p><img src="./automlgithubpagesimages//media/image45.png" /></p>
<p><img src="./automlgithubpagesimages//media/image46.png" /></p>
<p><img src="./automlgithubpagesimages//media/image47.png" width="13" height="16" /></p>
<p><img src="./automlgithubpagesimages//media/image48.png" /></p></td>
</tr>
</tbody>
</table>
<p><img src="./automlgithubpagesimages//media/image49.png" width="100" /></p>
<blockquote>
<p><strong>Fig.</strong> <strong>1.1</strong> Comparison of grid search and random search for minimizing a function with one important and one unimportant parameter. This ﬁgure is based on the illustration in Fig. 1 of <span id="_bookmark79" class="anchor"></span>Bergstra and Bengio [<a href="#_bookmark76">13</a>]</p>
<p><span id="_bookmark77" class="anchor"></span>1In some disciplines this is also known as <em>pure</em> random search <a href="#_bookmark80">[158</a>].</p>
<p>8 M. Feurer and F. Hutter</p>
<p>Further advantages over grid search include easier parallelization (since workers do not need to communicate with each other and failing workers do not leave holes in the design) and ﬂexible resource allocation (since one can add an arbitrary number of random points to a random search design to still yield a random search design; the equivalent does not hold for grid search).</p>
</blockquote>
<p>Random search is a useful baseline because it makes no assumptions on the machine learning algorithm being optimized, and, given enough resources, will, in expectation, achieves performance arbitrarily close to the optimum. Interleaving random search with more complex optimization strategies therefore allows to guarantee a minimal rate of convergence and also adds exploration that can improve model-based search [<a href="#_bookmark81">3</a>, <a href="#_bookmark82">59</a>]. Random search is also a useful method for initializing the search process, as it explores the entire conﬁguration space and thus often ﬁnds settings with reasonable performance. However, it is no silver bullet and often takes far longer than guided search methods to identify one of the best performing hyperparameter conﬁgurations: e.g., when sampling without replacement from a conﬁguration space with N Boolean hyperparameters with a good and a bad setting each and no interaction effects, it will require an expected 2N−1 function evaluations to ﬁnd the optimum, whereas a guided search could ﬁnd the optimum in N + 1 function evaluations as follows: starting from an arbitrary conﬁguration, loop over the hyperparameters and change one at a time, keeping the resulting conﬁguration if performance improves and reverting the change if it doesn’t. Accordingly, the guided search methods we discuss in the following sections usually outperform random search [<a href="#_bookmark45">12</a>, <a href="#_bookmark23">14</a>, <a href="#_bookmark50">33</a>, <a href="#_bookmark83">90</a>, <a href="#_bookmark84">153</a>].</p>
<p>Population-based methods, such as <em>genetic</em> <em>algorithms</em>, <em>evolutionary</em> <em>algorithms</em>, <em>evolutionary</em> <em>strategies</em>, and <em>particle</em> <em>swarm</em> <em>optimization</em> are optimization algo- rithms that maintain a population, i.e., a set of conﬁgurations, and improve this population by applying local perturbations (so-called mutations) and combinations of different members (so-called crossover) to obtain a new generation of better conﬁgurations. These methods are conceptually simple, can handle different data types, and are embarrassingly parallel [<a href="#_bookmark85">91</a>] since a population of N members can be evaluated in parallel on N machines.</p>
<p>One of the best known population-based methods is the covariance matrix adaption evolutionary strategy (CMA-ES [<a href="#_bookmark86">51</a>]); this simple evolutionary strategy samples conﬁgurations from a multivariate Gaussian whose mean and covariance are updated in each generation based on the success of the population’s individ- uals. CMA-ES is one of the most competitive blackbox optimization algorithms, regularly dominating the <em>Black-Box</em> <em>Optimization</em> <em>Benchmarking</em> (BBOB) chal- lenge [<a href="#_bookmark87">11</a>].</p>
<blockquote>
<p>For further details on population-based methods, we refer to [<a href="#_bookmark88">28</a>,<a href="#_bookmark89">138</a>]; we discuss applications to hyperparameter optimization in Sect.<a href="#_bookmark43">1.5</a>, applications to neural architecture search in Chap.<a href="#_bookmark4">3</a>, and genetic programming for AutoML pipelines in Chap.<a href="#_bookmark11">8</a>.</p>
<p>1 Hyperparameter Optimization 9</p>
</blockquote>
<p><em><strong>1.3.2</strong></em> <em><strong>Bayesian</strong></em> <em><strong>Optimization</strong></em></p>
<blockquote>
<p>Bayesian optimization is a state-of-the-art optimization framework for the global optimization of expensive blackbox functions, which recently gained traction in HPO by obtaining new state-of-the-art results in tuning deep neural networks for image classiﬁcation [<a href="#_bookmark22">140</a>, <a href="#_bookmark90">141</a>], speech recognition [<a href="#_bookmark91">22</a>] and neural language modeling [<a href="#_bookmark21">105</a>], and by demonstrating wide applicability to different problem settings. For an in-depth introduction to Bayesian optimization, we refer to the excellent tutorials by Shahriari et al. [<a href="#_bookmark92">135</a>] and Brochu et al. [<a href="#_bookmark93">18</a>].</p>
<p>In this section we ﬁrst give a brief introduction to Bayesian optimization, present alternative surrogate models used in it, describe extensions to conditional and constrained conﬁguration spaces, and then discuss several important applications to hyperparameter optimization.</p>
</blockquote>
<p>Many recent advances in Bayesian optimization do not treat HPO as a blackbox any more, for example multi-ﬁdelity HPO (see Sect.<a href="#_bookmark42">1.4</a>), Bayesian optimization with meta-learning (see Chap.<a href="#_bookmark3">2</a>), and Bayesian optimization taking the pipeline structure into account [<a href="#_bookmark94">159</a>, <a href="#_bookmark95">160</a>]. Furthermore, many recent developments in Bayesian optimization do not directly target HPO, but can often be readily applied to HPO, such as new acquisition functions, new models and kernels, and new parallelization schemes.</p>
<blockquote>
<p><strong>1.3.2.1</strong> <strong>Bayesian</strong> <strong>Optimization</strong> <strong>in</strong> <strong>a</strong> <strong>Nutshell</strong></p>
</blockquote>
<p>Bayesian optimization is an iterative algorithm with two key ingredients: a prob- abilistic surrogate model and an acquisition function to decide which point to evaluate next. In each iteration, the surrogate model is ﬁtted to all observations of the target function made so far. Then the acquisition function, which uses the predictive distribution of the probabilistic model, determines the utility of different candidate points, trading off exploration and exploitation. Compared to evaluating the expensive blackbox function, the acquisition function is cheap to compute and can therefore be thoroughly optimized.</p>
<blockquote>
<p>Although many acquisition functions exist, the <em>expected</em> <em>improvement</em> (EI) [<a href="#_bookmark96">72</a>]:</p>
</blockquote>
<p>E[I(<strong>λ</strong>)] = E[max(fmin − y, 0)] (1.2)</p>
<blockquote>
<p>is common choice since it can be computed in closed form if the model prediction y at conﬁguration <strong>λ</strong> follows a normal distribution:</p>
<p>E[I(<strong>λ</strong>)] = (fmin − μ(<strong>λ</strong>)) 免 ( <img src="./automlgithubpagesimages//media/image50.png" width="67" height="31" />) + σφ ( <img src="./automlgithubpagesimages//media/image51.png" width="67" height="31" />) , (1.3)</p>
<p>where φ(·) and 免( ·) are the standard normal density and standard normal distribu- tion function, and fmin is the best observed value so far.</p>
<p>Fig. <a href="#_bookmark97">1.2</a>illustrates Bayesian optimization optimizing a toy function.</p>
</blockquote>
<p><img src="./automlgithubpagesimages//media/image52.png" /></p>
<blockquote>
<p>10 M. Feurer and F. Hutter</p>
<p><span id="_bookmark98" class="anchor"></span><strong>1.3.2.2</strong> <strong>Surrogate</strong> <strong>Models</strong></p>
<p>Traditionally, Bayesian optimization employs Gaussian processes [<a href="#_bookmark99">124</a>] to model the target function because of their expressiveness, smooth and well-calibrated</p>
</blockquote>
<table>
<tbody>
<tr class="odd">
<td><img src="./automlgithubpagesimages//media/image53.png" width="443" height="112" /></td>
</tr>
</tbody>
</table>
<p><img src="./automlgithubpagesimages//media/image54.png" width="38" /></p>
<table>
<tbody>
<tr class="odd">
<td><img src="./automlgithubpagesimages//media/image55.png" width="443" height="121" /></td>
</tr>
</tbody>
</table>
<p><img src="./automlgithubpagesimages//media/image56.png" width="47" /></p>
<table>
<tbody>
<tr class="odd">
<td><img src="./automlgithubpagesimages//media/image57.png" width="443" height="121" /></td>
</tr>
</tbody>
</table>
<p><span id="_bookmark97" class="anchor"></span><strong>Fig.</strong> <strong>1.2</strong> Illustration of Bayesian optimization on a 1-d function. Our goal is to minimize the dashed line using a Gaussian process surrogate (predictions shown as black line, with blue tube representing the uncertainty) by maximizing the acquisition function represented by the lower orange curve. (Top) The acquisition value is low around observations, and the highest acquisition value is at a point where the predicted function value is low and the predictive uncertainty is relatively high. (Middle) While there is still a lot of variance to the left of the new observation, the predicted mean to the right is much lower and the next observation is conducted there. (Bottom) Although there is almost no uncertainty left around the location of the true maximum, the next evaluation is done there due to its expected improvement over the best point so far</p>
<blockquote>
<p>1 Hyperparameter Optimization 11</p>
<p>uncertainty estimates and closed-form computability of the predictive distribution. A Gaussian process G(m(<strong>λ</strong>), k(<strong>λ</strong> , <strong>λ</strong>\)) is fully speciﬁed by a mean m(<strong>λ</strong>) and a covariance function k(<strong>λ</strong> , <strong>λ</strong>\), although the mean function is usually assumed to be constant in Bayesian optimization. Mean and variance predictions μ( ·) and σ2 ( ·) for the noise-free case can be obtained by:</p>
</blockquote>
<p>μ(<strong>λ</strong>) = <strong>kK</strong>−1<strong>y</strong>, σ 2 (<strong>λ</strong>) = k(<strong>λ</strong> , <strong>λ</strong>) − <strong>kK</strong>−1<strong>k</strong>*, (1.4)</p>
<blockquote>
<p>where <strong>k</strong>* denotes the vector of covariances between <strong>λ</strong> and all previous observations, <strong>K</strong> is the covariance matrix of all previously evaluated conﬁgurations and <strong>y</strong> are the observed function values. The quality of the Gaussian process depends solely on the covariance function. A common choice is the Mátern 5/2 kernel, with its hyperparameters integrated out by Markov Chain Monte Carlo [<a href="#_bookmark22">140</a>].</p>
</blockquote>
<p>One downside of standard Gaussian processes is that they scale cubically in the number of data points, limiting their applicability when one can afford many function evaluations (e.g., with many parallel workers, or when function evaluations are cheap due to the use of lower ﬁdelities). This cubic scaling can be avoided by scalable Gaussian process approximations, such as sparse Gaussian processes. These approximate the full Gaussian process by using only a subset of the original dataset as <em>inducing</em> <em>points</em> to build the kernel matrix <strong>K</strong>. While they allowed Bayesian optimization with GPs to scale to tens of thousands of datapoints for optimizing the parameters of a randomized SAT solver [<a href="#_bookmark100">62</a>], there are criticism about the calibration of their uncertainty estimates and their applicability to standard HPO has not been tested [<a href="#_bookmark101">104</a>, <a href="#_bookmark102">154</a>].</p>
<p>Another downside of Gaussian processes with standard kernels is their poor scalability to high dimensions. As a result, many extensions have been proposed to efﬁciently handle intrinsic properties of conﬁguration spaces with large number of hyperparameters, such as the use of random embeddings [<a href="#_bookmark84">153</a>], using Gaussian processes on partitions of the conﬁguration space [<a href="#_bookmark102">154</a>], cylindric kernels [<a href="#_bookmark103">114</a>], and additive kernels [<a href="#_bookmark104">40</a>, <a href="#_bookmark105">75</a>].</p>
<blockquote>
<p>Since some other machine learning models are more scalable and ﬂexible than Gaussian processes, there is also a large body of research on adapting these models to Bayesian optimization. Firstly, (deep) neural networks are a very ﬂexible and scalable models. The simplest way to apply them to Bayesian optimization is as a feature extractor to preprocess inputs and then use the outputs of the ﬁnal hidden layer as basis functions for Bayesian linear regression [<a href="#_bookmark90">141</a>]. A more complex, fully Bayesian treatment of the network weights, is also possible by using a Bayesian neural network trained with stochastic gradient Hamiltonian Monte Carlo [<a href="#_bookmark106">144</a>]. Neural networks tend to be faster than Gaussian processes for Bayesian optimization after ∼250 function evaluations, which also allows for large-scale parallelism. The ﬂexibility of deep learning can also enable Bayesian optimization on more complex tasks. For example, a variational auto-encoder can be used to embed complex inputs (such as the structured conﬁgurations of the automated statistician, see Chap.<a href="#_bookmark12">9</a>) into a real-valued vector such that a regular Gaussian process can handle it [<a href="#_bookmark107">92</a>]. For multi-source Bayesian optimization, a neural network architecture built on</p>
<p>12 M. Feurer and F. Hutter</p>
</blockquote>
<p><em>factorization</em> <em>machines</em> [<a href="#_bookmark108">125</a>] can include information on previous tasks [<a href="#_bookmark109">131</a>] and has also been extended to tackle the CASH problem [<a href="#_bookmark110">132</a>].</p>
<blockquote>
<p>Another alternative model for Bayesian optimization are random forests [<a href="#_bookmark82">59</a>]. While GPs perform better than random forests on small, numerical conﬁguration spaces [<a href="#_bookmark111">29</a>], random forests natively handle larger, categorical and conditional conﬁguration spaces where standard GPs do not work well [<a href="#_bookmark111">29</a>, <a href="#_bookmark112">70</a>, <a href="#_bookmark83">90</a>]. Further- more, the computational complexity of random forests scales far better to many data points: while the computational complexity of ﬁtting and predicting variances with GPs for n data points scales as O(n3) and O(n2), respectively, for random forests, the scaling in n is only O(n log n) and O(log n), respectively. Due to these advantages, the SMAC framework for Bayesian optimization with random forests [<a href="#_bookmark82">59</a>] enabled the prominent AutoML frameworks Auto-WEKA [<a href="#_bookmark33">149</a>] and Auto-sklearn [<a href="#_bookmark48">34</a>] (which are described in Chaps.<a href="#_bookmark6">4</a> and <a href="#_bookmark8">6</a>).</p>
<p>Instead of modeling the probability p(<strong>y</strong>|<strong>λ</strong>) of observations <strong>y</strong> given the conﬁg- urations <strong>λ</strong>, the <em>Tree</em> <em>Parzen</em> <em>Estimator</em> (TPE [<a href="#_bookmark45">12</a>, <a href="#_bookmark23">14</a>]) models density functions p(<strong>λ</strong>|<strong>y</strong> &lt; α) and p(<strong>λ</strong>|<strong>y</strong> ≥ α). Given a percentile α (usually set to 15%), the observations are divided in good observations and bad observations and simple 1-d Parzen windows are used to model the two distributions. The ratio <img src="./automlgithubpagesimages//media/image58.png" width="41" height="22" /> is related to the expected improvement acquisition function and is used to propose new hyperparameter conﬁgurations. TPE uses a tree of Parzen estimators for conditional</p>
<p>hyperparameters and demonstrated good performance on such structured HPO tasks [<a href="#_bookmark45">12</a>, <a href="#_bookmark23">14</a>, <a href="#_bookmark111">29</a>, <a href="#_bookmark50">33</a>, <a href="#_bookmark113">143</a>, <a href="#_bookmark33">149</a>, <a href="#_bookmark95">160</a>], is conceptually simple, and parallelizes naturally [<a href="#_bookmark85">91</a>]. It is also the workhorse behind the AutoML framework Hyperopt- sklearn [<a href="#_bookmark49">83</a>] (which is described in Chap.<a href="#_bookmark7">5</a>).</p>
<p>Finally, we note that there are also surrogate-based approaches which do not follow the Bayesian optimization paradigm: Hord [<a href="#_bookmark114">67</a>] uses a deterministic RBF surrogate, and Harmonica [<a href="#_bookmark115">52</a>] uses a compressed sensing technique, both to tune the hyperparameters of deep neural networks.</p>
<p><strong>1.3.2.3</strong> <strong>Conﬁguration</strong> <strong>Space</strong> <strong>Description</strong></p>
<p>Bayesian optimization was originally designed to optimize box-constrained, real- valued functions. However, for many machine learning hyperparameters, such as the learning rate in neural networks or regularization in support vector machines, it is common to optimize the exponent of an exponential term to describe that changing it, e.g., from 0.001 to 0.01 is expected to have a similarly high impact as changing it from 0. 1 to 1. A technique known as <em>input</em> <em>warping</em> [<a href="#_bookmark116">142</a>] allows to automatically learn such transformations during the optimization process by replacing each input dimension with the two parameters of a Beta distribution and optimizing these.</p>
<p>One obvious limitation of the box-constraints is that the user needs to deﬁne these upfront. To avoid this, it is possible to dynamically expand the conﬁgura- tion space [<a href="#_bookmark46">113</a>, <a href="#_bookmark47">136</a>]. Alternatively, the estimation-of-distribution-style algorithm TPE [<a href="#_bookmark45">12</a>] is able to deal with inﬁnite spaces on which a (typically Gaussian) prior is placed.</p>
<p>1 Hyperparameter Optimization 13</p>
</blockquote>
<p>Integers and categorical hyperparameters require special treatment but can be integrated fairly easily into regular Bayesian optimization by small adaptations of the kernel and the optimization procedure (see Sect. 12. 1.2 of [<a href="#_bookmark117">58</a>], as well as [<a href="#_bookmark118">42</a>]). Other models, such as factorization machines and random forests, can also naturally handle these data types.</p>
<blockquote>
<p>Conditional hyperparameters are still an active area of research (see Chaps.<a href="#_bookmark7">5</a> and<a href="#_bookmark8">6</a>for depictions of conditional conﬁguration spaces in recent AutoML systems). They can be handled natively by tree-based methods, such as random forests [<a href="#_bookmark82">59</a>] and tree Parzen estimators (TPE) [<a href="#_bookmark45">12</a>], but due to the numerous advantages of Gaussian processes over other models, multiple kernels for structured conﬁguration spaces have also been proposed [<a href="#_bookmark60">4</a>, <a href="#_bookmark45">12</a>, <a href="#_bookmark119">63</a>, <a href="#_bookmark112">70</a>, <a href="#_bookmark107">92</a>, <a href="#_bookmark120">96</a>, <a href="#_bookmark121">146</a>].</p>
<p><span id="_bookmark72" class="anchor"></span><strong>1.3.2.4</strong> <strong>Constrained</strong> <strong>Bayesian</strong> <strong>Optimization</strong></p>
</blockquote>
<p>In realistic scenarios it is often necessary to satisfy constraints, such as memory consumption [<a href="#_bookmark122">139</a>, <a href="#_bookmark33">149</a>], training time [<a href="#_bookmark33">149</a>], prediction time [<a href="#_bookmark123">41</a>, <a href="#_bookmark124">43</a>], accuracy of a compressed model [<a href="#_bookmark123">41</a>], energy usage [<a href="#_bookmark124">43</a>] or simply to not fail during the training procedure [<a href="#_bookmark124">43</a>].</p>
<blockquote>
<p>Constraints can be <em>hidden</em> in that only a binary observation (success or failure) is available [<a href="#_bookmark125">88</a>]. Typical examples in AutoML are memory and time constraints to allow training of the algorithms in a shared computing system, and to make sure that a single slow algorithm conﬁguration does not use all the time available for HPO [<a href="#_bookmark48">34</a>, <a href="#_bookmark33">149</a>] (see also Chaps.<a href="#_bookmark6">4</a>and <a href="#_bookmark8">6</a>).</p>
<p>Constraints can also merely be <em>unknown</em>, meaning that we can observe and model an auxiliary constraint function, but only know about a constraint violation after evaluating the target function [<a href="#_bookmark126">46</a>]. An example of this is the prediction time of a support vector machine, which can only be obtained by training it as it depends on the number of support vectors selected during training.</p>
<p>The simplest approach to model violated constraints is to deﬁne a penalty value (at least as bad as the worst possible observable loss value) and use it as the observation for failed runs [<a href="#_bookmark48">34</a>, <a href="#_bookmark34">45</a>, <a href="#_bookmark82">59</a>, <a href="#_bookmark33">149</a>]. More advanced approaches model the probability of violating one or more constraints and actively search for conﬁgurations with low loss values that are unlikely to violate any of the given constraints [<a href="#_bookmark123">41</a>, <a href="#_bookmark124">43</a>, <a href="#_bookmark126">46</a>, <a href="#_bookmark125">88</a>].</p>
</blockquote>
<p>Bayesian optimization frameworks using information theoretic acquisition func- tions allow decoupling the evaluation of the target function and the constraints to dynamically choose which of them to evaluate next [<a href="#_bookmark124">43</a>, <a href="#_bookmark127">55</a>]. This becomes advantageous when evaluating the function of interest and the constraints require vastly different amounts of time, such as evaluating a deep neural network’s performance and memory consumption [<a href="#_bookmark124">43</a>].</p>
<blockquote>
<p>14 M. Feurer and F. Hutter</p>
<p><span id="_bookmark42" class="anchor"></span><strong>1.4</strong> <strong>Multi-ﬁdelity</strong> <strong>Optimization</strong></p>
</blockquote>
<p>Increasing dataset sizes and increasingly complex models are a major hurdle in HPO since they make blackbox performance evaluation more expensive. Training a single hyperparameter conﬁguration on large datasets can nowadays easily exceed several hours and take up to several days [<a href="#_bookmark128">85</a>].</p>
<p>A common technique to speed up manual tuning is therefore to probe an algorithm/hyperparameter conﬁguration on a small subset of the data, by training it only for a few iterations, by running it on a subset of features, by only using one or a few of the cross-validation folds, or by using down-sampled images in computer vision. Multi-ﬁdelity methods cast such manual heuristics into formal algorithms, using so-called low ﬁdelity approximations of the actual loss function to minimize. These approximations introduce a tradeoff between optimization performance and runtime, but in practice, the obtained speedups often outweigh the approximation error.</p>
<blockquote>
<p>First, we review methods which model an algorithm’s learning curve during training and can stop the training procedure if adding further resources is predicted to not help. Second, we discuss simple selection methods which only choose one of a ﬁnite set of given algorithms/hyperparameter conﬁgurations. Third, we discuss multi-ﬁdelity methods which can actively decide which ﬁdelity will provide most information about ﬁnding the optimal hyperparameters. We also refer to Chap.<a href="#_bookmark3">2</a> (which discusses how multi-ﬁdelity methods can be used across datasets) and Chap.<a href="#_bookmark4">3</a> (which describes low-ﬁdelity approximations for neural architecture search).</p>
</blockquote>
<p><em><strong>1.4.1</strong></em> <em><strong>Learning</strong></em> <em><strong>Curve-Based</strong></em> <em><strong>Predictionfor</strong></em> <em><strong>Early</strong></em> <em><strong>Stopping</strong></em></p>
<p>We start this section on multi-ﬁdelity methods in HPO with methods that evaluate and model learning curves during HPO [<a href="#_bookmark26">82</a>, <a href="#_bookmark129">123</a>] and then decide whether to add further resources or stop the training procedure for a given hyperparameter conﬁguration. Examples of learning curves are the performance of the same con- ﬁguration trained on increasing dataset subsets, or the performance of an iterative algorithm measured for each iteration (or every i -th iteration if the calculation of the performance is expensive).</p>
<blockquote>
<p>Learning curve extrapolation is used in the context of<em>predictive</em> <em>termination</em> [<a href="#_bookmark130">26</a>], where a learning curve model is used to extrapolate a partially observed learning curve for a conﬁguration, and the training process is stopped if the conﬁguration is predicted to not reach the performance of the best model trained so far in the optimization process. Each learning curve is modeled as a weighted combination of 11 parametric functions from various scientiﬁc areas. These functions’ parameters and their weights are sampled via Markov chain Monte Carlo to minimize the loss of ﬁtting the partially observed learning curve. This yields a predictive distribution,</p>
<p>1 Hyperparameter Optimization 15</p>
</blockquote>
<p>which allows to stop training based on the probability of not beating the best known model. When combined with Bayesian optimization, the predictive termination cri- terion enabled lower error rates than off-the-shelve blackbox Bayesian optimization for optimizing neural networks. On average, the method sped up the optimization by a factor of two and was able to ﬁnd a (then) state-of-the-art neural network for CIFAR- 10 (without data augmentation) [<a href="#_bookmark130">26</a>].</p>
<p>While the method above is limited by not sharing information across different hyperparameter conﬁgurations, this can be achieved by using the basis functions as the output layer of a Bayesian neural network [<a href="#_bookmark131">80</a>]. The parameters and weights of the basis functions, and thus the full learning curve, can thereby be predicted for arbitrary hyperparameter conﬁgurations. Alternatively, it is possible to use previous learning curves as basis function extrapolators [<a href="#_bookmark132">21</a>]. While the experimental results are inconclusive on whether the proposed method is superior to pre-speciﬁed parametric functions, not having to manually deﬁne them is a clear advantage.</p>
<blockquote>
<p><em>Freeze-Thaw</em> Bayesian optimization [<a href="#_bookmark133">148</a>] is a full integration of learning curves into the modeling and selection process of Bayesian optimization. Instead of terminating a conﬁguration, the machine learning models are trained iteratively for a few iterations and then<em>frozen</em>. Bayesian optimization can then decide to <em>thaw</em> one of the frozen models, which means to continue training it. Alternatively, the method can also decide to start a new conﬁguration. Freeze-Thaw models the performance of a converged algorithm with a regular Gaussian process and introduces a special covariance function corresponding to exponentially decaying functions to model the learning curves with per-learning curve Gaussian processes.</p>
</blockquote>
<p><span id="_bookmark134" class="anchor"></span><em><strong>1.4.2</strong></em> <em><strong>Bandit-Based</strong></em> <em><strong>Algorithm</strong></em> <em><strong>Selection</strong></em> <em><strong>Methods</strong></em></p>
<blockquote>
<p>In this section, we describe methods that try to determine the best algorithm out of a given ﬁnite set of algorithms based on low-ﬁdelity approximations of their performance; towards its end, we also discuss potential combinations with adaptive conﬁguration strategies. We focus on variants of the bandit-based strategies <em>successive</em> <em>halving</em> and <em>Hyperband</em>, since these have shown strong performance, especially for optimizing deep learning algorithms. Strictly speaking, some of the methods which we will discuss in this subsection also model learning curves, but they provide no means of selecting new conﬁgurations based on these models.</p>
<p>First, however, we brieﬂy describe the historical evolution of multi-ﬁdelity algorithm selection methods. In 2000, Petrak [<a href="#_bookmark135">120</a>] noted that simply testing various algorithms on a small subset of the data is a powerful and cheap mechanism to select an algorithm. Later approaches used iterative algorithm elimination schemes to drop hyperparameter conﬁgurations if they perform badly on subsets of the data [<a href="#_bookmark136">17</a>], if they perform signiﬁcantly worse than a group of top-performing conﬁgurations [<a href="#_bookmark137">86</a>], if they perform worse than the best conﬁguration by a user- speciﬁed factor [<a href="#_bookmark113">143</a>], or if even an optimistic performance bound for an algorithm is worse than the best known algorithm [<a href="#_bookmark138">128</a>]. Likewise, it is possible to drop</p>
</blockquote>
<p><img src="./automlgithubpagesimages//media/image12.jpeg" width="136" /></p>
<blockquote>
<p>16 M. Feurer and F. Hutter</p>
<p>hyperparameter conﬁgurations if they perform badly on one or a few cross- validation folds [<a href="#_bookmark33">149</a>]. Finally, Jamieson and Talwalkar [<a href="#_bookmark139">69</a>] proposed to use the <em>successive</em> <em>halving</em> algorithm originally introduced by Karnin et al. [<a href="#_bookmark140">76</a>] for HPO.</p>
</blockquote>
<p><img src="./automlgithubpagesimages//media/image65.png" width="34" height="9" /></p>
<blockquote>
<p><span id="_bookmark141" class="anchor"></span><strong>Fig.</strong> <strong>1.3</strong> Illustration of successive halving for eight algorithms/conﬁgurations. After evaluating all algorithms on 1<img src="./automlgithubpagesimages//media/image66.jpeg" />8 of the total budget, half of them are dropped and the budget given to the remaining algorithms is doubled</p>
</blockquote>
<p><em>Successive</em> <em>halving</em> is an extremely simple, yet powerful, and therefore popular strategy for multi-ﬁdelity algorithm selection: for a given initial budget, query all algorithms for that budget; then, remove the half that performed worst, double the budget <a href="#_bookmark142">2</a> and successively repeat until only a single algorithm is left. This process is illustrated in Fig.<a href="#_bookmark141">1.3</a>. Jamieson and Talwalkar [<a href="#_bookmark139">69</a>] benchmarked several common bandit methods and found that successive halving performs well both in terms of the number of required iterations and in the required computation time, that the algorithm theoretically outperforms a uniform budget allocation strategy if the algorithms converge favorably, and that it is preferable to many well-known bandit strategies from the literature, such as <em>UCB</em> and <em>EXP3</em>.</p>
<p>While successive halving is an efﬁcient approach, it suffers from the budget- vs-number of conﬁgurations trade off. Given a total budget, the user has to decide beforehand whether to try many conﬁgurations and only assign a small budget to each, or to try only a few and assign them a larger budget. Assigning too small a budget can result in prematurely terminating good conﬁgurations, while assigning too large a budget can result in running poor conﬁgurations too long and thereby <span id="_bookmark142" class="anchor"></span>wasting resources.</p>
<blockquote>
<p>2More precisely, drop the worst fraction <img src="./automlgithubpagesimages//media/image67.png" width="15" height="17" /> of algorithms and multiply the budget for the remaining algorithms by η, where η is a hyperparameter. Its default value was changed from 2 to 3 with the introduction of HyperBand [<a href="#_bookmark83">90</a>].</p>
<p>1 Hyperparameter Optimization 17</p>
</blockquote>
<p>HyperBand [<a href="#_bookmark83">90</a>] is a hedging strategy designed to combat this problem when selecting from randomly sampled conﬁgurations. It divides the total budget into several combinations of number of conﬁgurations vs. budget for each, to then call successive halving as a subroutine on each set of random conﬁgurations. Due to the hedging strategy which includes running some conﬁgurations only on the maximal budget, in the worst case, HyperBand takes at most a constant factor more time than vanilla random search on the maximal budget. In practice, due to its use of cheap low-ﬁdelity evaluations, HyperBand has been shown to improve over vanilla random search and blackbox Bayesian optimization for data subsets, feature subsets and iterative algorithms, such as stochastic gradient descent for deep neural networks.</p>
<p>Despite HyperBand’s success for deep neural networks it is very limiting to not adapt the conﬁguration proposal strategy to the function evaluations. To overcome this limitation, the recent approach BOHB [<a href="#_bookmark50">33</a>] combines Bayesian optimization and HyperBand to achieve the best of both worlds: strong anytime performance (quick improvements in the beginning by using low ﬁdelities in HyperBand) and strong ﬁnal performance (good performance in the long run by replacing HyperBand’s random search by Bayesian optimization). BOHB also uses parallel resources effectively and deals with problem domains ranging from a few to many dozen hyperparameters. BOHB’s Bayesian optimization component resembles TPE [<a href="#_bookmark45">12</a>], but differs by using multidimensional kernel density estimators. It only ﬁts a model on the highest ﬁdelity for which at least |<strong>A</strong>| + 1 evaluations have been performed (the number of hyperparameters, plus one). BOHB’s ﬁrst model is therefore ﬁtted on the lowest ﬁdelity, and over time models trained on higher ﬁdelities take over, while still using the lower ﬁdelities in successive halving. Empirically, BOHB was shown to outperform several state-of-the-art HPO methods for tuning support vector machines, neural networks and reinforcement learning algorithms, including most methods presented in this section [<a href="#_bookmark50">33</a>]. Further approaches to combine HyperBand and Bayesian optimization have also been proposed [<a href="#_bookmark143">15</a>, <a href="#_bookmark144">151</a>].</p>
<p>Multiple ﬁdelity evaluations can also be combined with HPO in other ways. Instead of switching between lower ﬁdelities and the highest ﬁdelity, it is possible to perform HPO on a subset of the original data and extract the best-performing con- ﬁgurations in order to use them as an initial design for HPO on the full dataset [<a href="#_bookmark145">152</a>]. To speed up solutions to the CASH problem, it is also possible to iteratively remove entire algorithms (and their hyperparameters) from the conﬁguration space based on poor performance on small dataset subsets [<a href="#_bookmark94">159</a>].</p>
<p><em><strong>1.4.3</strong></em> <em><strong>Adaptive</strong></em> <em><strong>Choices</strong></em> <em><strong>of</strong></em> <em><strong>Fidelities</strong></em></p>
<blockquote>
<p>All methods in the previous subsection follow a predeﬁned schedule for the ﬁdelities. Alternatively, one might want to actively choose which ﬁdelities to evaluate given previous observations to prevent a misspeciﬁcation of the schedule.</p>
<p>18 M. Feurer and F. Hutter</p>
</blockquote>
<p>Multi-task Bayesian optimization [<a href="#_bookmark55">147</a>] uses a multi-task Gaussian process to model the performance of related tasks and to automatically learn the tasks’ correlation during the optimization process. This method can dynamically switch between cheaper, low-ﬁdelity tasks and the expensive, high-ﬁdelity target task based on a cost-aware information-theoretic acquisition function. In practice, the proposed method starts exploring the conﬁguration space on the cheaper task and only switches to the more expensive conﬁguration space in later parts of the optimization, approximately halving the time required for HPO. Multi-task Bayesian optimization can also be used to transfer information from previous optimization tasks, and we refer to Chap.<a href="#_bookmark3">2</a> for further details.</p>
<blockquote>
<p>Multi-task Bayesian optimization (and the methods presented in the previous subsection) requires an upfront speciﬁcation of a set of ﬁdelities. This can be suboptimal since these can be misspeciﬁed [<a href="#_bookmark146">74</a>, <a href="#_bookmark53">78</a>] and because the number of ﬁdelities that can be handled is low (usually ﬁve or less). Therefore, and in order to exploit the typically smooth dependence on the ﬁdelity (such as, e.g., size of the data subset used), it often yields better results to treat the ﬁdelity as continuous (and, e.g., choose a continuous percentage of the full data set to evaluate a conﬁguration on), trading off the information gain and the time required for evaluation [<a href="#_bookmark53">78</a>]. To exploit the domain knowledge that performance typically improves with more data, with diminishing returns, a special kernel can be constructed for the data subsets [<a href="#_bookmark53">78</a>]. This generalization of multi-task Bayesian optimization improves performance and can achieve a 10– 100 fold speedup compared to blackbox Bayesian optimization.</p>
</blockquote>
<p>Instead of using an information-theoretic acquisition function, Bayesian opti- mization with the <em>Upper</em> <em>Conﬁdence</em> <em>Bound</em> (UCB) acquisition function can also be extended to multiple ﬁdelities [<a href="#_bookmark147">73</a>, <a href="#_bookmark146">74</a>]. While the ﬁrst such approach, MF- GP-UCB [<a href="#_bookmark147">73</a>], required upfront ﬁdelity deﬁnitions, the later BOCA algorithm [<a href="#_bookmark146">74</a>] dropped that requirement. BOCA has also been applied to optimization with more than one continuous ﬁdelity, and we expect HPO for more than one continuous ﬁdelity to be of further interest in the future.</p>
<blockquote>
<p>Generally speaking, methods that can adaptively choose their ﬁdelity are very appealing and more powerful than the conceptually simpler bandit-based methods discussed in Sect.<a href="#_bookmark134">1.4.2</a>, but in practice we caution that strong models are required to make successful choices about the ﬁdelities. When the models are not strong (since they do not have enough training data yet, or due to model mismatch), these methods may spend too much time evaluating higher ﬁdelities, and the more robust ﬁxed budget schedules discussed in Sect.<a href="#_bookmark134">1.4.2</a>might yield better performance given a ﬁxed time limit.</p>
<p><span id="_bookmark43" class="anchor"></span><strong>1.5</strong> <strong>Applications</strong> <strong>to</strong> <strong>AutoML</strong></p>
<p>In this section, we provide a historical overview of the most important hyperparam- eter optimization systems and applications to automated machine learning.</p>
<p>1 Hyperparameter Optimization 19</p>
<p>Grid search has been used for hyperparameter optimization since the 1990s [<a href="#_bookmark148">71</a>, <a href="#_bookmark27">107</a>] and was already supported by early machine learning tools in 2002 [<a href="#_bookmark149">35</a>]. The ﬁrst adaptive optimization methods applied to HPO were greedy depth-ﬁrst search [<a href="#_bookmark26">82</a>] and pattern search [<a href="#_bookmark59">109</a>], both improving over default hyperparam- eter conﬁgurations, and pattern search improving over grid search, too. Genetic algorithms were ﬁrst applied to tuning the two hyperparameters C and γ of an RBF- SVM in 2004 [<a href="#_bookmark150">119</a>] and resulted in improved classiﬁcation performance in less time than grid search. In the same year, an evolutionary algorithm was used to learn a composition of three different kernels for an SVM, the kernel hyperparameters and to jointly select a feature subset; the learned combination of kernels was able to outperform every single optimized kernel. Similar in spirit, also in 2004, a genetic algorithm was used to select both the features used by and the hyperparameters of either an SVM or a neural network [<a href="#_bookmark151">129</a>].</p>
<p>CMA-ES was ﬁrst used for hyperparameter optimization in 2005 [<a href="#_bookmark152">38</a>], in that case to optimize an SVM’s hyperparameters C and γ , a kernel lengthscale li for each dimension of the input data, and a complete rotation and scaling matrix. Much more recently, CMA-ES has been demonstrated to be an excellent choice for parallel HPO, outperforming state-of-the-art Bayesian optimization tools when optimizing 19 hyperparameters of a deep neural network on 30 GPUs in parallel [<a href="#_bookmark85">91</a>].</p>
</blockquote>
<p>In 2009, Escalante et al. [<a href="#_bookmark29">30</a>] extended the HPO problem to the <em>Full</em> <em>Model</em> <em>Selection</em> problem, which includes selecting a preprocessing algorithm, a feature selection algorithm, a classiﬁer and all their hyperparameters. By being able to construct a machine learning pipeline from multiple off-the-shelf machine learning algorithms using HPO, the authors empirically found that they can apply their method to any data set as no domain knowledge is required, and demonstrated the applicability of their approach to a variety of domains [<a href="#_bookmark153">32</a>, <a href="#_bookmark154">49</a>]. Their proposed method, particle swarm model selection (PSMS), uses a modiﬁed particle swarm optimizer to handle the conditional conﬁguration space. To avoid overﬁtting, PSMS was extended with a custom ensembling strategy which combined the best solutions from multiple generations [<a href="#_bookmark62">31</a>]. Since particle swarm optimization was originally designed to work on continuous conﬁguration spaces, PSMS was later also extended to use a genetic algorithm to optimize the pipeline structure and only use particle swarm optimization to optimize the hyperparameters of each pipeline [<a href="#_bookmark155">145</a>].</p>
<p>To the best of our knowledge, the ﬁrst application of Bayesian optimization to HPO dates back to 2005, when Frohlich and Zell [<a href="#_bookmark156">39</a>] used an online Gaussian process together with EI to optimize the hyperparameters of an SVM, achieving speedups of factor 10 (classiﬁcation, 2 hyperparameters) and 100 (regression, 3 hyperparameters) over grid search. Tuned Data Mining [<a href="#_bookmark157">84</a>] proposed to tune the hyperparameters of a full machine learning pipeline using Bayesian optimization; speciﬁcally, this used a single ﬁxed pipeline and tuned the hyperparameters of the classiﬁer as well as the per-class classiﬁcation threshold and class weights.</p>
<blockquote>
<p>In 2011, Bergstra et al. [<a href="#_bookmark45">12</a>] were the ﬁrst to apply Bayesian optimization to tune the hyperparameters of a deep neural network, outperforming both manual and random search. Furthermore, they demonstrated that TPE resulted in better</p>
<p>20 M. Feurer and F. Hutter</p>
<p>performance than a Gaussian process-based approach. TPE, as well as Bayesian optimization with random forests, were also successful for joint neural architecture search and hyperparameter optimization [<a href="#_bookmark23">14</a>, <a href="#_bookmark158">106</a>].</p>
</blockquote>
<p>Another important step in applying Bayesian optimization to HPO was made by Snoek et al. in the 2012 paper <em>Practical</em> <em>Bayesian</em> <em>Optimization</em> <em>of</em> <em>Machine</em> <em>Learning</em> <em>Algorithms</em> [<a href="#_bookmark22">140</a>], which describes several tricks of the trade for Gaussian process- based HPO implemented in the Spearmint system and obtained a new state-of-the- art result for hyperparameter optimization of deep neural networks.</p>
<blockquote>
<p>Independently of the Full Model Selection paradigm, Auto-WEKA [<a href="#_bookmark33">149</a>] (see also Chap.<a href="#_bookmark6">4</a>) introduced the <em>Combined</em> <em>Algorithm</em> <em>Selection</em> <em>and</em> <em>Hyperparameter</em> <em>Optimization</em> (CASH) problem, in which the choice of a classiﬁcation algorithm is modeled as a categorical variable, the algorithm hyperparameters are modeled as conditional hyperparameters, and the random-forest based Bayesian optimization system SMAC [<a href="#_bookmark82">59</a>] is used for joint optimization in the resulting 786-dimensional conﬁguration space.</p>
<p>In recent years, multi-ﬁdelity methods have become very popular, especially in deep learning. Firstly, using low-ﬁdelity approximations based on data subsets, feature subsets and short runs of iterative algorithms, Hyperband [<a href="#_bookmark83">90</a>] was shown to outperform blackbox Bayesian optimization methods that did not take these lower ﬁdelities into account. Finally, most recently, in the 2018 paper <em>BOHB:</em> <em>Robust</em> <em>and</em> <em>Efﬁcient</em> <em>Hyperparameter</em> <em>Optimization</em> <em>at</em> <em>Scale</em>, Falkner et al. [<a href="#_bookmark50">33</a>] introduced a robust, ﬂexible, and parallelizable combination of Bayesian optimiza- tion and Hyperband that substantially outperformed both Hyperband and blackbox Bayesian optimization for a wide range of problems, including tuning support vector machines, various types of neural networks, and reinforcement learning algorithms.</p>
<p>At the time of writing, we make the following recommendations for which tools we would use in practical applications of HPO:</p>
<p>• If multiple ﬁdelities are applicable (i.e., if it is possible to deﬁne substantially cheaper versions of the objective function of interest, such that the performance for these roughly correlates with the performance for the full objective function of interest), we recommend BOHB [<a href="#_bookmark50">33</a>] as a robust, efﬁcient, versatile, and parallelizable default hyperparameter optimization method.</p>
<p>• If multiple ﬁdelities are not applicable:</p>
<p>– If all hyperparameters are real-valued and one can only afford a few dozen function evaluations, we recommend the use of a Gaussian process-based Bayesian optimization tool, such as Spearmint [<a href="#_bookmark22">140</a>].</p>
<p>– For large and conditional conﬁguration spaces we suggest either the random forest-based SMAC [<a href="#_bookmark82">59</a>] or TPE [<a href="#_bookmark23">14</a>], due to their proven strong performance on such tasks [<a href="#_bookmark111">29</a>].</p>
<p>– For purely real-valued spaces and relatively cheap objective functions, for which one can afford more than hundreds of evaluations, we recommend CMA-ES [<a href="#_bookmark86">51</a>].</p>
<p>1 Hyperparameter Optimization 21</p>
<p><span id="_bookmark44" class="anchor"></span><strong>1.6</strong> <strong>Open</strong> <strong>Problems</strong> <strong>and</strong> <strong>Future</strong> <strong>Research</strong> <strong>Directions</strong></p>
</blockquote>
<p>We conclude this chapter with a discussion of open problems, current research questions and potential further developments we expect to have an impact on HPO in the future. Notably, despite their relevance, we leave out discussions on hyperparameter importance and conﬁguration space deﬁnition as these fall under the umbrella of meta-learning and can be found in Chap.<a href="#_bookmark3">2</a>.</p>
<p><em><strong>1.6.1</strong></em> <em><strong>Benchmarks</strong></em> <em><strong>and</strong></em> <em><strong>Comparability</strong></em></p>
<p>Given the breadth of existing HPO methods, a natural question is what are the strengths and weaknesses of each of them. In order to allow for a fair com- parison between different HPO approaches, the community needs to design and agree upon a common set of benchmarks that expands over time, as new HPO variants, such as multi-ﬁdelity optimization, emerge. As a particular example for what this could look like we would like to mention the COCO platform (short for comparing continuous optimizers), which provides benchmark and analysis tools for continuous optimization and is used as a workbench for the yearly Black-Box Optimization Benchmarking (BBOB) challenge [<a href="#_bookmark87">11</a>]. Efforts along similar lines in HPO have already yielded the hyperparameter optimization library (HPOlib [<a href="#_bookmark111">29</a>]) and a benchmark collection speciﬁcally for Bayesian optimization methods [<a href="#_bookmark159">25</a>]. However, neither of these has gained similar traction as the COCO platform.</p>
<p>Additionaly, the community needs clearly deﬁned metrics, but currently different works use different metrics. One important dimension in which evaluations differ is whether they report performance on the validation set used for optimization or on a separate test set. The former helps to study the strength of the optimizer in isolation, without the noise that is added in the evaluation when going from validation to test set; on the other hand, some optimizers may lead to more overﬁtting than others, which can only be diagnosed by using the test set. Another important dimension in which evaluations differ is whether they report perfor- mance after a given number of function evaluations or after a given amount of time. The latter accounts for the difference in time between evaluating different hyperparameter conﬁgurations and includes optimization overheads, and therefore reﬂects what is required in practice; however, the former is more convenient and aids reproducibility by yielding the same results irrespective of the hardware used. To aid reproducibility, especially studies that use time should therefore release an implementation.</p>
<blockquote>
<p>We note that it is important to compare against strong baselines when using new benchmarks, which is another reason why HPO methods should be published with an accompanying implementation. Unfortunately, there is no common software library as is, for example, available in deep learning research that implements all</p>
<p>22 M. Feurer and F. Hutter</p>
</blockquote>
<p>the basic building blocks [<a href="#_bookmark160">2</a>, <a href="#_bookmark161">117</a>]. As a simple, yet effective baseline that can be trivially included in empirical studies, Jamieson and Recht [<a href="#_bookmark162">68</a>] suggest to compare against different parallelization levels of random search to demonstrate the speedups over regular random search. When comparing to other optimization techniques it is important to compare against a solid implementation, since, e.g., simpler versions of Bayesian optimization have been shown to yield inferior performance [<a href="#_bookmark163">79</a>, <a href="#_bookmark22">140</a>, <a href="#_bookmark116">142</a>].</p>
<p><em><strong>1.6.2</strong></em> <em><strong>Gradient-Based</strong></em> <em><strong>Optimization</strong></em></p>
<blockquote>
<p>In some cases (e.g., least-squares support vector machines and neural networks) it is possible to obtain the gradient of the model selection criterion with respect to some of the model hyperparameters. Different to blackbox HPO, in this case each evaluation of the target function results in an entire hypergradient vector instead of</p>
<p>a single ﬂoat value, allowing for faster HPO.</p>
</blockquote>
<p>Maclaurin et al. [<a href="#_bookmark164">99</a>] described a procedure to compute the exact gradients of validation performance with respect to all continuous hyperparameters of a neural network by backpropagating through the entire training procedure of stochastic gradient descent with momentum (using a novel, memory-efﬁcient algorithm). Being able to handle many hyperparameters efﬁciently through gradient-based methods allows for a new paradigm of hyperparametrizing the model to obtain ﬂexibility over model classes, regularization, and training methods. Maclaurin et al. demonstrated the applicability of gradient-based HPO to many high-dimensional HPO problems, such as optimizing the learning rate of a neural network for each iteration and layer separately, optimizing the weight initialization scale hyperpa- rameter for each layer in a neural network, optimizing the l2 penalty for each individual parameter in logistic regression, and learning completely new training datasets. As a small downside, backpropagating through the entire training proce- dure comes at the price of doubling the time complexity of the training procedure. The described method can also be generalized to work with other parameter update algorithms [<a href="#_bookmark165">36</a>]. To overcome the necessity of backpropagating through the complete training procedure, later work allows to perform hyperparameter updates with respect to a separate validation set interleaved with the training process [<a href="#_bookmark166">5</a>, <a href="#_bookmark167">10</a>, <a href="#_bookmark165">36</a>, <a href="#_bookmark168">37</a>, <a href="#_bookmark169">93</a>].</p>
<blockquote>
<p>Recent examples of gradient-based optimization of simple model’s hyperparam- eters [<a href="#_bookmark170">118</a>] and of neural network structures (see Chap. <a href="#_bookmark4">3</a>) show promising results, outperforming state-of-the-art Bayesian optimization models. Despite being highly model-speciﬁc, the fact that gradient-based hyperparemeter optimization allows tuning several hundreds of hyperparameters could allow substantial improvements</p>
<p>in HPO.</p>
</blockquote>
<p><img src="./automlgithubpagesimages//media/image12.jpeg" width="136" /></p>
<blockquote>
<p>1 Hyperparameter Optimization 23</p>
<p><em><strong>1.6.3</strong></em> <em><strong>Scalability</strong></em></p>
<p>Despite recent successes in multi-ﬁdelity optimization, there are still machine learning problems which have not been directly tackled by HPO due to their scale, and which might require novel approaches. Here, scale can mean both the size of the conﬁguration space and the expense of individual model evaluations. For example, there has not been any work on HPO for deep neural networks on the ImageNet challenge dataset [<a href="#_bookmark171">127</a>] yet, mostly because of the high cost of training even a simple neural network on the dataset. It will be interesting to see whether methods going beyond the blackbox view from Sect.<a href="#_bookmark41">1.3</a>, such as the multi-ﬁdelity methods described in Sect.<a href="#_bookmark42">1.4</a>, gradient-based methods, or meta-learning methods (described in Chap.<a href="#_bookmark3">2</a>) allow to tackle such problems. Chap. <a href="#_bookmark4">3</a> describes ﬁrst successes in learning neural network building blocks on smaller datasets and applying them to ImageNet, but the hyperparameters of the training procedure are still set manually.</p>
</blockquote>
<p>Given the necessity of parallel computing, we are looking forward to new methods that fully exploit large-scale compute clusters. While there exists much work on parallel Bayesian optimization [<a href="#_bookmark45">12</a>, <a href="#_bookmark172">24</a>, <a href="#_bookmark50">33</a>, <a href="#_bookmark173">44</a>, <a href="#_bookmark174">54</a>, <a href="#_bookmark175">60</a>, <a href="#_bookmark92">135</a>, <a href="#_bookmark22">140</a>], except for the neural networks described in Sect.<a href="#_bookmark98">1.3.2.2</a> [<a href="#_bookmark90">141</a>], so far no method has demonstrated scalability to hundreds of workers. Despite their popularity, and with a single exception of HPO applied to deep neural networks [<a href="#_bookmark85">91</a>],<a href="#_bookmark176">3</a> population- based approaches have not yet been shown to be applicable to hyperparameter optimization on datasets larger than a few thousand data points.</p>
<p>Overall, we expect that more sophisticated and specialized methods, leaving the blackbox view behind, will be needed to further scale hyperparameter to interesting problems.</p>
<blockquote>
<p><em><strong>1.6.4</strong></em> <em><strong>Overﬁtting</strong></em> <em><strong>and</strong></em> <em><strong>Generalization</strong></em></p>
<p>An open problem in HPO is overﬁtting. As noted in the problem statement (see Sect.<a href="#_bookmark40">1.2</a>), we usually only have a ﬁnite number of data points available for calculating the validation loss to be optimized and thereby do not necessarily optimize for generalization to unseen test datapoints. Similarly to overﬁtting a machine learning algorithm to training data, this problem is about overﬁtting the hyperparameters to the ﬁnite validation set; this was also demonstrated to happen experimentally [<a href="#_bookmark177">20</a>, <a href="#_bookmark178">81</a>].</p>
<p>A simple strategy to reduce the amount of overﬁtting is to employ a different shufﬂing of the train and validation split for each function evaluation; this was shown to improve generalization performance for SVM tuning, both with a holdout and a cross-validation strategy [<a href="#_bookmark179">95</a>]. The selection of the ﬁnal conﬁguration can</p>
<p>3 See also Chap. <a href="#_bookmark4">3</a> where population-based methods are applied to Neural Architecture Search <span id="_bookmark176" class="anchor"></span>problems.</p>
<p>24 M. Feurer and F. Hutter</p>
</blockquote>
<p>be further robustiﬁed by not choosing it according to the lowest observed value, but according to the lowest predictive mean of the Gaussian process model used in Bayesian optimization [<a href="#_bookmark179">95</a>].</p>
<blockquote>
<p>Another possibility is to use a separate holdout set to assess conﬁgurations found by HPO to avoid bias towards the standard validation set [<a href="#_bookmark180">108</a>, <a href="#_bookmark94">159</a>]. Different approximations of the generalization performance can lead to different test performances [<a href="#_bookmark180">108</a>], and there have been reports that several resampling strategies can result in measurable performance differences for HPO of support vector machines [<a href="#_bookmark181">150</a>].</p>
</blockquote>
<p>A different approach to combat overﬁtting might be to ﬁnd <em>stable</em> <em>optima</em> instead of <em>sharp</em> <em>optima</em> of the objective function [<a href="#_bookmark182">112</a>]. The idea is that for stable optima, the function value around an optimum does not change for slight perturbations of the hyperparameters, whereas it <em>does</em> change for sharp optima. Stable optima lead to better generalization when applying the found hyperparameters to a new, unseen set of datapoints (i.e., the test set). An acquisition function built around this was shown to only slightly overﬁt for support vector machine HPO, while regular Bayesian optimization exhibited strong overﬁtting [<a href="#_bookmark182">112</a>].</p>
<p>Further approaches to combat overﬁtting are the ensemble methods and Bayesian methods presented in Sect.<a href="#_bookmark57">1.2.1</a>. Given all these different techniques, there is no commonly agreed-upon technique for how to best avoid overﬁtting, though, and it remains up to the user to ﬁnd out which strategy performs best on their particular HPO problem. We note that the best strategy might actually vary across HPO problems.</p>
<p><em><strong>1.6.5</strong></em> <em><strong>Arbitrary-Size</strong></em> <em><strong>Pipeline</strong></em> <em><strong>Construction</strong></em></p>
<blockquote>
<p>All HPO techniques we discussed so far assume a ﬁnite set of components for machine learning pipelines or a ﬁnite maximum number of layers in neural networks. For machine learning pipelines (see the AutoML systems covered in Part <a href="#_bookmark5">II</a> of this book) it might be helpful to use more than one feature preprocessing algorithm and dynamically add them if necessary for a problem, enlarging the search space by a hyperparameter to select an appropriate preprocessing algorithm and its own hyperparameters. While a search space for standard blackbox optimization tools could easily include several extra such preprocessors (and their hyperparame- ters) as conditional hyperparameters, an unbounded number of these would be hard to support.</p>
<p>One approach for handling arbitrary-sized pipelines more natively is the tree- structured pipeline optimization toolkit (TPOT [<a href="#_bookmark183">115</a>], see also Chap.<a href="#_bookmark11">8</a>), which uses genetic programming and describes possible pipelines by a grammar. TPOT uses multi-objective optimization to trade off pipeline complexity with performance to avoid generating unnecessarily complex pipelines.</p>
<p>1 Hyperparameter Optimization 25</p>
</blockquote>
<p>A different pipeline creation paradigm is the usage of hierarchical planning; the recent ML-Plan [<a href="#_bookmark184">101</a>, <a href="#_bookmark180">108</a>] uses hierarchical task networks and shows competitive performance compared to Auto-WEKA [<a href="#_bookmark33">149</a>] and Auto-sklearn [<a href="#_bookmark48">34</a>].</p>
<p>So far these approaches are not consistently outperforming AutoML systems with a ﬁxed pipeline length, but larger pipelines may provide more improvement. Similarly, neural architecture search yields complex conﬁguration spaces and we refer to Chap.<a href="#_bookmark4">3</a>for a description of methods to tackle them.</p>
<p><strong>Acknowledgements</strong> We would like to thank Luca Franceschi, Raghu Rajan, Stefan Falkner and Arlind Kadra for valuable feedback on the manuscript.</p>
<blockquote>
<p><span id="_bookmark185" class="anchor"><span id="_bookmark160" class="anchor"></span></span><strong>Bibliography</strong></p>
<p>1. Proceedings of the International Conference on Learning Representations (ICLR’18) (2018), published online: <a href="www.iclr.cc">iclr.cc</a></p>
<p>2. Abadi, M., Agarwal, A., Barham, P., Brevdo, E., Chen, Z., Citro, C., Corrado, G., Davis, A., Dean, J., Devin, M., Ghemawat, S., Goodfellow, I., Harp, A., Irving, G., Isard, M., Jia, Y., Jozefowicz, R., Kaiser, L., Kudlur, M., Levenberg, J., Mané, D., Monga, R., Moore, S., Murray, D., Olah, C., Schuster, M., Shlens, J., Steiner, B., Sutskever, I., Talwar, K., Tucker, P., Vanhoucke, V., Vasudevan, V., Viégas, F., Vinyals, O., Warden, P., Wattenberg, M., Wicke, M., Yu, Y., Zheng, X.: TensorFlow: Large-scale machine learning on heterogeneous systems</p>
<p><span id="_bookmark81" class="anchor"></span>(2015), <a href="https://www.tensorflow.org/">https://www.tensorﬂow.org/</a></p>
<p>3. Ahmed, M., Shahriari, B., Schmidt, M.: Do we need “harmless” Bayesian optimization and “ﬁrst-order” Bayesian optimization. In: NeurIPS Workshop on Bayesian Optimization <span id="_bookmark60" class="anchor"></span>(BayesOpt’16) (2016)</p>
<p>4. Alaa, A., van der Schaar, M.: AutoPrognosis: Automated Clinical Prognostic Modeling via Bayesian Optimization with Structured Kernel Learning. In: Dy and Krause [<a href="#_bookmark186">27</a>], pp. 139– 148</p>
<p><span id="_bookmark166" class="anchor"></span>5. Almeida, L.B., Langlois, T., Amaral, J.D., Plakhov, A.: Parameter Adaptation in Stochastic <span id="_bookmark35" class="anchor"></span>Optimization, p. 111– 134. Cambridge University Press (1999)</p>
<p>6. Amazon: Automatic model tuning (2018), <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning.html">https://docs.aws.amazon.com/sagemaker/latest/dg/</a> <span id="_bookmark187" class="anchor"></span><a href="https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning.html">automatic-model-tuning.html</a></p>
<p>7. Bach, F., Blei, D. (eds.): Proceedings of the 32nd International Conference on Machine <span id="_bookmark188" class="anchor"></span>Learning (ICML’15), vol. 37. Omnipress (2015)</p>
<p>8. Balcan, M., Weinberger, K. (eds.): Proceedings of the 33rd International Conference on Machine Learning (ICML’17), vol. 48. Proceedings of Machine Learning Research (2016)</p>
<p><span id="_bookmark189" class="anchor"></span>9. Bartlett, P., Pereira, F., Burges, C., Bottou, L., Weinberger, K. (eds.): Proceedings of the 26th International Conference on Advances in Neural Information Processing Systems <span id="_bookmark167" class="anchor"></span>(NeurIPS’12) (2012)</p>
<p>10. Baydin, A.G., Cornish, R., Rubio, D.M., Schmidt, M., Wood, F.: Online Learning Rate Adaption with Hypergradient Descent. In: Proceedings of the International Conference on <span id="_bookmark87" class="anchor"></span>Learning Representations (ICLR’18) [<a href="#_bookmark185">1</a>], published online: <a href="www.iclr.cc">iclr.cc</a></p>
<p>11. BBOBies: Black-box Optimization Benchmarking (BBOB) workshop series (2018), <a href="http://numbbo.github.io/workshops/index.html">http://</a> <span id="_bookmark45" class="anchor"></span><a href="http://numbbo.github.io/workshops/index.html">numbbo.github.io/workshops/index.html</a></p>
<p>12. Bergstra, J., Bardenet, R., Bengio, Y., Kégl, B.: Algorithms for hyper-parameter optimization. In: Shawe-Taylor, J., Zemel, R., Bartlett, P., Pereira, F., Weinberger, K. (eds.) Proceedings of the 25th International Conference on Advances in Neural Information Processing Systems <span id="_bookmark76" class="anchor"></span>(NeurIPS’11). pp. 2546–2554 (2011)</p>
<p>13. Bergstra, J., Bengio, Y.: Random search for hyper-parameter optimization. Journal of Machine Learning Research 13, 281–305 (2012)</p>
</blockquote>
<p>26 M. Feurer and F. Hutter</p>
<blockquote>
<p><span id="_bookmark23" class="anchor"></span>14. Bergstra, J., Yamins, D., Cox, D.: Making a science of model search: Hyperparameter optimization in hundreds of dimensions for vision architectures. In: Dasgupta and McAllester <span id="_bookmark143" class="anchor"></span>[<a href="#_bookmark190">23</a>], pp. 115– 123</p>
<p>15. Bertrand, H., Ardon, R., Perrot, M., Bloch, I.: Hyperparameter optimization of deep neural networks: Combining hyperband with Bayesian model selection. In: Conférence sur <span id="_bookmark52" class="anchor"></span>l’Apprentissage Automatique (2017)</p>
<p>16. Bischl, B., Mersmann, O., Trautmann, H., Weihs, C.: Resampling methods for meta-model validation with recommendations for evolutionary computation. Evolutionary Computation <span id="_bookmark136" class="anchor"></span>20(2), 249–275 (2012)</p>
<p>17. Van den Bosch, A.: Wrapped progressive sampling search for optimizing learning algorithm parameters. In: Proceedings of the sixteenth Belgian-Dutch Conference on Artiﬁcial Intelli- <span id="_bookmark93" class="anchor"></span>gence. pp. 219–226 (2004)</p>
<p>18. Brochu, E., Cora, V., de Freitas, N.: A tutorial on Bayesian optimization of expensive cost functions, with application to active user modeling and hierarchical reinforcement learning. <span id="_bookmark61" class="anchor"></span>arXiv:1012.2599v1 [cs.LG] (2010)</p>
<p>19. Bürger, F., Pauli, J.: A Holistic Classiﬁcation Optimization Framework with Feature Selec- tion, Preprocessing, Manifold Learning and Classiﬁers., pp. 52–68. Springer (2015)</p>
<p><span id="_bookmark177" class="anchor"></span>20. Cawley, G., Talbot, N.: On Overﬁtting in Model Selection and Subsequent Selection Bias in <span id="_bookmark132" class="anchor"></span>Performance Evaluation. Journal of Machine Learning Research 11 (2010)</p>
<p>21. Chandrashekaran, A., Lane, I.: Speeding up Hyper-parameter Optimization by Extrapolation of Learning Curves using Previous Builds. In: Ceci, M., Hollmen, J., Todorovski, L., Vens, C., Džeroski, S. (eds.) Machine Learning and Knowledge Discovery in Databases (ECML/PKDD’17). Lecture Notes in Computer Science, vol. 10534. Springer (2017)</p>
<p><span id="_bookmark91" class="anchor"></span>22. Dahl, G., Sainath, T., Hinton, G.: Improving deep neural networks for LVCSR using rectiﬁed linear units and dropout. In: Adams, M., Zhao, V. (eds.) International Conference on Acoustics, Speech and Signal Processing (ICASSP’13). pp. 8609–8613. IEEE Computer <span id="_bookmark190" class="anchor"></span>Society Press (2013)</p>
<p>23. Dasgupta, S., McAllester, D. (eds.): Proceedings of the 30th International Conference on <span id="_bookmark172" class="anchor"></span>Machine Learning (ICML’13). Omnipress (2014)</p>
<p>24. Desautels, T., Krause, A., Burdick, J.: Parallelizing exploration-exploitation tradeoffs in Gaussian process bandit optimization. Journal of Machine Learning Research 15, 4053–4103</p>
<p><span id="_bookmark159" class="anchor"></span>(2014)</p>
<p>25. Dewancker, I., McCourt, M., Clark, S., Hayes, P., Johnson, A., Ke, G.: A stratiﬁed analysis of <span id="_bookmark130" class="anchor"></span>Bayesian optimization methods. arXiv:1603.09441v1 [cs.LG] (2016)</p>
<p>26. Domhan, T., Springenberg, J.T., Hutter, F.: Speeding up automatic hyperparameter optimiza- tion of deep neural networks by extrapolation of learning curves. In: Yang, Q., Wooldridge,</p>
<p>M. (eds.) Proceedings of the 25th International Joint Conference on Artiﬁcial Intelligence <span id="_bookmark186" class="anchor"></span>(IJCAI’15). pp. 3460–3468 (2015)</p>
<p>27. Dy, J., Krause, A. (eds.): Proceedings of the 35th International Conference on Machine Learning (ICML’18), vol. 80. Proceedings of Machine Learning Research (2018)</p>
<p><span id="_bookmark88" class="anchor"></span>28. Eberhart, R., Shi, Y.: Comparison between genetic algorithms and particle swarm optimiza- tion. In: Porto, V., Saravanan, N., Waagen, D., Eiben, A. (eds.) 7th International conference <span id="_bookmark111" class="anchor"></span>on evolutionary programming. pp. 611–616. Springer (1998)</p>
<p>29. Eggensperger, K., Feurer, M., Hutter, F., Bergstra, J., Snoek, J., Hoos, H., Leyton-Brown, K.: Towards an empirical foundation for assessing Bayesian optimization of hyperparameters. In: NeurIPS Workshop on Bayesian Optimization in Theory and Practice (BayesOpt’13) (2013)</p>
<p>30. Escalante, H., Montes, M., Sucar, E.: Particle Swarm Model Selection. Journal of Machine <span id="_bookmark62" class="anchor"><span id="_bookmark29" class="anchor"></span></span>Learning Research 10, 405–440 (2009)</p>
<p>31. Escalante, H., Montes, M., Sucar, E.: Ensemble particle swarm model selection. In: Proceed- ings of the 2010 IEEE International Joint Conference on Neural Networks (IJCNN). pp. 1–8. <span id="_bookmark153" class="anchor"></span>IEEE Computer Society Press (2010)</p>
<p>32. Escalante, H., Montes, M., Villaseñor, L.: Particle swarm model selection for authorship veriﬁcation. In: Bayro-Corrochano, E., Eklundh, J.O. (eds.) Progress in Pattern Recognition, Image Analysis, Computer Vision, and Applications. pp. 563–570 (2009)</p>
</blockquote>
<p>1 Hyperparameter Optimization 27</p>
<blockquote>
<p>33. Falkner, S., Klein, A., Hutter, F.: BOHB: Robust and Efﬁcient Hyperparameter Optimization <span id="_bookmark50" class="anchor"><span id="_bookmark48" class="anchor"></span></span>at Scale. In: Dy and Krause [<a href="#_bookmark186">27</a>], pp. 1437– 1446</p>
<p>34. Feurer, M., Klein, A., Eggensperger, K., Springenberg, J.T., Blum, M., Hutter, F.: Efﬁcient and robust automated machine learning. In: Cortes, C., Lawrence, N., Lee, D., Sugiyama, M., Garnett, R. (eds.) Proceedings of the 29th International Conference on Advances in Neural <span id="_bookmark149" class="anchor"></span>Information Processing Systems (NeurIPS’15). pp. 2962–2970 (2015)</p>
<p>35. Fischer, S., Klinkenberg, R., Mierswa, I., Ritthoff, O.: Yale: Yet another learning environment</p>
<p><span id="_bookmark165" class="anchor"></span>– tutorial. Tech. rep., University of Dortmund (2002)</p>
<p>36. Franceschi, L., Donini, M., Frasconi, P., Pontil, M.: Forward and Reverse Gradient-Based <span id="_bookmark168" class="anchor"></span>Hyperparameter Optimization. In: Precup and Teh [<a href="#_bookmark191">122</a>], pp. 1165– 1173</p>
<p>37. Franceschi, L., Frasconi, P., Salzo, S., Grazzi, R., Pontil, M.: Bilevel Programming for Hyperparameter Optimization and Meta-Learning. In: Dy and Krause [<a href="#_bookmark186">27</a>], pp. 1568– 1577</p>
<p>38. Friedrichs, F., Igel, C.: Evolutionary tuning of multiple SVM parameters. Neurocomputing <span id="_bookmark152" class="anchor"><span id="_bookmark156" class="anchor"></span></span>64, 107– 117 (2005)</p>
<p>39. Frohlich, H., Zell, A.: Efﬁcient parameter selection for support vector machines in classiﬁca- tion and regression via model-based global optimization. In: Prokhorov, D., Levine, D., Ham, F., Howell, W. (eds.) Proceedings of the 2005 IEEE International Joint Conference on Neural <span id="_bookmark104" class="anchor"></span>Networks (IJCNN). pp. 1431– 1436. IEEE Computer Society Press (2005)</p>
<p>40. Gardner, J., Guo, C., Weinberger, K., Garnett, R., Grosse, R.: Discovering and Exploiting Additive Structure for Bayesian Optimization. In: Singh, A., Zhu, J. (eds.) Proceedings of the Seventeenth International Conference on Artiﬁcial Intelligence and Statistics (AISTATS). <span id="_bookmark123" class="anchor"></span>vol. 54, pp. 1311– 1319. Proceedings of Machine Learning Research (2017)</p>
<p>41. Gardner, J., Kusner, M., Xu, Z., Weinberger, K., Cunningham, J.: Bayesian Optimization with <span id="_bookmark118" class="anchor"></span>Inequality Constraints. In: Xing and Jebara <a href="#_bookmark192">[157</a>], pp. 937–945</p>
<p>42. Garrido-Merchán, E., Hernández-Lobato, D.: Dealing with integer-valued variables in Bayesian optimization with Gaussian processes. arXiv:1706.03673v2 [stats.ML] (2017)</p>
<p><span id="_bookmark124" class="anchor"></span>43. Gelbart, M., Snoek, J., Adams, R.: Bayesian optimization with unknown constraints. In: Zhang, N., Tian, J. (eds.) Proceedings of the 30th conference on Uncertainty in Artiﬁcial <span id="_bookmark173" class="anchor"></span>Intelligence (UAI’14). AUAI Press (2014)</p>
<p>44. Ginsbourger, D., Le Riche, R., Carraro, L.: Kriging Is Well-Suited to Parallelize Optimization. In: Computational Intelligence in Expensive Optimization Problems, pp. 131– 162. Springer</p>
<p><span id="_bookmark34" class="anchor"></span>(2010)</p>
<p>45. Golovin, D., Solnik, B., Moitra, S., Kochanski, G., Karro, J., Sculley, D.: Google Vizier: A service for black-box optimization. In: Matwin, S., Yu, S., Farooq, F. (eds.) Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD). pp. 1487– 1495. ACM Press (2017)</p>
<p>46. Gramacy, R., Lee, H.: Optimization under unknown constraints. Bayesian Statistics 9(9), 229– <span id="_bookmark193" class="anchor"><span id="_bookmark126" class="anchor"></span></span>246 (2011)</p>
<p>47. Gretton, A., Robert, C. (eds.): Proceedings of the Seventeenth International Conference on Artiﬁcial Intelligence and Statistics (AISTATS), vol. 51. Proceedings of Machine Learning <span id="_bookmark194" class="anchor"></span>Research (2016)</p>
<p>48. Guyon, I., von Luxburg, U., Bengio, S., Wallach, H., Fergus, R., Vishwanathan, S., Garnett, R. (eds.): Proceedings of the 31st International Conference on Advances in Neural Information <span id="_bookmark154" class="anchor"></span>Processing Systems (NeurIPS’17) (2017)</p>
<p>49. Guyon, I., Saffari, A., Dror, G., Cawley, G.: Analysis of the IJCNN 2007 agnostic learning vs. prior knowledge challenge. Neural Networks 21(2), 544–550 (2008)</p>
<p><span id="_bookmark58" class="anchor"></span>50. Guyon, I., Saffari, A., Dror, G., Cawley, G.: Model Selection: Beyond the Bayesian/Frequen- <span id="_bookmark86" class="anchor"></span>tist Divide. Journal of Machine Learning Research 11, 61–87 (2010)</p>
<p>51. Hansen, N.: The CMA evolution strategy: A tutorial. arXiv:1604.00772v1 [cs.LG] (2016)</p>
<p><span id="_bookmark115" class="anchor"></span>52. Hazan, E., Klivans, A., Yuan, Y.: Hyperparameter optimization: A spectral approach. In: Proceedings of the International Conference on Learning Representations (ICLR’18) [<a href="#_bookmark185">1</a>], <span id="_bookmark73" class="anchor"></span>published online: <a href="www.iclr.cc">iclr.cc</a></p>
<p>53. Hernandez-Lobato, D., Hernandez-Lobato, J., Shah, A., Adams, R.: Predictive Entropy Search for Multi-objective Bayesian Optimization. In: Balcan and Weinberger [<a href="#_bookmark188">8</a>], pp. 1492–</p>
</blockquote>
<p>28 M. Feurer and F. Hutter</p>
<blockquote>
<p><span id="_bookmark174" class="anchor"></span>54. Hernández-Lobato, J., Requeima, J., Pyzer-Knapp, E., Aspuru-Guzik, A.: Parallel and distributed Thompson sampling for large-scale accelerated exploration of chemical space. <span id="_bookmark127" class="anchor"></span>In: Precup and Teh [<a href="#_bookmark191">122</a>], pp. 1470– 1479</p>
<p>55. Hernández-Lobato, J., Gelbart, M., Adams, R., Hoffman, M., Ghahramani, Z.: A general framework for constrained Bayesian optimization using information-based search. The <span id="_bookmark67" class="anchor"></span>Journal of Machine Learning Research 17(1), 5549–5601 (2016)</p>
<p>56. Hoeting, J., Madigan, D., Raftery, A., Volinsky, C.: Bayesian model averaging: a tutorial. <span id="_bookmark71" class="anchor"></span>Statistical science pp. 382–401 (1999)</p>
<p>57. Horn, D., Bischl, B.: Multi-objective parameter conﬁguration of machine learning algorithms using model-based optimization. In: Likas, A. (ed.) 2016 IEEE Symposium Series on Computational Intelligence (SSCI). pp. 1–8. IEEE Computer Society Press (2016)</p>
<p><span id="_bookmark117" class="anchor"></span>58. Hutter, F.: Automated Conﬁguration of Algorithms for Solving Hard Computational Prob- lems. Ph.D. thesis, University of British Columbia, Department of Computer Science, <span id="_bookmark82" class="anchor"></span>Vancouver, Canada (2009)</p>
<p>59. Hutter, F., Hoos, H., Leyton-Brown, K.: Sequential model-based optimization for general algorithm conﬁguration. In: Coello, C. (ed.) Proceedings of the Fifth International Conference on Learning and Intelligent Optimization (LION’11). Lecture Notes in Computer Science, <span id="_bookmark175" class="anchor"></span>vol. 6683, pp. 507–523. Springer (2011)</p>
<p>60. Hutter, F., Hoos, H., Leyton-Brown, K.: Parallel algorithm conﬁguration. In: Hamadi, Y., Schoenauer, M. (eds.) Proceedings of the Sixth International Conference on Learning and Intelligent Optimization (LION’12). Lecture Notes in Computer Science, vol. 7219, pp. 55–</p>
<p><span id="_bookmark78" class="anchor"></span>70. Springer (2012)</p>
<p>61. Hutter, F., Hoos, H., Leyton-Brown, K.: An efﬁcient approach for assessing hyperparameter <span id="_bookmark100" class="anchor"></span>importance. In: Xing and Jebara <a href="#_bookmark192">[157</a>], pp. 754–762</p>
<p>62. Hutter, F., Hoos, H., Leyton-Brown, K., Murphy, K.: Time-bounded sequential parameter optimization. In: Blum, C. (ed.) Proceedings of the Fourth International Conference on Learning and Intelligent Optimization (LION’10). Lecture Notes in Computer Science, vol. <span id="_bookmark119" class="anchor"></span>6073, pp. 281–298. Springer (2010)</p>
<p>63. Hutter, F., Osborne, M.: A kernel for hierarchical parameter spaces. arXiv:1310.5738v1 <span id="_bookmark38" class="anchor"></span>[stats.ML] (2013)</p>
<p>64. Hutter, F., Lücke, J., Schmidt-Thieme, L.: Beyond Manual Tuning of Hyperparameters. KI - <span id="_bookmark70" class="anchor"></span>Künstliche Intelligenz 29(4), 329–337 (2015)</p>
<p>65. Igel, C.: Multi-objective Model Selection for Support Vector Machines. In: Coello, C., Aguirre, A., Zitzler, E. (eds.) Evolutionary Multi-Criterion Optimization. pp. 534–546. <span id="_bookmark195" class="anchor"></span>Springer (2005)</p>
<p>66. Ihler, A., Janzing, D. (eds.): Proceedings of the 32nd conference on Uncertainty in Artiﬁcial <span id="_bookmark114" class="anchor"></span>Intelligence (UAI’16). AUAI Press (2016)</p>
<p>67. Ilievski, I., Akhtar, T., Feng, J., Shoemaker, C.: Efﬁcient Hyperparameter Optimization for Deep Learning Algorithms Using Deterministic RBF Surrogates. In: Sierra, C. (ed.) Proceedings of the 27th International Joint Conference on Artiﬁcial Intelligence (IJCAI’17)</p>
<p><span id="_bookmark162" class="anchor"></span>(2017)</p>
<p>68. Jamieson, K., Recht, B.: The news on auto-tuning (2016), <a href="http://www.argmin.net/2016/06/20/hypertuning/">http://www.argmin.net/2016/06/20/</a> <span id="_bookmark139" class="anchor"></span><a href="http://www.argmin.net/2016/06/20/hypertuning/">hypertuning/</a></p>
<p>69. Jamieson, K., Talwalkar, A.: Non-stochastic best arm identiﬁcation and hyperparameter <span id="_bookmark112" class="anchor"></span>optimization. In: Gretton and Robert [<a href="#_bookmark193">47</a>], pp. 240–248</p>
<p>70. Jenatton, R., Archambeau, C., González, J., Seeger, M.: Bayesian Optimization with Tree- structured Dependencies. In: Precup and Teh [<a href="#_bookmark191">122</a>], pp. 1655– 1664</p>
<p><span id="_bookmark148" class="anchor"></span>71. John, G.: Cross-Validated C4.5: Using Error Estimation for Automatic Parameter Selection. Tech. Rep. STAN-CS-TN-94- 12, Stanford University, Stanford University (1994)</p>
<p><span id="_bookmark96" class="anchor"></span>72. Jones, D., Schonlau, M., Welch, W.: Efﬁcient global optimization of expensive black box <span id="_bookmark147" class="anchor"></span>functions. Journal of Global Optimization 13, 455–492 (1998)</p>
<p>73. Kandasamy, K., Dasarathy, G., Oliva, J., Schneider, J., Póczos, B.: Gaussian Process Bandit Optimisation with Multi-ﬁdelity Evaluations. In: Lee et al. [<a href="#_bookmark196">87</a>], pp. 992– 1000</p>
</blockquote>
<p>1 Hyperparameter Optimization 29</p>
<blockquote>
<p><span id="_bookmark146" class="anchor"></span>74. Kandasamy, K., Dasarathy, G., Schneider, J., Póczos, B.: Multi-ﬁdelity Bayesian Optimisa- <span id="_bookmark105" class="anchor"></span>tion with Continuous Approximations. In: Precup and Teh [<a href="#_bookmark191">122</a>], pp. 1799– 1808</p>
<p>75. Kandasamy, K., Schneider, J., Póczos, B.: High Dimensional Bayesian Optimisation and <span id="_bookmark140" class="anchor"></span>Bandits via Additive Models. In: Bach and Blei [<a href="#_bookmark187">7</a>], pp. 295–304</p>
<p>76. Karnin, Z., Koren, T., Somekh, O.: Almost optimal exploration in multi-armed bandits. In: <span id="_bookmark25" class="anchor"></span>Dasgupta and McAllester [<a href="#_bookmark190">23</a>], pp. 1238– 1246</p>
<p>77. King, R., Feng, C., Sutherland, A.: Statlog: comparison of classiﬁcation algorithms on large real-world problems. Applied Artiﬁcial Intelligence an International Journal 9(3), 289–333</p>
<p><span id="_bookmark53" class="anchor"></span>(1995)</p>
<p>78. Klein, A., Falkner, S., Bartels, S., Hennig, P., Hutter, F.: Fast bayesian hyperparameter <span id="_bookmark163" class="anchor"></span>optimization on large datasets. In: Electronic Journal of Statistics. vol. 11 (2017)</p>
<p>79. Klein, A., Falkner, S., Mansur, N., Hutter, F.: RoBO: A ﬂexible and robust Bayesian optimiza- tion framework in Python. In: NeurIPS workshop on Bayesian Optimization (BayesOpt’17)</p>
<p><span id="_bookmark131" class="anchor"></span>(2017)</p>
<p>80. Klein, A., Falkner, S., Springenberg, J.T., Hutter, F.: Learning curve prediction with Bayesian neural networks. In: Proceedings of the International Conference on Learning Representations <span id="_bookmark178" class="anchor"></span>(ICLR’17) (2017), published online: <a href="www.iclr.cc">iclr.cc</a></p>
<p>81. Koch, P., Konen, W., Flasch, O., Bartz-Beielstein, T.: Optimizing support vector machines for stormwater prediction. Tech. Rep. TR10-2-007, Technische Universität Dortmund (2010)</p>
<p><span id="_bookmark26" class="anchor"></span>82. Kohavi, R., John, G.: Automatic Parameter Selection by Minimizing Estimated Error. In: Prieditis, A., Russell, S. (eds.) Proceedings of the Twelfth International Conference on <span id="_bookmark49" class="anchor"></span>Machine Learning, pp. 304–312. Morgan Kaufmann Publishers (1995)</p>
<p>83. Komer, B., Bergstra, J., Eliasmith, C.: Hyperopt-sklearn: Automatic hyperparameter conﬁg- uration for scikit-learn. In: Hutter, F., Caruana, R., Bardenet, R., Bilenko, M., Guyon, I., Kégl, B., Larochelle, H. (eds.) ICML workshop on Automated Machine Learning (AutoML <span id="_bookmark157" class="anchor"></span>workshop 2014) (2014)</p>
<p>84. Konen, W., Koch, P., Flasch, O., Bartz-Beielstein, T., Friese, M., Naujoks, B.: Tuned data mining: a benchmark study on different tuners. In: Krasnogor, N. (ed.) Proceedings of the 13th Annual Conference on Genetic and Evolutionary Computation (GECCO’11). pp. 1995–</p>
<p><span id="_bookmark128" class="anchor"></span>2002. ACM (2011)</p>
<p>85. Krizhevsky, A., Sutskever, I., Hinton, G.: Imagenet classiﬁcation with deep convolutional <span id="_bookmark137" class="anchor"></span>neural networks. In: Bartlett et al. [<a href="#_bookmark189">9</a>], pp. 1097– 1105</p>
<p>86. Krueger, T., Panknin, D., Braun, M.: Fast cross-validation via sequential testing. Journal of <span id="_bookmark196" class="anchor"></span>Machine Learning Research (2015)</p>
<p>87. Lee, D., Sugiyama, M., von Luxburg, U., Guyon, I., Garnett, R. (eds.): Proceedings of the 30th International Conference on Advances in Neural Information Processing Systems <span id="_bookmark125" class="anchor"></span>(NeurIPS’16) (2016)</p>
<p>88. Lee, H., Gramacy, R.: Optimization Subject to Hidden Constraints via Statistical Emulation. <span id="_bookmark36" class="anchor"></span>Paciﬁc Journal of Optimization 7(3), 467–478 (2011)</p>
<p>89. Li, F.F., Li, J.: Cloud AutoML: Making AI accessible to every business (2018), <a href="https://www.blog.google/products/google-cloud/cloud-automl-making-ai-accessible-every-business/">https://www</a>. <a href="https://www.blog.google/products/google-cloud/cloud-automl-making-ai-accessible-every-business/">blog.google/products/google-cloud/cloud-automl-making-ai-accessible-every-business/</a></p>
<p><span id="_bookmark83" class="anchor"></span>90. Li, L., Jamieson, K., DeSalvo, G., Rostamizadeh, A., Talwalkar, A.: Hyperband: A novel bandit-based approach to hyperparameter optimization. Journal of Machine Learning <span id="_bookmark85" class="anchor"></span>Research 18(185), 1–52 (2018)</p>
<p>91. Loshchilov, I., Hutter, F.: CMA-ES for hyperparameter optimization of deep neural networks. In: International Conference on Learning Representations Workshop track (2016), published <span id="_bookmark107" class="anchor"></span>online: <a href="www.iclr.cc">iclr.cc</a></p>
<p>92. Lu, X., Gonzalez, J., Dai, Z., Lawrence, N.: Structured Variationally Auto-encoded Optimiza- <span id="_bookmark169" class="anchor"></span>tion. In: Dy and Krause [<a href="#_bookmark186">27</a>], pp. 3273–3281</p>
<p>93. Luketina, J., Berglund, M., Greff, K., Raiko, T.: Scalable Gradient-Based Tuning of Continu- ous Regularization Hyperparameters. In: Balcan and Weinberger [<a href="#_bookmark188">8</a>], pp. 2952–2960</p>
<p><span id="_bookmark39" class="anchor"></span>94. Luo, G.: A review of automatic selection methods for machine learning algorithms and hyper- parameter values. Network Modeling Analysis in Health Informatics and Bioinformatics 5(1)</p>
<p>(2016)</p>
</blockquote>
<p>30 M. Feurer and F. Hutter</p>
<blockquote>
<p><span id="_bookmark179" class="anchor"></span>95. Lévesque, J.C.: Bayesian Hyperparameter Optimization: Overﬁtting, Ensembles and Condi- <span id="_bookmark120" class="anchor"></span>tional Spaces. Ph.D. thesis, Université Laval (2018)</p>
<p>96. Lévesque, J.C., Durand, A., Gagné, C., Sabourin, R.: Bayesian optimization for conditional hyperparameter spaces. In: Howell, B. (ed.) 2017 International Joint Conference on Neural <span id="_bookmark65" class="anchor"></span>Networks (IJCNN). pp. 286–293. IEEE (2017)</p>
<p>97. Lévesque, J.C., Gagné, C., Sabourin, R.: Bayesian Hyperparameter Optimization for Ensem- <span id="_bookmark66" class="anchor"></span>ble Learning. In: Ihler and Janzing [<a href="#_bookmark195">66</a>], pp. 437–446</p>
<p><span id="_bookmark164" class="anchor"></span>98. MacKay, D.: Hyperparameters: Optimize, or Integrate Out?, pp. 43–59. Springer (1996)</p>
<p>99. Maclaurin, D., Duvenaud, D., Adams, R.: Gradient-based Hyperparameter Optimization <span id="_bookmark30" class="anchor"></span>through Reversible Learning. In: Bach and Blei [<a href="#_bookmark187">7</a>], pp. 2113–2122</p>
<p>100. Mantovani, R., Horvath, T., Cerri, R., Vanschoren, J., Carvalho, A.: Hyper-Parameter Tuning of a Decision Tree Induction Algorithm. In: 2016 5th Brazilian Conference on Intelligent <span id="_bookmark184" class="anchor"></span>Systems (BRACIS). pp. 37–42. IEEE Computer Society Press (2016)</p>
<p>101. Marcel Wever, F.M., Hüllermeier, E.: ML-Plan for unlimited-length machine learning pipelines. In: Garnett, R., Vanschoren, F.H.J., Brazdil, P., Caruana, R., Giraud-Carrier, C., Guyon, I., Kégl, B. (eds.) ICML workshop on Automated Machine Learning (AutoML <span id="_bookmark54" class="anchor"></span>workshop 2018) (2018)</p>
<p>102. Maron, O., Moore, A.: The racing algorithm: Model selection for lazy learners. Artiﬁcial <span id="_bookmark69" class="anchor"></span>Intelligence Review 11(1–5), 193–225 (1997)</p>
<p>103. McInerney, J.: An Empirical Bayes Approach to Optimizing Machine Learning Algorithms. <span id="_bookmark101" class="anchor"></span>In: Guyon et al. [<a href="#_bookmark194">48</a>], pp. 2712–2721</p>
<p>104. McIntire, M., Ratner, D., Ermon, S.: Sparse Gaussian Processes for Bayesian Optimization. <span id="_bookmark21" class="anchor"></span>In: Ihler and Janzing [<a href="#_bookmark195">66</a>]</p>
<p>105. Melis, G., Dyer, C., Blunsom, P.: On the state of the art of evaluation in neural language mod- els. In: Proceedings of the International Conference on Learning Representations (ICLR’18) <span id="_bookmark158" class="anchor"></span>[<a href="#_bookmark185">1</a>], published online: <a href="www.iclr.cc">iclr.cc</a></p>
<p>106. Mendoza, H., Klein, A., Feurer, M., Springenberg, J., Hutter, F.: Towards automatically-tuned <span id="_bookmark27" class="anchor"></span>neural networks. In: ICML 2016 AutoML Workshop (2016)</p>
<p>107. Michie, D., Spiegelhalter, D., Taylor, C., Campbell, J. (eds.): Machine Learning, Neural and <span id="_bookmark180" class="anchor"></span>Statistical Classiﬁcation. Ellis Horwood (1994)</p>
<p>108. Mohr, F., Wever, M., Höllermeier, E.: ML-Plan: Automated machine learning via hierarchical <span id="_bookmark59" class="anchor"></span>planning. Machine Learning 107(8– 10), 1495– 1515 (2018)</p>
<p>109. Momma, M., Bennett, K.: A Pattern Search Method for Model Selection of Support Vector Regression. In: Proceedings of the 2002 SIAM International Conference on Data Mining, <span id="_bookmark75" class="anchor"></span>pp. 261–274 (2002)</p>
<p>110. Montgomery, D.: Design and analysis of experiments. John Wiley &amp; Sons, Inc, eighth edn.</p>
<p><span id="_bookmark68" class="anchor"></span>(2013)</p>
<p>111. Murray, I., Adams, R.: Slice sampling covariance hyperparameters of latent Gaussian models. In: Lafferty, J., Williams, C., Shawe-Taylor, J., Zemel, R., Culotta, A. (eds.) Proceedings of the 24th International Conference on Advances in Neural Information Processing Systems <span id="_bookmark182" class="anchor"></span>(NeurIPS’10). pp. 1732– 1740 (2010)</p>
<p>112. Nguyen, T., Gupta, S., Rana, S., Venkatesh, S.: Stable Bayesian Optimization. In: Kim, J., Shim, K., Cao, L., Lee, J.G., Lin, X., Moon, Y.S. (eds.) Advances in Knowledge Discovery and Data Mining (PAKDD’17). Lecture Notes in Artiﬁcial Intelligence, vol. 10235, pp. 578– <span id="_bookmark46" class="anchor"></span>591 (2017)</p>
<p>113. Nguyen, V., Gupta, S., Rana, S., Li, C., Venkatesh, S.: Filtering Bayesian optimization approach in weakly speciﬁed search space. Knowledge and Information Systems (2018)</p>
<p>114. Oh, C., Gavves, E., Welling, M.: BOCK: Bayesian Optimization with Cylindrical Kernels. In: <span id="_bookmark103" class="anchor"><span id="_bookmark183" class="anchor"></span></span>Dy and Krause [<a href="#_bookmark186">27</a>], pp. 3865–3874</p>
<p>115. Olson, R., Bartley, N., Urbanowicz, R., Moore, J.: Evaluation of a Tree-based Pipeline Optimization Tool for Automating Data Science. In: Friedrich, T. (ed.) Proceedings of the Genetic and Evolutionary Computation Conference (GECCO’16). pp. 485–492. ACM (2016)</p>
<p><span id="_bookmark31" class="anchor"></span>116. Olson, R., La Cava, W., Mustahsan, Z., Varik, A., Moore, J.: Data-driven advice for applying machine learning to bioinformatics problems. In: Proceedings of the Paciﬁc Symposium in Biocomputing 2018. pp. 192–203 (2018)</p>
</blockquote>
<p>1 Hyperparameter Optimization 31</p>
<p><span id="_bookmark161" class="anchor"></span>117. Paszke, A., Gross, S., Chintala, S., Chanan, G., Yang, E., DeVito, Z., Lin, Z., Desmaison, A., Antiga, L., Lerer, A.: Automatic differentiation in PyTorch. In: NeurIPS Autodiff Workshop</p>
<blockquote>
<p><span id="_bookmark170" class="anchor"></span>(2017)</p>
</blockquote>
<p>118. Pedregosa, F.: Hyperparameter optimization with approximate gradient. In: Balcan and <span id="_bookmark150" class="anchor"></span>Weinberger [<a href="#_bookmark188">8</a>], pp. 737–746</p>
<p>119. Peng-Wei Chen, Jung-Ying Wang, Hahn-Ming Lee: Model selection of SVMs using GA approach. In: Proceedings of the 2004 IEEE International Joint Conference on Neural <span id="_bookmark135" class="anchor"></span>Networks (IJCNN). vol. 3, pp. 2035–2040. IEEE Computer Society Press (2004)</p>
<p>120. Petrak, J.: Fast subsampling performance estimates for classiﬁcation algorithm selection. Technical Report TR-2000-07, Austrian Research Institute for Artiﬁcial Intelligence (2000)</p>
<p>121. Poloczek, M., Wang, J., Frazier, P.: Multi-Information Source Optimization. In: Guyon et al. <span id="_bookmark191" class="anchor"><span id="_bookmark56" class="anchor"></span></span>[<a href="#_bookmark194">48</a>], pp. 4288–4298</p>
<p>122. Precup, D., Teh, Y. (eds.): Proceedings of the 34th International Conference on Machine <span id="_bookmark129" class="anchor"></span>Learning (ICML’17), vol. 70. Proceedings of Machine Learning Research (2017)</p>
<p>123. Provost, F., Jensen, D., Oates, T.: Efﬁcient progressive sampling. In: Fayyad, U., Chaudhuri, S., Madigan, D. (eds.) The 5th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD’99). pp. 23–32. ACM Press (1999)</p>
<p>124. Rasmussen, C., Williams, C.: Gaussian Processes for Machine Learning. The MIT Press</p>
<blockquote>
<p><span id="_bookmark99" class="anchor"><span id="_bookmark108" class="anchor"></span></span>(2006)</p>
</blockquote>
<p>125. Rendle, S.: Factorization machines. In: Webb, G., Liu, B., Zhang, C., Gunopulos, D., Wu, X. (eds.) Proceedings of the 10th IEEE International Conference on Data Mining (ICDM’06). <span id="_bookmark28" class="anchor"></span>pp. 995– 1000. IEEE Computer Society Press (2010)</p>
<p>126. Ripley, B.D.: Statistical aspects of neural networks. Networks and chaos—statistical and <span id="_bookmark171" class="anchor"></span>probabilistic aspects 50, 40– 123 (1993)</p>
<p>127. Russakovsky, O., Deng, J., Su, H., Krause, J., Satheesh, S., Ma, S., Huang, Z., Karpathy, A., Khosla, A., Bernstein, M., Berg, A., Fei-Fei, L.: Imagenet large scale visual recognition challenge. International Journal of Computer Vision 115(3), 211–252 (2015)</p>
<p><span id="_bookmark138" class="anchor"></span>128. Sabharwal, A., Samulowitz, H., Tesauro, G.: Selecting Near-Optimal Learners via Incremen- tal Data Allocation. In: Schuurmans, D., Wellman, M. (eds.) Proceedings of the Thirtieth <span id="_bookmark151" class="anchor"></span>National Conference on Artiﬁcial Intelligence (AAAI’16). AAAI Press (2016)</p>
<p>129. Samanta, B.: Gear fault detection using artiﬁcial neural networks and support vector machines with genetic algorithms. Mechanical Systems and Signal Processing 18(3), 625–644 (2004)</p>
<p><span id="_bookmark32" class="anchor"></span>130. Sanders, S., Giraud-Carrier, C.: Informing the Use of Hyperparameter Optimization Through Metalearning. In: Gottumukkala, R., Ning, X., Dong, G., Raghavan, V., Aluru, S., Karypis, G., Miele, L., Wu, X. (eds.) 2017 IEEE International Conference on Big Data (Big Data). <span id="_bookmark109" class="anchor"></span>IEEE Computer Society Press (2017)</p>
<p>131. Schilling, N., Wistuba, M., Drumond, L., Schmidt-Thieme, L.: Hyperparameter optimization with factorized multilayer perceptrons. In: Appice, A., Rodrigues, P., Costa, V., Gama, J., Jorge, A., Soares, C. (eds.) Machine Learning and Knowledge Discovery in Databases (ECML/PKDD’15). Lecture Notes in Computer Science, vol. 9285, pp. 87– 103. Springer</p>
<blockquote>
<p><span id="_bookmark110" class="anchor"></span>(2015)</p>
</blockquote>
<p>132. Schilling, N., Wistuba, M., Drumond, L., Schmidt-Thieme, L.: Joint Model Choice and Hyperparameter Optimization with Factorized Multilayer Perceptrons. In: 2015 IEEE 27th International Conference on Tools with Artiﬁcial Intelligence (ICTAI). pp. 72–79. IEEE <span id="_bookmark24" class="anchor"></span>Computer Society Press (2015)</p>
<p>133. Sculley, D., Snoek, J., Wiltschko, A., Rahimi, A.: Winner’s curse? on pace, progress, and empirical rigor. In: International Conference on Learning Representations Workshop track</p>
<blockquote>
<p><span id="_bookmark74" class="anchor"></span>(2018), published online: <a href="www.iclr.cc">iclr.cc</a></p>
</blockquote>
<p>134. Shah, A., Ghahramani, Z.: Pareto Frontier Learning with Expensive Correlated Objectives. <span id="_bookmark92" class="anchor"></span>In: Balcan and Weinberger [<a href="#_bookmark188">8</a>], pp. 1919– 1927</p>
<p>135. Shahriari, B., Swersky, K., Wang, Z., Adams, R., de Freitas, N.: Taking the human out of the loop: A review of Bayesian optimization. Proceedings of the IEEE 104(1), 148– 175 (2016)</p>
<p><span id="_bookmark47" class="anchor"></span>136. Shahriari, B., Bouchard-Cote, A., de Freitas, N.: Unbounded Bayesian optimization via regularization. In: Gretton and Robert [<a href="#_bookmark193">47</a>], pp. 1168– 1176</p>
<p>32 M. Feurer and F. Hutter</p>
<blockquote>
<p><span id="_bookmark37" class="anchor"><span id="_bookmark89" class="anchor"></span></span>137. SIGOPT: Improve ML models 100x faster (2018), <a href="https://sigopt.com/" class="uri">https://sigopt.com/</a></p>
<p><span id="_bookmark122" class="anchor"></span>138. Simon, D.: Evolutionary optimization algorithms. John Wiley &amp; Sons (2013)</p>
<p>139. Snoek, J.: Bayesian optimization and semiparametric models with applications to assistive <span id="_bookmark22" class="anchor"></span>technology. PhD Thesis, University of Toronto (2013)</p>
<p>140. Snoek, J., Larochelle, H., Adams, R.: Practical Bayesian optimization of machine learning <span id="_bookmark90" class="anchor"></span>algorithms. In: Bartlett et al. [<a href="#_bookmark189">9</a>], pp. 2960–2968</p>
<p>141. Snoek, J., Rippel, O., Swersky, K., Kiros, R., Satish, N., Sundaram, N., Patwary, M., Prabhat, Adams, R.: Scalable Bayesian optimization using deep neural networks. In: Bach and Blei <span id="_bookmark116" class="anchor"></span>[<a href="#_bookmark187">7</a>], pp. 2171–2180</p>
<p>142. Snoek, J., Swersky, K., Zemel, R., Adams, R.: Input warping for Bayesian optimization of <span id="_bookmark113" class="anchor"></span>non-stationary functions. In: Xing and Jebara <a href="#_bookmark192">[157</a>], pp. 1674– 1682</p>
<p>143. Sparks, E., Talwalkar, A., Haas, D., Franklin, M., Jordan, M., Kraska, T.: Automating model search for large scale machine learning. In: Balazinska, M. (ed.) Proceedings of the Sixth ACM Symposium on Cloud Computing - SoCC ’15. pp. 368–380. ACM Press (2015)</p>
<p>144. Springenberg, J., Klein, A., Falkner, S., Hutter, F.: Bayesian optimization with robust <span id="_bookmark106" class="anchor"><span id="_bookmark155" class="anchor"></span></span>Bayesian neural networks. In: Lee et al. [<a href="#_bookmark196">87</a>]</p>
<p>145. Sun, Q., Pfahringer, B., Mayo, M.: Towards a Framework for Designing Full Model Selection and Optimization Systems. In: Multiple Classiﬁer Systems, vol. 7872, pp. 259–270. Springer</p>
<p><span id="_bookmark121" class="anchor"></span>(2013)</p>
<p>146. Swersky, K., Duvenaud, D., Snoek, J., Hutter, F., Osborne, M.: Raiders of the lost architecture: Kernels for Bayesian optimization in conditional parameter spaces. In: NeurIPS Workshop on <span id="_bookmark55" class="anchor"></span>Bayesian Optimization in Theory and Practice (BayesOpt’14) (2014)</p>
<p>147. Swersky, K., Snoek, J., Adams, R.: Multi-task Bayesian optimization. In: Burges, C., Bottou, L., Welling, M., Ghahramani, Z., Weinberger, K. (eds.) Proceedings of the 27th International Conference on Advances in Neural Information Processing Systems (NeurIPS’13). pp. 2004– <span id="_bookmark133" class="anchor"></span>2012 (2013)</p>
<p>148. Swersky, K., Snoek, J., Adams, R.: Freeze-thaw Bayesian optimization arXiv:1406.3896v1 <span id="_bookmark33" class="anchor"></span>[stats.ML] (2014)</p>
<p>149. Thornton, C., Hutter, F., Hoos, H., Leyton-Brown, K.: Auto-WEKA: combined selection and hyperparameter optimization of classiﬁcation algorithms. In: Dhillon, I., Koren, Y., Ghani, R., Senator, T., Bradley, P., Parekh, R., He, J., Grossman, R., Uthurusamy, R. (eds.) The 19th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining <span id="_bookmark181" class="anchor"></span>(KDD’13). pp. 847–855. ACM Press (2013)</p>
<p>150. Wainer, J., Cawley, G.: Empirical Evaluation of Resampling Procedures for Optimising SVM <span id="_bookmark144" class="anchor"></span>Hyperparameters. Journal of Machine Learning Research 18, 1–35 (2017)</p>
<p>151. Wang, J., Xu, J., Wang, X.: Combination of hyperband and Bayesian optimization for hyperparameter optimization in deep learning. arXiv:1801.01596v1 [cs.CV] (2018)</p>
<p><span id="_bookmark145" class="anchor"></span>152. Wang, L., Feng, M., Zhou, B., Xiang, B., Mahadevan, S.: Efﬁcient Hyper-parameter Optimization for NLP Applications. In: Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing. pp. 2112–2117. Association for Computational <span id="_bookmark84" class="anchor"></span>Linguistics (2015)</p>
<p>153. Wang, Z., Hutter, F., Zoghi, M., Matheson, D., de Feitas, N.: Bayesian optimization in a billion dimensions via random embeddings. Journal of Artiﬁcial Intelligence Research 55, 361–387</p>
<p><span id="_bookmark102" class="anchor"></span>(2016)</p>
<p>154. Wang, Z., Gehring, C., Kohli, P., Jegelka, S.: Batched Large-scale Bayesian Optimization in High-dimensional Spaces. In: Storkey, A., Perez-Cruz, F. (eds.) Proceedings of the 21st International Conference on Artiﬁcial Intelligence and Statistics (AISTATS). vol. 84. <span id="_bookmark63" class="anchor"></span>Proceedings of Machine Learning Research (2018)</p>
<p>155. Wistuba, M., Schilling, N., Schmidt-Thieme, L.: Automatic Frankensteining: Creating Com- plex Ensembles Autonomously. In: Proceedings of the 2017 SIAM International Conference <span id="_bookmark64" class="anchor"></span>on Data Mining (2017)</p>
<p>156. Wolpert, D.: Stacked generalization. Neural Networks 5(2), 241–259 (1992)</p>
<p><span id="_bookmark192" class="anchor"></span>157. Xing, E., Jebara, T. (eds.): Proceedings of the 31th International Conference on Machine Learning, (ICML’14). Omnipress (2014)</p>
<p>1 Hyperparameter Optimization 33</p>
<p><span id="_bookmark80" class="anchor"></span>158. Zabinsky, Z.: Pure Random Search and Pure Adaptive Search. In: Stochastic Adaptive Search <span id="_bookmark94" class="anchor"></span>for Global Optimization, pp. 25–54. Springer (2003)</p>
<p>159. Zeng, X., Luo, G.: Progressive sampling-based Bayesian optimization for efﬁcient and automatic machine learning model selection. Health Information Science and Systems 5(1)</p>
<p><span id="_bookmark95" class="anchor"></span>(2017)</p>
<p>160. Zhang, Y., Bahadori, M.T., Su, H., Sun, J.: FLASH: Fast Bayesian Optimization for Data Analytic Pipelines. In: Krishnapuram, B., Shah, M., Smola, A., Aggarwal, C., Shen, D., Rastogi, R. (eds.) Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD). pp. 2065–2074. ACM Press (2016)</p>
<p><strong>Open</strong> <strong>Access</strong> This chapter is licensed under the terms of the Creative Commons Attribution 4.0 International License <a href="http://creativecommons.org/licenses/by/4.0/">(http://creativecommons.org/licenses/by/4.0/</a>), which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence and indicate if changes were made.</p>
<p>The images or other third party material in this chapter are included in the chapter’s Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the chapter’s Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder.</p>
</blockquote>
<p><img src="./automlgithubpagesimages//media/image68.png" width="75" height="26" /></p>
<p><img src="./automlgithubpagesimages//media/image69.png" width="41" height="41" /><img src="./automlgithubpagesimages//media/image12.jpeg" width="136" /></p>
<blockquote>
<p><span id="_bookmark3" class="anchor"></span><strong>Chapter</strong> <strong>2</strong></p>
<p><strong>Meta-Learning</strong></p>
</blockquote>
<p><img src="./automlgithubpagesimages//media/image70.png" /></p>
<blockquote>
<p><strong>Joaquin</strong> <strong>Vanschoren</strong> <a href="https://orcid.org/0000-0001-7044-9805"><img src="./automlgithubpagesimages//media/image71.png" width="13" height="11" /></a></p>
<p><strong>Abstract</strong> Meta-learning, or <em>learning</em> <em>to</em> <em>learn</em>, is the science of systematically observing how different machine learning approaches perform on a wide range of learning tasks, and then learning from this experience, or <em>meta-data</em>, to learn new tasks much faster than otherwise possible. Not only does this dramatically speed up and improve the design of machine learning pipelines or neural architectures, it also allows us to replace hand-engineered algorithms with novel approaches learned in a data-driven way. In this chapter, we provide an overview of the state of the art in this fascinating and continuously evolving ﬁeld.</p>
<p><strong>2.1</strong> <strong>Introduction</strong></p>
<p>When we learn new skills, we rarely – if ever – start from scratch. We start from skills learned earlier in related tasks, reuse approaches that worked well before, and focus on what is likely worth trying based on experience [<a href="#_bookmark197">82</a>]. With every skill learned, learning new skills becomes easier, requiring fewer examples and less trial- and-error. In short, we <em>learn</em> <em>how</em> <em>to</em> <em>learn</em> across tasks. Likewise, when building machine learning models for a speciﬁc task, we often build on experience with related tasks, or use our (often implicit) understanding of the behavior of machine learning techniques to help make the right choices.</p>
</blockquote>
<p>The challenge in meta-learning is to learn from prior experience in a systematic, data-driven way. First, we need to collect <em>meta-data</em> that describe prior learning tasks and previously learned models. They comprise the exact <em>algorithm</em> <em>con-</em> <em>ﬁgurations</em> used to train the models, including hyperparameter settings, pipeline compositions and/or network architectures, the resulting <em>model</em> <em>evaluations</em>, such as accuracy and training time, the learned model parameters, such as the trained weights of a neural net, as well as measurable properties of the task itself, also</p>
<blockquote>
<p>J. Vanschoren (凶)</p>
<p>Department of Mathematics and Computer Science, TU Eindhoven, Eindhoven, North Brabant, The Netherlands</p>
<p>e-mail: <a href="mailto:j.vanschoren@tue.nl">j.vanschoren@tue.nl</a></p>
<p>© The Author(s) 2019</p>
<p>F. Hutter et al. (eds.), <em>Automated</em> <em>Machine</em> <em>Learning</em>, The Springer Series on Challenges in Machine Learning, <a href="https://doi.org/10.1007/978-3-030-05318-5_2" class="uri">https://doi.org/10.1007/978-3-030-05318-5_2</a></p>
<p>36 J. Vanschoren</p>
</blockquote>
<p>known as <em>meta-features</em>. Second, we need to <em>learn</em> from this prior meta-data, to extract and transfer knowledge that guides the search for optimal models for new tasks. This chapter presents a concise overview of different meta-learning approaches to do this effectively.</p>
<blockquote>
<p>The term <em>meta-learning</em> covers any type of learning based on prior experience with other tasks. The more <em>similar</em> those previous tasks are, the more types of meta-data we can leverage, and deﬁning task similarity will be a key overarching challenge. Perhaps needless to say, there is no free lunch [<a href="#_bookmark198">57</a>, <a href="#_bookmark199">188</a>]. When a new task represents completely unrelated phenomena, or random noise, leveraging prior experience will not be effective. Luckily, in real-world tasks, there are plenty of opportunities to learn from prior experience.</p>
<p>In the remainder of this chapter, we categorize meta-learning techniques based on the type of meta-data they leverage, from the most general to the most task- speciﬁc. First, in Sect.<a href="#_bookmark200">2.2</a>, we discuss how to <em>learn</em> <em>purely</em> <em>from</em> <em>model</em> <em>evaluations</em>. These techniques can be used to recommend generally useful conﬁgurations and conﬁguration search spaces, as well as transfer knowledge from <em>empirically</em> <em>similar</em> tasks. In Sect.<a href="#_bookmark201">2.3</a>, we discuss how we can <em>characterize</em> tasks to more explicitly express task similarity and build meta-models that learn the relationships between data characteristics and learning performance. Finally, Sect.<a href="#_bookmark202">2.4</a>covers how we can <em>transfer</em> <em>trained</em> <em>model</em> <em>parameters</em> between tasks that are inherently similar, e.g. sharing the same input features, which enables transfer learning [<a href="#_bookmark203">111</a>] and few-shot learning [<a href="#_bookmark204">126</a>] among others.</p>
<p>Note that while <em>multi-task</em> <em>learning</em> [<a href="#_bookmark205">25</a>] (learning multiple related tasks simulta- neously) and <em>ensemble</em> <em>learning</em> [<a href="#_bookmark206">35</a>] (building multiple models on the same task), can often be meaningfully combined with meta-learning systems, they do not in themselves involve learning from prior experience on other tasks.</p>
<p>This chapter is based on a very recent survey article [<a href="#_bookmark207">176</a>].</p>
<p><span id="_bookmark200" class="anchor"></span><strong>2.2</strong> <strong>Learning</strong> <strong>from</strong> <strong>Model</strong> <strong>Evaluations</strong></p>
</blockquote>
<p>Consider that we have access to prior tasks tj ∈ T , the set of all known tasks, as well as a set of learning algorithms, fully deﬁned by their <em>conﬁgurations</em> θi ∈ O; here O represents a discrete, continuous, or mixed conﬁguration space which can cover hyperparameter settings, pipeline components and/or network architecture components. <strong>P</strong> is the set of all prior scalar evaluations Pi,j = P(θi,tj) of conﬁguration θi on task tj, according to a predeﬁned evaluation measure, e.g. accuracy, and model evaluation technique, e.g. cross-validation. <strong>P</strong>new is the set of known evaluations Pi,new on a new task tnew . We now want to train a <em>meta-</em> <em>learner</em> L that predicts recommended conﬁgurations Oew for a new task tnew . The meta-learner is trained on meta-data <strong>P</strong> ∪ <strong>P</strong>new . <strong>P</strong> is usually gathered beforehand, or extracted from meta-data repositories [<a href="#_bookmark208">174</a>, <a href="#_bookmark209">177</a>]. <strong>P</strong>new is learned by the meta- learning technique itself in an iterative fashion, sometimes <em>warm-started</em> with an initial <strong>P</strong><img src="./automlgithubpagesimages//media/image72.png" height="20" />ew generated by another method.</p>
<blockquote>
<p>2 Meta-Learning 37</p>
<p><span id="_bookmark210" class="anchor"></span><em><strong>2.2.1</strong></em> <em><strong>Task-Independent</strong></em> <em><strong>Recommendations</strong></em></p>
<p>First, imagine not having access to any evaluations on tnew, hence <strong>P</strong>new = ∅. We can then still learn a function f : O × T → {θ<img src="./automlgithubpagesimages//media/image73.png" height="18" />}, k = 1..K , yielding a set of recommended conﬁgurations <em>independent</em> of tnew . These θ<img src="./automlgithubpagesimages//media/image74.png" height="18" /> can then be evaluated</p>
<p>on tnew to select the best one, or to warm-start further optimization approaches, such as those discussed in Sect.<a href="#_bookmark211">2.2.3</a>.</p>
</blockquote>
<p>Such approaches often produce a ranking, i.e. an <em>ordered</em> set θ<img src="./automlgithubpagesimages//media/image75.png" height="18" /> . This is typically done by discretizing O into a set of candidate conﬁgurations θi, also called a <em>portfolio</em>, evaluated on a large number of tasks tj . We can then build a ranking per task, for instance using <em>success</em> <em>rates</em>, <em>AUC</em>, or <em>signiﬁcant</em> <em>wins</em> [<a href="#_bookmark212">21</a>, <a href="#_bookmark213">34</a>, <a href="#_bookmark214">85</a>].</p>
<blockquote>
<p>However, it is often desirable that equally good but faster algorithms are ranked higher, and multiple methods have been proposed to trade off accuracy and training time [<a href="#_bookmark212">21</a>, <a href="#_bookmark215">134</a>]. Next, we can aggregate these single-task rankings into a <em>global</em> <em>ranking</em>, for instance by computing the average rank [<a href="#_bookmark216">1</a>, <a href="#_bookmark217">91</a>] across all tasks. When there is insufﬁcient data to build a global ranking, one can recommend <em>subsets</em> <em>of</em> <em>conﬁgurations</em> based on the best known conﬁgurations for each prior task [<a href="#_bookmark218">70</a>, <a href="#_bookmark219">173</a>], or return <em>quasi-linear</em> <em>rankings</em> [<a href="#_bookmark220">30</a>].</p>
<p>To ﬁnd the best θ ∗ for a task tnew, never before seen, a simple anytime method is to select the top-K conﬁgurations [<a href="#_bookmark212">21</a>], going down the list and evaluating each conﬁguration on tnew in turn. This evaluation can be halted after a predeﬁned value for K , a time budget, or when a sufﬁciently accurate model is found. In time- constrained settings, it has been shown that multi-objective rankings (including training time) converge to near-optimal models much faster [<a href="#_bookmark216">1</a>, <a href="#_bookmark215">134</a>], and provide a strong baseline for algorithm comparisons [<a href="#_bookmark216">1</a>, <a href="#_bookmark214">85</a>].</p>
<p>A very different approach to the one above is to ﬁrst ﬁt a differentiable function</p>
<p>fj(θi) = Pi,j on all prior evaluations of a speciﬁc task tj, and then use gradient descent to ﬁnd an optimized conﬁguration θ<img src="./automlgithubpagesimages//media/image76.png" height="17" /> per prior task [<a href="#_bookmark221">186</a>]. Assuming that</p>
<p>some of the tasks tj will be similar to tnew, those θ<img src="./automlgithubpagesimages//media/image77.png" height="17" /> will be useful for warm-starting Bayesian optimization approaches.</p>
<p><em><strong>2.2.2</strong></em> <em><strong>Conﬁguration</strong></em> <em><strong>Space</strong></em> <em><strong>Design</strong></em></p>
<p>Prior evaluations can also be used to learn a better <em>conﬁguration</em> <em>space</em> O∗ . While again independent from tnew, this can radically speed up the search for optimal models, since only the more relevant regions of the conﬁguration space are explored. This is critical when computational resources are limited, and has proven to be an important factor in practical comparisons of AutoML systems [<a href="#_bookmark222">33</a>].</p>
<p>First, in the functional ANOVA [<a href="#_bookmark223">67</a>] approach, hyperparameters are deemed important if they explain most of the variance in algorithm performance on a given task. In [<a href="#_bookmark224">136</a>], this was explored using 250,000 OpenML experiments with 3 algorithms across 100 datasets.</p>
<p>38 J. Vanschoren</p>
<p>An alternative approach is to ﬁrst <em>learn</em> an optimal hyperparameter default setting, and then deﬁne hyperparameter importance as the <em>performance</em> <em>gain</em> that can be achieved by tuning the hyperparameter instead of leaving it at that default value. Indeed, even though a hyperparameter may cause a lot of variance, it may also have one speciﬁc setting that always results in good performance. In [<a href="#_bookmark225">120</a>], this was done using about 500,000 OpenML experiments on 6 algorithms and 38 datasets. Default values are learned <em>jointly</em> for all hyperparameters of an algorithm by ﬁrst training surrogate models for that algorithm for a large number of tasks. Next, many conﬁgurations are sampled, and the conﬁguration that minimizes the average risk across all tasks is the recommended default conﬁguration. Finally, the importance (or <em>tunability</em>) of each hyperparameter is estimated by observing how much improvement can still be gained by tuning it.</p>
<p>In [<a href="#_bookmark226">183</a>], defaults are learned <em>independently</em> from other hyperparameters, and deﬁned as the conﬁgurations that occur most frequently in the top-K conﬁgurations for every task. In the case that the optimal default value depends on meta-features (e.g. the number of training instances or features), simple functions are learned that include these meta-features. Next, a statistical test deﬁnes whether a hyperparameter can be safely left at this default, based on the <em>performance</em> <em>loss</em> observed when <em>not</em> tuning a hyperparameter (or a set of hyperparameters), while all other parameters are tuned. This was evaluated using 118,000 OpenML experiments with 2 algorithms (SVMs and Random Forests) across 59 datasets.</p>
</blockquote>
<p><span id="_bookmark211" class="anchor"></span><em><strong>2.2.3</strong></em> <em><strong>Conﬁguration</strong></em> <em><strong>Transfer</strong></em></p>
<blockquote>
<p>If we want to provide recommendations for a speciﬁc task tnew, we need additional information on how similar tnew is to prior tasks tj . One waytodo this istoevaluate a number of recommended (or potentially random) conﬁgurations on tnew, yielding new evidence <strong>P</strong>new . If we then observe that the evaluations Pi,new are similar to Pi,j , then tj and tnew can be considered intrinsically similar, based on empirical evidence. We can include this knowledge to train a meta-learner that predicts a recommended set of conﬁgurations Oew for tnew . Moreover, every selected θew can be evaluated and included in <strong>P</strong>new, repeating the cycle and collecting more empirical evidence to learn which tasks are similar to each other.</p>
<p><strong>2.2.3.1</strong> <strong>Relative</strong> <strong>Landmarks</strong></p>
<p>A ﬁrst measure for task similarity considers the relative (pairwise) performance differences, also called <em>relative</em> <em>landmarks</em>, RLa,b,j = Pa,j − Pb,j between two conﬁgurations θa and θb on a particular task tj [<a href="#_bookmark227">53</a>]. <em>Active</em> <em>testing</em> [<a href="#_bookmark214">85</a>] leverages these as follows: it warm-starts with the globally best conﬁguration (see Sect.<a href="#_bookmark210">2.2.1</a>), calls it θbest, and proceeds in a tournament-style fashion. In each round, it selects the ‘competitor’ θc that most convincingly outperforms θbest on similar tasks. It</p>
<p>2 Meta-Learning 39</p>
</blockquote>
<p>deems tasks to be similar if the relative landmarks of all evaluated conﬁgurations are similar, i.e., if the conﬁgurations perform similarly on both tj and tnew then the tasks are deemed similar. Next, it evaluates the competitor θc, yielding Pc,new , updates the task similarities, and repeats. A limitation of this method is that it can only consider conﬁgurations θi that were evaluated on many prior tasks.</p>
<blockquote>
<p><strong>2.2.3.2</strong> <strong>Surrogate</strong> <strong>Models</strong></p>
<p>A more ﬂexible way to transfer information is to build <em>surrogate</em> <em>models</em> sj(θi) = Pi,j for all prior tasks tj, trained using all available <strong>P</strong>. One can then deﬁne task similarity in terms of the error between sj(θi) and Pi,new: if the surrogate model for tj can generate accurate predictions for tnew, then those tasks are intrinsically similar. This is usually done in combination with Bayesian optimization (see</p>
<p>Chap.<a href="#_bookmark2">1</a>) to determine the next θi .</p>
</blockquote>
<p>Wistuba et al. [<a href="#_bookmark228">187</a>] train surrogate models based on Gaussian Processes (GPs) for every prior task, plus one for tnew, and combine them into a weighted, normalized sum, with the (new) predicted mean μ deﬁned as the weighted sum of the individual μj ’s (obtained from prior tasks tj). The weights of the μj ’s are computed using the Nadaraya-Watson kernel-weighted average, where each task is represented as a vector of relative landmarks, and the Epanechnikov quadratic kernel [<a href="#_bookmark229">104</a>] is used to measure the similarity between the relative landmark vectors of tj and tnew . The more similar tj is to tnew, the larger the weight sj , increasing the inﬂuence of the surrogate model for tj .</p>
<p>Feurer et al. [<a href="#_bookmark230">45</a>] propose to combine the predictive distributions of the individual Gaussian processes, which makes the combined model a Gaussian process again. The weights are computed following the agnostic Bayesian ensemble of Lacoste et al. [<a href="#_bookmark231">81</a>], which weights predictors according to an estimate of their generalization performance.</p>
<p>Meta-data can also be transferred in the acquisition function rather than the surrogate model [<a href="#_bookmark228">187</a>]. The surrogate model is only trained on Pi,new, but the next θi to evaluate is provided by an acquisition function which is the weighted average of the expected improvement [<a href="#_bookmark232">69</a>] on Pi,new and the predicted improvements on all prior Pi,j . The weights of the prior tasks can again be deﬁned via the accuracy of the surrogate model or via relative landmarks. The weight of the expected improvement component is gradually increased with every iteration as more evidence Pi,new is collected.</p>
<blockquote>
<p><strong>2.2.3.3</strong> <strong>Warm-Started</strong> <strong>Multi-task</strong> <strong>Learning</strong></p>
<p>Another approach to relate prior tasks tj is to learn a joint task representation using <strong>P</strong> prior evaluations. In [<a href="#_bookmark233">114</a>], task-speciﬁc Bayesian linear regression [<a href="#_bookmark234">20</a>] surrogate models sj(θ) are trained in a novel conﬁguration θz learned by a feedforward Neural Network <em>NN</em>(θi) which learns a suitable basis expansion θz of the original</p>
<p>40 J. Vanschoren</p>
<p>conﬁguration θ in which linear surrogate models can accurately predict Pi,new . The surrogate models are pre-trained on OpenML meta-data to provide a warm-start for optimizing <em>NN</em>(θi) in a multi-task learning setting. Earlier work on multi-task learning [<a href="#_bookmark235">166</a>] assumed that we already have a set of ‘similar’ source tasks tj .</p>
</blockquote>
<p>It transfers information between these tj and tnew by building a joint GP model for Bayesian optimization that learns and exploits the exact relationship between the tasks. Learning a joint GP tends to be less scalable than building one GP per task, though. Springenberg et al. [<a href="#_bookmark236">161</a>] also assumes that the tasks are related and similar, but learns the relationship between tasks during the optimization process using Bayesian Neural Networks. As such, their method is somewhat of a hybrid of the previous two approaches. Golovin et al. [<a href="#_bookmark237">58</a>] assume a sequence order (e.g., time) across tasks. It builds a stack of GP regressors, one per task, training each GP on the residuals relative to the regressor below it. Hence, each task uses the tasks before it to deﬁne its priors.</p>
<blockquote>
<p><strong>2.2.3.4</strong> <strong>Other</strong> <strong>Techniques</strong></p>
</blockquote>
<p>Multi-armed bandits [<a href="#_bookmark238">139</a>] provide yet another approach to ﬁnd the source tasks tj most related to tnew [<a href="#_bookmark239">125</a>]. In this analogy, each tj is one arm, and the (stochastic) reward for selecting (pulling) a particular prior task (arm) is deﬁned in terms of the error in the predictions of a GP-based Bayesian optimizer that models the prior evaluations of tj as noisy measurements and combines them with the existing evaluations on tnew . The cubic scaling of the GP makes this approach less scalable, though.</p>
<blockquote>
<p>Another way to deﬁne task similarity is to take the existing evaluations Pi,j , use Thompson Sampling [<a href="#_bookmark240">167</a>] to obtain the optima distribution ρax , and then measure the KL-divergence [<a href="#_bookmark241">80</a>] between ρax and ρ [<a href="#_bookmark242">124</a>]. These distributions are then merged into a mixture distribution based on the similarities and used to build an acquisition function that predicts the next most promising conﬁguration to evaluate.</p>
<p>It is so far only evaluated to tune 2 SVM hyperparameters using 5 tasks.</p>
</blockquote>
<p>Finally, a complementary way to leverage <strong>P</strong> is to recommend which conﬁgu- rations should <em>not</em> be used. After training surrogate models per task, we can look up which tj are most similar to tnew, and then use sj(θi) to discover regions of O where performance is predicted to be poor. Excluding these regions can speed up the search for better-performing ones. Wistuba et al. [<a href="#_bookmark243">185</a>], do this using a task similarity measure based on the Kendall tau rank correlation coefﬁcient [<a href="#_bookmark244">73</a>] between the ranks obtained by ranking conﬁgurations θi using Pi,j and Pi,new, respectively.</p>
<blockquote>
<p>2 Meta-Learning 41</p>
</blockquote>
<p><em><strong>2.2.4</strong></em> <em><strong>Learning</strong></em> <em><strong>Curves</strong></em></p>
<blockquote>
<p>We can also extract meta-data about the training process itself, such as how fast model performance improves as more training data is added. If we divide the training in steps st, usually adding a ﬁxed number of training examples every step, we can measure the performance P(θi,tj,st) = Pi,j,t of conﬁguration θi on task tj after step st, yielding a <em>learning</em> <em>curve</em> across the time steps st . As discussed in Chap.<a href="#_bookmark2">1</a>, learning curves are also used to speed up hyperparameter optimization on a given task. In meta-learning, learning curve information is transferred across tasks.</p>
<p>While evaluating a conﬁguration on new task tnew, we can halt the training after a certain number of iterations r &lt; t, and use the partially observed learning curve to predict how well the conﬁguration will perform on the full dataset based on prior experience with other tasks, and decide whether to continue the training or not. This can signiﬁcantly speed up the search for good conﬁgurations.</p>
<p>One approach is to assume that similar tasks yield similar learning curves. First, deﬁne a distance between tasks based on how similar the partial learning curves are: dist(ta,tb) = f(Pi,a,t,Pi,b,t) with t = 1, . . . , r . Next, ﬁnd the k most similar tasks t1...k and use their complete learning curves to predict how well the conﬁguration will perform on the new complete dataset. Task similarity can be measured by comparing the shapes of the partial curves across all conﬁgurations tried, and the prediction is made by adapting the ‘nearest’ complete curve(s) to the new partial curve [<a href="#_bookmark245">83</a>, <a href="#_bookmark246">84</a>]. This approach was also successful in combination with active testing [<a href="#_bookmark247">86</a>], and can be sped up further by using multi-objective evaluation measures that include training time [<a href="#_bookmark215">134</a>].</p>
<p>Interestingly, while several methods aim to predict learning curves during neural architecture search (see Chap.<a href="#_bookmark4">3</a>), as of yet none of this work leverages learning curves previously observed on other tasks.</p>
<p><span id="_bookmark201" class="anchor"></span><strong>2.3</strong> <strong>Learning</strong> <strong>from</strong> <strong>Task</strong> <strong>Properties</strong></p>
<p>Another rich source of meta-data are characterizations (meta-features) of the task at hand. Each task tj ∈ T is described with a vector m(tj) = (mj,1 , . . . , mj,K) of K meta-features mj,k ∈ M , the set of all known meta-features. This can be used to deﬁne a task similarity measure based on, for instance, the Euclidean distance between m(ti) and m(tj), so that we can transfer information from the most similar tasks to the new task tnew . Moreover, together with prior evaluations <strong>P</strong>, we can train a <em>meta-learner</em> L to predict the performance Pi,new of conﬁgurations θi on a new task tnew .</p>
<p>42 J. Vanschoren</p>
</blockquote>
<p><em><strong>2.3.1</strong></em> <em><strong>Meta-Features</strong></em></p>
<blockquote>
<p>Table <a href="#_bookmark248">2.1</a> provides a concise overview of the most commonly used meta-features, together with a short rationale for why they are indicative of model performance. Where possible, we also show the formulas to compute them. More complete surveys can be found in the literature [<a href="#_bookmark249">26</a>, <a href="#_bookmark250">98</a>, <a href="#_bookmark251">130</a>, <a href="#_bookmark252">138</a>, <a href="#_bookmark253">175</a>].</p>
<p>To build a meta-feature vector m(tj), one needs to select and further process these meta-features. Studies on OpenML meta-data have shown that the optimal set of meta-features depends on the application [<a href="#_bookmark254">17</a>]. Many meta-features are computed on single features, or combinations of features, and need to be aggregated by summary statistics (min,max,μ,σ ,quartiles,<em>q</em>1... 4) or histograms [<a href="#_bookmark255">72</a>]. One needs to systematically extract and aggregate them [<a href="#_bookmark256">117</a>]. When computing task similarity, it is also important to normalize all meta-features [<a href="#_bookmark257">9</a>], perform feature selection [<a href="#_bookmark258">172</a>], or employ dimensionality reduction techniques (e.g. PCA) [<a href="#_bookmark254">17</a>]. When learning meta-models, one can also use relational meta-learners [<a href="#_bookmark219">173</a>] or case-based reasoning methods [<a href="#_bookmark259">63</a>, <a href="#_bookmark260">71</a>, <a href="#_bookmark261">92</a>].</p>
<p>Beyond these general-purpose meta-features, many more speciﬁc ones were formulated. For streaming data one can use streaming landmarks [<a href="#_bookmark262">135</a>, <a href="#_bookmark263">137</a>], for time series data one can compute autocorrelation coefﬁcients or the slope of regression models [<a href="#_bookmark264">7</a>, <a href="#_bookmark265">121</a>, <a href="#_bookmark266">147</a>], and for unsupervised problems one can cluster the data in different ways and extract properties of these clusters [<a href="#_bookmark267">159</a>]. In many applications, domain-speciﬁc information can be leveraged as well [<a href="#_bookmark268">109</a>, <a href="#_bookmark269">156</a>].</p>
</blockquote>
<p><em><strong>2.3.2</strong></em> <em><strong>Learning</strong></em> <em><strong>Meta-Features</strong></em></p>
<blockquote>
<p>Instead of manually deﬁning meta-features, we can also <em>learn</em> a joint represen- tation for groups of tasks. One approach is to build meta-models that generate a landmark-like meta-feature representation M\ given other task meta-features M and trained on performance meta-data <strong>P</strong>, or f : M l→ M\ . Sun and Pfahringer [<a href="#_bookmark270">165</a>] do this by evaluating a predeﬁned set of conﬁgurations θi on all prior tasks tj, and generating a binary metafeature mj,a,b ∈ M\ for every pairwise combination of conﬁgurations θa and θb, indicating whether θa outperformed θb or not, thus m\(tj) = (mj,a,b,mj,a,c,mj,b,c , . . .). To compute mnew,a,b , <em>meta-rules</em> are learned for every pairwise combination (a,b), each pre- dicting whether θa will outperform θb on task tj, given its other meta-features m(tj).</p>
<p>We can also learn a joint representation based entirely on the available <strong>P</strong> meta- data, i.e. f : <strong>P</strong> × O l→ M\ . We previously discussed how to do this with feed- forward neural nets [<a href="#_bookmark233">114</a>] in Sect.<a href="#_bookmark211">2.2.3</a>. If the tasks share the same input space, e.g., they are images of the same resolution, one can also use deep metric learning to learn a meta-feature representation, for instance, using Siamese networks [<a href="#_bookmark271">75</a>].</p>
<p>2 Meta-Learning 43</p>
<p><span id="_bookmark248" class="anchor"></span><strong>Table</strong> <strong>2.1</strong> Overview of commonly used meta-features. Groups from top to bottom: simple, statistical, information-theoretic, complexity, model-based, and landmarkers. Continuous features X and target Y have mean μX , stdev σX , variance σ . Categorical features X and class C have categorical values πi , conditional probabilities πi|j , joint probabilities πi,j , marginal probabilities πi+ = 对j πij, entropy H(X) = − 对iπi+log2 (πi+)</p>
</blockquote>
<table>
<tbody>
<tr class="odd">
<td><blockquote>
<p>Name</p>
</blockquote></td>
<td><blockquote>
<p>Formula</p>
</blockquote></td>
<td><blockquote>
<p>Rationale</p>
</blockquote></td>
<td><blockquote>
<p>Variants</p>
</blockquote></td>
</tr>
<tr class="even">
<td><blockquote>
<p>Nr instances</p>
</blockquote></td>
<td><blockquote>
<p>n</p>
</blockquote></td>
<td><blockquote>
<p>Speed, Scalability [<a href="#_bookmark272">99</a>]</p>
</blockquote></td>
<td><blockquote>
<p>p/n, log(n), log(n/p)</p>
</blockquote></td>
</tr>
<tr class="odd">
<td><blockquote>
<p>Nr features</p>
</blockquote></td>
<td><blockquote>
<p>p</p>
</blockquote></td>
<td><blockquote>
<p>Curse of dimensionality [<a href="#_bookmark272">99</a>]</p>
</blockquote></td>
<td><blockquote>
<p>log(p), % categorical</p>
</blockquote></td>
</tr>
<tr class="even">
<td><blockquote>
<p>Nr classes</p>
</blockquote></td>
<td><blockquote>
<p>c</p>
</blockquote></td>
<td><blockquote>
<p>Complexity, imbalance [<a href="#_bookmark272">99</a>]</p>
</blockquote></td>
<td><blockquote>
<p>ratio min/maj class</p>
</blockquote></td>
</tr>
<tr class="odd">
<td><blockquote>
<p>Nr missing values</p>
</blockquote></td>
<td><blockquote>
<p>m</p>
</blockquote></td>
<td><blockquote>
<p>Imputation effects [<a href="#_bookmark218">70</a>]</p>
</blockquote></td>
<td><blockquote>
<p>% missing</p>
</blockquote></td>
</tr>
<tr class="even">
<td><blockquote>
<p>Nr outliers</p>
</blockquote></td>
<td><blockquote>
<p>o</p>
</blockquote></td>
<td><blockquote>
<p>Data noisiness <a href="#_bookmark273">[</a> 141<a href="#_bookmark273">]</a></p>
</blockquote></td>
<td><blockquote>
<p>o/n</p>
</blockquote></td>
</tr>
<tr class="odd">
<td><blockquote>
<p>Skewness</p>
</blockquote></td>
<td><blockquote>
<p><img src="./automlgithubpagesimages//media/image78.png" width="42" height="10" /></p>
<p>σ</p>
</blockquote></td>
<td><blockquote>
<p>Feature normality [<a href="#_bookmark272">99</a>]</p>
</blockquote></td>
<td><blockquote>
<p>min,max,μ,σ ,q1 ,q3</p>
</blockquote></td>
</tr>
<tr class="even">
<td><blockquote>
<p>Kurtosis</p>
</blockquote></td>
<td><blockquote>
<p><img src="./automlgithubpagesimages//media/image79.png" width="42" height="10" /></p>
<p>σ</p>
</blockquote></td>
<td><blockquote>
<p>Feature normality [<a href="#_bookmark272">99</a>]</p>
</blockquote></td>
<td><blockquote>
<p>min,max,μ,σ ,q1 ,q3</p>
</blockquote></td>
</tr>
<tr class="odd">
<td><blockquote>
<p>Correlation</p>
</blockquote></td>
<td><blockquote>
<p>ρX1X2</p>
</blockquote></td>
<td><blockquote>
<p>Feature interdependence [<a href="#_bookmark272">99</a>]</p>
</blockquote></td>
<td><blockquote>
<p>min,max,μ,σ ,ρXY <a href="#_bookmark274">[</a>158<a href="#_bookmark274">]</a></p>
</blockquote></td>
</tr>
<tr class="even">
<td><blockquote>
<p>Covariance</p>
</blockquote></td>
<td><blockquote>
<p>covX1X2</p>
</blockquote></td>
<td><blockquote>
<p>Feature interdependence [<a href="#_bookmark272">99</a>]</p>
</blockquote></td>
<td><blockquote>
<p>min,max,μ,σ ,covXY</p>
</blockquote></td>
</tr>
<tr class="odd">
<td><blockquote>
<p>Concentration</p>
</blockquote></td>
<td><blockquote>
<p>τX1X2</p>
</blockquote></td>
<td><blockquote>
<p>Feature interdependence [<a href="#_bookmark255">72</a>]</p>
</blockquote></td>
<td><blockquote>
<p>min,max,μ,σ , τXY</p>
</blockquote></td>
</tr>
<tr class="even">
<td><blockquote>
<p>Sparsity</p>
</blockquote></td>
<td><blockquote>
<p>sparsity(X)</p>
</blockquote></td>
<td><blockquote>
<p>Degree of discreteness [<a href="#_bookmark275">143</a>]</p>
</blockquote></td>
<td><blockquote>
<p>min,max,μ,σ</p>
</blockquote></td>
</tr>
<tr class="odd">
<td><blockquote>
<p>Gravity</p>
</blockquote></td>
<td><blockquote>
<p>gravity(X)</p>
</blockquote></td>
<td><blockquote>
<p>Inter-class dispersion <a href="#_bookmark276">[</a>5<a href="#_bookmark276">]</a></p>
</blockquote></td>
<td></td>
</tr>
<tr class="even">
<td><blockquote>
<p>ANOVA p-value</p>
</blockquote></td>
<td><blockquote>
<p>pvalX1X2</p>
</blockquote></td>
<td><blockquote>
<p>Feature redundancy [<a href="#_bookmark218">70</a>]</p>
</blockquote></td>
<td><blockquote>
<p>pvalXY <a href="#_bookmark274">[</a>158<a href="#_bookmark274">]</a></p>
</blockquote></td>
</tr>
<tr class="odd">
<td><blockquote>
<p>Coeff. of variation</p>
</blockquote></td>
<td><blockquote>
<p>σY</p>
<p>μY</p>
</blockquote></td>
<td><blockquote>
<p>Variation in target <a href="#_bookmark274">[</a>158<a href="#_bookmark274">]</a></p>
</blockquote></td>
<td></td>
</tr>
<tr class="even">
<td><blockquote>
<p>PCA ρλ1</p>
</blockquote></td>
<td><blockquote>
<p>^ <img src="./automlgithubpagesimages//media/image80.png" width="19" height="16" /></p>
</blockquote></td>
<td><blockquote>
<p>Variance in ﬁrst PC <a href="#_bookmark272">[</a>99<a href="#_bookmark272">]</a></p>
</blockquote></td>
<td><blockquote>
<p>λ 1<img src="./automlgithubpagesimages//media/image81.jpeg" />对iλi <a href="#_bookmark272">[</a>99<a href="#_bookmark272">]</a></p>
</blockquote></td>
</tr>
<tr class="odd">
<td><blockquote>
<p>PCA skewness</p>
</blockquote></td>
<td></td>
<td><blockquote>
<p>Skewness of ﬁrst PC <a href="#_bookmark277">[</a>48<a href="#_bookmark277">]</a></p>
</blockquote></td>
<td><blockquote>
<p>PCA kurtosis <a href="#_bookmark277">[</a>48<a href="#_bookmark277">]</a></p>
</blockquote></td>
</tr>
<tr class="even">
<td><blockquote>
<p>PCA 95%</p>
</blockquote></td>
<td><blockquote>
<p>dim95%var</p>
<p>p</p>
</blockquote></td>
<td><blockquote>
<p>Intrinsic dimensionality [<a href="#_bookmark257">9</a>]</p>
</blockquote></td>
<td></td>
</tr>
<tr class="odd">
<td><blockquote>
<p>Class probability</p>
</blockquote></td>
<td><blockquote>
<p>P(C)</p>
</blockquote></td>
<td><blockquote>
<p>Class distribution <a href="#_bookmark272">[</a>99<a href="#_bookmark272">]</a></p>
</blockquote></td>
<td><blockquote>
<p>min,max,μ,σ</p>
</blockquote></td>
</tr>
<tr class="even">
<td><blockquote>
<p>Class entropy</p>
</blockquote></td>
<td><blockquote>
<p>H(C)</p>
</blockquote></td>
<td><blockquote>
<p>Class imbalance <a href="#_bookmark272">[</a>99<a href="#_bookmark272">]</a></p>
</blockquote></td>
<td></td>
</tr>
<tr class="odd">
<td><blockquote>
<p>Norm. entropy</p>
</blockquote></td>
<td><blockquote>
<p>H(X)</p>
<p>log2n</p>
</blockquote></td>
<td><blockquote>
<p>Feature informativeness <a href="#_bookmark249">[</a>26<a href="#_bookmark249">]</a></p>
</blockquote></td>
<td><blockquote>
<p>min,max,μ,σ</p>
</blockquote></td>
</tr>
<tr class="even">
<td><blockquote>
<p>Mutual inform.</p>
</blockquote></td>
<td><blockquote>
<p>MI (C, X)</p>
</blockquote></td>
<td><blockquote>
<p>Feature importance [<a href="#_bookmark272">99</a>]</p>
</blockquote></td>
<td><blockquote>
<p>min,max,μ,σ</p>
</blockquote></td>
</tr>
<tr class="odd">
<td><blockquote>
<p>Uncertainty coeff.</p>
</blockquote></td>
<td><blockquote>
<p>MI (C,X)</p>
<p>H(C)</p>
</blockquote></td>
<td><blockquote>
<p>Feature importance [<a href="#_bookmark278">3</a>]</p>
</blockquote></td>
<td><blockquote>
<p>min,max,μ,σ</p>
</blockquote></td>
</tr>
<tr class="even">
<td><blockquote>
<p>Equiv. nr. feats</p>
</blockquote></td>
<td><blockquote>
<p>H(C)</p>
<p>MI (C,X)</p>
</blockquote></td>
<td><blockquote>
<p>Intrinsic dimensionality [<a href="#_bookmark272">99</a>]</p>
</blockquote></td>
<td></td>
</tr>
<tr class="odd">
<td><blockquote>
<p>Noise-signal ratio</p>
</blockquote></td>
<td><blockquote>
<p>H(X)−MI (C,X)</p>
<p>MI (C,X)</p>
</blockquote></td>
<td><blockquote>
<p>Noisiness of data <a href="#_bookmark272">[</a>99<a href="#_bookmark272">]</a></p>
</blockquote></td>
<td></td>
</tr>
<tr class="even">
<td><blockquote>
<p>Fisher’s discrimin.</p>
</blockquote></td>
<td><blockquote>
<p><img src="./automlgithubpagesimages//media/image82.png" width="43" height="10" /></p>
<p>σ1 −σ</p>
</blockquote></td>
<td><blockquote>
<p>Separability classes c1 ,c2 <a href="#_bookmark279">[</a>64<a href="#_bookmark279">]</a></p>
</blockquote></td>
<td><blockquote>
<p>See <a href="#_bookmark279">[</a>64<a href="#_bookmark279">]</a></p>
</blockquote></td>
</tr>
<tr class="odd">
<td><blockquote>
<p>Volume of overlap</p>
</blockquote></td>
<td></td>
<td><blockquote>
<p>Class distribution overlap [<a href="#_bookmark279">64</a>]</p>
</blockquote></td>
<td><blockquote>
<p>See <a href="#_bookmark279">[</a>64<a href="#_bookmark279">]</a></p>
</blockquote></td>
</tr>
<tr class="even">
<td><blockquote>
<p>Concept variation</p>
</blockquote></td>
<td></td>
<td><blockquote>
<p>Task complexity [<a href="#_bookmark280">180</a>]</p>
</blockquote></td>
<td><blockquote>
<p>See <a href="#_bookmark281">[</a>179<a href="#_bookmark281">,</a> <a href="#_bookmark280">180</a>]</p>
</blockquote></td>
</tr>
<tr class="odd">
<td><blockquote>
<p>Data consistency</p>
</blockquote></td>
<td></td>
<td><blockquote>
<p>Data quality [<a href="#_bookmark282">76</a>]</p>
</blockquote></td>
<td><blockquote>
<p>See <a href="#_bookmark282">[</a>76<a href="#_bookmark282">]</a></p>
</blockquote></td>
</tr>
<tr class="even">
<td><blockquote>
<p>Nr nodes, leaves</p>
</blockquote></td>
<td><blockquote>
<p>|η|, |ψ|</p>
</blockquote></td>
<td><blockquote>
<p>Concept complexity [<a href="#_bookmark283">113</a>]</p>
</blockquote></td>
<td><blockquote>
<p>Tree depth</p>
</blockquote></td>
</tr>
<tr class="odd">
<td><blockquote>
<p>Branch length</p>
</blockquote></td>
<td></td>
<td><blockquote>
<p>Concept complexity [<a href="#_bookmark283">113</a>]</p>
</blockquote></td>
<td><blockquote>
<p>min,max,μ,σ</p>
</blockquote></td>
</tr>
<tr class="even">
<td><blockquote>
<p>Nodes per feature</p>
</blockquote></td>
<td><blockquote>
<p>|ηX |</p>
</blockquote></td>
<td><blockquote>
<p>Feature importance [<a href="#_bookmark283">113</a>]</p>
</blockquote></td>
<td><blockquote>
<p>min,max,μ,σ</p>
</blockquote></td>
</tr>
<tr class="odd">
<td><blockquote>
<p>Leaves per class</p>
</blockquote></td>
<td><table>
<tbody>
<tr class="odd">
<td><blockquote>
<p>ψc|</p>
</blockquote></td>
</tr>
<tr class="even">
<td></td>
</tr>
</tbody>
</table></td>
<td><blockquote>
<p>Class complexity [<a href="#_bookmark284">49</a>]</p>
</blockquote></td>
<td><blockquote>
<p>min,max,μ,σ</p>
</blockquote></td>
</tr>
<tr class="even">
<td><blockquote>
<p>Leaves agreement</p>
</blockquote></td>
<td><blockquote>
<p>nψi</p>
<p>n</p>
</blockquote></td>
<td><blockquote>
<p>Class separability [<a href="#_bookmark285">16</a>]</p>
</blockquote></td>
<td><blockquote>
<p>min,max,μ,σ</p>
</blockquote></td>
</tr>
<tr class="odd">
<td><blockquote>
<p>Information gain</p>
</blockquote></td>
<td></td>
<td><blockquote>
<p>Feature importance [<a href="#_bookmark285">16</a>]</p>
</blockquote></td>
<td><blockquote>
<p>min,max,μ,σ , gini</p>
</blockquote></td>
</tr>
</tbody>
</table>
<p>(continued)</p>
<blockquote>
<p>44 J. Vanschoren</p>
<p><strong>Table</strong> <strong>2.1</strong> (continued)</p>
</blockquote>
<table>
<tbody>
<tr class="odd">
<td><blockquote>
<p>Name</p>
</blockquote></td>
<td><blockquote>
<p>Formula</p>
</blockquote></td>
<td><blockquote>
<p>Rationale</p>
</blockquote></td>
<td><blockquote>
<p>Variants</p>
</blockquote></td>
</tr>
<tr class="even">
<td><blockquote>
<p>Landmarker(1NN)</p>
</blockquote></td>
<td><blockquote>
<p>P(θ 1NN ,tj)</p>
</blockquote></td>
<td><blockquote>
<p>Data sparsity <a href="#_bookmark286">[</a>115<a href="#_bookmark286">]</a></p>
</blockquote></td>
<td><blockquote>
<p>Elite 1NN <a href="#_bookmark286">[</a>115<a href="#_bookmark286">]</a></p>
</blockquote></td>
</tr>
<tr class="odd">
<td><blockquote>
<p>Landmarker(Tree)</p>
</blockquote></td>
<td><blockquote>
<p>P(θTree ,tj)</p>
</blockquote></td>
<td><blockquote>
<p>Data separability <a href="#_bookmark286">[</a>115<a href="#_bookmark286">]</a></p>
</blockquote></td>
<td><blockquote>
<p>Stump,RandomTree</p>
</blockquote></td>
</tr>
<tr class="even">
<td><blockquote>
<p>Landmarker(Lin)</p>
</blockquote></td>
<td><blockquote>
<p>P(θLin ,tj)</p>
</blockquote></td>
<td><blockquote>
<p>Linear separability <a href="#_bookmark286">[</a>115<a href="#_bookmark286">]</a></p>
</blockquote></td>
<td><blockquote>
<p>Lin.Disciminant</p>
</blockquote></td>
</tr>
<tr class="odd">
<td><blockquote>
<p>Landmarker(NB)</p>
</blockquote></td>
<td><blockquote>
<p>P(θNB ,tj)</p>
</blockquote></td>
<td><blockquote>
<p>Feature independence <a href="#_bookmark286">[</a>115<a href="#_bookmark286">]</a></p>
</blockquote></td>
<td><blockquote>
<p>More models <a href="#_bookmark288">[</a> 14<a href="#_bookmark288">,</a> <a href="#_bookmark287">88</a>]</p>
</blockquote></td>
</tr>
<tr class="even">
<td><blockquote>
<p>Relative LM</p>
</blockquote></td>
<td><blockquote>
<p>Pa,j − Pb,j</p>
</blockquote></td>
<td><blockquote>
<p>Probing performance <a href="#_bookmark227">[</a>53<a href="#_bookmark227">]</a></p>
</blockquote></td>
<td></td>
</tr>
<tr class="odd">
<td><blockquote>
<p>Subsample LM</p>
</blockquote></td>
<td><blockquote>
<p>P(θi,tj,st)</p>
</blockquote></td>
<td><blockquote>
<p>Probing performance [<a href="#_bookmark289">160</a>]</p>
</blockquote></td>
<td></td>
</tr>
</tbody>
</table>
<blockquote>
<p>These are trained by feeding the data of two different tasks to two twin networks, and using the differences between the predicted and observed performance Pi,new as the error signal. Since the model parameters between both networks are tied in a Siamese network, two very similar tasks are mapped to the same regions in the latent meta-feature space. They can be used for warm starting Bayesian hyperparameter optimization [<a href="#_bookmark271">75</a>] and neural architecture search [<a href="#_bookmark290">2</a>].</p>
</blockquote>
<p><span id="_bookmark291" class="anchor"></span><em><strong>2.3.3</strong></em> <em><strong>Warm-Starting</strong></em> <em><strong>Optimizationfrom</strong></em> <em><strong>Similar</strong></em> <em><strong>Tasks</strong></em></p>
<blockquote>
<p>Meta-features are a very natural way to estimate task similarity and initialize optimization procedures based on promising conﬁgurations on similar tasks. This is akin to how human experts start a manual search for good models, given experience on related tasks.</p>
<p>First, starting a <em>genetic</em> <em>search</em> algorithm in regions of the search space with promising solutions can signiﬁcantly speed up convergence to a good solution. Gomes et al. [<a href="#_bookmark292">59</a>] recommend initial conﬁgurations by ﬁnding the k most similar prior tasks tj based on the L1 distance between vectors m(tj) and m(tnew), where each m(tj) includes 17 simple and statistical meta-features. For each of the k most similar tasks, the best conﬁguration is evaluated on tnew, and used to initialize a genetic search algorithm (Particle Swarm Optimization), as well as Tabu Search. Reif et al. [<a href="#_bookmark293">129</a>] follow a very similar approach, using 15 simple, statistical, and landmarking meta-features. They use a forward selection technique to ﬁnd the most useful meta-features, and warm-start a standard genetic algorithm (GAlib) with a modiﬁed Gaussian mutation operation. Variants of active testing (see Sect.<a href="#_bookmark211">2.2.3</a>) that use meta-features were also tried [<a href="#_bookmark214">85</a>, <a href="#_bookmark294">100</a>], but did not perform better than the approaches based on relative landmarks.</p>
<p>Also model-based optimization approaches can beneﬁt greatly from an initial set of promising conﬁgurations. SCoT [<a href="#_bookmark257">9</a>] trains a single surrogate ranking model f : M × O → R, predicting the rank of θi on task tj . M contains 4 meta-features (3 simple ones and one based on PCA). The surrogate model is trained on all the rankings, including those on tnew . Ranking is used because the scale of evaluation</p>
<p>2 Meta-Learning 45</p>
</blockquote>
<p>values can differ greatly between tasks. A GP regression converts the ranks to probabilities to do Bayesian optimization, and each new Pi,new is used to retrain the surrogate model after every step.</p>
<p>Schilling et al. [<a href="#_bookmark295">148</a>] use a modiﬁed multilayer perceptron as a surrogate model, of the form sj(θi,m(tj), b(tj)) = Pi,j where m(tj) are the meta-features and b(tj) is a vector of j binary indications which are 1 if the meta-instance is from tj and 0 otherwise. The multi-layer perceptron uses a modiﬁed activation function based on factorization machines [<a href="#_bookmark296">132</a>] in the ﬁrst layer, aimed at learning a latent representation for each task to model task similarities. Since this model cannot represent uncertainties, an ensemble of 100 multilayer perceptrons is trained to get predictive means and simulate variances.</p>
<blockquote>
<p>Training a single surrogate model on all prior meta-data is often less scalable. Yogatama and Mann [<a href="#_bookmark297">190</a>] also build a single Bayesian surrogate model, but only include tasks similar to tnew, where task similarity is deﬁned as the Euclidean distance between meta-feature vectors consisting of 3 simple meta-features. The Pi,j values are standardized to overcome the problem of different scales for each tj . The surrogate model learns a Gaussian process with a speciﬁc kernel combination on all instances.</p>
</blockquote>
<p>Feurer et al. [<a href="#_bookmark277">48</a>] offer a simpler, more scalable method that warm-starts Bayesian optimization by sorting all prior tasks tj similar to [<a href="#_bookmark292">59</a>], but including 46 simple, statistical, and landmarking meta-features, as well as H(C). The t best conﬁgurations on the d most similar tasks are used to warm-start the surrogate model. They search over many more hyperparameters than earlier work, including preprocessing steps. This warm-starting approach was also used in later work [<a href="#_bookmark298">46</a>], which is discussed in detail in Chap.<a href="#_bookmark8">6</a>.</p>
<p>Finally, one can also use <em>collaborative</em> <em>ﬁltering</em> to recommend promising con- ﬁgurations [<a href="#_bookmark299">162</a>]. By analogy, the tasks tj (users) provide ratings (Pi,j) for the conﬁgurations θi (items), and matrix factorization techniques are used to predict unknown Pi,j values and recommend the best conﬁgurations for any task. An important issue here is the cold start problem, since the matrix factorization requires at least some evaluations on tnew . Yang et al. [<a href="#_bookmark300">189</a>] use a D-optimal experiment design to sample an initial set of evaluations Pi,new . They predict both the predictive performance and runtime, to recommend a set of warm-start conﬁgurations that are both accurate and fast. Misir and Sebag [<a href="#_bookmark301">102</a>, <a href="#_bookmark302">103</a>] leverage meta-features to solve the cold start problem. Fusi et al. [<a href="#_bookmark303">54</a>] also use meta-features, following the same procedure as [<a href="#_bookmark298">46</a>], and use a probabilistic matrix factorization approach that</p>
<blockquote>
<p>allows them to perform Bayesian optimization to further optimize their pipeline conﬁgurations θi . This approach yields useful latent embeddings of both the tasks and conﬁgurations, in which the bayesian optimization can be performed more efﬁciently.</p>
<p>46 J. Vanschoren</p>
</blockquote>
<p><em><strong>2.3.4</strong></em> <em><strong>Meta-Models</strong></em></p>
<blockquote>
<p>We can also <em>learn</em> the complex relationship between a task’s meta-features and the</p>
<p>utility of speciﬁc conﬁgurations by building a meta-model L that recommends the</p>
<p>most useful conﬁgurations Oew given the meta-features M of the new task tnew .</p>
<p>There exists a rich body of earlier work [<a href="#_bookmark304">22</a>, <a href="#_bookmark305">56</a>, <a href="#_bookmark306">87</a>, <a href="#_bookmark307">94</a>] on building meta-models</p>
<p>for algorithm selection [<a href="#_bookmark308">15</a>, <a href="#_bookmark309">19</a>, <a href="#_bookmark218">70</a>, <a href="#_bookmark286">115</a>] and hyperparameter recommendation [<a href="#_bookmark310">4</a>,</p>
<p><a href="#_bookmark311">79</a>, <a href="#_bookmark312">108</a>, <a href="#_bookmark274">158</a>]. Experiments showed that boosted and bagged trees often yielded the</p>
<p>best predictions, although much depends on the exact meta-features used [<a href="#_bookmark255">72</a>, <a href="#_bookmark282">76</a>].</p>
<p><strong>2.3.4.1</strong> <strong>Ranking</strong></p>
<p>Meta-models can also generate a <em>ranking</em> of the top-K most promising conﬁgura- tions. One approach is to build a k-nearest neighbor (kNN) meta-model to predict which tasks are similar, and then rank the best conﬁgurations on these similar tasks [<a href="#_bookmark313">23</a>, <a href="#_bookmark266">147</a>]. This is similar to the work discussed in Sect.<a href="#_bookmark291">2.3.3</a>, but without ties to a follow-up optimization approach. Meta-models speciﬁcally meant for ranking, such as predictive clustering trees [<a href="#_bookmark314">171</a>] and label ranking trees [<a href="#_bookmark315">29</a>] were also shown to work well. Approximate Ranking Tree Forests (ART Forests) [<a href="#_bookmark270">165</a>], ensembles of fast ranking trees, prove to be especially effective, since they have ‘built-in’ meta-feature selection, work well even if few prior tasks are available, and the ensembling makes the method more robust. <em>autoBagging</em> [<a href="#_bookmark316">116</a>] ranks Bagging workﬂows including four different Bagging hyperparameters, using an XGBoost- based ranker, trained on 140 OpenML datasets and 146 meta-features. Lorena et al. [<a href="#_bookmark317">93</a>] recommends SVM conﬁgurations for regression problems using a kNN meta- model and a new set of meta-features based on data complexity.</p>
<p><strong>2.3.4.2</strong> <strong>Performance</strong> <strong>Prediction</strong></p>
<p>Meta-models can also directly predict the performance, e.g. accuracy or training time, of a conﬁguration on a given task, given its meta-features. This allows us to estimate whether a conﬁguration will be interesting enough to evaluate in any optimization procedure. Early work used linear regression or rule-base regressors to predict the performance of a discrete set of conﬁgurations and then rank them accordingly [<a href="#_bookmark288">14</a>, <a href="#_bookmark318">77</a>]. Guerra et al. [<a href="#_bookmark319">61</a>] train an SVM meta-regressor per classiﬁcation algorithm to predict its accuracy, under default settings, on a new task tnew given its meta-features. Reif et al. [<a href="#_bookmark251">130</a>] train a similar meta-regressor on more meta-data to predict its <em>optimized</em> performance. Davis et al. [<a href="#_bookmark320">32</a>] use a MultiLayer Perceptron based meta-learner instead, predicting the performance of a speciﬁc algorithm conﬁguration.</p>
<p>Instead of predicting predictive performance, a meta-regressor can also be trained to predict algorithm training/prediction time, for instance, using an SVM regressor</p>
<p>2 Meta-Learning 47</p>
<p>trained on meta-features [<a href="#_bookmark321">128</a>], itself tuned via genetic algorithms [<a href="#_bookmark322">119</a>]. Yang et al. [<a href="#_bookmark300">189</a>] predict conﬁguration runtime using polynomial regression, based only on the number of instances and features. Hutter et al. [<a href="#_bookmark323">68</a>] provide a general treatise on predicting algorithm runtime in various domains.</p>
<p>Most of these meta-models generate promising conﬁgurations, but don’t actually tune these conﬁgurations to tnew themselves. Instead, the predictions can be used to warm-start or guide any other optimization technique, which allows for all kinds of combinations of meta-models and optimization techniques. Indeed, some of the work discussed in Sect.<a href="#_bookmark291">2.3.3</a>can be seen as using a distance-based meta-model to warm-start Bayesian optimization [<a href="#_bookmark277">48</a>, <a href="#_bookmark303">54</a>] or evolutionary algorithms [<a href="#_bookmark292">59</a>, <a href="#_bookmark293">129</a>]. In principle, other meta-models could be used here as well.</p>
<p>Instead of learning the relationship between a task’s meta-features and conﬁgu- ration performance, one can also build surrogate models predicting the performance of conﬁgurations on speciﬁc tasks [<a href="#_bookmark324">40</a>]. One can then learn how to combine these per-task predictions to warm-start or guide optimization techniques on a new task tnew [<a href="#_bookmark230">45</a>, <a href="#_bookmark233">114</a>, <a href="#_bookmark236">161</a>, <a href="#_bookmark228">187</a>], as discussed in Sect.<a href="#_bookmark211">2.2.3</a>. While meta-features could also be used to combine per-task predictions based on task similarity, it is ultimately more effective to gather new observations Pi,new, since these allow us to reﬁne the task similarity estimates with every new observation [<a href="#_bookmark325">47</a>, <a href="#_bookmark214">85</a>, <a href="#_bookmark228">187</a>].</p>
</blockquote>
<p><em><strong>2.3.5</strong></em> <em><strong>Pipeline</strong></em> <em><strong>Synthesis</strong></em></p>
<blockquote>
<p>When creating entire machine learning pipelines [<a href="#_bookmark326">153</a>], the number of conﬁguration options grows dramatically, making it even more important to leverage prior experience. One can control the search space by imposing a ﬁxed structure on the pipeline, fully described by a set of hyperparameters. One can then use the most promising pipelines on similar tasks to warm-start a Bayesian optimization [<a href="#_bookmark298">46</a>,<a href="#_bookmark303">54</a>].</p>
<p>Other approaches give recommendations for certain pipeline steps [<a href="#_bookmark327">118</a>, <a href="#_bookmark328">163</a>], and can be leveraged in larger pipeline construction approaches, such as planning [<a href="#_bookmark329">55</a>, <a href="#_bookmark330">74</a>, <a href="#_bookmark331">105</a>, <a href="#_bookmark332">184</a>] or evolutionary techniques [<a href="#_bookmark333">110</a>, <a href="#_bookmark334">164</a>]. Nguyen et al. [<a href="#_bookmark331">105</a>] con- struct new pipelines using a beam search focussed on components recommended by a meta-learner, and is itself trained on examples of successful prior pipelines. Bilalli et al. [<a href="#_bookmark335">18</a>] predict which pre-processing techniques are recommended for a given classiﬁcation algorithm. They build a meta-model per target classiﬁcation algorithm that, given the tnew meta-features, predicts which preprocessing technique should be included in the pipeline. Similarly, Schoenfeld et al. [<a href="#_bookmark336">152</a>] build meta-models predicting when a preprocessing algorithm will improve a particular classiﬁer’s accuracy or runtime.</p>
<p>AlphaD3M [<a href="#_bookmark337">38</a>] uses a <em>self-play</em> reinforcement learning approach in which the current state is represented by the current pipeline, and actions include the addition, deletion, or replacement of pipeline components. A Monte Carlo Tree Search (MCTS) generates pipelines, which are evaluated to train a recurrent neural network (LSTM) that can predict pipeline performance, in turn producing the action</p>
<p>48 J. Vanschoren</p>
<p>probabilities for the MCTS in the next round. The state description also includes meta-features of the current task, allowing the neural network to learn across tasks. Mosaic [<a href="#_bookmark338">123</a>] also generates pipelines using MCTS, but instead uses a bandits-based approach to select promising pipelines.</p>
</blockquote>
<p><em><strong>2.3.6</strong></em> <em><strong>To</strong></em> <em><strong>Tune</strong></em> <em><strong>or</strong></em> <em><strong>Not</strong></em> <em><strong>to</strong></em> <em><strong>Tune?</strong></em></p>
<blockquote>
<p>To reduce the number of conﬁguration parameters to be optimized, and to save valuable optimization time in time-constrained settings, meta-models have also been proposed to predict whether or not it is worth tuning a given algorithm <em>given</em> <em>the</em> <em>meta-features</em> <em>of</em> <em>the</em> <em>task</em> <em>at</em> <em>hand</em> [<a href="#_bookmark339">133</a>] and how much improvement we can expect from tuning a speciﬁc algorithm versus the additional time investment [<a href="#_bookmark340">144</a>]. More focused studies on speciﬁc learning algorithms yielded meta-models predicting when it is necessary to tune SVMs [<a href="#_bookmark341">96</a>], what are good default hyperparameters for SVMs given the task (including interpretable meta-models) [<a href="#_bookmark342">97</a>], and how to tune decision trees [<a href="#_bookmark343">95</a>].</p>
<p><span id="_bookmark202" class="anchor"></span><strong>2.4</strong> <strong>Learning</strong> <strong>from</strong> <strong>Prior</strong> <strong>Models</strong></p>
<p>The ﬁnal type of meta-data we can learn from are prior machine learning models themselves, i.e., their structure and learned model parameters. In short, we want to train a <em>meta-learner</em> L that learns how to train a (base-) learner lnew for a new task tnew, given similar tasks tj ∈ T and the corresponding optimized models lj ∈ L, where L is the space of all possible models. The learner lj is typically deﬁned by its model parameters W = {wk}, k = 1 . . . K and/or its conﬁguration θi ∈ O.</p>
</blockquote>
<p><em><strong>2.4.1</strong></em> <em><strong>Transfer</strong></em> <em><strong>Learning</strong></em></p>
<blockquote>
<p>In <em>transfer</em> <em>learning</em> [<a href="#_bookmark344">170</a>], we take models trained on one or more <em>source</em> tasks tj , and use them as starting points for creating a model on a similar <em>target</em> task tnew . This can be done by forcing the target model to be structurally or otherwise similar to the source model(s). This is a generally applicable idea, and transfer learning approaches have been proposed for kernel methods [<a href="#_bookmark345">41</a>, <a href="#_bookmark346">42</a>], parametric Bayesian models [<a href="#_bookmark347">8</a>, <a href="#_bookmark348">122</a>, <a href="#_bookmark349">140</a>], Bayesian networks [<a href="#_bookmark350">107</a>], clustering [<a href="#_bookmark351">168</a>] and reinforcement learning [<a href="#_bookmark352">36</a>, <a href="#_bookmark353">62</a>]. Neural networks, however, are exceptionally suitable for transfer learning because both the structure and the model parameters of the source models can be used as a good initialization for the target model, yielding a <em>pre-trained</em> model which can then be further ﬁne-tuned using the available training data on tnew [<a href="#_bookmark354">11</a>, <a href="#_bookmark355">13</a>, <a href="#_bookmark356">24</a>, <a href="#_bookmark357">169</a>]. In some cases, the source network may need to be modiﬁed before transferring it [<a href="#_bookmark358">155</a>]. We will focus on neural networks in the remainder of this section.</p>
<p>2 Meta-Learning 49</p>
<p>Especially large image datasets, such as ImageNet [<a href="#_bookmark359">78</a>], have been shown to yield pre-trained models that transfer exceptionally well to other tasks [<a href="#_bookmark360">37</a>,<a href="#_bookmark361">154</a>]. However, it has also been shown that this approach doesn’t work well when the target task is not so similar [<a href="#_bookmark362">191</a>]. Rather than hoping that a pre-trained model ‘accidentally’ transfers well to a new problem, we can purposefully imbue meta-learners with an inductive bias (learned from many similar tasks) that allows them to learn new tasks much faster, as we will discuss below.</p>
</blockquote>
<p><em><strong>2.4.2</strong></em> <em><strong>Meta-Learning</strong></em> <em><strong>in</strong></em> <em><strong>Neural</strong></em> <em><strong>Networks</strong></em></p>
<blockquote>
<p>An early meta-learning approach is to create recurrent neural networks (RNNs) able to modify their own weights [<a href="#_bookmark363">149</a>, <a href="#_bookmark364">150</a>]. During training, they use their own weights as additional input data and observe their own errors to learn how to modify these weights in response to the new task at hand. The updating of the weights is deﬁned in a parametric form that is differentiable end-to-end and can jointly optimize both the network and training algorithm using gradient descent, yet is also very difﬁcult to train. Later work used reinforcement learning across tasks to adapt the search strategy [<a href="#_bookmark365">151</a>] or the learning rate for gradient descent [<a href="#_bookmark366">31</a>] to the task at hand.</p>
<p>Inspired by the feeling that backpropagation is an unlikely learning mechanism for our own brains, Bengio et al. [<a href="#_bookmark367">12</a>] replace backpropagation with simple biologically-inspired parametric rules (or evolved rules [<a href="#_bookmark368">27</a>]) to update the synaptic weights. The parameters are optimized, e.g. using gradient descent or evolution, across a set of input tasks. Runarsson and Jonsson [<a href="#_bookmark369">142</a>] replaced these parametric rules with a single layer neural network. Santoro et al. [<a href="#_bookmark370">146</a>] instead use a memory- augmented neural network to learn how to store and retrieve ‘memories’ of prior classiﬁcation tasks. Hochreiter et al. [<a href="#_bookmark371">65</a>] use LSTMs [<a href="#_bookmark372">66</a>] as a meta-learner to train multi-layer perceptrons.</p>
<p>Andrychowicz et al. [<a href="#_bookmark373">6</a>] also replace the optimizer, e.g. stochastic gradient descent, with an LSTM trained on multiple prior tasks. The loss of the meta-learner (optimizer) is deﬁned as the sum of the losses of the base-learners (optimizees), and optimized using gradient descent. At every step, the meta-learner chooses the weight update estimated to reduce the optimizee’s loss the most, based on the learned model weights {wk} of the previous step as well as the current performance gradient. Later work generalizes this approach by training an optimizer on synthetic functions, using gradient descent [<a href="#_bookmark374">28</a>]. This allows meta-learners to optimize optimizees even if these do not have access to gradients.</p>
<p>In parallel, Li and Malik [<a href="#_bookmark375">89</a>] proposed a framework for learning optimization algorithms from a reinforcement learning perspective. It represents any particular optimization algorithm as a policy, and then learns this policy via guided policy search. Follow-up work [<a href="#_bookmark376">90</a>] shows how to leverage this approach to learn opti- mization algorithms for (shallow) neural networks.</p>
<p>The ﬁeld of <em>neural</em> <em>architecture</em> <em>search</em> includes many other methods that build a model of neural network performance for a speciﬁc task, for instance using Bayesian</p>
<p>50 J. Vanschoren</p>
<p>optimization or reinforcement learning. See Chap.<a href="#_bookmark4">3</a> for an in-depth discussion. However, most of these methods do not (yet) generalize across tasks and are therefore not discussed here.</p>
<p><em><strong>2.4.3</strong></em> <em><strong>Few-Shot</strong></em> <em><strong>Learning</strong></em></p>
</blockquote>
<p>A particularly challenging meta-learning problem is to train an accurate deep learning model using only a few training examples, given prior experience with very similar tasks for which we have large training sets available. This is called <em>few-shot</em> <em>learning</em>. Humans have an innate ability to do this, and we wish to build machine learning agents that can do the same [<a href="#_bookmark197">82</a>]. A particular example of this is ‘K-shot N-way’ classiﬁcation, in which we are given many examples (e.g., images)</p>
<blockquote>
<p>of certain classes (e.g., objects), and want to learn a classiﬁer lnew able to classify N new classes using only K examples of each.</p>
<p>Using prior experience, we can, for instance, learn a common feature represen- tation of all the tasks, start training lnew with a better model parameter initialization Winit and acquire an inductive bias that helps guide the optimization of the model parameters, so that lnew can be trained much faster than otherwise possible.</p>
<p>Earlier work on <em>one-shot</em> learning is largely based on hand-engineered features [<a href="#_bookmark377">10</a>, <a href="#_bookmark378">43</a>, <a href="#_bookmark379">44</a>, <a href="#_bookmark380">50</a>]. With meta-learning, however, we hope to learn a common feature representation for all tasks in an end-to-end fashion.</p>
<p>Vinyals et al. [<a href="#_bookmark381">181</a>] state that, to learn from very little data, one should look to non-parameteric models (such as k-nearest neighbors), which use a memory component rather than learning many model parameters. Their meta-learner is a Matching Network that applies the idea of a memory component in a neural net. It learns a common representation for the labelled examples, and <em>matches</em> each new test instance to the memorized examples using cosine similarity. The network is trained on minibatches with only a few examples of a speciﬁc task each.</p>
<p>Snell et al. [<a href="#_bookmark382">157</a>] propose Prototypical Networks, which map examples to a p- dimensional vector space such that examples of a given output class are close together. It then calculates a prototype (mean vector) for every class. New test instances are mapped to the same vector space and a distance metric is used to create a softmax over all possible classes. Ren et al. [<a href="#_bookmark383">131</a>] extend this approach to semi-supervised learning.</p>
<p>Ravi and Larochelle [<a href="#_bookmark204">126</a>] use an LSTM-based meta-learner to learn an update rule for training a neural network learner. With every new example, the learner returns the current gradient and loss to the LSTM meta-learner, which then updates the model parameters {wk} of the learner. The meta-learner is trained across all prior tasks.</p>
<p>Model-Agnostic Meta-Learning (MAML) [<a href="#_bookmark384">51</a>], on the other hand, does not try to learn an update rule, but instead learns a model parameter initialization Winit that generalizes better to similar tasks. Starting from a random {wk}, it iteratively selects a batch of prior tasks, and for each it trains the learner on K examples to compute the</p>
<p>2 Meta-Learning 51</p>
<p>gradient and loss (on a test set). It then backpropagates the <em>meta-gradient</em> to update the weights {wk} in the direction in which they would have been easier to update. In other words, after each iteration, the weights {wk} become a better Winit to start ﬁnetuning any of the tasks. Finn and Levine [<a href="#_bookmark385">52</a>] also argue that MAML is able to approximate any learning algorithm when using a sufﬁciently deep fully connected ReLU network and certain losses. They also conclude that the MAML initializations are more resilient to overﬁtting on small samples, and generalize more widely than meta-learning approaches based on LSTMs.</p>
<p>REPTILE [<a href="#_bookmark386">106</a>] is an approximation of MAML that executes stochastic gradient descent for K iterations on a given task, and then gradually moves the initialization weights in the direction of the weights obtained after the K iterations. The intuition is that every task likely has more than one set of optimal weights {w}, and the goal is to ﬁnd a Winit that is close to at least one of those {w} for every task.</p>
<p>Finally, we can also derive a meta-learner from a black-box neural network. Santoro et al. [<a href="#_bookmark387">145</a>] propose Memory-Augmented Neural Networks (MANNs), which train a Neural Turing Machine (NTM) [<a href="#_bookmark388">60</a>], a neural network with augmented memory capabilities, as a meta-learner. This meta-learner can then memorize information about previous tasks and leverage that to learn a learner lnew . SNAIL [<a href="#_bookmark389">101</a>] is a generic meta-learner architecture consisting of interleaved temporal con- volution and causal attention layers. The convolutional networks learn a common feature vector for the training instances (images) to aggregate information from past experiences. The causal attention layers learn which pieces of information to pick out from the gathered experience to generalize to new tasks.</p>
<p>Overall, the intersection of deep learning and meta-learning proves to be particular fertile ground for groundbreaking new ideas, and we expect this ﬁeld to become more important over time.</p>
</blockquote>
<p><em><strong>2.4.4</strong></em> <em><strong>Beyond</strong></em> <em><strong>Supervised</strong></em> <em><strong>Learning</strong></em></p>
<blockquote>
<p>Meta-learning is certainly not limited to (semi-)supervised tasks, and has been successfully applied to solve tasks as varied as reinforcement learning, active learning, density estimation and item recommendation. The base-learner may be unsupervised while the meta-learner is supervised, but other combinations are certainly possible as well.</p>
<p>Duan et al. [<a href="#_bookmark390">39</a>] propose an end-to-end reinforcement learning (RL) approach consisting of a task-speciﬁc<em>fast</em> RL algorithm which is guided by a general-purpose <em>slow</em> meta-RL algorithm. The tasks are interrelated Markov Decision Processes (MDPs). The meta-RL algorithm is modeled as an RNN, which receives the observations, actions, rewards and termination ﬂags. The activations of the RNN store the state of the fast RL learner, and the RNN’s weights are learned by observing the performance of fast learners across tasks.</p>
<p>In parallel, Wang et al. [<a href="#_bookmark391">182</a>] also proposed to use a deep RL algorithm to train an RNN, receiving the actions and rewards of the previous interval in order</p>
<p><span id="_bookmark15" class="anchor"></span>52 J. Vanschoren</p>
<p>to learn a base-level RL algorithm for speciﬁc tasks. Rather than using relatively unstructured tasks such as random MDPs, they focus on structured task distributions (e.g., dependent bandits) in which the meta-RL algorithm can exploit the inherent task structure.</p>
</blockquote>
<p>Pang et al. [<a href="#_bookmark392">112</a>] offer a meta-learning approach to active learning (AL). The base-learner can be any binary classiﬁer, and the meta-learner is a deep RL network consisting of a deep neural network that learns a representation of the AL problem across tasks, and a policy network that learns the optimal policy, parameterized as weights in the network. The meta-learner receives the current state (the unlabeled point set and base classiﬁer state) and reward (the performance of the base classiﬁer), and emits a query probability, i.e. which points in the unlabeled set to query next.</p>
<p>Reed et al. [<a href="#_bookmark393">127</a>] propose a few-shot approach for density estimation (DE). The goal is to learn a probability distribution over a small number of images of a certain concept (e.g., a handwritten letter) that can be used to generate images of that concept, or compute the probability that an image shows that concept. The approach uses autoregressive image models which factorize the joint distribution into per- pixel factors. Usually these are conditioned on (many) examples of the target concept. Instead, a MAML-based few-shot learner is used, trained on examples of many other (similar) concepts.</p>
<blockquote>
<p>Finally, Vartak et al. [<a href="#_bookmark394">178</a>] address the cold-start problem in matrix factorization. They propose a deep neural network architecture that learns a (base) neural network whose biases are adjusted based on task information. While the structure and weights of the neural net recommenders remain ﬁxed, the meta-learner learns how to adjust the biases based on each user’s item history.</p>
</blockquote>
<p>All these recent new developments illustrate that it is often fruitful to look at problems through a <em>meta-learning</em> <em>lens</em> and ﬁnd new, data-driven approaches to replace hand-engineered base-learners.</p>
<blockquote>
<p><strong>2.5</strong> <strong>Conclusion</strong></p>
</blockquote>
<p>Meta-learning opportunities present themselves in many different ways, and can be embraced using a wide spectrum of learning techniques. Every time we try to learn a certain task, whether successful or not, we gain useful experience that we can leverage to learn new tasks. We should never have to start entirely from scratch. Instead, we should systematically collect our ‘learning experiences’ and learn from them to build AutoML systems that continuously improve over time, helping us tackle new learning problems ever more efﬁciently. The more new tasks we encounter, and the more similar those new tasks are, the more we can tap into prior experience, to the point that most of the required learning has already been done beforehand. The ability of computer systems to store virtually inﬁnite amounts of prior learning experiences (in the form of meta-data) opens up a wide range of opportunities to use that experience in completely new ways, and we are only</p>
<blockquote>
<p>2 Meta-Learning 53</p>
<p>starting to learn how to learn from prior experience effectively. Yet, this is a worthy goal: learning how to learn any task empowers us far beyond knowing how to learn any speciﬁc task.</p>
</blockquote>
<p><strong>Acknowledgements</strong> The author would like to thank Pavel Brazdil, Matthias Feurer, Frank Hutter, Raghu Rajan, Erin Grant, Hugo Larochelle, Jan van Rijn and Jane Wang for many invaluable discussions and feedback on the manuscript.</p>
<blockquote>
<p><span id="_bookmark216" class="anchor"></span><strong>Bibliography</strong></p>
<p>1. Abdulrahman, S., Brazdil, P., van Rijn, J., Vanschoren, J.: Speeding up Algorithm Selection using Average Ranking and Active Testing by Introducing Runtime. Machine Learning 107, <span id="_bookmark290" class="anchor"></span>79– 108 (2018)</p>
<p>2. Aﬁf, I.N.: Warm-Starting Deep Learning Model Construction using Meta-Learning. Master’s <span id="_bookmark278" class="anchor"></span>thesis, TU Eindhoven (2018)</p>
<p><span id="_bookmark310" class="anchor"></span>3. Agresti, A.: Categorical Data Analysis. Wiley Interscience (2002)</p>
<p>4. Ali, S., Smith-Miles, K.A.: Metalearning approach to automatic kernel selection for support <span id="_bookmark276" class="anchor"></span>vector machines. Neurocomputing 70(1), 173– 186 (2006)</p>
<p>5. Ali, S., Smith-Miles, K.A.: On learning algorithm selection for classiﬁcation. Applied Soft <span id="_bookmark373" class="anchor"></span>Computing 6(2), 119– 138 (2006)</p>
<p>6. Andrychowicz, M., Denil, M., Gomez, S., Hoffman, M.W., Pfau, D., Schaul, T., Shillingford, B., De Freitas, N.: Learning to learn by gradient descent by gradient descent. In: Advances in Neural Information Processing Systems. pp. 3981–3989 (2016)</p>
<p>7. Arinze, B.: Selecting appropriate forecasting models using rule induction. Omega 22(6), 647– <span id="_bookmark264" class="anchor"><span id="_bookmark347" class="anchor"></span></span>658 (1994)</p>
<p>8. Bakker, B., Heskes, T.: Task Clustering and Gating for Bayesian Multitask Learning. Journal <span id="_bookmark257" class="anchor"></span>of Machine Learning Research 4, 83–999 (2003)</p>
<p>9. Bardenet, R., Brendel, M., Kégl, B., Sebag, M.: Collaborative hyperparameter tuning. In: <span id="_bookmark377" class="anchor"></span>Proceedings of ICML 2013. pp. 199–207 (2013)</p>
<p>10. Bart, E., Ullman, S.: Cross-generalization: Learning novel classes from a single example by feature replacement. In: Proceedings of CVPR 2005. pp. 672–679 (2005)</p>
<p>11. Baxter, J.: Learning Internal Representations. In: Advances in Neural Information Processing <span id="_bookmark354" class="anchor"><span id="_bookmark367" class="anchor"></span></span>Systems, NeurIPS (1996)</p>
<p>12. Bengio, S., Bengio, Y., Cloutier, J.: On the search for new learning rules for anns. Neural <span id="_bookmark355" class="anchor"></span>Processing Letters 2(4), 26–30 (1995)</p>
<p>13. Bengio, Y.: Deep learning of representations for unsupervised and transfer learning. In: ICML <span id="_bookmark288" class="anchor"></span>Workshop on Unsupervised and Transfer Learning. pp. 17–36 (2012)</p>
<p>14. Bensusan, H., Kalousis, A.: Estimating the predictive accuracy of a classiﬁer. Lecture Notes <span id="_bookmark308" class="anchor"></span>in Computer Science 2167, 25–36 (2001)</p>
<p>15. Bensusan, H., Giraud-Carrier, C.: Discovering task neighbourhoods through landmark learn- ing performances. In: Proceedings of PKDD 2000. pp. 325–330 (2000)</p>
<p><span id="_bookmark285" class="anchor"></span>16. Bensusan, H., Giraud-Carrier, C., Kennedy, C.: A higher-order approach to meta-learning. In: <span id="_bookmark254" class="anchor"></span>Proceedings of ILP 2000. pp. 33–42 (2000)</p>
<p>17. Bilalli, B., Abelló, A., Aluja-Banet, T.: On the predictive power of meta-features in OpenML. International Journal of Applied Mathematics and Computer Science 27(4), 697–712 (2017)</p>
<p><span id="_bookmark335" class="anchor"></span>18. Bilalli, B., Abelló, A., Aluja-Banet, T., Wrembel, R.: Intelligent assistance for data pre- <span id="_bookmark309" class="anchor"></span>processing. Computer Standards and Interfaces 57, 101– 109 (2018)</p>
<p>19. Bischl, B., Kerschke, P., Kotthoff, L., Lindauer, M., Malitsky, Y., Fréchette, A., Hoos, H., Hutter, F., Leyton-Brown, K., Tierney, K., Vanschoren, J.: ASLib: A benchmark library for algorithm selection. Artiﬁcial Intelligence 237, 41–58 (2016)</p>
<p><span id="_bookmark234" class="anchor"></span>20. Bishop, C.M.: Pattern recognition and machine learning. Springer (2006)</p>
</blockquote>
<p>54 J. Vanschoren</p>
<blockquote>
<p><span id="_bookmark212" class="anchor"></span>21. Brazdil, P., Soares, C., da Costa, J.P.: Ranking learning algorithms: Using IBL and meta- <span id="_bookmark304" class="anchor"></span>learning on accuracy and time results. Machine Learning 50(3), 251–277 (2003)</p>
<p>22. Brazdil, P., Giraud-Carrier, C., Soares, C., Vilalta, R.: Metalearning: Applications to Data <span id="_bookmark313" class="anchor"></span>Mining. Springer-Verlag Berlin Heidelberg (2009)</p>
<p>23. Brazdil, P.B., Soares, C., Da Coasta, J.P.: Ranking learning algorithms: Using IBL and meta- <span id="_bookmark356" class="anchor"></span>learning on accuracy and time results. Machine Learning 50(3), 251–277 (2003)</p>
<p>24. Caruana, R.: Learning many related tasks at the same time with backpropagation. Neural <span id="_bookmark205" class="anchor"></span>Information Processing Systems pp. 657–664 (1995)</p>
<p><span id="_bookmark249" class="anchor"></span>25. Caruana, R.: Multitask Learning. Machine Learning 28(1), 41–75 (1997)</p>
<p>26. Castiello, C., Castellano, G., Fanelli, A.M.: Meta-data: Characterization of input features for meta-learning. In: 2nd International Conference on Modeling Decisions for Artiﬁcial <span id="_bookmark368" class="anchor"></span>Intelligence (MDAI). pp. 457–468 (2005)</p>
<p>27. Chalmers, D.J.: The evolution of learning: An experiment in genetic connectionism. In: <span id="_bookmark374" class="anchor"></span>Connectionist Models, pp. 81–90. Elsevier (1991)</p>
<p>28. Chen, Y., Hoffman, M.W., Colmenarejo, S.G., Denil, M., Lillicrap, T.P., Botvinick, M., de Freitas, N.: Learning to learn without gradient descent by gradient descent. In: Proceedings <span id="_bookmark315" class="anchor"></span>of ICML 2017, PMLR 70, pp. 748–756 (2017)</p>
<p>29. Cheng, W., Hühn, J., Hüllermeier, E.: Decision tree and instance-based learning for label <span id="_bookmark220" class="anchor"></span>ranking. In: Proceedings of ICML 2009. pp. 161– 168 (2009)</p>
<p>30. Cook, W.D., Kress, M., Seiford, L.W.: A general framework for distance-based consensus in ordinal ranking models. European Journal of Operational Research 96(2), 392–397 (1996)</p>
<p><span id="_bookmark366" class="anchor"></span>31. Daniel, C., Taylor, J., Nowozin, S.: Learning step size controllers for robust neural network <span id="_bookmark320" class="anchor"></span>training. In: Proceedings of AAAI 2016. pp. 1519– 1525 (2016)</p>
<p>32. Davis, C., Giraud-Carrier, C.: Annotative experts for hyperparameter selection. In: AutoML <span id="_bookmark222" class="anchor"></span>Workshop at ICML 2018 (2018)</p>
<p>33. De Sa, A., Pinto, W., Oliveira, L.O., Pappa, G.: RECIPE: A grammar-based framework for automatically evolving classiﬁcation pipelines. In: European Conference on Genetic <span id="_bookmark213" class="anchor"></span>Programming. pp. 246–261 (2017)</p>
<p>34. Demšar, J.: Statistical Comparisons of Classiﬁers over Multiple Data Sets. Journal of Machine <span id="_bookmark206" class="anchor"></span>Learning Research 7, 1–30 (2006)</p>
<p>35. Dietterich, T.: Ensemble methods in machine learning. In: International workshop on multiple <span id="_bookmark352" class="anchor"></span>classiﬁer systems. pp. 1– 15 (2000)</p>
<p>36. Dietterich, T., Busquets, D., Lopez de Mantaras, R., Sierra, C.: Action Reﬁnement in Reinforcement Learning by Probability Smoothing. In: 19th International Conference on <span id="_bookmark360" class="anchor"></span>Machine Learning. pp. 107– 114 (2002)</p>
<p>37. Donahue, J., Jia, Y., Vinyals, O., Hoffman, J., Zhang, N., Tzeng, E., Darrell, T.: DeCAF: A deep convolutional activation feature for generic visual recognition. In: Proceedings of ICML</p>
<p><span id="_bookmark337" class="anchor"></span>2014. pp. 647–655 (2014)</p>
<p>38. Drori, I., Krishnamurthy, Y., Rampin, R., de Paula Lourenco, R., Ono, J.P., Cho, K., Silva, C., Freire, J.: AlphaD3M: Machine learning pipeline synthesis. In: AutoML Workshop at ICML</p>
<p><span id="_bookmark390" class="anchor"></span>(2018)</p>
<p>39. Duan, Y., Schulman, J., Chen, X., Bartlett, P.L., Sutskever, I., Abbeel, P.: RL2: Fast reinforcement learning via slow reinforcement learning. arXiv preprint arXiv:1611.02779</p>
<p><span id="_bookmark324" class="anchor"></span>(2016)</p>
<p>40. Eggensperger, K., Lindauer, M., Hoos, H., Hutter, F., Leyton-Brown, K.: Efﬁcient Bench- marking of Algorithm Conﬁguration Procedures via Model-Based Surrogates . Machine <span id="_bookmark345" class="anchor"></span>Learning 107, 15–41 (2018)</p>
<p>41. Evgeniou, T., Micchelli, C., Pontil, M.: Learning Multiple Tasks with Kernel Methods. <span id="_bookmark346" class="anchor"></span>Journal of Machine Learning Research 6, 615–637 (2005)</p>
<p>42. Evgeniou, T., Pontil, M.: Regularized multi-task learning. In: Tenth Conference on Knowl- <span id="_bookmark378" class="anchor"></span>edge Discovery and Data Mining (2004)</p>
<p>43. Fei-Fei, L.: Knowledge transfer in learning to recognize visual objects classes. In: Interna- <span id="_bookmark379" class="anchor"></span>tional Conference on Development and Learning. Art. 51 (2006)</p>
<p>44. Fei-Fei, L., Fergus, R., Perona, P.: One-shot learning of object categories. Pattern analysis and machine intelligence 28(4), 594–611 (2006)</p>
</blockquote>
<p>2 Meta-Learning 55</p>
<blockquote>
<p>45. Feurer, M., Letham, B., Bakshy, E.: Scalable meta-learning for Bayesian optimization. arXiv</p>
<p><span id="_bookmark298" class="anchor"><span id="_bookmark230" class="anchor"></span></span>1802.02219 (2018)</p>
<p>46. Feurer, M., Klein, A., Eggensperger, K., Springenberg, J., Blum, M., Hutter, F.: Efﬁcient and robust automated machine learning. In: Advances in Neural Information Processing Systems</p>
<p><span id="_bookmark325" class="anchor"></span>28. pp. 2944–2952 (2015)</p>
<p>47. Feurer, M., Letham, B., Bakshy, E.: Scalable meta-learning for Bayesian optimization using ranking-weighted gaussian process ensembles. In: AutoML Workshop at ICML 2018 (2018)</p>
<p><span id="_bookmark277" class="anchor"></span>48. Feurer, M., Springenberg, J.T., Hutter, F.: Using meta-learning to initialize Bayesian opti- mization of hyperparameters. In: International Conference on Metalearning and Algorithm <span id="_bookmark284" class="anchor"></span>Selection. pp. 3– 10 (2014)</p>
<p>49. Filchenkov, A., Pendryak, A.: Dataset metafeature description for recommending feature <span id="_bookmark380" class="anchor"></span>selection. In: Proceedings of AINL-ISMW FRUCT 2015. pp. 11– 18 (2015)</p>
<p>50. Fink, M.: Object classiﬁcation from a single example utilizing class relevance metrics. In: Advances in Neural information processing systems, NeurIPS 2005. pp. 449–456 (2005)</p>
<p><span id="_bookmark384" class="anchor"></span>51. Finn, C., Abbeel, P., Levine, S.: Model-agnostic meta-learning for fast adaptation of deep <span id="_bookmark385" class="anchor"></span>networks. In: Proceedings of ICML 2017. pp. 1126– 1135 (2017)</p>
<p>52. Finn, C., Levine, S.: Meta-learning and universality: Deep representations and Gradient Descent can Approximate any Learning Algorithm. In: Proceedings of ICLR 2018 (2018)</p>
<p><span id="_bookmark227" class="anchor"></span>53. Fürnkranz, J., Petrak, J.: An evaluation of landmarking variants. ECML/PKDD 2001 Work- shop on Integrating Aspects of Data Mining, Decision Support and Meta-Learning pp. 57–68</p>
<p><span id="_bookmark303" class="anchor"></span>(2001)</p>
<p>54. Fusi, N., Sheth, R., Elibol, H.M.: Probabilistic matrix factorization for automated machine learning. In: Advances in Neural information processing systems, NeurIPS 2018, pp. 3352– <span id="_bookmark329" class="anchor"></span>3361 (2018)</p>
<p>55. Gil, Y., Yao, K.T., Ratnakar, V., Garijo, D., Ver Steeg, G., Szekely, P., Brekelmans, R., Kejriwal, M., Luo, F., Huang, I.H.: P4ML: A phased performance-based pipeline planner for automated machine learning. In: AutoML Workshop at ICML 2018 (2018)</p>
<p><span id="_bookmark305" class="anchor"></span>56. Giraud-Carrier, C.: Metalearning-a tutorial. In: Tutorial at the International Conference on <span id="_bookmark198" class="anchor"></span>Machine Learning and Applications. pp. 1–45 (2008)</p>
<p>57. Giraud-Carrier, C., Provost, F.: Toward a justiﬁcation of meta-learning: Is the no free lunch theorem a show-stopper. In: Proceedings of the ICML-2005 Workshop on Meta-learning. <span id="_bookmark237" class="anchor"></span>pp. 12– 19 (2005)</p>
<p>58. Golovin, D., Solnik, B., Moitra, S., Kochanski, G., Karro, J., Sculley, D.: Google vizier: A service for black-box optimization. In: Proceedings of ICDM 2017. pp. 1487– 1495 (2017)</p>
<p><span id="_bookmark292" class="anchor"></span>59. Gomes, T.A., Prudêncio, R.B., Soares, C., Rossi, A.L., Carvalho, A.: Combining meta- learning and search techniques to select parameters for support vector machines. Neurocom- <span id="_bookmark388" class="anchor"></span>puting 75(1), 3– 13 (2012)</p>
<p>60. Graves, A., Wayne, G., Danihelka, I.: Neural turing machines. arXiv preprint <span id="_bookmark319" class="anchor"></span>arXiv:1410.5401 (2014)</p>
<p>61. Guerra, S.B., Prudêncio, R.B., Ludermir, T.B.: Predicting the performance of learning algorithms using support vector machines as meta- regressors. In: Proceedings of ICANN. <span id="_bookmark353" class="anchor"></span>pp. 523–532 (2008)</p>
<p>62. Hengst, B.: Discovering Hierarchy in Reinforcement Learning with HEXQ. In: International <span id="_bookmark259" class="anchor"></span>Conference on Machine Learning. pp. 243–250 (2002)</p>
<p>63. Hilario, M., Kalousis, A.: Fusion of meta-knowledge and meta-data for case-based model <span id="_bookmark279" class="anchor"></span>selection. Lecture Notes in Computer Science 2168, 180– 191 (2001)</p>
<p>64. Ho, T.K., Basu, M.: Complexity measures of supervised classiﬁcation problems. Pattern <span id="_bookmark371" class="anchor"></span>Analysis and Machine Intelligence. 24(3), 289–300 (2002)</p>
<p>65. Hochreiter, S., Younger, A., Conwell, P.: Learning to learn using gradient descent. In: Lecture Notes on Computer Science, 2130. pp. 87–94 (2001)</p>
<p>66. Hochreiter, S., Schmidhuber, J.: Long short-term memory. Neural computation 9(8), 1735– <span id="_bookmark223" class="anchor"><span id="_bookmark372" class="anchor"></span></span>1780 (1997)</p>
<p>67. Hutter, F., Hoos, H., Leyton-Brown, K.: An Efﬁcient Approach for Assessing Hyperparameter Importance. In: Proceedings of ICML (2014)</p>
</blockquote>
<p>56 J. Vanschoren</p>
<blockquote>
<p><span id="_bookmark323" class="anchor"></span>68. Hutter, F., Xu, L., Hoos, H., Leyton-Brown, K.: Algorithm runtime prediction: Methods &amp; <span id="_bookmark232" class="anchor"></span>evaluation. Artiﬁcial Intelligence 206, 79– 111 (2014)</p>
<p>69. Jones, D.R., Schonlau, M., Welch, W.J.: Efﬁcient global optimization of expensive black-box <span id="_bookmark218" class="anchor"></span>functions. Journal of Global Optimization 13(4), 455–492 (1998)</p>
<p>70. Kalousis, A.: Algorithm Selection via Meta-Learning. Ph.D. thesis, University of Geneva, <span id="_bookmark260" class="anchor"></span>Department of Computer Science (2002)</p>
<p>71. Kalousis, A., Hilario, M.: Representational issues in meta-learning. Proceedings of ICML</p>
<p><span id="_bookmark255" class="anchor"></span>2003 pp. 313–320 (2003)</p>
<p>72. Kalousis, A., Hilario, M.: Model selection via meta-learning: a compara- tive study. Interna- <span id="_bookmark244" class="anchor"></span>tional Journal on Artiﬁcial Intelligence Tools 10(4), 525–554 (2001)</p>
<p><span id="_bookmark330" class="anchor"></span>73. Kendall, M.G.: A new measure of rank correlation. Biometrika 30(1/2), 81–93 (1938)</p>
<p>74. Kietz, J.U., Serban, F., Bernstein, A., Fischer, S.: Designing KDD-workﬂows via HTN- planning for intelligent discovery assistance. In: 5th Planning to Learn Workshop at ECAI <span id="_bookmark271" class="anchor"></span>2012 (2012)</p>
<p>75. Kim, J., Kim, S., Choi, S.: Learning to warm-start Bayesian hyperparameter optimization. <span id="_bookmark282" class="anchor"></span>arXiv preprint arXiv:1710.06219 (2017)</p>
<p>76. Köpf, C., Iglezakis, I.: Combination of task description strategies and case base properties for meta-learning. ECML/PKDD Workshop on Integration and Collaboration Aspects of Data <span id="_bookmark318" class="anchor"></span>Mining pp. 65–76 (2002)</p>
<p>77. Köpf, C., Taylor, C., Keller, J.: Meta-analysis: From data characterization for meta-learning to meta-regression. In: PKDD Workshop on Data Mining, Decision Support, Meta-Learning <span id="_bookmark359" class="anchor"></span>and ILP. pp. 15–26 (2000)</p>
<p>78. Krizhevsky, A., Sutskever, I., Hinton, G.E.: Imagenet classiﬁcation with deep convolutional neural networks. In: Advances in neural information processing systems. pp. 1097– 1105</p>
<p><span id="_bookmark311" class="anchor"></span>(2012)</p>
<p>79. Kuba, P., Brazdil, P., Soares, C., Woznica, A.: Exploiting sampling and meta-learning for parameter setting support vector machines. In: Proceedings of IBERAMIA 2002. pp. 217– <span id="_bookmark241" class="anchor"></span>225 (2002)</p>
<p>80. Kullback, S., Leibler, R.A.: On information and sufﬁciency. The annals of mathematical <span id="_bookmark231" class="anchor"></span>statistics 22(1), 79–86 (1951)</p>
<p>81. Lacoste, A., Marchand, M., Laviolette, F., Larochelle, H.: Agnostic Bayesian learning of <span id="_bookmark197" class="anchor"></span>ensembles. In: Proceedings of ICML. pp. 611–619 (2014)</p>
<p>82. Lake, B.M., Ullman, T.D., Tenenbaum, J.B., Gershman, S.J.: Building machines that learn <span id="_bookmark245" class="anchor"></span>and think like people. Behavior and Brain Science 40 (2017)</p>
<p>83. Leite, R., Brazdil, P.: Predicting relative performance of classiﬁers from samples. Proceedings <span id="_bookmark246" class="anchor"></span>of ICML pp. 497–504 (2005)</p>
<p>84. Leite, R., Brazdil, P.: An iterative process for building learning curves and predicting relative performance of classiﬁers. Lecture Notes in Computer Science 4874, 87–98 (2007)</p>
<p><span id="_bookmark214" class="anchor"></span>85. Leite, R., Brazdil, P., Vanschoren, J.: Selecting Classiﬁcation Algorithms with Active Testing. <span id="_bookmark247" class="anchor"></span>Lecture Notes in Artiﬁcial Intelligence 10934, 117– 131 (2012)</p>
<p>86. Leite, R., Brazdil, P.: Active testing strategy to predict the best classiﬁcation algorithm via sampling and metalearning. In: Proceedings of ECAI 2010. pp. 309–314 (2010)</p>
<p><span id="_bookmark306" class="anchor"></span>87. Lemke, C., Budka, M., Gabrys, B.: Metalearning: a survey of trends and technologies. <span id="_bookmark287" class="anchor"></span>Artiﬁcial intelligence review 44(1), 117– 130 (2015)</p>
<p>88. Ler, D., Koprinska, I., Chawla, S.: Utilizing regression-based landmarkers within a meta- learning framework for algorithm selection. Technical Report 569. University of Sydney <span id="_bookmark375" class="anchor"><span id="_bookmark376" class="anchor"></span></span>pp. 44–51 (2005)</p>
<p>89. Li, K., Malik, J.: Learning to optimize. In: Proceedings of ICLR 2017 (2017)</p>
<p>90. Li, K., Malik, J.: Learning to optimize neural nets. arXiv preprint arXiv:1703.00441 (2017)</p>
<p><span id="_bookmark217" class="anchor"></span>91. Lin, S.: Rank aggregation methods. WIREs Computational Statistics 2, 555–570 (2010)</p>
<p><span id="_bookmark261" class="anchor"></span>92. Lindner, G., Studer, R.: AST: Support for algorithm selection with a CBR approach. In: ICML Workshop on Recent Advances in Meta-Learning and Future Work. pp. 38–47. J. Stefan <span id="_bookmark317" class="anchor"></span>Institute (1999)</p>
<p>93. Lorena, A.C., Maciel, A.I., de Miranda, P.B.C., Costa, I.G., Prudêncio, R.B.C.: Data complexity meta-features for regression problems. Machine Learning 107(1), 209–246 (2018)</p>
</blockquote>
<p>2 Meta-Learning 57</p>
<blockquote>
<p><span id="_bookmark307" class="anchor"></span>94. Luo, G.: A review of automatic selection methods for machine learning algorithms and hyper- parameter values. Network Modeling Analysis in Health Informatics and Bioinformatics 5(1), <span id="_bookmark343" class="anchor"></span>18 (2016)</p>
<p>95. Mantovani, R.G., Horváth, T., Cerri, R., Vanschoren, J., de Carvalho, A.C.: Hyper-parameter tuning of a decision tree induction algorithm. In: Brazilian Conference on Intelligent Systems. <span id="_bookmark341" class="anchor"></span>pp. 37–42 (2016)</p>
<p>96. Mantovani, R.G., Rossi, A.L., Vanschoren, J., Bischl, B., Carvalho, A.C.: To tune or not to tune: recommending when to adjust SVM hyper-parameters via meta-learning. In: <span id="_bookmark342" class="anchor"></span>Proceedings of IJCNN. pp. 1–8 (2015)</p>
<p>97. Mantovani, R.G., Rossi, A.L., Vanschoren, J., Carvalho, A.C.: Meta-learning recommenda- tion of default hyper-parameter values for SVMs in classiﬁcations tasks. In: ECML PKDD <span id="_bookmark250" class="anchor"></span>Workshop on Meta-Learning and Algorithm Selection (2015)</p>
<p>98. Mantovani, R.: Use of meta-learning for hyperparameter tuning of classiﬁcation problems. <span id="_bookmark272" class="anchor"></span>Ph.D. thesis, University of Sao Carlos, Brazil (2018)</p>
<p>99. Michie, D., Spiegelhalter, D.J., Taylor, C.C., Campbell, J.: Machine Learning, Neural and <span id="_bookmark294" class="anchor"></span>Statistical Classiﬁcation. Ellis Horwood (1994)</p>
<p>100. Miranda, P., Prudêncio, R.: Active testing for SVM parameter selection. In: Proceedings of <span id="_bookmark389" class="anchor"></span>IJCNN. pp. 1–8 (2013)</p>
<p>101. Mishra, N., Rohaninejad, M., Chen, X., Abbeel, P.: A simple neural attentive meta-learner. <span id="_bookmark301" class="anchor"></span>In: Proceedings of ICLR (2018)</p>
<p>102. Misir, M., Sebag, M.: Algorithm Selection as a Collaborative Filtering Problem. Research <span id="_bookmark302" class="anchor"></span>report, INRIA (2013)</p>
<p>103. Mısır, M., Sebag, M.: Alors: An algorithm recommender system. Artiﬁcial Intelligence 244, <span id="_bookmark229" class="anchor"></span>291–314 (2017)</p>
<p>104. Nadaraya, E.A.: On estimating regression. Theory of Probability &amp; Its Applications 9(1), <span id="_bookmark331" class="anchor"></span>141– 142 (1964)</p>
<p>105. Nguyen, P., Hilario, M., Kalousis, A.: Using meta-mining to support data mining workﬂow planning and optimization. Journal of Artiﬁcial Intelligence Research 51, 605–644 (2014)</p>
<p>106. Nichol, A., Achiam, J., Schulman, J.: On ﬁrst-order meta-learning algorithms. arXiv <span id="_bookmark386" class="anchor"><span id="_bookmark350" class="anchor"></span></span>1803.02999v2 (2018)</p>
<p>107. Niculescu-Mizil, A., Caruana, R.: Learning the Structure of Related Tasks. In: Proceedings <span id="_bookmark312" class="anchor"></span>of NIPS Workshop on Inductive Transfer (2005)</p>
<p>108. Nisioti, E., Chatzidimitriou, K., Symeonidis, A.: Predicting hyperparameters from meta- features in binary classiﬁcation problems. In: AutoML Workshop at ICML (2018)</p>
<p><span id="_bookmark268" class="anchor"></span>109. Olier, I., Sadawi, N., Bickerton, G., Vanschoren, J., Grosan, C., Soldatova, L., King, R.: Meta- QSAR: learning how to learn QSARs. Machine Learning 107, 285–311 (2018)</p>
<p><span id="_bookmark333" class="anchor"></span>110. Olson, R.S., Bartley, N., Urbanowicz, R.J., Moore, J.H.: Evaluation of a tree-based pipeline optimization tool for automating data science. In: Proceedings of GECCO. pp. 485–492</p>
<p><span id="_bookmark203" class="anchor"></span>(2016)</p>
<p>111. Pan, S.J., Yang, Q.: A survey on transfer learning. IEEE Transactions on knowledge and data <span id="_bookmark392" class="anchor"></span>engineering 22(10), 1345– 1359 (2010)</p>
<p>112. Pang, K., Dong, M., Wu, Y., Hospedales, T.: Meta-learning transferable active learning policies by deep reinforcement learning. In: AutoML Workshop at ICML (2018)</p>
<p><span id="_bookmark283" class="anchor"></span>113. Peng, Y., Flach, P., Soares, C., Brazdil, P.: Improved dataset characterisation for meta- <span id="_bookmark233" class="anchor"></span>learning. Lecture Notes in Computer Science 2534, 141– 152 (2002)</p>
<p>114. Perrone, V., Jenatton, R., Seeger, M., Archambeau, C.: Multiple adaptive Bayesian linear regression for scalable Bayesian optimization with warm start. In: Advances in Neural <span id="_bookmark286" class="anchor"></span>information processing systems, NeurIPS 2018 (2018)</p>
<p>115. Pfahringer, B., Bensusan, H., Giraud-Carrier, C.G.: Meta-learning by landmarking various learning algorithms. In: 17th International Conference on Machine Learning (ICML). <span id="_bookmark316" class="anchor"></span>pp. 743–750 (2000)</p>
<p>116. Pinto, F., Cerqueira, V., Soares, C., Mendes-Moreira, J.: autoBagging: Learning to rank <span id="_bookmark256" class="anchor"></span>bagging workﬂows with metalearning. arXiv 1706.09367 (2017)</p>
<p>117. Pinto, F., Soares, C., Mendes-Moreira, J.: Towards automatic generation of metafeatures. In: Proceedings of PAKDD. pp. 215–226 (2016)</p>
</blockquote>
<p>58 J. Vanschoren</p>
<blockquote>
<p><span id="_bookmark327" class="anchor"></span>118. Post, M.J., van der Putten, P., van Rijn, J.N.: Does Feature Selection Improve Classiﬁcation? A Large Scale Experiment in OpenML. In: Advances in Intelligent Data Analysis XV. <span id="_bookmark322" class="anchor"></span>pp. 158– 170 (2016)</p>
<p>119. Priya, R., De Souza, B.F., Rossi, A., Carvalho, A.: Using genetic algorithms to improve prediction of execution times of ML tasks. In: Lecture Notes in Computer Science. vol. 7208, <span id="_bookmark225" class="anchor"></span>pp. 196–207 (2012)</p>
<p>120. Probst, P., Bischl, B., Boulesteix, A.L.: Tunability: Importance of hyperparameters of machine <span id="_bookmark265" class="anchor"></span>learning algorithms. ArXiv 1802.09596 (2018)</p>
<p>121. Prudêncio, R., Ludermir, T.: Meta-learning approaches to selecting time series models. <span id="_bookmark348" class="anchor"></span>Neurocomputing 61, 121– 137 (2004)</p>
<p>122. Raina, R., Ng, A.Y., Koller, D.: Transfer Learning by Constructing Informative Priors. In: <span id="_bookmark338" class="anchor"></span>Proceedings of ICML (2006)</p>
<p>123. Rakotoarison, H., Sebag, M.: AutoML with Monte Carlo Tree Search. In: ICML Workshop <span id="_bookmark242" class="anchor"></span>on AutoML 2018 (2018)</p>
<p>124. Ramachandran, A., Gupta, S., Rana, S., Venkatesh, S.: Information-theoretic transfer learning <span id="_bookmark239" class="anchor"></span>framework for Bayesian optimisation. In: Proceedings of ECMLPKDD (2018)</p>
<p>125. Ramachandran, A., Gupta, S., Rana, S., Venkatesh, S.: Selecting optimal source for transfer learning in Bayesian optimisation. In: Proceedings of PRICAI. pp. 42–56 (2018)</p>
<p>126. Ravi, S., Larochelle, H.: Optimization as a model for few-shot learning. In: Proceedings of <span id="_bookmark204" class="anchor"><span id="_bookmark393" class="anchor"></span></span>ICLR (2017)</p>
<p>127. Reed, S., Chen, Y., Paine, T., Oord, A.v.d., Eslami, S., Rezende, D., Vinyals, O., de Freitas, N.: Few-shot autoregressive density estimation: Towards learning to learn distributions. In: <span id="_bookmark321" class="anchor"></span>Proceedings of ICLR 2018 (2018)</p>
<p>128. Reif, M., Shafait, F., Dengel, A.: Prediction of classiﬁer training time including parameter <span id="_bookmark293" class="anchor"></span>optimization. In: Proceedings of GfKI 2011. pp. 260–271 (2011)</p>
<p>129. Reif, M., Shafait, F., Dengel, A.: Meta-learning for evolutionary parameter optimization of <span id="_bookmark251" class="anchor"></span>classiﬁers. Machine learning 87(3), 357–380 (2012)</p>
<p>130. Reif, M., Shafait, F., Goldstein, M., Breuel, T., Dengel, A.: Automatic classiﬁer selection for <span id="_bookmark383" class="anchor"></span>non-experts. Pattern Analysis and Applications 17(1), 83–96 (2014)</p>
<p>131. Ren, M., Triantaﬁllou, E., Ravi, S., Snell, J., Swersky, K., Tenenbaum, J.B., Larochelle, H., Zemel, R.S.: Meta-learning for semi-supervised few- shot classiﬁcation. In: Proceedings of <span id="_bookmark296" class="anchor"><span id="_bookmark339" class="anchor"></span></span>ICLR 2018 (2018)</p>
<p>132. Rendle, S.: Factorization machines. In: Proceedings of ICDM 2015. pp. 995– 1000 (2010)</p>
<p>133. Ridd, P., Giraud-Carrier, C.: Using metalearning to predict when parameter optimization is likely to improve classiﬁcation accuracy. In: ECAI Workshop on Meta-learning and <span id="_bookmark215" class="anchor"></span>Algorithm Selection. pp. 18–23 (2014)</p>
<p>134. van Rijn, J., Abdulrahman, S., Brazdil, P., Vanschoren, J.: Fast Algorithm Selection Using <span id="_bookmark262" class="anchor"></span>Learning Curves. In: Proceedings of IDA (2015)</p>
<p>135. van Rijn, J., Holmes, G., Pfahringer, B., Vanschoren, J.: The Online Performance Estimation Framework. Heterogeneous Ensemble Learning for Data Streams. Machine Learning 107, <span id="_bookmark224" class="anchor"></span>149– 176 (2018)</p>
<p>136. van Rijn, J.N., Hutter, F.: Hyperparameter importance across datasets. In: Proceedings of <span id="_bookmark263" class="anchor"></span>KDD. pp. 2367–2376 (2018)</p>
<p>137. van Rijn, J.N., Holmes, G., Pfahringer, B., Vanschoren, J.: Algorithm selection on data <span id="_bookmark252" class="anchor"></span>streams. In: Discovery Science. pp. 325–336 (2014)</p>
<p>138. Rivolli, A., Garcia, L., Soares, C., Vanschoren, J., de Carvalho, A.: Towards reproducible empirical research in meta-learning. arXiv preprint 1808. 10406 (2018)</p>
<p><span id="_bookmark238" class="anchor"></span>139. Robbins, H.: Some aspects of the sequential design of experiments. In: Herbert Robbins <span id="_bookmark349" class="anchor"></span>Selected Papers, pp. 169– 177. Springer (1985)</p>
<p>140. Rosenstein, M.T., Marx, Z., Kaelbling, L.P.: To Transfer or Not To Transfer. In: NIPS <span id="_bookmark273" class="anchor"></span>Workshop on transfer learning (2005)</p>
<p>141. Rousseeuw, P.J., Hubert, M.: Robust statistics for outlier detection. Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery 1(1), 73–79 (2011)</p>
</blockquote>
<p>2 Meta-Learning 59</p>
<blockquote>
<p><span id="_bookmark369" class="anchor"></span>142. Runarsson, T.P., Jonsson, M.T.: Evolution and design of distributed learning rules. In: IEEE Symposium on Combinations of Evolutionary Computation and Neural Networks. pp. 59–63</p>
<p><span id="_bookmark275" class="anchor"></span>(2000)</p>
<p>143. Salama, M.A., Hassanien, A.E., Revett, K.: Employment of neural network and rough set in <span id="_bookmark340" class="anchor"></span>meta-learning. Memetic Computing 5(3), 165– 177 (2013)</p>
<p>144. Sanders, S., Giraud-Carrier, C.: Informing the use of hyperparameter optimization through <span id="_bookmark387" class="anchor"></span>metalearning. In: Proceedings of ICDM 2017. pp. 1051– 1056 (2017)</p>
<p>145. Santoro, A., Bartunov, S., Botvinick, M., Wierstra, D., Lillicrap, T.: Meta-learning with memory-augmented neural networks. In: International conference on machine learning. <span id="_bookmark370" class="anchor"></span>pp. 1842– 1850 (2016)</p>
<p>146. Santoro, A., Bartunov, S., Botvinick, M., Wierstra, D., Lillicrap, T.: One-shot learning with <span id="_bookmark266" class="anchor"></span>memory-augmented neural networks. arXiv preprint arXiv:1605.06065 (2016)</p>
<p>147. dos Santos, P., Ludermir, T., Prudêncio, R.: Selection of time series forecasting models based on performance information. 4th International Conference on Hybrid Intelligent Systems <span id="_bookmark295" class="anchor"></span>pp. 366–371 (2004)</p>
<p>148. Schilling, N., Wistuba, M., Drumond, L., Schmidt-Thieme, L.: Hyperparameter optimization with factorized multilayer perceptrons. In: Proceedings of ECML PKDD. pp. 87– 103 (2015)</p>
<p><span id="_bookmark363" class="anchor"></span>149. Schmidhuber, J.: Learning to control fast-weight memories: An alternative to dynamic recurrent networks. Neural Computing 4(1), 131– 139 (1992)</p>
<p>150. Schmidhuber, J.: A neural network that embeds its own meta-levels. In: Proceedings of ICNN. <span id="_bookmark364" class="anchor"><span id="_bookmark365" class="anchor"></span></span>pp. 407–412 (1993)</p>
<p>151. Schmidhuber, J., Zhao, J., Wiering, M.: Shifting inductive bias with success-story algorithm, adaptive levin search, and incremental self-improvement. Machine Learning 28(1), 105– 130</p>
<p><span id="_bookmark336" class="anchor"></span>(1997)</p>
<p>152. Schoenfeld, B., Giraud-Carrier, C., Poggeman, M., Christensen, J., Seppi, K.: Feature selection for high-dimensional data: A fast correlation-based ﬁlter solution. In: AutoML <span id="_bookmark326" class="anchor"></span>Workshop at ICML (2018)</p>
<p>153. Serban, F., Vanschoren, J., Kietz, J., Bernstein, A.: A survey of intelligent assistants for data <span id="_bookmark361" class="anchor"></span>analysis. ACM Computing Surveys 45(3), Art.31 (2013)</p>
<p>154. Sharif Razavian, A., Azizpour, H., Sullivan, J., Carlsson, S.: Cnn features off-the-shelf: an astounding baseline for recognition. In: Proceedings of CVPR 2014. pp. 806–813 (2014)</p>
<p>155. Sharkey, N.E., Sharkey, A.J.C.: Adaptive Generalization. Artiﬁcial Intelligence Review 7, <span id="_bookmark358" class="anchor"><span id="_bookmark269" class="anchor"></span></span>313–328 (1993)</p>
<p>156. Smith-Miles, K.A.: Cross-disciplinary perspectives on meta-learning for algorithm selection. <span id="_bookmark382" class="anchor"></span>ACM Computing Surveys 41(1), 1–25 (2009)</p>
<p>157. Snell, J., Swersky, K., Zemel, R.: Prototypical networks for few-shot learning. In: Neural <span id="_bookmark274" class="anchor"></span>Information Processing Systems. pp. 4077–4087 (2017)</p>
<p>158. Soares, C., Brazdil, P., Kuba, P.: A meta-learning method to select the kernel width in support <span id="_bookmark267" class="anchor"></span>vector regression. Machine Learning 54, 195–209 (2004)</p>
<p>159. Soares, C., Ludermir, T., Carvalho, F.D.: An analysis of meta-learning techniques for ranking clustering algorithms applied to artiﬁcial data. Lecture Notes in Computer Science 5768, 131– <span id="_bookmark289" class="anchor"></span>140 (2009)</p>
<p>160. Soares, C., Petrak, J., Brazdil, P.: Sampling based relative landmarks: Systematically testdriv- ing algorithms before choosing. Lecture Notes in Computer Science 3201, 250–261 (2001)</p>
<p><span id="_bookmark236" class="anchor"></span>161. Springenberg, J., Klein, A., Falkner, S., Hutter, F.: Bayesian optimization with robust Bayesian neural networks. In: Advances in Neural Information Processing Systems (2016)</p>
<p><span id="_bookmark299" class="anchor"></span>162. Stern, D.H., Samulowitz, H., Herbrich, R., Graepel, T., Pulina, L., Tacchella, A.: Collaborative expert portfolio management. In: Proceedings of AAAI. pp. 179– 184 (2010)</p>
<p><span id="_bookmark328" class="anchor"></span>163. Strang, B., van der Putten, P., van Rijn, J.N., Hutter, F.: Don’t Rule Out Simple Models <span id="_bookmark334" class="anchor"></span>Prematurely. In: Advances in Intelligent Data Analysis (2018)</p>
<p>164. Sun, Q., Pfahringer, B., Mayo, M.: Towards a Framework for Designing Full Model Selection and Optimization Systems. In: International Workshop on Multiple Classiﬁer Systems. pp. 259–270 (2013)</p>
</blockquote>
<p>60 J. Vanschoren</p>
<blockquote>
<p><span id="_bookmark270" class="anchor"></span>165. Sun, Q., Pfahringer, B.: Pairwise meta-rules for better meta-learning-based algorithm ranking. <span id="_bookmark235" class="anchor"></span>Machine Learning 93(1), 141– 161 (2013)</p>
<p>166. Swersky, K., Snoek, J., Adams, R.P.: Multi-task Bayesian optimization. In: Advances in <span id="_bookmark240" class="anchor"></span>neural information processing systems. pp. 2004–2012 (2013)</p>
<p>167. Thompson, W.R.: On the likelihood that one unknown probability exceeds another in view of <span id="_bookmark351" class="anchor"></span>the evidence of two samples. Biometrika 25(3/4), 285–294 (1933)</p>
<p>168. Thrun, S.: Lifelong Learning Algorithms. In: Learning to Learn, chap. 8, pp. 181–209. Kluwer <span id="_bookmark357" class="anchor"></span>Academic Publishers, MA (1998)</p>
<p>169. Thrun, S., Mitchell, T.: Learning One More Thing. In: Proceedings of IJCAI. pp. 1217– 1223</p>
<p><span id="_bookmark344" class="anchor"></span>(1995)</p>
<p>170. Thrun, S., Pratt, L.: Learning to Learn: Introduction and Overview. In: Learning to Learn, <span id="_bookmark314" class="anchor"></span>pp. 3– 17. Kluwer (1998)</p>
<p>171. Todorovski, L., Blockeel, H., Džeroski, S.: Ranking with predictive clustering trees. Lecture <span id="_bookmark258" class="anchor"></span>Notes in Artiﬁcial Intelligence 2430, 444–455 (2002)</p>
<p>172. Todorovski, L., Brazdil, P., Soares, C.: Report on the experiments with feature selection in meta-level learning. PKDD 2000 Workshop on Data mining, Decision support, Meta-learning <span id="_bookmark219" class="anchor"></span>and ILP pp. 27–39 (2000)</p>
<p>173. Todorovski, L., Dzeroski, S.: Experiments in meta-level learning with ILP. Lecture Notes in <span id="_bookmark208" class="anchor"></span>Computer Science 1704, 98– 106 (1999)</p>
<p>174. Vanschoren, J., van Rijn, J.N., Bischl, B., Torgo, L.: OpenML: networked science in machine <span id="_bookmark253" class="anchor"></span>learning. ACM SIGKDD Explorations Newsletter 15(2), 49–60 (2014)</p>
<p>175. Vanschoren, J.: Understanding Machine Learning Performance with Experiment Databases. <span id="_bookmark207" class="anchor"></span>Ph.D. thesis, Leuven Univeristy (2010)</p>
<p><span id="_bookmark209" class="anchor"></span>176. Vanschoren, J.: Meta-learning: A survey. arXiv:1810.03548 (2018)</p>
<p>177. Vanschoren, J., Blockeel, H., Pfahringer, B., Holmes, G.: Experiment databases. Machine <span id="_bookmark394" class="anchor"></span>Learning 87(2), 127– 158 (2012)</p>
<p>178. Vartak, M., Thiagarajan, A., Miranda, C., Bratman, J., Larochelle, H.: A meta-learning perspective on cold-start recommendations for items. In: Advances in Neural Information <span id="_bookmark281" class="anchor"></span>Processing Systems. pp. 6904–6914 (2017)</p>
<p>179. Vilalta, R.: Understanding accuracy performance through concept characterization and algorithm analysis. ICML Workshop on Recent Advances in Meta-Learning and Future Work</p>
<p><span id="_bookmark280" class="anchor"></span>(1999)</p>
<p>180. Vilalta, R., Drissi, Y.: A characterization of difﬁcult problems in classiﬁcation. Proceedings <span id="_bookmark381" class="anchor"></span>of ICMLA (2002)</p>
<p>181. Vinyals, O., Blundell, C., Lillicrap, T., Wierstra, D., et al.: Matching networks for one shot learning. In: Advances in Neural Information Processing Systems. pp. 3630–3638 (2016)</p>
<p><span id="_bookmark391" class="anchor"></span>182. Weerts, H., Meuller, M., Vanschoren, J.: Importance of tuning hyperparameters of machine <span id="_bookmark226" class="anchor"></span>learning algorithms. Technical report, TU Eindhoven (2018)</p>
<p>183. Weerts, H., Meuller, M., Vanschoren, J.: Importance of tuning hyperparameters of machine <span id="_bookmark332" class="anchor"></span>learning algorithms. Tech. rep., TU Eindhoven (2018)</p>
<p>184. Wever, M., Mohr, F., Hüllermeier, E.: Ml-plan for unlimited-length machine learning <span id="_bookmark243" class="anchor"></span>pipelines. In: AutoML Workshop at ICML 2018 (2018)</p>
<p>185. Wistuba, M., Schilling, N., Schmidt-Thieme, L.: Hyperparameter search space pruning, a new component for sequential model-based hyperparameter optimization. In: ECML PKDD 2015. <span id="_bookmark221" class="anchor"></span>pp. 104– 119 (2015)</p>
<p>186. Wistuba, M., Schilling, N., Schmidt-Thieme, L.: Learning hyperparameter optimization initializations. In: 2015 IEEE International Conference on Data Science and Advanced <span id="_bookmark228" class="anchor"></span>Analytics (DSAA). pp. 1– 10 (2015)</p>
<p>187. Wolpert, D., Macready, W.: No free lunch theorems for search. Technical Report SFI-TR-95- 02-010, The Santa Fe Institute (1996)</p>
<p>2 Meta-Learning 61</p>
<p><span id="_bookmark199" class="anchor"></span>188. Yang, C., Akimoto, Y., Kim, D., Udell, M.: OBOE: Collaborative ﬁltering for automl <span id="_bookmark300" class="anchor"></span>initialization. In: NeurIPS 2018 Workshop on Metalearning (2018)</p>
<p>189. Yang, C., Akimoto, Y., Kim, D., Udell, M.: Oboe: Collaborative ﬁltering for automl <span id="_bookmark297" class="anchor"></span>initialization. arXiv preprint arXiv:1808.03233 (2018)</p>
<p>190. Yogatama, D., Mann, G.: Efﬁcient transfer learning method for automatic hyperparameter <span id="_bookmark362" class="anchor"></span>tuning. In: AI and Statistics. pp. 1077– 1085 (2014)</p>
<p>191. Yosinski, J., Clune, J., Bengio, Y., Lipson, H.: How transferable are features in deep neural networks? In: Advances in neural information processing systems. pp. 3320–3328 (2014)</p>
<p><strong>Open</strong> <strong>Access</strong> This chapter is licensed under the terms of the Creative Commons Attribution 4.0 International License <a href="http://creativecommons.org/licenses/by/4.0/">(http://creativecommons.org/licenses/by/4.0/</a>), which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence and indicate if changes were made.</p>
<p>The images or other third party material in this chapter are included in the chapter’s Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the chapter’s Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder.</p>
</blockquote>
<p><img src="./automlgithubpagesimages//media/image83.png" width="75" height="26" /></p>
<p><img src="./automlgithubpagesimages//media/image84.png" width="41" height="41" /><img src="./automlgithubpagesimages//media/image9.jpeg" width="136" /></p>
<blockquote>
<p><span id="_bookmark4" class="anchor"></span><strong>Chapter</strong> <strong>3</strong></p>
<p><strong>Neural</strong> <strong>Architecture</strong> <strong>Search</strong></p>
</blockquote>
<p><img src="./automlgithubpagesimages//media/image85.png" /></p>
<blockquote>
<p><strong>Thomas</strong> <strong>Elsken,</strong> <strong>Jan</strong> <strong>Hendrik</strong> <strong>Metzen,</strong> <strong>and</strong> <strong>Frank</strong> <strong>Hutter</strong></p>
<p><strong>Abstract</strong> Deep Learning has enabled remarkable progress over the last years on a variety of tasks, such as image recognition, speech recognition, and machine translation. One crucial aspect for this progress are novel neural architectures. Currently employed architectures have mostly been developed manually by human experts, which is a time-consuming and error-prone process. Because of this, there is growing interest in automated <em>neural</em> <em>architecture</em> <em>search</em> methods. We provide an overview of existing work in this ﬁeld of research and categorize them according to three dimensions: search space, search strategy, and performance estimation strategy.</p>
<p><strong>3.1</strong> <strong>Introduction</strong></p>
</blockquote>
<p>The success of deep learning in perceptual tasks is largely due to its automation of the feature engineering process: hierarchical feature extractors are learned in an end-to-end fashion from data rather than manually designed. This success has been accompanied, however, by a rising demand for <em>architecture</em> <em>engineering</em>, where increasingly more complex neural architectures are designed manually. <em>Neural</em> <em>Architecture</em> <em>Search</em> (NAS), the process of automating architecture engineering, is thus a logical next step in automating machine learning. NAS can be seen as subﬁeld of AutoML and has signiﬁcant overlap with hyperparameter optimization and meta-learning (which are described in Chaps.<a href="#_bookmark2">1</a>and<a href="#_bookmark3">2</a>of this book, respectively).</p>
<blockquote>
<p>T. Elsken (凶)</p>
<p>Institut für Informatik, University of Freiburg, Freiburg, Baden-Württemberg, Germany e-mail: <a href="mailto:elsken@informatik.uni-freiburg.de">elsken@informatik.uni-freiburg.de</a>; <a href="mailto:thomas.elsken@de.bosch.com">thomas.elsken@de.bosch.com</a></p>
<p>J. H. Metzen</p>
<p>Bosch Center for Artiﬁcial Intelligence, Robert Bosch GmbH, Renningen, Baden-Württemberg, Germany</p>
<p>F. Hutter</p>
<p>Department of Computer Science, University of Freiburg, Freiburg, Germany</p>
<p>© The Author(s) 2019</p>
<p>F. Hutter et al. (eds.), <em>Automated</em> <em>Machine</em> <em>Learning</em>, The Springer Series on Challenges in Machine Learning, <a href="https://doi.org/10.1007/978-3-030-05318-5_3" class="uri">https://doi.org/10.1007/978-3-030-05318-5_3</a></p>
<p>64 T. Elsken et al.</p>
</blockquote>
<p>We categorize methods for NAS according to three dimensions: search space, search strategy, and performance estimation strategy:</p>
<blockquote>
<p>• <strong>Search</strong> <strong>Space.</strong> The search space deﬁnes which architectures can be represented in principle. Incorporating prior knowledge about properties well-suited for a task can reduce the size of the search space and simplify the search. However, this also introduces a human bias, which may prevent ﬁnding novel architectural building blocks that go beyond the current human knowledge.</p>
<p>architecture</p>
</blockquote>
<table>
<tbody>
<tr class="odd">
<td><blockquote>
<p>Search Space A</p>
</blockquote></td>
<td></td>
<td><blockquote>
<p>Search Strategy</p>
</blockquote></td>
</tr>
<tr class="even">
<td></td>
<td><img src="./automlgithubpagesimages//media/image86.png" /></td>
<td></td>
</tr>
</tbody>
</table>
<blockquote>
<p><span id="_bookmark395" class="anchor"></span><strong>Fig.</strong> <strong>3.1</strong> Abstract illustration of Neural Architecture Search methods. A search strategy selects an architecture A from a predeﬁned search space A. The architecture is passed to a performance estimation strategy, which returns the estimated performance of A to the search strategy</p>
<p>• <strong>Search</strong> <strong>Strategy.</strong> The search strategy details how to explore the search space. It encompasses the classical exploration-exploitation trade-off since, on the one hand, it is desirable to ﬁnd well-performing architectures quickly, while on the other hand, premature convergence to a region of suboptimal architectures should be avoided.</p>
<p>• <strong>Performance</strong> <strong>Estimation</strong> <strong>Strategy.</strong> The objective of NAS is typically to ﬁnd architectures that achieve high predictive performance on unseen data. <em>Per-</em> <em>formance</em> <em>Estimation</em> refers to the process of estimating this performance: the simplest option is to perform a standard training and validation of the architecture on data, but this is unfortunately computationally expensive and limits the number of architectures that can be explored. Much recent research therefore focuses on developing methods that reduce the cost of these performance estimations.</p>
<p>We refer to Fig.<a href="#_bookmark395">3.1</a> for an illustration. The chapter is also structured according to these three dimensions: we start with discussing search spaces in Sect.<a href="#_bookmark396">3.2</a>, cover search strategies in Sect.<a href="#_bookmark397">3.3</a>, and outline approaches to performance estimation in Sect.<a href="#_bookmark398">3.4</a>. We conclude with an outlook on future directions in Sect.<a href="#_bookmark399">3.5</a>.</p>
<p>This chapter is based on a very recent survey article [<a href="#_bookmark400">23</a>].</p>
<p><span id="_bookmark396" class="anchor"></span><strong>3.2</strong> <strong>Search</strong> <strong>Space</strong></p>
<p>The search space deﬁnes which neural architectures a NAS approach might discover in principle. We now discuss common search spaces from recent works.</p>
<p>A relatively simple search space is the space of <em>chain-structured</em> <em>neural</em> <em>networks</em>, as illustrated in Fig.<a href="#_bookmark401">3.2</a> (left). A chain-structured neural network architecture A</p>
</blockquote>
<p><img src="./automlgithubpagesimages//media/image87.png" width="46" height="20" /><img src="./automlgithubpagesimages//media/image88.png" width="46" height="54" /><img src="./automlgithubpagesimages//media/image89.png" height="19" /><img src="./automlgithubpagesimages//media/image90.png" width="28" height="18" /><img src="./automlgithubpagesimages//media/image91.png" width="57" height="21" /><img src="./automlgithubpagesimages//media/image92.png" width="58" height="19" /><img src="./automlgithubpagesimages//media/image93.png" width="44" height="19" /></p>
<blockquote>
<p>3 Neural Architecture Search</p>
<p><span id="_bookmark401" class="anchor"></span><strong>Fig.</strong> <strong>3.2</strong> An illustration of</p>
<p>different architecture spaces.</p>
<p>Each node in the graphs</p>
<p>corresponds to a layer in a</p>
<p>neural network, e.g., a</p>
<p>convolutional or pooling</p>
<p>layer. Different layer types</p>
<p>are visualized by different</p>
<p>colors. An edge from layer Li</p>
<p>to layer Lj denotes that Lj</p>
</blockquote>
<p>receives the output of Li as</p>
<blockquote>
<p>input. Left: an element of a</p>
<p>chain-structured space. Right:</p>
<p>an element of a more</p>
<p>complex search space with</p>
<p>additional layer types and</p>
<p>multiple branches and skip</p>
<p>connections</p>
</blockquote>
<table>
<tbody>
<tr class="odd">
<td><blockquote>
<p>input</p>
</blockquote></td>
</tr>
<tr class="even">
<td></td>
</tr>
<tr class="odd">
<td><blockquote>
<p>L0</p>
</blockquote></td>
</tr>
<tr class="even">
<td></td>
</tr>
<tr class="odd">
<td><blockquote>
<p>L1</p>
</blockquote></td>
</tr>
</tbody>
</table>
<p><img src="./automlgithubpagesimages//media/image94.png" height="22" /></p>
<table>
<tbody>
<tr class="odd">
<td></td>
<td></td>
</tr>
<tr class="even">
<td><blockquote>
<p>Ln − 1</p>
</blockquote></td>
</tr>
<tr class="odd">
<td></td>
<td></td>
</tr>
<tr class="even">
<td><blockquote>
<p>Ln</p>
</blockquote></td>
</tr>
<tr class="odd">
<td></td>
<td></td>
</tr>
<tr class="even">
<td><blockquote>
<p>output</p>
</blockquote></td>
</tr>
</tbody>
</table>
<p>65</p>
<table>
<tbody>
<tr class="odd">
<td><blockquote>
<p>input</p>
</blockquote></td>
</tr>
</tbody>
</table>
<p><img src="./automlgithubpagesimages//media/image95.png" width="29" height="17" /></p>
<table>
<tbody>
<tr class="odd">
<td><blockquote>
<p>L1</p>
</blockquote></td>
</tr>
<tr class="even">
<td></td>
</tr>
<tr class="odd">
<td><blockquote>
<p>L3</p>
</blockquote></td>
</tr>
</tbody>
</table>
<table>
<tbody>
<tr class="odd">
<td><blockquote>
<p>L10</p>
</blockquote></td>
</tr>
<tr class="even">
<td></td>
</tr>
<tr class="odd">
<td><blockquote>
<p>output</p>
</blockquote></td>
</tr>
</tbody>
</table>
<blockquote>
<p>can be written as a sequence of n layers, where the i’th layer Li receives its input from layer i − 1 and its output serves as the input for layer i + 1, i.e., A = Ln ◦ . . . L1 ◦ L0 . The search space is then parametrized by: (i) the (maximum) number of layers n (possibly unbounded); (ii) the type of operation every layer can execute, e.g., pooling, convolution, or more advanced layer types like depthwise separable convolutions [<a href="#_bookmark402">13</a>] or dilated convolutions [<a href="#_bookmark403">68</a>]; and (iii) hyperparameters associated with the operation, e.g., number of ﬁlters, kernel size and strides for a convolutional layer [<a href="#_bookmark404">4</a>, <a href="#_bookmark405">10</a>, <a href="#_bookmark406">59</a>], or simply number of units for fully-connected networks [<a href="#_bookmark407">41</a>]. Note that the parameters from (iii) are conditioned on (ii), hence the parametrization of the search space is not ﬁxed-length but rather a conditional space.</p>
<p>Recent work on NAS [<a href="#_bookmark408">9</a>, <a href="#_bookmark409">11</a>, <a href="#_bookmark410">21</a>, <a href="#_bookmark411">22</a>, <a href="#_bookmark412">49</a>, <a href="#_bookmark413">75</a>] incorporate modern design elements</p>
</blockquote>
<p>known from hand-crafted architectures such as skip connections, which allow to</p>
<p>build complex, <em>multi-branch</em> <em>networks</em>, as illustrated in Fig.<a href="#_bookmark401">3.2</a> (right). In this case</p>
<blockquote>
<p>the input of layer i can be formally described as a function gi(L<img src="./automlgithubpagesimages//media/image96.png" width="39" height="17" /> , L)</p>
<p>combining previous layer outputs. Employing such a function results in signiﬁcantly</p>
<p>more degrees of freedom. Special cases of these multi-branch architectures are (i)</p>
<p>the chain-structured networks (by setting gi(L<img src="./automlgithubpagesimages//media/image97.png" width="39" height="17" /> , L) = L<img src="./automlgithubpagesimages//media/image98.png" width="16" height="17" />), (ii) Residual</p>
<p>Networks [<a href="#_bookmark414">28</a>], where previous layer outputs are summed (gi(L<img src="./automlgithubpagesimages//media/image99.png" height="15" />t1 , . . . , L) =</p>
<p>L<img src="./automlgithubpagesimages//media/image100.png" height="17" />t1 + Lut,j &lt; i) and (iii) DenseNets [<a href="#_bookmark415">29</a>], where previous layer outputs are</p>
<p>concatenated (gi(L<img src="./automlgithubpagesimages//media/image101.png" width="39" height="15" /> , L) = concat (L<img src="./automlgithubpagesimages//media/image102.png" width="38" height="15" /> , L)).</p>
<p>Motivated by hand-crafted architectures consisting of repeated motifs [<a href="#_bookmark414">28</a>, <a href="#_bookmark415">29</a>, <a href="#_bookmark416">62</a>], Zoph et al. [<a href="#_bookmark413">75</a>] and Zhong et al. [<a href="#_bookmark417">71</a>] propose to search for such motifs, dubbed <em>cells</em> or <em>blocks</em>, respectively, rather than for whole architectures. Zoph et al. [<a href="#_bookmark413">75</a>] optimize two different kind of cells: a <em>normal</em> <em>cell</em> that preservers the dimensionality of the input and a <em>reduction</em> <em>cell</em> which reduces the spatial dimension. The ﬁnal architecture is then built by stacking these cells in a predeﬁned manner, as illustrated</p>
</blockquote>
<p><img src="./automlgithubpagesimages//media/image103.png" width="10" height="36" /><img src="./automlgithubpagesimages//media/image104.png" width="188" height="330" /><img src="./automlgithubpagesimages//media/image105.png" /><img src="./automlgithubpagesimages//media/image106.png" /><img src="./automlgithubpagesimages//media/image107.png" /><img src="./automlgithubpagesimages//media/image108.png" width="159" height="32" /><img src="./automlgithubpagesimages//media/image109.png" width="13" /><img src="./automlgithubpagesimages//media/image110.png" width="10" height="36" /><img src="./automlgithubpagesimages//media/image111.png" /><img src="./automlgithubpagesimages//media/image112.png" width="45" height="15" /><img src="./automlgithubpagesimages//media/image113.png" width="45" height="15" /><img src="./automlgithubpagesimages//media/image114.png" width="10" height="36" /><img src="./automlgithubpagesimages//media/image115.png" height="75" /><img src="./automlgithubpagesimages//media/image116.png" width="159" height="90" /><img src="./automlgithubpagesimages//media/image117.png" /><img src="./automlgithubpagesimages//media/image118.png" height="75" /><img src="./automlgithubpagesimages//media/image119.png" /><img src="./automlgithubpagesimages//media/image120.png" width="10" height="36" /><img src="./automlgithubpagesimages//media/image121.png" /><img src="./automlgithubpagesimages//media/image122.png" /><img src="./automlgithubpagesimages//media/image123.png" /><img src="./automlgithubpagesimages//media/image124.png" height="17" /><img src="./automlgithubpagesimages//media/image125.png" /><img src="./automlgithubpagesimages//media/image126.png" /><img src="./automlgithubpagesimages//media/image127.png" width="45" height="32" /><img src="./automlgithubpagesimages//media/image128.png" width="45" height="34" /><img src="./automlgithubpagesimages//media/image129.png" /><img src="./automlgithubpagesimages//media/image130.png" /><img src="./automlgithubpagesimages//media/image131.png" width="45" height="32" /><img src="./automlgithubpagesimages//media/image132.png" width="79" height="32" /><img src="./automlgithubpagesimages//media/image133.png" width="45" height="32" /><img src="./automlgithubpagesimages//media/image134.png" width="45" height="34" /></p>
<p>T. Elsken et al.</p>
<table>
<tbody>
<tr class="odd">
<td><blockquote>
<p>input</p>
</blockquote></td>
</tr>
<tr class="even">
<td></td>
</tr>
<tr class="odd">
<td></td>
</tr>
</tbody>
</table>
<table>
<tbody>
<tr class="odd">
<td></td>
</tr>
<tr class="even">
<td></td>
</tr>
<tr class="odd">
<td></td>
</tr>
</tbody>
</table>
<table>
<tbody>
<tr class="odd">
<td></td>
</tr>
<tr class="even">
<td></td>
</tr>
<tr class="odd">
<td></td>
</tr>
</tbody>
</table>
<table>
<tbody>
<tr class="odd">
<td></td>
<td></td>
</tr>
<tr class="even">
<td><blockquote>
<p>output</p>
</blockquote></td>
</tr>
</tbody>
</table>
<table>
<tbody>
<tr class="odd">
<td><blockquote>
<p>output</p>
</blockquote></td>
</tr>
</tbody>
</table>
<p><span id="_bookmark418" class="anchor"></span><strong>Fig.</strong> <strong>3.3</strong> Illustration of the cell search space. Left: Two different cells, e.g., a normal cell (top) and a reduction cell (bottom) <a href="#_bookmark413">[75</a>]. Right: an architecture built by stacking the cells sequentially. Note that cells can also be combined in a more complex manner, such as in multi-branch spaces, by simply replacing layers with cells</p>
<blockquote>
<p>in Fig.<a href="#_bookmark418">3.3</a>. This search space has two major advantages compared to the ones discussed above:</p>
<p>1. The size of the search space is drastically reduced since cells can be comparably small. For example, Zoph et al. [<a href="#_bookmark413">75</a>] estimate a seven-times speed-up compared to their previous work [<a href="#_bookmark419">74</a>] while achieving better performance.</p>
<p>2. Cells can more easily be transferred to other datasets by adapting the number of cells used within a model. Indeed, Zoph et al. [<a href="#_bookmark413">75</a>] transfer cells optimized on CIFAR- 10 to ImageNet and achieve state-of-the-art performance.</p>
</blockquote>
<p>Consequently, this cell-based search space was also successfully employed by many later works [<a href="#_bookmark409">11</a>, <a href="#_bookmark411">22</a>, <a href="#_bookmark420">37</a>, <a href="#_bookmark421">39</a>, <a href="#_bookmark422">46</a>, <a href="#_bookmark412">49</a>, <a href="#_bookmark423">72</a>]. However, a new design-choice arises when using a cell-based search space, namely how to choose the <em>meta-architecture</em>: how many cells shall be used and how should they be connected to build the actual model? For example, Zoph et al. [<a href="#_bookmark413">75</a>] build a sequential model from cells, in which each cell receives the outputs of the two preceding cells as input, while Cai et al. [<a href="#_bookmark409">11</a>] employ the high-level structure of well-known manually designed</p>
<blockquote>
<p>3 Neural Architecture Search 67</p>
</blockquote>
<p>architectures, such as DenseNet [<a href="#_bookmark415">29</a>], and use their cells within these models. In principle, cells can be combined arbitrarily, e.g., within the multi-branch space described above by simply replacing layers with cells. Ideally, the meta-architecture should be optimized automatically as part of NAS; otherwise one easily ends up doing meta-architecture engineering and the search for the cell becomes overly simple if most of the complexity is already accounted for by the meta-architecture.</p>
<blockquote>
<p>One step in the direction of optimizing meta-architectures is the hierarchical search space introduced by Liu et al. [<a href="#_bookmark424">38</a>], which consists of several levels of motifs. The ﬁrst level consists of the set of primitive operations, the second level of different motifs that connect primitive operations via a direct acyclic graphs, the third level of motifs that encode how to connect second-level motifs, and so on. The cell-based search space can be seen as a special case of this hierarchical search space where the number of levels is three, the second level motifs corresponds to the cells, and the third level is the hard-coded meta-architecture.</p>
</blockquote>
<p>The choice of the search space largely determines the difﬁculty of the optimiza- tion problem: even for the case of the search space based on a single cell with ﬁxed meta-architecture, the optimization problem remains (i) non-continuous and (ii) relatively high-dimensional (since more complex models tend to perform better, resulting in more design choices). We note that the architectures in many search spaces can be written as ﬁxed-length vectors; e.g., the search space for each of the two cells by Zoph et al. [<a href="#_bookmark413">75</a>] can be written as a 40-dimensional search space with categorical dimensions, each of which chooses between a small number of different building blocks and inputs. Similarly, unbounded search spaces can be constrained to have a maximal depth, giving rise to ﬁxed-size search spaces with (potentially many) conditional dimensions.</p>
<p>In the next section, we discuss Search Strategies that are well-suited for these kinds of search spaces.</p>
<blockquote>
<p><span id="_bookmark397" class="anchor"></span><strong>3.3</strong> <strong>Search</strong> <strong>Strategy</strong></p>
</blockquote>
<p>Many different search strategies can be used to explore the space of neural archi- tectures, including random search, Bayesian optimization, evolutionary methods, reinforcement learning (RL), and gradient-based methods. Historically, evolution- ary algorithms were already used by many researchers to evolve neural architectures (and often also their weights) decades ago [see, e.g.,<a href="#_bookmark425">2</a>,<a href="#_bookmark426">25</a>,<a href="#_bookmark427">55</a>,<a href="#_bookmark428">56</a>]. Yao [<a href="#_bookmark429">67</a>] provides</p>
<blockquote>
<p>a literature review of work earlier than 2000.</p>
</blockquote>
<p>Bayesian optimization celebrated several early successes in NAS since 2013, leading to state-of-the-art vision architectures [<a href="#_bookmark430">7</a>], state-of-the-art performance for CIFAR- 10 without data augmentation [<a href="#_bookmark431">19</a>], and the ﬁrst automatically-tuned neural networks to win competition datasets against human experts [<a href="#_bookmark407">41</a>]. NAS became a mainstream research topic in the machine learning community after Zoph and Le [<a href="#_bookmark419">74</a>] obtained competitive performance on the CIFAR- 10 and Penn Treebank benchmarks with a search strategy based on reinforcement learning. While Zoph</p>
<blockquote>
<p>68 T. Elsken et al.</p>
</blockquote>
<p>and Le [<a href="#_bookmark419">74</a>] use vast computational resources to achieve this result (800 GPUs for three to four weeks), after their work, a wide variety of methods have been published in quick succession to reduce the computational costs and achieve further improvements in performance.</p>
<p>To frame NAS as a <em>reinforcement</em> <em>learning</em> (RL) problem [<a href="#_bookmark404">4</a>, <a href="#_bookmark417">71</a>, <a href="#_bookmark419">74</a>, <a href="#_bookmark413">75</a>], the generation of a neural architecture can be considered to be the agent’s action, with the action space identical to the search space. The agent’s reward is based on an estimate of the performance of the trained architecture on unseen data (see Sect.<a href="#_bookmark398">3.4</a>). Different RL approaches differ in how they represent the agent’s policy and how they optimize it: Zoph and Le [<a href="#_bookmark419">74</a>] use a recurrent neural network (RNN) policy to sequentially sample a string that in turn encodes the neural architecture. They initially trained this network with the REINFORCE policy gradient algorithm, but in follow-up work use Proximal Policy Optimization (PPO) instead [<a href="#_bookmark413">75</a>]. Baker et al. [<a href="#_bookmark404">4</a>] use Q-learning to train a policy which sequentially chooses a layer’s type and corresponding hyperparameters. An alternative view of these approaches is as sequential decision processes in which the policy samples actions to generate the architecture sequentially, the environment’s “state” contains a summary of the actions sampled so far, and the (undiscounted) reward is obtained only after the ﬁnal action. However, since no interaction with an environment occurs during this sequential process (no external state is observed, and there are no intermediate rewards), we ﬁnd it more intuitive to interpret the architecture sampling process as the sequential generation of a single action; this simpliﬁes the RL problem to a stateless multi-armed bandit problem.</p>
<blockquote>
<p>A related approach was proposed by Cai et al. [<a href="#_bookmark405">10</a>], who frame NAS as a sequential decision process: in their approach the state is the current (partially trained) architecture, the reward is an estimate of the architecture’s performance, and the action corresponds to an application of function-preserving mutations, dubbed network morphisms [<a href="#_bookmark432">12</a>, <a href="#_bookmark433">63</a>], see also Sect.<a href="#_bookmark398">3.4</a>, followed by a phase of training the network. In order to deal with variable-length network architectures, they use a bi- directional LSTM to encode architectures into a ﬁxed-length representation. Based on this encoded representation, actor networks decide on the sampled action. The combination of these two components constitute the policy, which is trained end- to-end with the REINFORCE policy gradient algorithm. We note that this approach will not visit the same state (architecture) twice so that strong generalization over the architecture space is required from the policy.</p>
</blockquote>
<p>An alternative to using RL are <em>neuro-evolutionary</em> approaches that use evolu- tionary algorithms for optimizing the neural architecture. The ﬁrst such approach for designing neural networks we are aware of dates back almost three decades: Miller et al. [<a href="#_bookmark434">44</a>] use genetic algorithms to propose architectures and use back- propagation to optimize their weights. Many neuro-evolutionary approaches since then [<a href="#_bookmark425">2</a>, <a href="#_bookmark427">55</a>, <a href="#_bookmark428">56</a>] use genetic algorithms to optimize both the neural architecture and its weights; however, when scaling to contemporary neural architectures with millions of weights for supervised learning tasks, SGD-based weight optimization</p>
<p><img src="./automlgithubpagesimages//media/image12.jpeg" width="136" /></p>
<blockquote>
<p>3 Neural Architecture Search 69</p>
<p>methods currently outperform evolutionary ones.<a href="#_bookmark435">1</a> More recent neuro-evolutionary approaches [<a href="#_bookmark411">22</a>, <a href="#_bookmark424">38</a>, <a href="#_bookmark436">43</a>, <a href="#_bookmark412">49</a>, <a href="#_bookmark437">50</a>, <a href="#_bookmark406">59</a>, <a href="#_bookmark438">66</a>] therefore again use gradient-based methods for optimizing weights and solely use evolutionary algorithms for optimizing the neural architecture itself. Evolutionary algorithms evolve a population of models, i.e., a set of (possibly trained) networks; in every evolution step, at least one model from the population is sampled and serves as a parent to generate offsprings by applying mutations to it. In the context of NAS, mutations are local operations, such as adding or removing a layer, altering the hyperparameters of a layer, adding skip connections, as well as altering training hyperparameters. After training the offsprings, their ﬁtness (e.g., performance on a validation set) is evaluated and they are added to the population.</p>
</blockquote>
<p>Neuro-evolutionary methods differ in how they sample parents, update popula- tions, and generate offsprings. For example, Real et al. [<a href="#_bookmark437">50</a>], Real et al. [<a href="#_bookmark412">49</a>], and Liu et al. [<a href="#_bookmark424">38</a>] use tournament selection [<a href="#_bookmark439">27</a>] to sample parents, whereas Elsken et al. [<a href="#_bookmark411">22</a>] sample parents from a multi-objective Pareto front using an inverse density. Real et al. [<a href="#_bookmark437">50</a>] remove the worst individual from a population, while Real et al. [<a href="#_bookmark412">49</a>] found it beneﬁcial to remove the oldest individual (which decreases greediness), and Liu et al. [<a href="#_bookmark424">38</a>] do not remove individuals at all. To generate offspring, most approaches initialize child networks randomly, while Elsken et al. [<a href="#_bookmark411">22</a>] employ Lamarckian inheritance, i.e, knowledge (in the form of learned weights) is passed on from a parent network to its children by using network morphisms. Real et al. [<a href="#_bookmark437">50</a>] also let an offspring inherit all parameters of its parent that are not affected by the applied mutation; while this inheritance is not strictly function-preserving it might also speed up learning compared to a random initialization. Moreover, they also allow mutating the learning rate which can be seen as a way for optimizing the learning rate schedule during NAS.</p>
<p>Real et al. [<a href="#_bookmark412">49</a>] conduct a case study comparing RL, evolution, and random search (RS), concluding that RL and evolution perform equally well in terms of ﬁnal test accuracy, with evolution having better anytime performance and ﬁnding smaller models. Both approaches consistently perform better than RS in their experiments, but with a rather small margin: RS achieved test errors of approximately 4% on CIFAR- 10, while RL and evolution reached approximately 3.5% (after “model augmentation” where depth and number of ﬁlters was increased; the difference on the actual, non-augmented search space was approx. 2%). The difference was even smaller for Liu et al. [<a href="#_bookmark424">38</a>], who reported a test error of 3.9% on CIFAR- 10 and a top- 1 validation error of 21.0% on ImageNet for RS, compared to 3.75% and 20.3% for their evolution-based method, respectively.</p>
<blockquote>
<p><em>Bayesian</em> <em>Optimization</em> (BO, see, e.g., [<a href="#_bookmark440">53</a>]) is one of the most popular methods for hyperparameter optimization (see also Chap.<a href="#_bookmark2">1</a> of this book), but it has not</p>
</blockquote>
<p><span id="_bookmark435" class="anchor"></span>1 Some recent work shows that evolving even millions of weights is competitive to gradient- based optimization when only high-variance estimates of the gradient are available, e.g., for reinforcement learning tasks <a href="#_bookmark441">[15</a>,<a href="#_bookmark442">51</a>,<a href="#_bookmark443">57</a>]. Nonetheless, for supervised learning tasks gradient-based optimization is by far the most common approach.</p>
<blockquote>
<p>70 T. Elsken et al.</p>
</blockquote>
<p>been applied to NAS by many groups since typical BO toolboxes are based on Gaussian processes and focus on low-dimensional continuous optimization problems. Swersky et al. [<a href="#_bookmark444">60</a>] and Kandasamy et al. [<a href="#_bookmark445">31</a>] derive kernel functions for architecture search spaces in order to use classic GP-based BO methods, but so far without achieving new state-of-the-art performance. In contrast, several works use tree-based models (in particular, treed Parzen estimators [<a href="#_bookmark446">8</a>], or random forests [<a href="#_bookmark447">30</a>]) to effectively search very high-dimensional conditional spaces and achieve state-of-the-art performance on a wide range of problems, optimizing both</p>
<blockquote>
<p>neural architectures and their hyperparameters jointly [<a href="#_bookmark430">7</a>, <a href="#_bookmark431">19</a>, <a href="#_bookmark407">41</a>, <a href="#_bookmark448">69</a>]. While a full comparison is lacking, there is preliminary evidence that these approaches can also outperform evolutionary algorithms [<a href="#_bookmark449">33</a>].</p>
<p>Architectural search spaces have also been explored in a <em>hierarchical</em> manner, e.g., in combination with evolution [<a href="#_bookmark424">38</a>] or by sequential model-based optimization [<a href="#_bookmark420">37</a>]. Negrinho and Gordon [<a href="#_bookmark450">45</a>] and Wistuba [<a href="#_bookmark451">65</a>] exploit the tree-structure of their search space and use <em>Monte</em> <em>Carlo</em> <em>Tree</em> <em>Search</em>. Elsken et al. [<a href="#_bookmark410">21</a>] propose a simple yet well performing <em>hill</em> <em>climbing</em> algorithm that discovers high-quality architectures by greedily moving in the direction of better performing architectures without requiring more sophisticated exploration mechanisms.</p>
</blockquote>
<p>In contrast to the gradient-free optimization methods above, Liu et al. [<a href="#_bookmark421">39</a>] propose a continuous relaxation of the search space to enable <em>gradient-based</em> <em>optimization</em>: instead of ﬁxing a single operation oi (e.g., convolution or pooling) to be executed at a speciﬁc layer, the authors compute a convex combination from a set of operations {o1 , . . . , om}. More speciﬁcally, given a layer input x, the layer output y is computed as y = 对<img src="./automlgithubpagesimages//media/image135.png" width="11" height="18" />1 λioi(x), λi ≥ 0, 对<img src="./automlgithubpagesimages//media/image136.png" width="11" height="18" />1 λi = 1, where the convex coefﬁcients λi effectively parameterize the network architecture. Liu et al. [<a href="#_bookmark421">39</a>] then optimize both the network weights and the network architecture by alternating gradient descent steps on training data for weights and on validation data for architectural parameters such as λ . Eventually, a discrete architecture is obtained by choosing the operation i with i = arg maxi λi for every layer. Shin et al. [<a href="#_bookmark452">54</a>] and Ahmed and Torresani [<a href="#_bookmark453">1</a>] also employ gradient-based optimization of neural architectures, however they only consider optimizing layer hyperparameters or connectivity patterns, respectively.</p>
<blockquote>
<p><span id="_bookmark398" class="anchor"></span><strong>3.4</strong> <strong>Performance</strong> <strong>Estimation</strong> <strong>Strategy</strong></p>
<p>The search strategies discussed in Sect.<a href="#_bookmark397">3.3</a> aim at ﬁnding a neural architecture A that maximizes some performance measure, such as accuracy on unseen data. To guide their search process, these strategies need to estimate the performance of a given architecture A they consider. The simplest way of doing this is to train A on training data and evaluate its performance on validation data. However, training each architecture to be evaluated from scratch frequently yields computational demands in the order of thousands of GPU days for NAS [<a href="#_bookmark412">49</a>, <a href="#_bookmark437">50</a>, <a href="#_bookmark419">74</a>, <a href="#_bookmark413">75</a>].</p>
<p><span id="_bookmark16" class="anchor"></span>3 Neural Architecture Search 71</p>
</blockquote>
<p>To reduce this computational burden, performance can be estimated based on <em>lower</em> <em>ﬁdelities</em> of the actual performance after full training (also denoted as proxy metrics). Such lower ﬁdelities include shorter training times [<a href="#_bookmark448">69</a>, <a href="#_bookmark413">75</a>], training on a subset of the data [<a href="#_bookmark454">34</a>], on lower-resolution images [<a href="#_bookmark455">14</a>], or with less ﬁlters per layer [<a href="#_bookmark412">49</a>, <a href="#_bookmark413">75</a>]. While these low-ﬁdelity approximations reduce the computational cost, they also introduce bias in the estimate as performance will typically be underestimated. This may not be problematic as long as the search strategy only relies on ranking different architectures and the relative ranking remains stable. However, recent results indicate that this relative ranking can change dramatically when the difference between the cheap approximations and the “full” evaluation is too big [<a href="#_bookmark448">69</a>], arguing for a gradual increase in ﬁdelities [<a href="#_bookmark456">24</a>, <a href="#_bookmark457">35</a>].</p>
<p>Another possible way of estimating an architecture’s performance builds upon learning curve extrapolation [<a href="#_bookmark458">5</a>, <a href="#_bookmark431">19</a>, <a href="#_bookmark459">32</a>, <a href="#_bookmark460">48</a>, <a href="#_bookmark461">61</a>]. Domhan et al. [<a href="#_bookmark431">19</a>] propose to extrapolate initial learning curves and terminate those predicted to perform poorly to speed up the architecture search process. Baker et al. [<a href="#_bookmark458">5</a>], Klein et al. [<a href="#_bookmark459">32</a>], Rawal and Miikkulainen [<a href="#_bookmark460">48</a>], Swersky et al. [<a href="#_bookmark461">61</a>] also consider architectural hyperparameters for predicting which partial learning curves are most promising. Training a surrogate model for predicting the performance of novel architectures is also proposed by Liu et al. [<a href="#_bookmark420">37</a>], who do not employ learning curve extrapolation but support predicting performance based on architectural/cell properties and extrapolate to architectures/cells with larger size than seen during training. The main challenge for predicting the performances of neural architectures is that, in order to speed up the search process, good predictions in a relatively large search space need to be made based on relatively few evaluations.</p>
<blockquote>
<p>Another approach to speed up performance estimation is to initialize the weights of novel architectures based on weights of other architectures that have been trained before. One way of achieving this, dubbed <em>network</em> <em>morphisms</em> [<a href="#_bookmark462">64</a>], allows modifying an architecture while leaving the function represented by the network unchanged [<a href="#_bookmark405">10</a>,<a href="#_bookmark409">11</a>,<a href="#_bookmark410">21</a>,<a href="#_bookmark411">22</a>]. This allows increasing capacity of networks successively and retaining high performance without requiring training from scratch. Continuing training for a few epochs can also make use of the additional capacity introduced by network morphisms. An advantage of these approaches is that they allow search spaces without an inherent upper bound on the architecture’s size [<a href="#_bookmark410">21</a>]; on the other hand, strict network morphisms can only make architectures larger and may thus lead to overly complex architectures. This can be attenuated by employing approximate network morphisms that allow shrinking architectures [<a href="#_bookmark411">22</a>].</p>
</blockquote>
<p><em>One-Shot</em> <em>Architecture</em> <em>Search</em> is another promising approach for speeding up performance estimation, which treats all architectures as different subgraphs of a supergraph (the one-shot model) and shares weights between architectures that have edges of this supergraph in common [<a href="#_bookmark463">6</a>, <a href="#_bookmark408">9</a>, <a href="#_bookmark421">39</a>, <a href="#_bookmark422">46</a>, <a href="#_bookmark464">52</a>]. Only the weights of a single one-shot model need to be trained (in one of various ways), and architectures (which are just subgraphs of the one-shot model) can then be evaluated without any separate training by inheriting trained weights from the one-shot model. This greatly speeds up performance estimation of architectures, since no training is required (only evaluating performance on validation data). This approach typically</p>
<blockquote>
<p>72 T. Elsken et al.</p>
<p>incurs a large bias as it underestimates the actual performance of architectures severely; nevertheless, it allows ranking architectures reliably, since the estimated</p>
</blockquote>
<p>performance correlates strongly with the actual performance [<a href="#_bookmark463">6</a>]. Different one-shot NAS methods differ in how the one-shot model is trained: ENAS [<a href="#_bookmark422">46</a>] learns an RNN controller that samples architectures from the search space and trains the one-shot model based on approximate gradients obtained through REINFORCE. DARTS [<a href="#_bookmark421">39</a>] optimizes all weights of the one-shot model jointly with a continuous relaxation of the search space obtained by placing a mixture of candidate operations on each edge of the one-shot model. Bender et al. [<a href="#_bookmark463">6</a>] only train the one-shot model once and show that this is sufﬁcient when deactivating parts of this model stochastically during training using path dropout. While ENAS and DARTS optimize a distribution over architectures during training, the approach of Bender et al. [<a href="#_bookmark463">6</a>] can be seen as using a ﬁxed distribution. The high performance obtainable by the approach of Bender et al. [<a href="#_bookmark463">6</a>] indicates that the combination of weight sharing and a ﬁxed (carefully chosen) distribution might (perhaps surprisingly) be the only required ingredients for one-shot NAS. Related to these approaches is meta-learning of hypernetworks that generate weights for novel architectures and thus requires only training the hypernetwork but not the architectures themselves [<a href="#_bookmark408">9</a>]. The main difference here is that weights are not strictly shared but generated by the shared hypernetwork (conditional on the sampled architecture).</p>
<p>A general limitation of one-shot NAS is that the supergraph deﬁned a-priori restricts the search space to its subgraphs. Moreover, approaches which require that the entire supergraph resides in GPU memory during architecture search will be restricted to relatively small supergraphs and search spaces accordingly and are thus typically used in combination with cell-based search spaces. While approaches based on weight-sharing have substantially reduced the computational resources required for NAS (from thousands to a few GPU days), it is currently not well understood which biases they introduce into the search if the sampling distribution of architectures is optimized along with the one-shot model. For instance, an initial bias in exploring certain parts of the search space more than others might lead to the weights of the one-shot model being better adapted for these architectures, which in turn would reinforce the bias of the search to these parts of the search space. This might result in premature convergence of NAS and might be one advantage of a ﬁxed sampling distribution as used by Bender et al. [<a href="#_bookmark463">6</a>]. In general, a more systematic analysis of biases introduced by different performance estimators would be a desirable direction for future work.</p>
<blockquote>
<p><span id="_bookmark399" class="anchor"></span><strong>3.5</strong> <strong>Future</strong> <strong>Directions</strong></p>
<p>In this section, we discuss several current and future directions for research on NAS.</p>
<p>Most existing work has focused on NAS for image classiﬁcation. On the one hand, this provides a challenging benchmark since a lot of manual engineering has been devoted to ﬁnding architectures that perform well in this domain and are not easily outperformed by NAS. On the other hand, it is relatively easy to deﬁne a well-suited search space by utilizing knowledge from manual engineering. This in turn makes</p>
<p>3 Neural Architecture Search 73</p>
</blockquote>
<p>it unlikely that NAS will ﬁnd architectures that substantially outperform existing ones considerably since the found architectures cannot differ fundamentally. We thus consider it important to go beyond image classiﬁcation problems by applying NAS to less explored domains. Notable ﬁrst steps in this direction are applying NAS to language modeling [<a href="#_bookmark419">74</a>], music modeling [<a href="#_bookmark460">48</a>], image restoration [<a href="#_bookmark465">58</a>] and network compression [<a href="#_bookmark466">3</a>]; applications to reinforcement learning, generative adversarial networks, semantic segmentation, or sensor fusion could be further promising future directions.</p>
<p>An alternative direction is developing NAS methods for multi-task problems [<a href="#_bookmark467">36</a>, <a href="#_bookmark468">42</a>] and for multi-objective problems [<a href="#_bookmark469">20</a>, <a href="#_bookmark411">22</a>, <a href="#_bookmark470">73</a>], in which measures of resource efﬁciency are used as objectives along with the predictive performance on unseen data. Likewise, it would be interesting to extend RL/bandit approaches, such as those discussed in Sect.<a href="#_bookmark397">3.3</a>, to learn policies that are conditioned on a state that encodes task properties/resource requirements (i.e., turning the setting into a contextual bandit). A similar direction was followed by Ramachandran and Le [<a href="#_bookmark471">47</a>] in extending one-shot NAS to generate different architectures depending on the task or instance on-the-ﬂy. Moreover, applying NAS to searching for architectures that are more robust to adversarial examples [<a href="#_bookmark472">17</a>] is an intriguing recent direction.</p>
<p>Related to this is research on deﬁning more general and ﬂexible search spaces. For instance, while the cell-based search space provides high transferability between different image classiﬁcation tasks, it is largely based on human experience on image classiﬁcation and does not generalize easily to other domains where the hard- coded hierarchical structure (repeating the same cells several times in a chain-like structure) does not apply (e.g., semantic segmentation or object detection). A search space which allows representing and identifying more general hierarchical structure would thus make NAS more broadly applicable, see Liu et al. [<a href="#_bookmark424">38</a>] for ﬁrst work in this direction. Moreover, common search spaces are also based on predeﬁned building blocks, such as different kinds of convolutions and pooling, but do not allow identifying novel building blocks on this level; going beyond this limitation might substantially increase the power of NAS.</p>
<p>The comparison of different methods for NAS is complicated by the fact that measurements of an architecture’s performance depend on many factors other than the architecture itself. While most authors report results on the CIFAR- 10 dataset, experiments often differ with regard to search space, computational budget, data augmentation, training procedures, regularization, and other factors. For example, for CIFAR- 10, performance substantially improves when using a cosine annealing learning rate schedule [<a href="#_bookmark473">40</a>], data augmentation by CutOut [<a href="#_bookmark474">18</a>], by MixUp [<a href="#_bookmark475">70</a>] or by a combination of factors [<a href="#_bookmark476">16</a>], and regularization by Shake-Shake regularization [<a href="#_bookmark477">26</a>] or scheduled drop-path [<a href="#_bookmark413">75</a>]. It is therefore conceivable that improvements in these ingredients have a larger impact on reported performance numbers than the better architectures found by NAS. We thus consider the deﬁnition of common benchmarks to be crucial for a fair comparison of different NAS methods. A ﬁrst step in this direction is the deﬁnition of a benchmark for joint architecture and hyperparameter search for a fully connected neural network with two hidden layers [<a href="#_bookmark449">33</a>]. In this benchmark, nine discrete hyperparameters need to be optimized</p>
<blockquote>
<p>74 T. Elsken et al.</p>
<p>that control both architecture and optimization/regularization. All 62.208 possible hyperparameter combinations have been pre-evaluated such that different methods can be compared with low computational resources. However, the search space is still very simple compared to the spaces employed by most NAS methods. It would also be interesting to evaluate NAS methods not in isolation but as part of a full open-source AutoML system, where also hyperparameters [<a href="#_bookmark407">41</a>, <a href="#_bookmark437">50</a>, <a href="#_bookmark448">69</a>], and data augmentation pipeline [<a href="#_bookmark476">16</a>] are optimized along with NAS.</p>
<p>While NAS has achieved impressive performance, so far it provides little insights into why speciﬁc architectures work well and how similar the architectures derived in independent runs would be. Identifying common motifs, providing an understand- ing why those motifs are important for high performance, and investigating if these motifs generalize over different problems would be desirable.</p>
</blockquote>
<p><strong>Acknowledgements</strong> We would like to thank Esteban Real, Arber Zela, Gabriel Bender, Kenneth Stanley and Thomas Pfeil for feedback on earlier versions of this survey. This work has partly been supported by the European Research Council (ERC) under the European Union’s Horizon 2020 research and innovation programme under grant no. 716721.</p>
<blockquote>
<p><span id="_bookmark453" class="anchor"></span><strong>Bibliography</strong></p>
<p>1. Ahmed, K., Torresani, L.: Maskconnect: Connectivity learning by gradient descent. In: <span id="_bookmark425" class="anchor"></span>European Conference on Computer Vision (ECCV) (2018)</p>
<p>2. Angeline, P.J., Saunders, G.M., Pollack, J.B.: An evolutionary algorithm that constructs recurrent neural networks. IEEE transactions on neural networks 5 1, 54–65 (1994)</p>
<p><span id="_bookmark466" class="anchor"></span>3. Ashok, A., Rhinehart, N., Beainy, F., Kitani, K.M.: N2n learning: Network to network compression via policy gradient reinforcement learning. In: International Conference on <span id="_bookmark404" class="anchor"></span>Learning Representations (2018)</p>
<p>4. Baker, B., Gupta, O., Naik, N., Raskar, R.: Designing neural network architectures using reinforcement learning. In: International Conference on Learning Representations (2017a)</p>
<p><span id="_bookmark458" class="anchor"></span>5. Baker, B., Gupta, O., Raskar, R., Naik, N.: Accelerating Neural Architecture Search using <span id="_bookmark463" class="anchor"></span>Performance Prediction. In: NIPS Workshop on Meta-Learning (2017b)</p>
<p>6. Bender, G., Kindermans, P.J., Zoph, B., Vasudevan, V., Le, Q.: Understanding and simplifying one-shot architecture search. In: International Conference on Machine Learning (2018)</p>
<p><span id="_bookmark430" class="anchor"></span>7. Bergstra, J., Yamins, D., Cox, D.D.: Making a science of model search: Hyperparameter optimization in hundreds of dimensions for vision architectures. In: ICML (2013)</p>
<p><span id="_bookmark446" class="anchor"></span>8. Bergstra, J.S., Bardenet, R., Bengio, Y., Kégl, B.: Algorithms for hyper-parameter optimiza- tion. In: Shawe-Taylor, J., Zemel, R.S., Bartlett, P.L., Pereira, F., Weinberger, K.Q. (eds.) Advances in Neural Information Processing Systems 24. pp. 2546–2554 (2011)</p>
<p><span id="_bookmark408" class="anchor"></span>9. Brock, A., Lim, T., Ritchie, J.M., Weston, N.: SMASH: one-shot model architecture search <span id="_bookmark405" class="anchor"></span>through hypernetworks. In: NIPS Workshop on Meta-Learning (2017)</p>
<p>10. Cai, H., Chen, T., Zhang, W., Yu, Y., Wang, J.: Efﬁcient architecture search by network transformation. In: Association for the Advancement of Artiﬁcial Intelligence (2018a)</p>
<p><span id="_bookmark409" class="anchor"></span>11. Cai, H., Yang, J., Zhang, W., Han, S., Yu, Y.: Path-Level Network Transformation for Efﬁcient Architecture Search. In: International Conference on Machine Learning (Jun 2018b)</p>
<p><span id="_bookmark432" class="anchor"></span>12. Chen, T., Goodfellow, I.J., Shlens, J.: Net2net: Accelerating learning via knowledge transfer. In: International Conference on Learning Representations (2016)</p>
<p>13. Chollet, F.: Xception: Deep learning with depthwise separable convolutions. arXiv:1610.02357</p>
<p><span id="_bookmark455" class="anchor"><span id="_bookmark402" class="anchor"></span></span>(2016)</p>
<p>14. Chrabaszcz, P., Loshchilov, I., Hutter, F.: A downsampled variant of imagenet as an alternative to the CIFAR datasets. CoRR abs/1707.08819 (2017)</p>
<p>3 Neural Architecture Search 75</p>
<p><span id="_bookmark441" class="anchor"></span>15. Chrabaszcz, P., Loshchilov, I., Hutter, F.: Back to basics: Benchmarking canonical evolution strategies for playing atari. In: Proceedings of the Twenty-Seventh International Joint Confer- ence on Artiﬁcial Intelligence, IJCAI-18. pp. 1419– 1426. International Joint Conferences on <span id="_bookmark476" class="anchor"></span>Artiﬁcial Intelligence Organization (Jul 2018)</p>
<p>16. Cubuk, E.D., Zoph, B., Mane, D., Vasudevan, V., Le, Q.V.: AutoAugment: Learning Augmen- <span id="_bookmark472" class="anchor"></span>tation Policies from Data. In: arXiv:1805.09501 (May 2018)</p>
<p>17. Cubuk, E.D., Zoph, B., Schoenholz, S.S., Le, Q.V.: Intriguing Properties of Adversarial <span id="_bookmark474" class="anchor"></span>Examples. In: arXiv:1711.02846 (Nov 2017)</p>
<p>18. Devries, T., Taylor, G.W.: Improved regularization of convolutional neural networks with <span id="_bookmark431" class="anchor"></span>cutout. arXiv preprint abs/1708.04552 (2017)</p>
<p>19. Domhan, T., Springenberg, J.T., Hutter, F.: Speeding up automatic hyperparameter optimiza- tion of deep neural networks by extrapolation of learning curves. In: Proceedings of the 24th <span id="_bookmark469" class="anchor"></span>International Joint Conference on Artiﬁcial Intelligence (IJCAI) (2015)</p>
</blockquote>
<p>20. Dong, J.D., Cheng, A.C., Juan, D.C., Wei, W., Sun, M.: Dpp-net: Device-aware progressive search for pareto-optimal neural architectures. In: European Conference on Computer Vision</p>
<blockquote>
<p><span id="_bookmark410" class="anchor"></span>(2018)</p>
</blockquote>
<p>21. Elsken, T., Metzen, J.H., Hutter, F.: Simple And Efﬁcient Architecture Search for Convolu- <span id="_bookmark411" class="anchor"></span>tional Neural Networks. In: NIPS Workshop on Meta-Learning (2017)</p>
<p>22. Elsken, T., Metzen, J.H., Hutter, F.: Efﬁcient Multi-objective Neural Architecture Search via Lamarckian Evolution. In: International Conference on Learning Representations (2019)</p>
<p>23. Elsken, T., Metzen, J.H., Hutter, F.: Neural architecture search: A survey. arXiv:1808.05377</p>
<blockquote>
<p><span id="_bookmark400" class="anchor"><span id="_bookmark456" class="anchor"></span></span>(2018)</p>
</blockquote>
<p>24. Falkner, S., Klein, A., Hutter, F.: BOHB: Robust and efﬁcient hyperparameter optimization at scale. In: Dy, J., Krause, A. (eds.) Proceedings of the 35th International Conference on Machine Learning. Proceedings of Machine Learning Research, vol. 80, pp. 1436– 1445. <span id="_bookmark426" class="anchor"></span>PMLR, Stockholmsmässan, Stockholm Sweden (10– 15 Jul 2018)</p>
<p>25. Floreano, D., Dürr, P., Mattiussi, C.: Neuroevolution: from architectures to learning. Evolu- <span id="_bookmark477" class="anchor"></span>tionary Intelligence 1(1), 47–62 (2008)</p>
<p>26. Gastaldi, X.: Shake-shake regularization. In: International Conference on Learning Represen- <span id="_bookmark439" class="anchor"></span>tations Workshop (2017)</p>
<p>27. Goldberg, D.E., Deb, K.: A comparative analysis of selection schemes used in genetic algorithms. In: Foundations of Genetic Algorithms. pp. 69–93. Morgan Kaufmann (1991)</p>
<p><span id="_bookmark414" class="anchor"></span>28. He, K., Zhang, X., Ren, S., Sun, J.: Deep Residual Learning for Image Recognition. In: <span id="_bookmark415" class="anchor"></span>Conference on Computer Vision and Pattern Recognition (2016)</p>
<p>29. Huang, G., Liu, Z., Weinberger, K.Q.: Densely Connected Convolutional Networks. In: <span id="_bookmark447" class="anchor"></span>Conference on Computer Vision and Pattern Recognition (2017)</p>
<blockquote>
<p>30. Hutter, F., Hoos, H., Leyton-Brown, K.: Sequential model-based optimization for general <span id="_bookmark445" class="anchor"></span>algorithm conﬁguration. In: LION. pp. 507–523 (2011)</p>
<p>31. Kandasamy, K., Neiswanger, W., Schneider, J., Poczos, B., Xing, E.: Neural Architecture Search with Bayesian Optimisation and Optimal Transport. arXiv:1802.07191 (Feb 2018)</p>
<p><span id="_bookmark459" class="anchor"></span>32. Klein, A., Falkner, S., Springenberg, J.T., Hutter, F.: Learning curve prediction with Bayesian neural networks. In: International Conference on Learning Representations (2017a)</p>
<p><span id="_bookmark449" class="anchor"></span>33. Klein, A., Christiansen, E., Murphy, K., Hutter, F.: Towards reproducible neural architecture and hyperparameter search. In: ICML 2018 Workshop on Reproducibility in ML (RML 2018)</p>
<p><span id="_bookmark454" class="anchor"></span>(2018)</p>
<p>34. Klein, A., Falkner, S., Bartels, S., Hennig, P., Hutter, F.: Fast Bayesian Optimization of Machine Learning Hyperparameters on Large Datasets. In: Singh, A., Zhu, J. (eds.) Proceedings of the 20th International Conference on Artiﬁcial Intelligence and Statistics. Proceedings of Machine Learning Research, vol. 54, pp. 528–536. PMLR, Fort Lauderdale, <span id="_bookmark457" class="anchor"></span>FL, USA (20–22 Apr 2017b)</p>
<p>35. Li, L., Jamieson, K., DeSalvo, G., Rostamizadeh, A., Talwalkar, A.: Hyperband: bandit-based conﬁguration evaluation for hyperparameter optimization. In: International Conference on <span id="_bookmark467" class="anchor"></span>Learning Representations (2017)</p>
<p>36. Liang, J., Meyerson, E., Miikkulainen, R.: Evolutionary Architecture Search For Deep Multitask Networks. In: arXiv:1803.03745 (Mar 2018)</p>
<p>76 T. Elsken et al.</p>
<p><span id="_bookmark420" class="anchor"></span>37. Liu, C., Zoph, B., Neumann, M., Shlens, J., Hua, W., Li, L.J., Fei-Fei, L., Yuille, A., Huang, J., Murphy, K.: Progressive Neural Architecture Search. In: European Conference on Computer <span id="_bookmark424" class="anchor"></span>Vision (2018a)</p>
<p>38. Liu, H., Simonyan, K., Vinyals, O., Fernando, C., Kavukcuoglu, K.: Hierarchical Rep- resentations for Efﬁcient Architecture Search. In: International Conference on Learning <span id="_bookmark421" class="anchor"></span>Representations (2018b)</p>
<p>39. Liu, H., Simonyan, K., Yang, Y.: Darts: Differentiable architecture search. In: International <span id="_bookmark473" class="anchor"></span>Conference on Learning Representations (2019)</p>
</blockquote>
<p>40. Loshchilov, I., Hutter, F.: Sgdr: Stochastic gradient descent with warm restarts. In: International <span id="_bookmark407" class="anchor"></span>Conference on Learning Representations (2017)</p>
<p>41. Mendoza, H., Klein, A., Feurer, M., Springenberg, J., Hutter, F.: Towards Automatically-Tuned Neural Networks. In: International Conference on Machine Learning, AutoML Workshop (Jun <span id="_bookmark468" class="anchor"></span>2016)</p>
<p>42. Meyerson, E., Miikkulainen, R.: Pseudo-task Augmentation: From Deep Multitask Learning <span id="_bookmark436" class="anchor"></span>to Intratask Sharing and Back. In: arXiv:1803.03745 (Mar 2018)</p>
<p>43. Miikkulainen, R., Liang, J., Meyerson, E., Rawal, A., Fink, D., Francon, O., Raju, B., Shahrzad, H., Navruzyan, A., Duffy, N., Hodjat, B.: Evolving Deep Neural Networks. In: <span id="_bookmark434" class="anchor"></span>arXiv:1703.00548 (Mar 2017)</p>
<p>44. Miller, G., Todd, P., Hedge, S.: Designing neural networks using genetic algorithms. In: 3rd <span id="_bookmark450" class="anchor"></span>International Conference on Genetic Algorithms (ICGA’89) (1989)</p>
<p>45. Negrinho, R., Gordon, G.: DeepArchitect: Automatically Designing and Training Deep <span id="_bookmark422" class="anchor"></span>Architectures. arXiv:1704.08792 (2017)</p>
<p>46. Pham, H., Guan, M.Y., Zoph, B., Le, Q.V., Dean, J.: Efﬁcient neural architecture search via parameter sharing. In: International Conference on Machine Learning (2018)</p>
<p>47. Ramachandran, P., Le, Q.V.: Dynamic Network Architectures. In: AutoML 2018 (ICML <span id="_bookmark471" class="anchor"><span id="_bookmark460" class="anchor"></span></span>workshop) (2018)</p>
<p>48. Rawal, A., Miikkulainen, R.: From Nodes to Networks: Evolving Recurrent Neural Networks. <span id="_bookmark412" class="anchor"></span>In: arXiv:1803.04439 (Mar 2018)</p>
<p>49. Real, E., Aggarwal, A., Huang, Y., Le, Q.V.: Aging Evolution for Image Classiﬁer Architecture <span id="_bookmark437" class="anchor"></span>Search. In: AAAI Conference on Artiﬁcial Intelligence (2019)</p>
<blockquote>
<p>50. Real, E., Moore, S., Selle, A., Saxena, S., Suematsu, Y.L., Le, Q.V., Kurakin, A.: Large-scale evolution of image classiﬁers. International Conference on Machine Learning (2017)</p>
<p>51. Salimans, T., Ho, J., Chen, X., Sutskever, I.: Evolution strategies as a scalable alternative to <span id="_bookmark464" class="anchor"><span id="_bookmark442" class="anchor"></span></span>reinforcement learning. arXiv preprint (2017)</p>
<p>52. Saxena, S., Verbeek, J.: Convolutional neural fabrics. In: Lee, D.D., Sugiyama, M., Luxburg, U.V., Guyon, I., Garnett, R. (eds.) Advances in Neural Information Processing Systems 29, <span id="_bookmark440" class="anchor"></span>pp. 4053–4061. Curran Associates, Inc. (2016)</p>
<p>53. Shahriari, B., Swersky, K., Wang, Z., Adams, R.P., de Freitas, N.: Taking the human out of the loop: A review of bayesian optimization. Proceedings of the IEEE 104(1), 148– 175 (Jan 2016)</p>
<p><span id="_bookmark452" class="anchor"></span>54. Shin, R., Packer, C., Song, D.: Differentiable neural network architecture search. In: <span id="_bookmark427" class="anchor"></span>International Conference on Learning Representations Workshop (2018)</p>
<p>55. Stanley, K.O., D’Ambrosio, D.B., Gauci, J.: A hypercube-based encoding for evolving large- scale neural networks. Artif. Life 15(2), 185–212 (Apr 2009), URL <a href="https://doi.org/10.1162/artl.2009.15.2.15202">https://doi.org/10.1162/</a> <span id="_bookmark428" class="anchor"></span><a href="https://doi.org/10.1162/artl.2009.15.2.15202">artl.2009.15.2.15202</a></p>
<p>56. Stanley, K.O., Miikkulainen, R.: Evolving neural networks through augmenting topologies. <span id="_bookmark443" class="anchor"></span>Evolutionary Computation 10, 99– 127 (2002)</p>
<p>57. Such, F.P., Madhavan, V., Conti, E., Lehman, J., Stanley, K.O., Clune, J.: Deep neuroevolution: Genetic algorithms are a competitive alternative for training deep neural networks for <span id="_bookmark465" class="anchor"></span>reinforcement learning. arXiv preprint (2017)</p>
<p>58. Suganuma, M., Ozay, M., Okatani, T.: Exploiting the potential of standard convolutional autoencoders for image restoration by evolutionary search. In: Dy, J., Krause, A. (eds.) Proceedings of the 35th International Conference on Machine Learning. Proceedings of Machine Learning Research, vol. 80, pp. 4771–4780. PMLR, Stockholmsmässan, Stockholm Sweden (10– 15 Jul 2018)</p>
<p>3 Neural Architecture Search 77</p>
<p><span id="_bookmark406" class="anchor"></span>59. Suganuma, M., Shirakawa, S., Nagao, T.: A genetic programming approach to designing convolutional neural network architectures. In: Genetic and Evolutionary Computation <span id="_bookmark444" class="anchor"></span>Conference (2017)</p>
<p>60. Swersky, K., Duvenaud, D., Snoek, J., Hutter, F., Osborne, M.: Raiders of the lost architecture: Kernels for bayesian optimization in conditional parameter spaces. In: NIPS Workshop on <span id="_bookmark461" class="anchor"></span>Bayesian Optimization in Theory and Practice (2013)</p>
<p><span id="_bookmark416" class="anchor"></span>61. Swersky, K., Snoek, J., Adams, R.P.: Freeze-thaw bayesian optimization (2014)</p>
<p>62. Szegedy, C., Vanhoucke, V., Ioffe, S., Shlens, J., Wojna, Z.: Rethinking the Inception Archi- tecture for Computer Vision. In: Conference on Computer Vision and Pattern Recognition</p>
<p><span id="_bookmark433" class="anchor"></span>(2016)</p>
<p>63. Wei, T., Wang, C., Chen, C.W.: Modularized morphing of neural networks. arXiv:1701.03281</p>
<p><span id="_bookmark462" class="anchor"></span>(2017)</p>
<p>64. Wei, T., Wang, C., Rui, Y., Chen, C.W.: Network morphism. In: International Conference on <span id="_bookmark451" class="anchor"></span>Machine Learning (2016)</p>
<p>65. Wistuba, M.: Finding Competitive Network Architectures Within a Day Using UCT. In: <span id="_bookmark438" class="anchor"></span>arXiv:1712.07420 (Dec 2017)</p>
<p>66. Xie, L., Yuille, A.: Genetic CNN. In: International Conference on Computer Vision (2017)</p>
<p>67. Yao, X.: Evolving artiﬁcial neural networks. Proceedings of the IEEE 87(9), 1423– 1447 (Sept <span id="_bookmark403" class="anchor"><span id="_bookmark448" class="anchor"><span id="_bookmark429" class="anchor"></span></span></span>1999)</p>
<p>68. Yu, F., Koltun, V.: Multi-scale context aggregation by dilated convolutions (2016)</p>
<p>69. Zela, A., Klein, A., Falkner, S., Hutter, F.: Towards automated deep learning: Efﬁcient joint neural architecture and hyperparameter search. In: ICML 2018 Workshop on AutoML <span id="_bookmark475" class="anchor"></span>(AutoML 2018) (2018)</p>
<p>70. Zhang, H., Cissé, M., Dauphin, Y.N., Lopez-Paz, D.: mixup: Beyond empirical risk minimiza- <span id="_bookmark417" class="anchor"></span>tion. arXiv preprint abs/1710.09412 (2017)</p>
<p>71. Zhong, Z., Yan, J., Wu, W., Shao, J., Liu, C.L.: Practical block-wise neural network architecture generation. In: Proceedings of the IEEE Conference on Computer Vision and Pattern <span id="_bookmark423" class="anchor"></span>Recognition. pp. 2423–2432 (2018a)</p>
<p>72. Zhong, Z., Yang, Z., Deng, B., Yan, J., Wu, W., Shao, J., Liu, C.L.: Blockqnn: Efﬁcient block- <span id="_bookmark470" class="anchor"></span>wise neural network architecture generation. arXiv preprint (2018b)</p>
<p>73. Zhou, Y., Ebrahimi, S., Arik, S., Yu, H., Liu, H., Diamos, G.: Resource-efﬁcient neural <span id="_bookmark419" class="anchor"></span>architect. In: arXiv:1806.07912 (2018)</p>
<p>74. Zoph, B., Le, Q.V.: Neural architecture search with reinforcement learning. In: International <span id="_bookmark413" class="anchor"></span>Conference on Learning Representations (2017)</p>
<p>75. Zoph, B., Vasudevan, V., Shlens, J., Le, Q.V.: Learning transferable architectures for scalable image recognition. In: Conference on Computer Vision and Pattern Recognition (2018)</p>
<p><strong>Open</strong> <strong>Access</strong> This chapter is licensed under the terms of the Creative Commons Attribution 4.0 International License <a href="http://creativecommons.org/licenses/by/4.0/">(http://creativecommons.org/licenses/by/4.0/</a>), which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence and indicate if changes were made.</p>
<p>The images or other third party material in this chapter are included in the chapter’s Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the chapter’s Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder.</p>
</blockquote>
<p><img src="./automlgithubpagesimages//media/image137.png" width="75" height="26" /></p>
<p><span id="_bookmark5" class="anchor"></span><strong>Part</strong> <strong>II</strong></p>
<p><strong>AutoML</strong> <strong>Systems</strong></p>
<p><img src="./automlgithubpagesimages//media/image138.png" width="41" height="41" /><img src="./automlgithubpagesimages//media/image9.jpeg" width="136" /></p>
<blockquote>
<p><span id="_bookmark6" class="anchor"></span><strong>Chapter</strong> <strong>4</strong></p>
<p><strong>Auto-WEKA:</strong> <strong>Automatic</strong> <strong>Model</strong> <strong>Selection</strong></p>
<p><strong>and</strong> <strong>Hyperparameter</strong> <strong>Optimization</strong> <strong>in</strong> <strong>WEKA</strong></p>
</blockquote>
<p><img src="./automlgithubpagesimages//media/image139.png" /></p>
<blockquote>
<p><strong>Lars</strong> <strong>Kotthoff,</strong> <strong>Chris</strong> <strong>Thornton,</strong> <strong>Holger</strong> <strong>H.</strong> <strong>Hoos,</strong> <strong>Frank</strong> <strong>Hutter,</strong> <strong>and</strong> <strong>Kevin</strong> <strong>Leyton-Brown</strong></p>
<p><strong>Abstract</strong> Many different machine learning algorithms exist; taking into account each algorithm’s hyperparameters, there is a staggeringly large number of possible alternatives overall. We consider the problem of simultaneously selecting a learning algorithm and setting its hyperparameters. We show that this problem can be addressed by a fully automated approach, leveraging recent innovations in Bayesian optimization. Speciﬁcally, we consider feature selection techniques and all machine learning approaches implemented in WEKA’s standard distribution, spanning 2 ensemble methods, 10 meta-methods, 28 base learners, and hyperparameter settings for each learner. On each of 21 popular datasets from the UCI repository, the KDD Cup 09, variants of the MNIST dataset and CIFAR- 10, we show performance often much better than using standard selection and hyperparameter optimization methods. We hope that our approach will help non-expert users to more effectively identify machine learning algorithms and hyperparameter settings appropriate to their applications, and hence to achieve improved performance.</p>
<p><strong>4.1</strong> <strong>Introduction</strong></p>
<p>Increasingly, users of machine learning tools are non-experts who require off-the- shelf solutions. The machine learning community has much aided such users by making available a wide variety of sophisticated learning algorithms and feature</p>
<p>L. Kotthoff (凶)</p>
<p>University of Wyoming, Laramie, WY, USA</p>
<p>e-mail: <a href="mailto:larsko@uwyo.edu">larsko@uwyo.edu</a></p>
<p>C. Thornton · K. Leyton-Brown</p>
<p>Department of Computer Science, University of British Columbia, Vancouver, BC, Canada</p>
<p>H. H. Hoos</p>
<p>Leiden Institute for Advanced Computer Science, Leiden University, Leiden, The Netherlands</p>
<p>F. Hutter</p>
<p>Department of Computer Science, University of Freiburg, Freiburg, Germany</p>
<p>© The Author(s) 2019</p>
<p>F. Hutter et al. (eds.), <em>Automated</em> <em>Machine</em> <em>Learning</em>, The Springer Series on Challenges in Machine Learning, <a href="https://doi.org/10.1007/978-3-030-05318-5_4" class="uri">https://doi.org/10.1007/978-3-030-05318-5_4</a></p>
<p>82 L. Kotthoff et al.</p>
</blockquote>
<p>selection methods through open source packages, such as WEKA [<a href="#_bookmark478">15</a>] and mlr [<a href="#_bookmark479">7</a>]. Such packages ask a user to make two kinds of choices: selecting a learning algorithm and customizing it by setting hyperparameters (which also control feature selection, if applicable). It can be challenging to make the right choice when faced with these degrees of freedom, leaving many users to select algorithms based on reputation or intuitive appeal, and/or to leave hyperparameters set to default values. Of course, adopting this approach can yield performance far worse than that of the best method and hyperparameter settings.</p>
<p>This suggests a natural challenge for machine learning: given a dataset, auto- matically and simultaneously choosing a learning algorithm and setting its hyperpa- rameters to optimize empirical performance. We dub this the <em>combined</em> <em>algorithm</em> <em>selection</em> <em>and</em> <em>hyperparameter</em> <em>optimization</em> <em>(CASH)</em> <em>problem</em>; we formally deﬁne it in Sect.<a href="#_bookmark480">4.3</a>. There has been considerable past work separately addressing model selection, e.g., [<a href="#_bookmark481">1</a>, <a href="#_bookmark482">6</a>, <a href="#_bookmark483">8</a>, <a href="#_bookmark484">9</a>, <a href="#_bookmark485">11</a>, <a href="#_bookmark486">24</a>, <a href="#_bookmark487">25</a>, <a href="#_bookmark488">33</a>], and hyperparameter optimization, e.g., [<a href="#_bookmark489">3</a>– <a href="#_bookmark490">5</a>, <a href="#_bookmark491">14</a>, <a href="#_bookmark492">23</a>, <a href="#_bookmark493">28</a>, <a href="#_bookmark494">30</a>]. In contrast, despite its practical importance, we are surprised to ﬁnd only limited variants of the CASH problem in the literature; furthermore, these consider a ﬁxed and relatively small number of parameter conﬁgurations for each algorithm, see e.g., [<a href="#_bookmark495">22</a>].</p>
<blockquote>
<p>A likely explanation is that it is very challenging to search the combined space of learning algorithms and their hyperparameters: the response function is noisy and the space is high dimensional, involves both categorical and continuous choices, and contains hierarchical dependencies (e.g., , the hyperparameters of a learning algorithm are only meaningful if that algorithm is chosen; the algorithm choices in an ensemble method are only meaningful if that ensemble method is chosen; etc). Another related line of work is on meta-learning procedures that exploit characteristics of the dataset, such as the performance of so-called landmarking algorithms, to predict which algorithm or hyperparameter conﬁguration will per- form well [<a href="#_bookmark496">2</a>, <a href="#_bookmark495">22</a>, <a href="#_bookmark497">26</a>, <a href="#_bookmark498">32</a>]. While the CASH algorithms we study in this chapter start from scratch for each new dataset, these meta-learning procedures exploit information from previous datasets, which may not always be available.</p>
</blockquote>
<p>In what follows, we demonstrate that CASH can be viewed as a single hierarchi- cal hyperparameter optimization problem, in which even the choice of algorithm itself is considered a hyperparameter. We also show that—based on this prob- lem formulation—recent Bayesian optimization methods can obtain high quality results in reasonable time and with minimal human effort. After discussing some preliminaries (Sect.<a href="#_bookmark499">4.2</a>), we deﬁne the CASH problem and discuss methods for tackling it (Sect.<a href="#_bookmark480">4.3</a>). We then deﬁne a concrete CASH problem encompassing a wide range of learners and feature selectors in the open source package WEKA (Sect.<a href="#_bookmark500">4.4</a>), and show that a search in the combined space of algorithms and hyperparameters yields better-performing models than standard algorithm selection and hyperparameter optimization methods (Sect.<a href="#_bookmark501">4.5</a>). More speciﬁcally, we show that the recent Bayesian optimization procedures TPE [<a href="#_bookmark502">4</a>] and SMAC [<a href="#_bookmark503">16</a>] often ﬁnd combinations of algorithms and hyperparameters that outperform existing baseline methods, especially on large datasets.</p>
<p><img src="./automlgithubpagesimages//media/image12.jpeg" width="136" /></p>
<blockquote>
<p>4 Auto-WEKA: Automatic Model Selection and Hyperparameter... 83</p>
<p>This chapter is based on two previous papers, published in the <em>proceedings</em> <em>of</em> <em>KDD</em> <em>2013</em> [<a href="#_bookmark504">31</a>] and in the <em>journal</em> <em>of</em> <em>machine</em> <em>learning</em> <em>research</em> <em>(JMLR)</em> in 2017 [<a href="#_bookmark505">20</a>].</p>
<p><span id="_bookmark499" class="anchor"></span><strong>4.2</strong> <strong>Preliminaries</strong></p>
<p>We consider learning a function f : X →I Y, where Y is either ﬁnite (for classiﬁcation), or continuous (for regression). A <em>learning</em> <em>algorithm</em> A maps a set {d1 , . . . , dn} of training data points di = (<strong>x</strong>i,yi) ∈ X × Y to such a function, which is often expressed via a vector of <em>model</em> <em>parameters</em>. Most learning algorithms A further expose <em>hyperparameters</em> <strong>λ</strong> ∈ <strong>A</strong>, which change the way the learning algorithm A<strong>λ</strong> itself works. For example, hyperparameters are used to describe a description-length penalty, the number of neurons in a hidden layer, the number of data points that a leaf in a decision tree must contain to be eligible for splitting, etc. These hyperparameters are typically optimized in an “outer loop” that evaluates the performance of each hyperparameter conﬁguration using cross-validation.</p>
</blockquote>
<p><em><strong>4.2.1</strong></em> <em><strong>Model</strong></em> <em><strong>Selection</strong></em></p>
<blockquote>
<p>Given a set of learning algorithms A and a limited amount of training data D = {(<strong>x</strong>1 ,y1), . . . , (<strong>x</strong>n,yn)}, the goal of model selection is to determine the algorithm A* ∈ A with optimal generalization performance. Generalization performance is estimated by splitting D into disjoint training and validation sets D<img src="./automlgithubpagesimages//media/image140.png" height="20" />in and D<img src="./automlgithubpagesimages//media/image141.png" height="20" />id, learning functions fi by applying A* to D<img src="./automlgithubpagesimages//media/image142.png" height="20" />in, and evaluating the predictive performance of these functions on D<img src="./automlgithubpagesimages//media/image143.png" height="19" />id . This allows for the model selection problem to be written as:</p>
<p>A* ∈ argA<img src="./automlgithubpagesimages//media/image144.png" width="13" height="26" />n 1<img src="./automlgithubpagesimages//media/image145.jpeg" />k <img src="./automlgithubpagesimages//media/image146.png" width="15" height="42" /> L(A, D<img src="./automlgithubpagesimages//media/image147.png" height="20" />in , D<img src="./automlgithubpagesimages//media/image148.png" height="20" />id),</p>
<p>where L(A, D<img src="./automlgithubpagesimages//media/image149.png" height="19" />in , D<img src="./automlgithubpagesimages//media/image150.png" height="19" />id) is the loss achieved by A when trained on D<img src="./automlgithubpagesimages//media/image151.png" height="19" />in and</p>
<p>evaluated on D<img src="./automlgithubpagesimages//media/image152.png" height="18" />id .</p>
<p>We use k-fold cross-validation [<a href="#_bookmark506">19</a>], which splits the training data into k equal- sized partitions D<img src="./automlgithubpagesimages//media/image153.png" height="19" />id , . . . , D<img src="./automlgithubpagesimages//media/image154.png" height="19" />id, and sets D<img src="./automlgithubpagesimages//media/image155.png" height="19" />in = D / D<img src="./automlgithubpagesimages//media/image156.png" height="19" />id for i = 1, . . . , k .<a href="#_bookmark507">1</a></p>
<p><span id="_bookmark507" class="anchor"></span>1There are other ways of estimating generalization performance; e.g., we also experimented with repeated random subsampling validation [<a href="#_bookmark506">19</a>], and obtained similar results.</p>
<p>84 L. Kotthoff et al.</p>
</blockquote>
<p><em><strong>4.2.2</strong></em> <em><strong>Hyperparameter</strong></em> <em><strong>Optimization</strong></em></p>
<blockquote>
<p>The problem of optimizing the hyperparameters <strong>λ</strong> ∈ <strong>A</strong> of a given learning algorithm A is conceptually similar to that of model selection. Some key differences are that hyperparameters are often continuous, that hyperparameter spaces are often high dimensional, and that we can exploit correlation structure between different hyperparameter settings <strong>λ</strong> 1 , <strong>λ</strong>2 ∈ <strong>A</strong>. Given n hyperparameters λ 1 , . . . , λn with domains ^1 , . . . , ^n, the hyperparameter space <strong>A</strong> is a subset of the crossproduct of these domains: <strong>A</strong> ⊂ ^1 × · · · × ^n . This subset is often strict, such as when certain settings of one hyperparameter render other hyperparameters inactive. For example, the parameters determining the speciﬁcs of the third layer of a deep belief network are not relevant if the network depth is set to one or two. Likewise, the parameters of a support vector machine’s polynomial kernel are not relevant if we use a different kernel instead.</p>
<p>More formally, following [<a href="#_bookmark508">17</a>], we say that a hyperparameter λi is <em>conditional</em> on another hyperparameter λj , if λi is only active if hyperparameter λj takes values from a given set Vi(j ) 车 ^j ; in this case we call λj a <em>parent</em> of λi . Conditional hyperparameters can in turn be parents of other conditional hyperparameters, giving rise to a tree-structured space [<a href="#_bookmark502">4</a>] or, in some cases, a directed acyclic graph (DAG) [<a href="#_bookmark508">17</a>]. Given such a structured space <strong>A</strong>, the (hierarchical) hyperparameter optimization problem can be written as:</p>
<p><strong>λ</strong>* ∈ a<img src="./automlgithubpagesimages//media/image157.png" width="20" height="26" />in 1<img src="./automlgithubpagesimages//media/image158.jpeg" />k <img src="./automlgithubpagesimages//media/image159.png" width="16" height="42" /> L(A<strong>λ</strong> , D<img src="./automlgithubpagesimages//media/image160.png" height="20" />in , D<img src="./automlgithubpagesimages//media/image161.png" height="20" />id).</p>
<p><span id="_bookmark480" class="anchor"></span><strong>4.3</strong> <strong>Combined</strong> <strong>Algorithm</strong> <strong>Selection</strong> <strong>and</strong> <strong>Hyperparameter</strong></p>
<p><strong>Optimization</strong> <strong>(CASH)</strong></p>
<p>Given a set of algorithms A = {A(1) , . . . , A(k)} with associated hyperparameter spaces <strong>A</strong>(1) , . . . , <strong>A</strong>(k), we deﬁne the combined algorithm selection and hyperpa- rameter optimization problem (CASH) as computing</p>
<p><span id="_bookmark509" class="anchor"></span>A*<strong>λ</strong>* ∈ A(j<img src="./automlgithubpagesimages//media/image162.png" width="10" height="28" /><img src="./automlgithubpagesimages//media/image163.png" width="13" height="28" />(j) 1<img src="./automlgithubpagesimages//media/image164.jpeg" />k <img src="./automlgithubpagesimages//media/image165.png" width="16" height="42" /> L(A<img src="./automlgithubpagesimages//media/image166.png" width="11" height="20" /> , D<img src="./automlgithubpagesimages//media/image167.png" height="20" />in , D<img src="./automlgithubpagesimages//media/image168.png" height="20" />id).</p>
<p>(4. 1)</p>
<p>We note that this problem can be reformulated as a single combined hierarchical hyperparameter optimization problem with parameter space <strong>A</strong> = <strong>A</strong>(1) ∪ · · · ∪ <strong>A</strong>(k) ∪ {λr}, where λr is a new root-level hyperparameter that selects between algorithms A(1) , . . . , A(k) . The root-level parameters of each subspace <strong>A</strong>(i) are made conditional on λr being instantiated to Ai .</p>
<p>4 Auto-WEKA: Automatic Model Selection and Hyperparameter... 85</p>
<p><a href="#_bookmark509">In principle, problem (4.1</a>) can be tackled in various ways. A promising approach is Bayesian Optimization [<a href="#_bookmark510">10</a>], and in particular Sequential Model-Based Optimization (SMBO) [<a href="#_bookmark503">16</a>], a versatile stochastic optimization framework that can work with both categorical and continuous hyperparameters, and that can exploit hierarchical structure stemming from conditional parameters. SMBO (outlined in Algorithm <a href="#_bookmark511">1</a>) ﬁrst builds a model ML that captures the dependence of loss function L on hyperparameter settings <strong>λ</strong> (line 1 in Algorithm<a href="#_bookmark511">1</a>). It then iterates the following steps: use ML to determine a promising candidate conﬁguration of hyperparameters <strong>λ</strong> to evaluate next (line 3); evaluate the loss c of <strong>λ</strong> (line 4); and update the model ML with the new data point (<strong>λ</strong>,c) thus obtained (lines 5–6).</p>
</blockquote>
<table>
<tbody>
<tr class="odd">
<td><blockquote>
<p><span id="_bookmark511" class="anchor"></span><strong>Algorithm</strong> <strong>1</strong> SMBO</p>
</blockquote></td>
</tr>
<tr class="even">
<td><blockquote>
<p>1: initialise model ML; H ← ∅</p>
<p>2: <strong>while</strong> time budget for optimization has not been exhausted <strong>do</strong></p>
<p>3: <strong>λ</strong> ← candidate conﬁguration from ML</p>
<p>4: Compute c = L(A<strong>λ</strong> , D<img src="./automlgithubpagesimages//media/image169.png" height="16" />in , D<img src="./automlgithubpagesimages//media/image170.png" height="16" />id)</p>
<p>5: H ← H ∪ {(<strong>λ</strong>,c)}</p>
<p>6: Update ML given H</p>
<p>7: <strong>end</strong> <strong>while</strong></p>
<p>8: <strong>return</strong> <strong>λ</strong> from H with minimal c</p>
</blockquote></td>
</tr>
</tbody>
</table>
<blockquote>
<p>In order to select its next hyperparameter conﬁguration <strong>λ</strong> using model ML , SMBO uses a so-called <em>acquisition</em> <em>function</em> aML : <strong>A</strong> f→ R, which uses the predictive distribution of model ML at arbitrary hyperparameter conﬁgurations <strong>λ</strong> ∈ <strong>A</strong> to quantify (in closed form) how useful knowledge about <strong>λ</strong> would be. SMBO then simply maximizes this function over <strong>A</strong> to select the most useful conﬁguration <strong>λ</strong> to evaluate next. Several well-studied acquisition functions exist [<a href="#_bookmark512">18</a>,<a href="#_bookmark513">27</a>,<a href="#_bookmark514">29</a>]; all aim to automatically trade off exploitation (locally optimizing hyperparameters in regions known to perform well) versus exploration (trying hyperparameters in a relatively unexplored region of the space) in order to avoid premature convergence. In this work, we maximized <em>positive</em> <em>expected</em> <em>improvement</em> <em>(EI)</em> attainable over an existing given loss cmin [<a href="#_bookmark513">27</a>]. Let c(<strong>λ</strong>) denote the loss of hyperparameter conﬁguration <strong>λ</strong> . Then, the positive improvement function over cmin is deﬁned as</p>
<p>Icmin (<strong>λ</strong>) := max{cmin − c(<strong>λ</strong>), 0}.</p>
<p>Of course, we do not know c(<strong>λ</strong>). We can, however, compute its expectation with respect to the current model ML:</p>
<p><span id="_bookmark515" class="anchor"></span>EML [Icmin (<strong>λ</strong>)] = \−<img src="./automlgithubpagesimages//media/image171.png" width="16" height="35" /> max{cmin − c, 0} · pML (c | λ) dc . (4.2)</p>
<p>We brieﬂy review the SMBO approach used in this chapter.</p>
<p>86 L. Kotthoff et al.</p>
<p><em><strong>4.3.1</strong></em> <em><strong>Sequential</strong></em> <em><strong>Model-Based</strong></em> <em><strong>Algorithm</strong></em> <em><strong>Conﬁguration</strong></em></p>
<p><em><strong>(SMAC)</strong></em></p>
</blockquote>
<p>Sequential model-based algorithm conﬁguration (SMAC) [<a href="#_bookmark503">16</a>] supports a variety of models p(c | <strong>λ</strong>) to capture the dependence of the loss function c on hyper- parameters <strong>λ</strong>, including approximate Gaussian processes and random forests. In this chapter we use random forest models, since they tend to perform well with discrete and high-dimensional input data. SMAC handles conditional parameters by instantiating inactive conditional parameters in <strong>λ</strong> to default values for model training and prediction. This allows the individual decision trees to include splits of the kind “is hyperparameter λi active?”, allowing them to focus on active hyperparameters. While random forests are not usually treated as probabilistic models, SMAC obtains a predictive mean μ<strong>λ</strong> and variance σ<strong>λ</strong>2 of p(c | <strong>λ</strong>) as frequentist estimates over the predictions of its individual trees for <strong>λ</strong>; it then models pML (c | <strong>λ</strong>) as a Gaussian N(μ<strong>λ</strong>,σ<strong>λ</strong> 2).</p>
<blockquote>
<p>SMAC uses the expected improvement criterion deﬁned in Eq.<a href="#_bookmark515">4.2</a>, instantiating cmin to the loss of the best hyperparameter conﬁguration measured so far. Under SMAC’s predictive distribution pML (c | <strong>λ</strong>) = N(μ<strong>λ</strong>,σ<strong>λ</strong> 2), this expectation is the closed-form expression</p>
<p>EML [Icmin (<strong>λ</strong>)] = σ<strong>λ</strong> · [u · 免(u) + ϕ(u)],</p>
<p>where u = <img src="./automlgithubpagesimages//media/image172.png" width="37" height="19" />, and ϕ and 免 denote the probability density function and</p>
<p>cumulative distribution function of a standard normal distribution, respectively [<a href="#_bookmark512">18</a>].</p>
<p>SMAC is designed for robust optimization under noisy function evaluations, and as such implements special mechanisms to keep track of its best known conﬁguration and assure high conﬁdence in its estimate of that conﬁguration’s performance. This robustness against noisy function evaluations can be exploited in combined algorithm selection and hyperparameter optimization, since the function to be optimized in Eq. (<a href="#_bookmark509">4.1</a>) is a mean over a set of loss terms (each corresponding</p>
<p>to one pair of D<img src="./automlgithubpagesimages//media/image173.png" height="18" />in and D<img src="./automlgithubpagesimages//media/image174.png" height="18" />id constructed from the training set). A key idea in</p>
<p>SMAC is to make progressively better estimates of this mean by evaluating these terms one at a time, thus trading off accuracy and computational cost. In order for a new conﬁguration to become a new incumbent, it must outperform the previous incumbent in every comparison made: considering only one fold, two folds, and so on up to the total number of folds previously used to evaluate the incumbent. Furthermore, every time the incumbent survives such a comparison, it is evaluated on a new fold, up to the total number available, meaning that the number of folds used to evaluate the incumbent grows over time. A poorly performing conﬁguration can thus be discarded after considering just a single fold.</p>
<p>Finally, SMAC also implements a diversiﬁcation mechanism to achieve robust performance even when its model is misled, and to explore new parts of the space: every second conﬁguration is selected at random. Because of the evaluation procedure just described, this requires less overhead than one might imagine.</p>
<p>4 Auto-WEKA: Automatic Model Selection and Hyperparameter... 87</p>
<p><span id="_bookmark500" class="anchor"></span><strong>4.4</strong> <strong>Auto-WEKA</strong></p>
</blockquote>
<p>To demonstrate the feasibility of an automatic approach to solving the CASH problem, we built Auto-WEKA, which solves this problem for the learners and feature selectors implemented in the WEKA machine learning package [<a href="#_bookmark478">15</a>]. Note that while we have focused on classiﬁcation algorithms in WEKA, there is no obstacle to extending our approach to other settings. Indeed, another successful system that uses the same underlying technology is auto-sklearn [<a href="#_bookmark516">12</a>].</p>
<p>Fig. <a href="#_bookmark517">4.1</a> shows all supported learning algorithms and feature selectors with the number of hyperparameters. algorithms. Meta-methods take a single base classiﬁer and its parameters as an input, and the ensemble methods can take any number of base learners as input. We allowed the meta-methods to use any base learner with any hyperparameter settings, and allowed the ensemble methods to use up to ﬁve</p>
<blockquote>
<p><strong>Base</strong> <strong>Learners</strong></p>
<p>BayesNet</p>
<p>DecisionStump*</p>
<p>DecisionTable*</p>
<p>GaussianProcesses*</p>
<p>IBk*</p>
<p>J48</p>
<p>JRip</p>
<p>KStar*</p>
<p>LinearRegression*</p>
<p>LMT</p>
<p>Logistic</p>
<p>M5P</p>
<p>M5Rules</p>
<p>MultilayerPerceptron*</p>
<p><strong>Ensemble</strong> <strong>Methods</strong></p>
<p>Stacking</p>
<p><strong>Meta-Methods</strong></p>
<p>LWL</p>
<p>AdaBoostM1 AdditiveRegression AttributeSelectedClassiﬁer</p>
<p><span id="_bookmark517" class="anchor"></span><strong>Feature</strong> <strong>Selection</strong> <strong>Methods</strong></p>
<p>BestFirst</p>
<p>2</p>
<p>0</p>
<p>4</p>
<p>10</p>
<p>5</p>
<p>9</p>
<p>4</p>
<p>3</p>
<p>3</p>
<p>9</p>
<p>1</p>
<p>4</p>
<p>4</p>
<p>8</p>
<p>2</p>
<p>5</p>
<p>6</p>
<p>4</p>
<p>2</p>
<p>2</p>
<p>NaiveBayes NaiveBayesMultinomial OneR</p>
<p>PART</p>
<p>RandomForest</p>
<p>RandomTree*</p>
<p>REPTree*</p>
<p>SGD* SimpleLinearRegression* SimpleLogistic</p>
<p>SMO</p>
<p>SMOreg*</p>
</blockquote>
<p>VotedPerceptron</p>
<blockquote>
<p>ZeroR*</p>
</blockquote>
<p>Vote</p>
<blockquote>
<p>Bagging</p>
<p>RandomCommittee</p>
<p>RandomSubSpace</p>
<p>GreedyStepwise</p>
<p>2</p>
<p>0</p>
<p>1</p>
<p>4</p>
<p>7</p>
<p>11</p>
<p>6</p>
<p>5</p>
<p>0</p>
<p>5</p>
<p>11</p>
<p>13</p>
<p>3</p>
<p>0</p>
<p>2</p>
<p>4</p>
<p>2</p>
<p>3</p>
<p>4</p>
<p><strong>Fig.</strong> <strong>4.1</strong> Learners and methods supported by Auto-WEKA, along with number of hyperparameters |^|. Every learner supports classiﬁcation; starred learners also support regression</p>
<p>88 L. Kotthoff et al.</p>
<p>learners, again with any hyperparameter settings. Not all learners are applicable on all datasets (e.g., due to a classiﬁer’s inability to handle missing data). For a given dataset, our Auto-WEKA implementation automatically only considers the subset of applicable learners. Feature selection is run as a preprocessing phase before building any model.</p>
</blockquote>
<p>The algorithms in Fig.<a href="#_bookmark517">4.1</a> have a wide variety of hyperparameters, which take values from continuous intervals, from ranges of integers, and from other discrete sets. We associated either a uniform or log uniform prior with each numerical parameter, depending on its semantics. For example, we set a log uniform prior for the ridge regression penalty, and a uniform prior for the maximum depth for a tree in a random forest. Auto-WEKA works with continuous hyperparameter values directly up to the precision of the machine. We emphasize that this combined hyperparameter space is <em>much</em> larger than a simple union of the base learners’ hyperparameter spaces, since the ensemble methods allow up to 5 <em>independent</em> base learners. The meta- and ensemble methods as well as the feature selection contribute further to the total size of AutoWEKA’s hyperparameter space.</p>
<p>Auto-WEKA uses the SMAC optimizer described above to solve the CASH problem and is available to the public through the WEKA package manager; the source code can be found at <a href="https://github.com/automl/autoweka" class="uri">https://github.com/automl/autoweka</a> and the ofﬁcial project website is at <a href="http://www.cs.ubc.ca/labs/beta/Projects/autoweka" class="uri">http://www.cs.ubc.ca/labs/beta/Projects/autoweka</a>. For the experiments described in this chapter, we used Auto-WEKA version 0.5. The results the more recent versions achieve are similar; we did not replicate the full set of experiments because of the large computational cost.</p>
<blockquote>
<p><span id="_bookmark501" class="anchor"></span><strong>4.5</strong> <strong>Experimental</strong> <strong>Evaluation</strong></p>
</blockquote>
<p>We evaluated Auto-WEKA on 21 prominent benchmark datasets (see Table <a href="#_bookmark518">4.1</a>): 15 sets from the UCI repository [<a href="#_bookmark519">13</a>]; the ‘convex’, ‘MNIST basic’ and ‘rotated MNIST with background images’ tasks used in [<a href="#_bookmark490">5</a>]; the appentency task from the KDD Cup ’09; and two versions of the CIFAR- 10 image classiﬁcation task [<a href="#_bookmark520">21</a>] (CIFAR- 10-Small is a subset of CIFAR- 10, where only the ﬁrst 10,000 training data points are used rather than the full 50,000.) Note that in the experimental evaluation, we focus on classiﬁcation. For datasets with a predeﬁned training/test split, we used that split. Otherwise, we randomly split the dataset into 70% training and 30% test data. We withheld the test data from all optimization method; it was only used once in an ofﬂine analysis stage to evaluate the models found by the various optimization methods.</p>
<p>For each dataset, we ran Auto-WEKA with each hyperparameter optimization algorithm with a total time budget of 30 h. For each method, we performed 25 runs of this process with different random seeds and then—in order to simulate parallelization on a typical workstation—used bootstrap sampling to repeatedly select four random runs and report the performance of the one with best cross- validation performance.</p>
<blockquote>
<p><span id="_bookmark17" class="anchor"></span>4 Auto-WEKA: Automatic Model Selection and Hyperparameter... 89</p>
<p><span id="_bookmark518" class="anchor"></span><strong>Table</strong> <strong>4.1</strong> Datasets used; <em>Num.</em> <em>Discr.</em>. and <em>Num.</em> <em>Cont</em>. refer to the number of discrete and continuous attributes of elements in the dataset, respectively</p>
</blockquote>
<table>
<tbody>
<tr class="odd">
<td><blockquote>
<p>Name</p>
</blockquote></td>
<td><blockquote>
<p>Num</p>
<p>Discr.</p>
</blockquote></td>
<td><blockquote>
<p>Num</p>
<p>Cont.</p>
</blockquote></td>
<td><blockquote>
<p>Num</p>
<p>classes</p>
</blockquote></td>
<td><blockquote>
<p>Num</p>
<p>training</p>
</blockquote></td>
<td><blockquote>
<p>Num</p>
<p>test</p>
</blockquote></td>
</tr>
<tr class="even">
<td><blockquote>
<p>Dexter</p>
</blockquote></td>
<td><blockquote>
<p>20,000</p>
</blockquote></td>
<td><blockquote>
<p>0</p>
</blockquote></td>
<td><blockquote>
<p>2</p>
</blockquote></td>
<td><blockquote>
<p>420</p>
</blockquote></td>
<td><blockquote>
<p>180</p>
</blockquote></td>
</tr>
<tr class="odd">
<td><blockquote>
<p>GermanCredit</p>
</blockquote></td>
<td><blockquote>
<p>13</p>
</blockquote></td>
<td><blockquote>
<p>7</p>
</blockquote></td>
<td><blockquote>
<p>2</p>
</blockquote></td>
<td><blockquote>
<p>700</p>
</blockquote></td>
<td><blockquote>
<p>300</p>
</blockquote></td>
</tr>
<tr class="even">
<td><blockquote>
<p>Dorothea</p>
</blockquote></td>
<td><blockquote>
<p>100,000</p>
</blockquote></td>
<td><blockquote>
<p>0</p>
</blockquote></td>
<td><blockquote>
<p>2</p>
</blockquote></td>
<td><blockquote>
<p>805</p>
</blockquote></td>
<td><blockquote>
<p>345</p>
</blockquote></td>
</tr>
<tr class="odd">
<td><blockquote>
<p>Yeast</p>
</blockquote></td>
<td><blockquote>
<p>0</p>
</blockquote></td>
<td><blockquote>
<p>8</p>
</blockquote></td>
<td><blockquote>
<p>10</p>
</blockquote></td>
<td><blockquote>
<p>1,038</p>
</blockquote></td>
<td><blockquote>
<p>446</p>
</blockquote></td>
</tr>
<tr class="even">
<td><blockquote>
<p>Amazon</p>
</blockquote></td>
<td><blockquote>
<p>10,000</p>
</blockquote></td>
<td><blockquote>
<p>0</p>
</blockquote></td>
<td><blockquote>
<p>49</p>
</blockquote></td>
<td><blockquote>
<p>1,050</p>
</blockquote></td>
<td><blockquote>
<p>450</p>
</blockquote></td>
</tr>
<tr class="odd">
<td><blockquote>
<p>Secom</p>
</blockquote></td>
<td><blockquote>
<p>0</p>
</blockquote></td>
<td><blockquote>
<p>591</p>
</blockquote></td>
<td><blockquote>
<p>2</p>
</blockquote></td>
<td><blockquote>
<p>1,096</p>
</blockquote></td>
<td><blockquote>
<p>471</p>
</blockquote></td>
</tr>
<tr class="even">
<td><blockquote>
<p>Semeion</p>
</blockquote></td>
<td><blockquote>
<p>256</p>
</blockquote></td>
<td><blockquote>
<p>0</p>
</blockquote></td>
<td><blockquote>
<p>10</p>
</blockquote></td>
<td><blockquote>
<p>1,115</p>
</blockquote></td>
<td><blockquote>
<p>478</p>
</blockquote></td>
</tr>
<tr class="odd">
<td><blockquote>
<p>Car</p>
</blockquote></td>
<td><blockquote>
<p>6</p>
</blockquote></td>
<td><blockquote>
<p>0</p>
</blockquote></td>
<td><blockquote>
<p>4</p>
</blockquote></td>
<td><blockquote>
<p>1,209</p>
</blockquote></td>
<td><blockquote>
<p>519</p>
</blockquote></td>
</tr>
<tr class="even">
<td><blockquote>
<p>Madelon</p>
</blockquote></td>
<td><blockquote>
<p>500</p>
</blockquote></td>
<td><blockquote>
<p>0</p>
</blockquote></td>
<td><blockquote>
<p>2</p>
</blockquote></td>
<td><blockquote>
<p>1,820</p>
</blockquote></td>
<td><blockquote>
<p>780</p>
</blockquote></td>
</tr>
<tr class="odd">
<td><blockquote>
<p>KR-vs-KP</p>
</blockquote></td>
<td><blockquote>
<p>37</p>
</blockquote></td>
<td><blockquote>
<p>0</p>
</blockquote></td>
<td><blockquote>
<p>2</p>
</blockquote></td>
<td><blockquote>
<p>2,237</p>
</blockquote></td>
<td><blockquote>
<p>959</p>
</blockquote></td>
</tr>
<tr class="even">
<td><blockquote>
<p>Abalone</p>
</blockquote></td>
<td><blockquote>
<p>1</p>
</blockquote></td>
<td><blockquote>
<p>7</p>
</blockquote></td>
<td><blockquote>
<p>28</p>
</blockquote></td>
<td><blockquote>
<p>2,923</p>
</blockquote></td>
<td><blockquote>
<p>1,254</p>
</blockquote></td>
</tr>
<tr class="odd">
<td><blockquote>
<p>Wine Quality</p>
</blockquote></td>
<td><blockquote>
<p>0</p>
</blockquote></td>
<td><blockquote>
<p>11</p>
</blockquote></td>
<td><blockquote>
<p>11</p>
</blockquote></td>
<td><blockquote>
<p>3,425</p>
</blockquote></td>
<td><blockquote>
<p>1,469</p>
</blockquote></td>
</tr>
<tr class="even">
<td><blockquote>
<p>Waveform</p>
</blockquote></td>
<td><blockquote>
<p>0</p>
</blockquote></td>
<td><blockquote>
<p>40</p>
</blockquote></td>
<td><blockquote>
<p>3</p>
</blockquote></td>
<td><blockquote>
<p>3,500</p>
</blockquote></td>
<td><blockquote>
<p>1,500</p>
</blockquote></td>
</tr>
<tr class="odd">
<td><blockquote>
<p>Gisette</p>
</blockquote></td>
<td><blockquote>
<p>5,000</p>
</blockquote></td>
<td><blockquote>
<p>0</p>
</blockquote></td>
<td><blockquote>
<p>2</p>
</blockquote></td>
<td><blockquote>
<p>4,900</p>
</blockquote></td>
<td><blockquote>
<p>2,100</p>
</blockquote></td>
</tr>
<tr class="even">
<td><blockquote>
<p>Convex</p>
</blockquote></td>
<td><blockquote>
<p>0</p>
</blockquote></td>
<td><blockquote>
<p>784</p>
</blockquote></td>
<td><blockquote>
<p>2</p>
</blockquote></td>
<td><blockquote>
<p>8,000</p>
</blockquote></td>
<td><blockquote>
<p>50,000</p>
</blockquote></td>
</tr>
<tr class="odd">
<td><blockquote>
<p>CIFAR-10-Small</p>
</blockquote></td>
<td><blockquote>
<p>3,072</p>
</blockquote></td>
<td><blockquote>
<p>0</p>
</blockquote></td>
<td><blockquote>
<p>10</p>
</blockquote></td>
<td><blockquote>
<p>10,000</p>
</blockquote></td>
<td><blockquote>
<p>10,000</p>
</blockquote></td>
</tr>
<tr class="even">
<td><blockquote>
<p>MNIST Basic</p>
</blockquote></td>
<td><blockquote>
<p>0</p>
</blockquote></td>
<td><blockquote>
<p>784</p>
</blockquote></td>
<td><blockquote>
<p>10</p>
</blockquote></td>
<td><blockquote>
<p>12,000</p>
</blockquote></td>
<td><blockquote>
<p>50,000</p>
</blockquote></td>
</tr>
<tr class="odd">
<td><blockquote>
<p>Rot. MNIST + BI</p>
</blockquote></td>
<td><blockquote>
<p>0</p>
</blockquote></td>
<td><blockquote>
<p>784</p>
</blockquote></td>
<td><blockquote>
<p>10</p>
</blockquote></td>
<td><blockquote>
<p>12,000</p>
</blockquote></td>
<td><blockquote>
<p>50,000</p>
</blockquote></td>
</tr>
<tr class="even">
<td><blockquote>
<p>Shuttle</p>
</blockquote></td>
<td><blockquote>
<p>9</p>
</blockquote></td>
<td><blockquote>
<p>0</p>
</blockquote></td>
<td><blockquote>
<p>7</p>
</blockquote></td>
<td><blockquote>
<p>43,500</p>
</blockquote></td>
<td><blockquote>
<p>14,500</p>
</blockquote></td>
</tr>
<tr class="odd">
<td><blockquote>
<p>KDD09-Appentency</p>
</blockquote></td>
<td><blockquote>
<p>190</p>
</blockquote></td>
<td><blockquote>
<p>40</p>
</blockquote></td>
<td><blockquote>
<p>2</p>
</blockquote></td>
<td><blockquote>
<p>35,000</p>
</blockquote></td>
<td><blockquote>
<p>15,000</p>
</blockquote></td>
</tr>
<tr class="even">
<td><blockquote>
<p>CIFAR-10</p>
</blockquote></td>
<td><blockquote>
<p>3,072</p>
</blockquote></td>
<td><blockquote>
<p>0</p>
</blockquote></td>
<td><blockquote>
<p>10</p>
</blockquote></td>
<td><blockquote>
<p>50,000</p>
</blockquote></td>
<td><blockquote>
<p>10,000</p>
</blockquote></td>
</tr>
</tbody>
</table>
<blockquote>
<p>In early experiments, we observed a few cases in which Auto-WEKA’s SMBO method picked hyperparameters that had excellent training performance, but turned out to generalize poorly. To enable Auto-WEKA to detect such overﬁtting, we partitioned its training set into two subsets: 70% for use inside the SMBO method, and 30% of validation data that we only used after the SMBO method ﬁnished.</p>
</blockquote>
<p><em><strong>4.5.1</strong></em> <em><strong>Baseline</strong></em> <em><strong>Methods</strong></em></p>
<blockquote>
<p>Auto-WEKA aims to aid non-expert users of machine learning techniques. A natural approach that such a user might take is to perform 10-fold cross validation on the training set for each technique with unmodiﬁed hyperparameters, and select the classiﬁer with the smallest average misclassiﬁcation error across folds. We will refer to this method applied to our set of WEKA learners as <em>Ex-Def</em> ; it is the best choice that can be made for WEKA with default hyperparameters.</p>
<p>90 L. Kotthoff et al.</p>
<p>For each dataset, the second and third columns in Table <a href="#_bookmark521">4.2</a> present the best and worst “oracle performance” of the default learners when prepared given all the training data and evaluated on the test set. We observe that the gap between the best and worst learner was huge, e.g., misclassiﬁcation rates of 4.93% vs. 99.24% on the Dorothea dataset. This suggests that some form of algorithm selection is essential for achieving good performance.</p>
<p>A stronger baseline we will use is an approach that in addition to selecting the learner, also sets its hyperparameters optimally from a predeﬁned set. More precisely, this baseline performs an exhaustive search over a grid of hyperparameter settings for each of the base learners, discretizing numeric parameters into three points. We refer to this baseline as <em>grid</em> <em>search</em> and note that—as an optimization approach in the joint space of algorithms and hyperparameter settings—it is a simple CASH algorithm. However, it is quite expensive, requiring more than 10,000 CPU hours on each of Gisette, Convex, MNIST, Rot MNIST + BI, and both CIFAR variants, rendering it infeasible to use in most practical applications. (In contrast, we gave Auto-WEKA only 120 CPU hours.)</p>
<p>Table <a href="#_bookmark521">4.2</a>(columns four and ﬁve) shows the best and worst “oracle performance” on the test set across the classiﬁers evaluated by grid search. Comparing these performances to the default performance obtained using Ex-Def, we note that in most cases, even WEKA’s best default algorithm could be improved by selecting better hyperparameter settings, sometimes rather substantially: e.g., , in the CIFAR- 10 small task, grid search offered a 13% reduction in error over Ex-Def.</p>
<p>It has been demonstrated in previous work that, holding the overall time budget constant, grid search is outperformed by random search over the hyperparameter space [<a href="#_bookmark490">5</a>]. Our ﬁnal baseline, <em>random</em> <em>search</em>, implements such a method, picking algorithms and hyperparameters sampled at random, and computes their perfor- mance on the 10 cross-validation folds until it exhausts its time budget. For each dataset, we ﬁrst used 750 CPU hours to compute the cross-validation performance of randomly sampled combinations of algorithms and hyperparameters. We then simulated runs of random search by sampling combinations without replacement from these results that consumed 120 CPU hours and returning the sampled combination with the best performance.</p>
</blockquote>
<p><em><strong>4.5.2</strong></em> <em><strong>Resultsfor</strong></em> <em><strong>Cross-Validation</strong></em> <em><strong>Performance</strong></em></p>
<blockquote>
<p>The middle portion of Table <a href="#_bookmark521">4.2</a> reports our main results. First, we note that grid search over the hyperparameters of all base-classiﬁers yielded better results than Ex-Def in 17/21 cases, which underlines the importance of not only choosing the right algorithm but of also setting its hyperparameters well.</p>
<p>However, we note that we gave grid search a very large time budget (often in excess 10,000 CPU hours for each dataset, in total more than 10 CPU years), meaning that it would often be infeasible to use in practice.</p>
<p><strong>Table</strong> <strong>4.2</strong> Performance on both 10-fold cross-validation and test data. Ex-Def and Grid Search are deterministic. Random search had a time budget of 120 CPU hours. For Auto-WEKA, we performed 25 runs of 30 h each. We report results as mean loss across 100,000 bootstrap samples simulating 4 parallel runs. We determined test loss (misclassiﬁcation rate) by training the selected model/hyperparameters on the entire 70% training data and computing accuracy on the previously unused 30% test data. Bold face indicates the lowest error within a block of comparable methods that was statistically signiﬁcant</p>
</blockquote>
<table>
<tbody>
<tr class="odd">
<td><blockquote>
<p>Dataset</p>
</blockquote></td>
<td><blockquote>
<p>Oracle Perf. (%)</p>
</blockquote></td>
<td><blockquote>
<p>10-Fold C.V. performance (%)</p>
</blockquote></td>
<td><blockquote>
<p>Test performance (%)</p>
</blockquote></td>
</tr>
<tr class="even">
<td></td>
<td><blockquote>
<p>Ex-Def</p>
</blockquote></td>
<td><blockquote>
<p>Grid search</p>
</blockquote></td>
<td><blockquote>
<p>Ex-Def</p>
</blockquote></td>
</tr>
<tr class="odd">
<td></td>
<td><blockquote>
<p>Best</p>
</blockquote></td>
<td><blockquote>
<p>Worst</p>
</blockquote></td>
<td><blockquote>
<p>Best</p>
</blockquote></td>
</tr>
<tr class="even">
<td><blockquote>
<p>Dexter</p>
</blockquote></td>
<td><blockquote>
<p>7.78</p>
</blockquote></td>
<td><blockquote>
<p>52.78</p>
</blockquote></td>
<td><blockquote>
<p><strong>3</strong>.<strong>89</strong></p>
</blockquote></td>
</tr>
<tr class="odd">
<td><blockquote>
<p>GermanCredit</p>
</blockquote></td>
<td><blockquote>
<p>26.00</p>
</blockquote></td>
<td><blockquote>
<p>38.00</p>
</blockquote></td>
<td><blockquote>
<p><strong>25</strong>.<strong>00</strong></p>
</blockquote></td>
</tr>
<tr class="even">
<td><blockquote>
<p>Dorothea</p>
</blockquote></td>
<td><blockquote>
<p>4.93</p>
</blockquote></td>
<td><blockquote>
<p>99.24</p>
</blockquote></td>
<td><blockquote>
<p><strong>4</strong>.<strong>64</strong></p>
</blockquote></td>
</tr>
<tr class="odd">
<td><blockquote>
<p>Yeast</p>
</blockquote></td>
<td><blockquote>
<p>40.00</p>
</blockquote></td>
<td><blockquote>
<p>68.99</p>
</blockquote></td>
<td><blockquote>
<p><strong>36</strong>.<strong>85</strong></p>
</blockquote></td>
</tr>
<tr class="even">
<td><blockquote>
<p>Amazon</p>
</blockquote></td>
<td><blockquote>
<p>28.44</p>
</blockquote></td>
<td><blockquote>
<p>99.33</p>
</blockquote></td>
<td><blockquote>
<p><strong>17</strong>.<strong>56</strong></p>
</blockquote></td>
</tr>
<tr class="odd">
<td><blockquote>
<p>Secom</p>
</blockquote></td>
<td><blockquote>
<p>7.87</p>
</blockquote></td>
<td><blockquote>
<p>14.26</p>
</blockquote></td>
<td><blockquote>
<p><strong>7</strong>.<strong>66</strong></p>
</blockquote></td>
</tr>
<tr class="even">
<td><blockquote>
<p>Semeion</p>
</blockquote></td>
<td><blockquote>
<p>8.18</p>
</blockquote></td>
<td><blockquote>
<p>92.45</p>
</blockquote></td>
<td><blockquote>
<p><strong>5</strong>.<strong>24</strong></p>
</blockquote></td>
</tr>
<tr class="odd">
<td><blockquote>
<p>Car</p>
</blockquote></td>
<td><blockquote>
<p>0.77</p>
</blockquote></td>
<td><blockquote>
<p>29.15</p>
</blockquote></td>
<td><blockquote>
<p><strong>0</strong>.<strong>00</strong></p>
</blockquote></td>
</tr>
<tr class="even">
<td><blockquote>
<p>Madelon</p>
</blockquote></td>
<td><blockquote>
<p><strong>17</strong>.<strong>05</strong></p>
</blockquote></td>
<td><blockquote>
<p>50.26</p>
</blockquote></td>
<td><blockquote>
<p><strong>17</strong>.<strong>05</strong></p>
</blockquote></td>
</tr>
<tr class="odd">
<td><blockquote>
<p>KR-vs-KP</p>
</blockquote></td>
<td><blockquote>
<p>0.31</p>
</blockquote></td>
<td><blockquote>
<p>48.96</p>
</blockquote></td>
<td><blockquote>
<p><strong>0</strong>.<strong>21</strong></p>
</blockquote></td>
</tr>
<tr class="even">
<td><blockquote>
<p>Abalone</p>
</blockquote></td>
<td><blockquote>
<p>73.18</p>
</blockquote></td>
<td><blockquote>
<p>84.04</p>
</blockquote></td>
<td><blockquote>
<p><span id="_bookmark521" class="anchor"></span><strong>72</strong>.<strong>15</strong></p>
</blockquote></td>
</tr>
<tr class="odd">
<td><blockquote>
<p>Wine Quality</p>
</blockquote></td>
<td><blockquote>
<p>36.35</p>
</blockquote></td>
<td><blockquote>
<p>60.99</p>
</blockquote></td>
<td><blockquote>
<p><strong>32</strong>.<strong>88</strong></p>
</blockquote></td>
</tr>
<tr class="even">
<td><blockquote>
<p>Waveform</p>
</blockquote></td>
<td><blockquote>
<p>14.27</p>
</blockquote></td>
<td><blockquote>
<p>68.80</p>
</blockquote></td>
<td><blockquote>
<p><strong>13</strong>.<strong>47</strong></p>
</blockquote></td>
</tr>
<tr class="odd">
<td><blockquote>
<p>Gisette</p>
</blockquote></td>
<td><blockquote>
<p>2.52</p>
</blockquote></td>
<td><blockquote>
<p>50.91</p>
</blockquote></td>
<td><blockquote>
<p><strong>1</strong>.<strong>81</strong></p>
</blockquote></td>
</tr>
<tr class="even">
<td><blockquote>
<p>Convex</p>
</blockquote></td>
<td><blockquote>
<p>25.96</p>
</blockquote></td>
<td><blockquote>
<p>50.00</p>
</blockquote></td>
<td><blockquote>
<p><strong>19</strong>.<strong>94</strong></p>
</blockquote></td>
</tr>
<tr class="odd">
<td><blockquote>
<p>CIFAR-10-Small</p>
</blockquote></td>
<td><blockquote>
<p>65.91</p>
</blockquote></td>
<td><blockquote>
<p>90.00</p>
</blockquote></td>
<td><blockquote>
<p><strong>52</strong>.<strong>16</strong></p>
</blockquote></td>
</tr>
<tr class="even">
<td><blockquote>
<p>MNIST Basic</p>
</blockquote></td>
<td><blockquote>
<p>5.19</p>
</blockquote></td>
<td><blockquote>
<p>88.75</p>
</blockquote></td>
<td><blockquote>
<p><strong>2</strong>.<strong>58</strong></p>
</blockquote></td>
</tr>
<tr class="odd">
<td><blockquote>
<p>Rot. MNIST + BI</p>
</blockquote></td>
<td><blockquote>
<p>63.14</p>
</blockquote></td>
<td><blockquote>
<p>88.88</p>
</blockquote></td>
<td><blockquote>
<p><strong>55</strong>.<strong>34</strong></p>
</blockquote></td>
</tr>
<tr class="even">
<td><blockquote>
<p>Shuttle</p>
</blockquote></td>
<td><blockquote>
<p>0.0138</p>
</blockquote></td>
<td><blockquote>
<p>20.8414</p>
</blockquote></td>
<td><blockquote>
<p><strong>0</strong>.<strong>0069</strong></p>
</blockquote></td>
</tr>
<tr class="odd">
<td><blockquote>
<p>KDD09-Appentency</p>
</blockquote></td>
<td><blockquote>
<p>1.7400</p>
</blockquote></td>
<td><blockquote>
<p>6.9733</p>
</blockquote></td>
<td><blockquote>
<p><strong>1</strong>.<strong>6332</strong></p>
</blockquote></td>
</tr>
<tr class="even">
<td><blockquote>
<p>CIFAR-10</p>
</blockquote></td>
<td><blockquote>
<p>64.27</p>
</blockquote></td>
<td><blockquote>
<p>90.00</p>
</blockquote></td>
<td><blockquote>
<p><strong>55</strong>.<strong>27</strong></p>
</blockquote></td>
</tr>
</tbody>
</table>
<blockquote>
<p>92 L. Kotthoff et al.</p>
<p>In contrast, we gave each of the other methods only 4×30 CPU hours per dataset; nevertheless, they still yielded substantially better performance than grid search, outperforming it in 14/21 cases. Random search outperforms grid search in 9/21 cases, highlighting that even exhaustive grid search with a large time budget is not always the right thing to do. We note that sometimes Auto-WEKA’s performance improvements over the baselines were substantial, with relative reductions of the cross-validation loss (in this case the misclassiﬁcation rate) exceeding 10% in 6/21 cases.</p>
</blockquote>
<p><em><strong>4.5.3</strong></em> <em><strong>Resultsfor</strong></em> <em><strong>Test</strong></em> <em><strong>Performance</strong></em></p>
<blockquote>
<p>The results just shown demonstrate that Auto-WEKA is effective at optimizing its given objective function; however, this is not sufﬁcient to allow us to conclude that it ﬁts models that generalize well. As the number of hyperparameters of a machine learning algorithm grows, so does its potential for overﬁtting. The use of cross- validation substantially increases Auto-WEKA’s robustness against overﬁtting, but since its hyperparameter space is much larger than that of standard classiﬁcation algorithms, it is important to carefully study whether (and to what extent) overﬁtting poses a problem.</p>
<p>To evaluate generalization, we determined a combination of algorithm and hyperparameter settings Aλ by running Auto-WEKA as before (cross-validating on the training set), trained Aλ on the entire training set, and then evaluated the resulting model on the test set. The right portion of Table <a href="#_bookmark521">4.2</a> reports the test performance obtained with all methods.</p>
<p>Broadly speaking, similar trends held as for cross-validation performance: Auto- WEKA outperforms the baselines, with grid search and random search performing better than Ex-Def. However, the performance differences were less pronounced: grid search only yields better results than Ex-Def in 15/21 cases, and random search in turn outperforms grid search in 7/21 cases. Auto-WEKA outperforms the baselines in 15/21 cases. Notably, on 12 of the 13 largest datasets, Auto- WEKA outperforms our baselines; we attribute this to the fact that the risk of overﬁtting decreases with dataset size. Sometimes, Auto-WEKA’s performance improvements over the other methods were substantial, with relative reductions of the test misclassiﬁcation rate exceeding 16% in 3/21 cases.</p>
<p>As mentioned earlier, Auto-WEKA only used 70% of its training set during the optimization of cross-validation performance, reserving the remaining 30% for assessing the risk of overﬁtting. At any point in time, Auto-WEKA’s SMBO method keeps track of its <em>incumbent</em> (the hyperparameter conﬁguration with the lowest cross-validation misclassiﬁcation rate seen so far). After its SMBO procedure has ﬁnished, Auto-WEKA extracts a trajectory of these incumbents from it and computes their generalization performance on the withheld 30% validation data.</p>
<p>4 Auto-WEKA: Automatic Model Selection and Hyperparameter... 93</p>
<p>It then computes the Spearman rank coefﬁcient between the sequence of training performances (evaluated by the SMBO method through cross-validation) and this generalization performance.</p>
<p><strong>4.6</strong> <strong>Conclusion</strong></p>
<p>In this work, we have shown that the daunting problem of combined algorithm selection and hyperparameter optimization (CASH) can be solved by a practical, fully automated tool. This is made possible by recent Bayesian optimization tech- niques that iteratively build models of the algorithm/hyperparameter landscape and leverage these models to identify new points in the space that deserve investigation. We built a tool, Auto-WEKA, that draws on the full range of learning algorithms in WEKA and makes it easy for non-experts to build high-quality classiﬁers for given application scenarios. An extensive empirical comparison on 21 prominent</p>
<p>datasets showed that Auto-WEKA often outperformed standard algorithm selection and hyperparameter optimization methods, especially on large datasets.</p>
</blockquote>
<p><em><strong>4.6.1</strong></em> <em><strong>Community</strong></em> <em><strong>Adoption</strong></em></p>
<blockquote>
<p>Auto-WEKA was the ﬁrst method to use Bayesian optimization to automatically instantiate a highly parametric machine learning framework at the push of a button. Since its initial release, it has been adopted by many users in industry and academia; the 2.0 line, which integrates with the WEKA package manager, has been downloaded more than 30,000 times, averaging more than 550 downloads a week. It is under active development, with new features added recently and in the pipeline.</p>
<p><span id="_bookmark481" class="anchor"></span><strong>Bibliography</strong></p>
<p>1. Adankon, M., Cheriet, M.: Model selection for the LS-SVM. application to handwriting recognition. Pattern Recognition 42(12), 3264–3270 (2009)</p>
<p>2. Bardenet, R., Brendel, M., Kégl, B., Sebag, M.: Collaborative hyperparameter tuning. In: <span id="_bookmark496" class="anchor"><span id="_bookmark489" class="anchor"></span></span>Proc. of ICML- 13 (2013)</p>
<p>3. Bengio, Y.: Gradient-based optimization of hyperparameters. Neural Computation 12(8), <span id="_bookmark502" class="anchor"></span>1889– 1900 (2000)</p>
<p>4. Bergstra, J., Bardenet, R., Bengio, Y., Kégl, B.: Algorithms for Hyper-Parameter Optimization. <span id="_bookmark490" class="anchor"></span>In: Proc. of NIPS- 11 (2011)</p>
<p>5. Bergstra, J., Bengio, Y.: Random search for hyper-parameter optimization. JMLR 13, 281–305</p>
<p><span id="_bookmark482" class="anchor"></span>(2012)</p>
<p>6. Biem, A.: A model selection criterion for classiﬁcation: Application to HMM topology optimization. In: Proc. of ICDAR-03. pp. 104– 108. IEEE (2003)</p>
</blockquote>
<p>94 L. Kotthoff et al.</p>
<blockquote>
<p><span id="_bookmark479" class="anchor"></span>7. Bischl, B., Lang, M., Kotthoff, L., Schiffner, J., Richter, J., Studerus, E., Casalicchio, G., Jones,</p>
<p>Z.M.: mlr: Machine Learning in R. Journal of Machine Learning Research 17(170), 1–5 (2016),</p>
<p><span id="_bookmark483" class="anchor"></span><a href="http://jmlr.org/papers/v17/15-066.html" class="uri">http://jmlr.org/papers/v17/15-066.html</a></p>
<p>8. Bozdogan, H.: Model selection and Akaike’s information criterion (AIC): The general theory <span id="_bookmark484" class="anchor"></span>and its analytical extensions. Psychometrika 52(3), 345–370 (1987)</p>
<p>9. Brazdil, P., Soares, C., Da Costa, J.: Ranking learning algorithms: Using IBL and meta-learning <span id="_bookmark510" class="anchor"></span>on accuracy and time results. Machine Learning 50(3), 251–277 (2003)</p>
<p>10. Brochu, E., Cora, V.M., de Freitas, N.: A tutorial on Bayesian optimization of expensive cost functions, with application to active user modeling and hierarchical reinforcement learning. Tech. Rep. UBC TR-2009-23 and arXiv:1012.2599v1, Department of Computer Science, <span id="_bookmark485" class="anchor"></span>University of British Columbia (2009)</p>
<p>11. Chapelle, O., Vapnik, V., Bengio, Y.: Model selection for small sample regression. Machine <span id="_bookmark516" class="anchor"></span>Learning (2001)</p>
<p>12. Feurer, M., Klein, A., Eggensperger, K., Springenberg, J., Blum, M., Hutter, F.: Efﬁcient and robust automated machine learning. In: Cortes, C., Lawrence, N.D., Lee, D.D., Sugiyama, M., Garnett, R. (eds.) Advances in Neural Information Processing Systems 28, pp. 2962–</p>
<p>2970. Curran Associates, Inc. (2015), <a href="http://papers.nips.cc/paper/5872-efficient-and-robust-automated-machine-learning.pdf">http://papers.nips.cc/paper/5872-efﬁcient-and-robust-</a> <span id="_bookmark519" class="anchor"></span><a href="http://papers.nips.cc/paper/5872-efficient-and-robust-automated-machine-learning.pdf">automated-machine-learning.pdf</a></p>
<p>13. Frank, A., Asuncion, A.: UCI machine learning repository (2010), <a href="http://archive.ics.uci.edu/ml">http://archive.ics.uci.edu/</a> <a href="http://archive.ics.uci.edu/ml">ml</a>, uRL: <a href="http://archive.ics.uci.edu/ml" class="uri">http://archive.ics.uci.edu/ml</a>. University of California, Irvine, School of Information <span id="_bookmark491" class="anchor"></span>and Computer Sciences</p>
<p>14. Guo, X., Yang, J., Wu, C., Wang, C., Liang, Y.: A novel LS-SVMs hyper-parameter selection based on particle swarm optimization. Neurocomputing 71(16), 3211–3215 (2008)</p>
<p><span id="_bookmark478" class="anchor"></span>15. Hall, M., Frank, E., Holmes, G., Pfahringer, B., Reutemann, P., Witten, I.: The WEKA data mining software: an update. ACM SIGKDD Explorations Newsletter 11(1), 10– 18 (2009)</p>
<p><span id="_bookmark503" class="anchor"></span>16. Hutter, F., Hoos, H., Leyton-Brown, K.: Sequential model-based optimization for general <span id="_bookmark508" class="anchor"></span>algorithm conﬁguration. In: Proc. of LION-5. pp. 507–523 (2011)</p>
<p>17. Hutter, F., Hoos, H., Leyton-Brown, K., Stützle, T.: ParamILS: an automatic algorithm <span id="_bookmark512" class="anchor"></span>conﬁguration framework. JAIR 36(1), 267–306 (2009)</p>
<p>18. Jones, D.R., Schonlau, M., Welch, W.J.: Efﬁcient global optimization of expensive black box <span id="_bookmark506" class="anchor"></span>functions. Journal of Global Optimization 13, 455–492 (1998)</p>
<p>19. Kohavi, R.: A study of cross-validation and bootstrap for accuracy estimation and model <span id="_bookmark505" class="anchor"></span>selection. In: Proc. of IJCAI-95. pp. 1137– 1145 (1995)</p>
</blockquote>
<p>20. Kotthoff, L., Thornton, C., Hoos, H.H., Hutter, F., Leyton-Brown, K.: Auto-WEKA 2.0: Automatic model selection and hyperparameter optimization in WEKA. Journal of Machine Learning Research 18(25), 1–5 (2017), <a href="http://jmlr.org/papers/v18/16-261.html" class="uri">http://jmlr.org/papers/v18/16-261.html</a></p>
<p><span id="_bookmark520" class="anchor"></span>21. Krizhevsky, A., Hinton, G.: Learning multiple layers of features from tiny images. Master’s <span id="_bookmark495" class="anchor"></span>thesis, Department of Computer Science, University of Toronto (2009)</p>
<p>22. Leite, R., Brazdil, P., Vanschoren, J.: Selecting classiﬁcation algorithms with active testing. In: <span id="_bookmark492" class="anchor"></span>Proc. of MLDM-12. pp. 117– 131 (2012)</p>
<p>23. López-Ibáñez, M., Dubois-Lacoste, J., Stützle, T., Birattari, M.: The irace package, iterated race for automatic algorithm conﬁguration. Tech. Rep. TR/IRIDIA/2011-004, IRIDIA, Uni- versité Libre de Bruxelles, Belgium (2011), <a href="http://iridia.ulb.ac.be/IridiaTrSeries/IridiaTr2011-004.pdf">http://iridia.ulb.ac.be/IridiaTrSeries/IridiaTr2011-</a> <span id="_bookmark486" class="anchor"></span><a href="http://iridia.ulb.ac.be/IridiaTrSeries/IridiaTr2011-004.pdf">004.pdf</a></p>
<p>24. Maron, O., Moore, A.: Hoeffding races: Accelerating model selection search for classiﬁcation <span id="_bookmark487" class="anchor"></span>and function approximation. In: Proc. of NIPS-94. pp. 59–66 (1994)</p>
<p>25. McQuarrie, A., Tsai, C.: Regression and time series model selection. World Scientiﬁc (1998)</p>
<p><span id="_bookmark497" class="anchor"></span>26. Pfahringer, B., Bensusan, H., Giraud-Carrier, C.: Meta-learning by landmarking various <span id="_bookmark513" class="anchor"></span>learning algorithms. In: Proc. of ICML-00. pp. 743–750 (2000)</p>
<p>27. Schonlau, M., Welch, W.J., Jones, D.R.: Global versus local search in constrained optimization of computer models. In: Flournoy, N., Rosenberger, W., Wong, W. (eds.) New Developments and Applications in Experimental Design, vol. 34, pp. 11–25. Institute of Mathematical Statistics, Hayward, California (1998)</p>
<blockquote>
<p>4 Auto-WEKA: Automatic Model Selection and Hyperparameter... 95</p>
<p>28. Snoek, J., Larochelle, H., Adams, R.P.: Practical bayesian optimization of machine learning <span id="_bookmark514" class="anchor"><span id="_bookmark493" class="anchor"></span></span>algorithms. In: Proc. of NIPS- 12 (2012)</p>
<p>29. Srinivas, N., Krause, A., Kakade, S., Seeger, M.: Gaussian process optimization in the bandit setting: No regret and experimental design. In: Proc. of ICML- 10. pp. 1015– 1022 (2010)</p>
<p><span id="_bookmark494" class="anchor"></span>30. Strijov, V., Weber, G.: Nonlinear regression model generation using hyperparameter optimiza- <span id="_bookmark504" class="anchor"></span>tion. Computers &amp; Mathematics with Applications 60(4), 981–988 (2010)</p>
<p>31. Thornton, C., Hutter, F., Hoos, H.H., Leyton-Brown, K.: Auto-WEKA: Combined selection and hyperparameter optimization of classiﬁcation algorithms. In: KDD (2013)</p>
<p>32. Vilalta, R., Drissi, Y.: A perspective view and survey of meta-learning. Artif. Intell. Rev. 18(2), <span id="_bookmark498" class="anchor"><span id="_bookmark488" class="anchor"></span></span>77–95 (Oct 2002)</p>
<p>33. Zhao, P., Yu, B.: On model selection consistency of lasso. JMLR 7, 2541–2563 (Dec 2006)</p>
<p><strong>Open</strong> <strong>Access</strong> This chapter is licensed under the terms of the Creative Commons Attribution 4.0 International License <a href="http://creativecommons.org/licenses/by/4.0/">(http://creativecommons.org/licenses/by/4.0/</a>), which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence and indicate if changes were made.</p>
<p>The images or other third party material in this chapter are included in the chapter’s Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the chapter’s Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder.</p>
</blockquote>
<p><img src="./automlgithubpagesimages//media/image175.png" width="75" height="26" /></p>
<p><img src="./automlgithubpagesimages//media/image176.png" width="41" height="41" /><img src="./automlgithubpagesimages//media/image12.jpeg" width="136" /></p>
<blockquote>
<p><span id="_bookmark7" class="anchor"></span><strong>Chapter</strong> <strong>5</strong></p>
<p><strong>Hyperopt-Sklearn</strong></p>
</blockquote>
<p><img src="./automlgithubpagesimages//media/image177.png" /></p>
<blockquote>
<p><strong>Brent</strong> <strong>Komer,</strong> <strong>James</strong> <strong>Bergstra,</strong> <strong>and</strong> <strong>Chris</strong> <strong>Eliasmith</strong></p>
</blockquote>
<p><strong>Abstract</strong> Hyperopt-sklearn is a software project that provides automated algorithm conﬁguration of the Scikit-learn machine learning library. Following Auto-Weka, we take the view that the choice of classiﬁer and even the choice of preprocessing module can be taken together to represent a single large hyperparameter optimiza- tion problem. We use Hyperopt to deﬁne a search space that encompasses many standard components (e.g. SVM, RF, KNN, PCA, TFIDF) and common patterns of composing them together. We demonstrate, using search algorithms in Hyperopt and standard benchmarking data sets (MNIST, 20-Newsgroups, Convex Shapes), that searching this space is practical and effective. In particular, we improve on best-known scores for the model space for both MNIST and Convex Shapes at the time of release.</p>
<blockquote>
<p><strong>5.1</strong> <strong>Introduction</strong></p>
<p>Relative to deep networks, algorithms such as Support Vector Machines (SVMs) and Random Forests (RFs) have a small-enough number of hyperparameters that manual tuning and grid or random search provides satisfactory results. Taking a step back though, there is often no particular reason to use either an SVM or an RF when they are both computationally viable. A model-agnostic practitioner may simply prefer to go with the one that provides greater accuracy. In this light, the choice of classiﬁer can be seen as hyperparameter alongside the C-value in the SVM and the max-tree- depth of the RF. Indeed the choice and conﬁguration of preprocessing components may likewise be seen as part of the model selection/hyperparameter optimization problem.</p>
<p>B. Komer (凶) · J. Bergstra · C. Eliasmith</p>
<p>Center for Theoretical Neuroscience, University of Waterloo, Waterloo, ON, Canada e-mail: <a href="mailto:bjkomer@uwaterloo.ca">bjkomer@uwaterloo.ca</a></p>
<p>© The Author(s) 2019</p>
<p>F. Hutter et al. (eds.), <em>Automated</em> <em>Machine</em> <em>Learning</em>, The Springer Series on Challenges in Machine Learning, <a href="https://doi.org/10.1007/978-3-030-05318-5_5" class="uri">https://doi.org/10.1007/978-3-030-05318-5_5</a></p>
<p>98 B. Komer et al.</p>
<p>The Auto-Weka project [<a href="#_bookmark522">19</a>] was the ﬁrst to show that an entire library of machine learning approaches (Weka [<a href="#_bookmark523">8</a>]) can be searched within the scope of a single run of hyperparameter tuning. However, Weka is a GPL-licensed Java library, and was not written with scalability in mind, so we feel there is a need for alternatives to Auto-Weka. Scikit-learn [<a href="#_bookmark524">16</a>] is another library of machine learning algorithms. It is written in Python (with many modules in C for greater speed), and is BSD-licensed. Scikit-learn is widely used in the scientiﬁc Python community and supports many machine learning application areas.</p>
</blockquote>
<p>This chapter introduces Hyperopt-Sklearn: a project that brings the bene- ﬁts of automated algorithm conﬁguration to users of Python and scikit-learn. Hyperopt-Sklearn uses Hyperopt [<a href="#_bookmark525">3</a>] to describe a search space over possible conﬁgurations of scikit-learn components, including preprocessing, classiﬁcation, and regression modules. One of the main design features of this project is to provide an interface that is familiar to users of scikit-learn. With very little changes, hyperparameter search can be applied to an existing code base. This chapter begins with a background of Hyperopt and the conﬁguration space it uses within scikit-learn, followed by example usage and experimental results with this software.</p>
<blockquote>
<p>This chapter is an extended version of our 2014 paper introducing hyperopt- sklearn, presented at the <em>2014</em> <em>ICML</em> <em>Workshop</em> <em>on</em> <em>AutoML</em> [<a href="#_bookmark526">10</a>].</p>
<p><strong>5.2</strong> <strong>Background:</strong> <strong>Hyperopt</strong> <strong>for</strong> <strong>Optimization</strong></p>
</blockquote>
<p>The Hyperopt library [<a href="#_bookmark525">3</a>] offers optimization algorithms for search spaces that arise in algorithm conﬁguration. These spaces are characterized by a variety of types of variables (continuous, ordinal, categorical), different sensitivity proﬁles (e.g. uniform vs. log scaling), and conditional structure (when there is a choice between two classiﬁers, the parameters of one classiﬁer are irrelevant when the other classiﬁer is chosen). To use Hyperopt, a user must deﬁne/choose three things:</p>
<blockquote>
<p>• A search domain,</p>
<p>• An objective function,</p>
<p>• An optimization algorithm.</p>
</blockquote>
<p>The search domain is speciﬁed via random variables, whose distributions should be chosen so that the most promising combinations have high prior probability. The search domain can include Python operators and functions that combine random variables into more convenient data structures for the objective function. Any conditional structure is deﬁned within this domain. The objective function maps a joint sampling of these random variables to a scalar-valued score that the optimization algorithm will try to minimize.</p>
<p><img src="./automlgithubpagesimages//media/image178.jpeg" width="442" /><img src="./automlgithubpagesimages//media/image179.jpeg" width="442" /><img src="./automlgithubpagesimages//media/image191.png" width="107" height="32" /><img src="./automlgithubpagesimages//media/image195.jpeg" width="29" height="10" /><img src="./automlgithubpagesimages//media/image196.jpeg" width="45" height="10" /><img src="./automlgithubpagesimages//media/image197.jpeg" width="53" height="9" /><img src="./automlgithubpagesimages//media/image198.png" width="26" /><img src="./automlgithubpagesimages//media/image199.png" width="27" height="13" /><img src="./automlgithubpagesimages//media/image200.png" /><img src="./automlgithubpagesimages//media/image201.png" width="19" /><img src="./automlgithubpagesimages//media/image202.png" /><img src="./automlgithubpagesimages//media/image203.png" width="32" /></p>
<blockquote>
<p>5 Hyperopt-Sklearn 99</p>
<p>An example search domain using Hyperopt is depicted below.</p>
<p>from hyperopt import hp</p>
<p>space = hp .choice(’my_conditional’ ,</p>
<p>[</p>
<p>(’case 1’ , 1 + hp .lognormal(’c1’ , 0, 1)),</p>
<p>(’case 2’ , hp .uniform(’c2’ , -10, 10))</p>
<p>(’case 3’ , hp .choice( ’c3’ , [ ’a’ , ’b’ , ’c’]))</p>
<p>])</p>
</blockquote>
<table>
<tbody>
<tr class="odd">
<td><img src="./automlgithubpagesimages//media/image204.png" width="66" height="12" /></td>
</tr>
</tbody>
</table>
<table>
<tbody>
<tr class="odd">
<td><img src="./automlgithubpagesimages//media/image205.png" width="39" height="12" /></td>
</tr>
</tbody>
</table>
<table>
<tbody>
<tr class="odd">
<td><img src="./automlgithubpagesimages//media/image206.png" width="46" height="13" /></td>
</tr>
</tbody>
</table>
<p><img src="./automlgithubpagesimages//media/image207.png" width="70" height="10" /></p>
<p><img src="./automlgithubpagesimages//media/image208.png" width="60" /></p>
<p><img src="./automlgithubpagesimages//media/image209.png" width="397" height="32" /></p>
<p><span id="_bookmark527" class="anchor"></span><strong>Fig.</strong> <strong>5.1</strong> An example hyperopt-sklearn search space consisting of a preprocessing step followed by a classiﬁer. There are six possible preprocessing modules and six possible classiﬁers. Choosing a model within this conﬁguration space means choosing paths in an ancestral sampling process. The highlighted light blue nodes represent a (PCA, K-Nearest Neighbor) model. The white leaf nodes at the bottom depict example values for their parent hyperparameters. The number of active hyperparameters in a model is the sum of parenthetical numbers in the selected boxes. For the PCA + KNN combination, eight hyperparameters are activated</p>
<blockquote>
<p>Here there are four parameters, one for selecting which case is active, and one for each of the three cases. The ﬁrst case contains a positive valued parameter that is sensitive to log scaling. The second case contains a bounded real valued parameter. The third case contains a categorical parameter with three options.</p>
<p>Having chosen a search domain, an objective function, and an optimization algorithm, Hyperopt’s fminfunction carries out the optimization, and stores results of the search to a database (e.g. either a simple Python list or a MongoDB instance). The fmin call carries out the simple analysis of ﬁnding the best-performing conﬁguration, and returns that to the caller. The fmin call can use multiple workers when using the MongoDB backend, to implement parallel model selection on a compute cluster.</p>
<p>100 B. Komer et al.</p>
<p><strong>5.3</strong> <strong>Scikit-Learn</strong> <strong>Model</strong> <strong>Selection</strong> <strong>as</strong> <strong>a</strong> <strong>Search</strong> <strong>Problem</strong></p>
</blockquote>
<p>Model selection is the process of estimating which machine learning model performs best from among a possibly inﬁnite set of options. As an optimization problem, the search domain is the set of valid assignments to the conﬁguration parameters (hyperparameters) of the machine learning model.The objective function is typically the measure of success (e.g. accuracy, F1-Score, etc) on held-out examples. Often the negative degree of success (loss) is used to set up the task as a minimization problem, and cross-validation is applied to produce a more robust ﬁnal score. Practitioners usually address this optimization by hand, by grid search, or by random search. In this chapter we discuss solving it with the Hyperopt optimization library. The basic approach is to set up a search space with random variable hyperparameters, use scikit-learn to implement the objective function that performs model training and model validation, and use Hyperopt to optimize the hyperparameters.</p>
<p>Scikit-learn includes many algorithms for learning from data (classiﬁcation or regression), as well as many algorithms for preprocessing data into the vectors expected by these learning algorithms. Classiﬁers include for example, K-Nearest- Neighbors, Support Vector Machines, and Random Forest algorithms. Prepro- cessing algorithms include transformations such as component-wise Z-scaling (Normalizer) and Principle Components Analysis (PCA). A full classiﬁcation algorithm typically includes a series of preprocessing steps followed by a classiﬁer. For this reason, scikit-learn provides a pipeline data structure to represent and use a sequence of preprocessing steps and a classiﬁer as if they were just one component (typically with an API similar to the classiﬁer). Although hyperopt-sklearn does not formally use scikit-learn’s pipeline object, it provides related functionality. Hyperopt-sklearn provides a parameterization of a search space over pipelines, that is, of sequences of preprocessing steps and classiﬁers or regressors.</p>
<p>The conﬁguration space provided at the time of this writing currently includes 24 classiﬁers, 12 regressors, and 7 preprocessing methods. Being an open-source project, this space is likely to expand in the future as more users contribute. Upon initial release, only a subset of the search space was available, consisting of six classiﬁers and ﬁve preprocessing algorithms. This space was used for initial performance analysis and is illustrated in Fig.<a href="#_bookmark527">5.1</a>. In total, this parameterization contains 65 hyperparameters: 15 boolean variables, 14 categorical, 17 discrete, and 19 real-valued variables.</p>
<blockquote>
<p>Although the total number of hyperparameters in the full conﬁguration space is large, the number of active hyperparameters describing any one model is much smaller: a model consisting of PCA and a RandomForest for example, would have only 12 active hyperparameters (1 for the choice of preprocessing, 2 internal to PCA, 1 for the choice of classiﬁer and 8 internal to the RF). Hyperopt description language allows us to differentiate between conditional hyperparameters (which must always be assigned) and non-conditional hyperparameters (which may remain unassigned when they would be unused). We make use of this</p>
</blockquote>
<p><img src="./automlgithubpagesimages//media/image210.jpeg" width="442" /></p>
<blockquote>
<p>5 Hyperopt-Sklearn 101</p>
</blockquote>
<p>mechanism extensively so that Hyperopt’s search algorithms do not waste time learning by trial and error that e.g. RF hyperparameters have no effect on SVM performance. Even internally within classiﬁers, there are instances of conditional parameters: KNN has conditional parameters depending on the distance metric, and LinearSVC has 3 binary parameters (loss, penalty, and dual) that admit only 4 valid joint assignments. Hyperopt-sklearn also includes a blacklist of (preprocessing, classiﬁer) pairs that do not work together, e.g. PCA and MinMaxScaler were incompatible with MultinomialNB, TF-IDF could only be used for text data, and the tree-based classiﬁers were not compatible with the sparse features produced by the TF-IDF preprocessor. Allowing for a 10-way discretization of real-valued hyperparameters, and taking these conditional hyperparameters into account, a grid search of our search space would still require an infeasible number of evalutions (on the order of 1012).</p>
<blockquote>
<p>Finally, the search space becomes an optimization problem when we also deﬁne a scalar-valued search objective. By default, Hyperopt-sklearn uses scikit-learn’s score method on validation data to deﬁne the search criterion. For classiﬁers, this is the so-called “Zero-One Loss”: the number of correct label predictions among data that has been withheld from the data set used for training (and also from the data used for testing after the model selection search process).</p>
<p><strong>5.4</strong> <strong>Example</strong> <strong>Usage</strong></p>
<p>Following Scikit-learn’s convention, hyperopt-sklearn provides an Estimator class with a ﬁt method and a predict method. The ﬁt method of this class performs hyperparameter optimization, and after it has completed, the predict method applies the best model to given test data. Each evaluation during optimization performs training on a large fraction of the training set, estimates test set accuracy on a validation set, and returns that validation set score to the optimizer. At the end of search, the best conﬁguration is retrained on the whole data set to produce the classiﬁer that handles subsequent predict calls.</p>
<p>One of the important goals of hyperopt-sklearn is that it is easy to learn and to use. To facilitate this, the syntax for ﬁtting a classiﬁer to data and making predictions is very similar to scikit-learn. Here is the simplest example of using this software.</p>
<p>from hpsklearn import HyperoptEstimator</p>
<p># Load data</p>
<p>train_data, train_label, test_data, test_label =</p>
<p>load_my_data()</p>
<p># Create the estimator object</p>
<p>estim = HyperoptEstimator()</p>
<p>102 B. Komer et al.</p>
<p># Search the space of classifiers and preprocessing steps and</p>
<p>their</p>
<p># respective hyperparameters in scikit-learn to fit a model</p>
<p>to the data</p>
<p>estim.fit (train_data, train_label)</p>
<p># Make a prediction using the optimized model</p>
<p>prediction = estim .predict(test_data)</p>
<p># Report the accuracy of the classifier on a given set of data</p>
<p>score = estim .score(test_data, test_label)</p>
<p># Return instances of the classifier and preprocessing steps</p>
<p>model = estim.best_model ()</p>
</blockquote>
<table>
<tbody>
<tr class="odd">
<td><blockquote>
<p>The HyperoptEstimator object contains the information of what space to search as well as how to search it. It can be conﬁgured to use a variety of hyperparameter search algorithms and also supports using a combination of algorithms. Any algorithm that supports the same interface as the algorithms in hyperopt can be used here. This is also where you, the user, can specify the maximum number of function evaluations you would like to be run as well as a timeout (in seconds) for each run.</p>
</blockquote></td>
</tr>
<tr class="even">
<td><blockquote>
<p>from hpsklearn import HyperoptEstimator</p>
<p>from hyperopt import tpe</p>
<p>estim = HyperoptEstimator(algo=tpe .suggest,</p>
<p>max_evals=150,</p>
<p>trial_timeout=60)</p>
</blockquote></td>
</tr>
<tr class="odd">
<td>Each search algorithm can bring its own bias to the search space, and it may not be clear that one particular strategy is the best in all cases. Sometimes it can be helpful to use a mixture of search algorithms.</td>
</tr>
<tr class="even">
<td><blockquote>
<p>from hpsklearn import HyperoptEstimator</p>
<p>from hyperopt import anneal, rand, tpe, mix</p>
<p># define an algorithm that searches randomly 5% of the time,</p>
<p># uses TPE 75% of the time, and uses annealing 20% of the time</p>
<p>mix_algo = partial(mix .suggest, p_suggest=[</p>
<p>(0 .05, rand .suggest),</p>
<p>(0 .75, tpe .suggest),</p>
<p>(0 .20, anneal .suggest)])</p>
<p>estim = HyperoptEstimator(algo=mix_algo,</p>
<p>max_evals=150,</p>
<p>trial_timeout=60)</p>
</blockquote></td>
</tr>
</tbody>
</table>
<blockquote>
<p>Searching effectively over the entire space of classiﬁers available in scikit-learn can use a lot of time and computational resources. Sometimes you might have a particular subspace of models that they are more interested in. With hyperopt- sklearn it is possible to specify a more narrow search space to allow it to be explored in greater depth.</p>
<p>5 Hyperopt-Sklearn 103</p>
</blockquote>
<table>
<tbody>
<tr class="odd">
<td><blockquote>
<p>from hpsklearn import HyperoptEstimator, svc</p>
<p># limit the search to only SVC models</p>
<p>estim = HyperoptEstimator(classifier=svc( ’my_svc’ ))</p>
</blockquote></td>
</tr>
<tr class="even">
<td><blockquote>
<p>Combinations of different spaces can also be used.</p>
</blockquote></td>
</tr>
<tr class="odd">
<td><blockquote>
<p>from hpsklearn import HyperoptEstimator, svc, knn</p>
<p>from hyperopt import hp</p>
<p># restrict the space to contain only random forest,</p>
<p># k-nearest neighbors, and SVC models .</p>
<p>clf = hp .choice(’my_name’ ,</p>
<p>[random_forest( ’my_name .random_forest’ ),</p>
<p>svc( ’my_name .svc’ ),</p>
<p>knn( ’my_name .knn’ )])</p>
<p>estim = HyperoptEstimator(classifier=clf)</p>
</blockquote></td>
</tr>
<tr class="even">
<td><blockquote>
<p>The support vector machine provided by scikit-learn has a number of different kernels that can be used (linear, rbf, poly, sigmoid). Changing the kernel can have a large effect on the performance of the model, and each kernel has its own unique hyperparameters. To account for this, hyperopt-sklearn treats each kernel choice as a unique model in the search space. If you already know which kernel works best for your data, or you are just interested in exploring models with a particular kernel, you may specify it directly rather than going through the svc.</p>
</blockquote></td>
</tr>
<tr class="odd">
<td><blockquote>
<p>from hpsklearn import HyperoptEstimator, svc_rbf</p>
<p>estim = HyperoptEstimator(classifier=svc_rbf(’my_svc’ ))</p>
</blockquote></td>
</tr>
<tr class="even">
<td><blockquote>
<p>It is also possible to specify which kernels you are interested in by passing a list to the svc.</p>
</blockquote></td>
</tr>
<tr class="odd">
<td><blockquote>
<p>from hpsklearn import HyperoptEstimator, svc</p>
<p>estim = HyperoptEstimator(</p>
<p>classifier=svc(’my_svc’ ,</p>
<p>kernels=[ ’linear’ ,</p>
<p>’sigmoid’]))</p>
</blockquote></td>
</tr>
<tr class="even">
<td><blockquote>
<p>In a similar manner to classiﬁers, the space of preprocessing modules can be ﬁne tuned. Multiple successive stages of preprocessing can be speciﬁed through an ordered list. An empty list means that no preprocessing will be done on the data.</p>
</blockquote></td>
</tr>
<tr class="odd">
<td><blockquote>
<p>from hpsklearn import HyperoptEstimator, pca</p>
<p>estim = HyperoptEstimator(preprocessing=[pca(’my_pca’)])</p>
</blockquote></td>
</tr>
</tbody>
</table>
<blockquote>
<p>104 B. Komer et al.</p>
<p>Combinations of different spaces can be used here as well.</p>
</blockquote>
<table>
<tbody>
<tr class="odd">
<td><blockquote>
<p>from hpsklearn import HyperoptEstimator, tfidf, pca</p>
<p>from hyperopt import hp</p>
<p>preproc = hp .choice( ’my_name’ ,</p>
<p>[[pca(’my_name .pca’)],</p>
<p>[pca( ’my_name .pca’ ), normalizer(’my_name .norm’ )]</p>
<p>[standard_scaler(’my_name .std_scaler’ )],</p>
<p>[]])</p>
<p>estim = HyperoptEstimator(preprocessing=preproc)</p>
</blockquote></td>
</tr>
<tr class="even">
<td><blockquote>
<p>Some types of preprocessing will only work on speciﬁc types of data. For example, the TﬁdfVectorizer that scikit-learn provides is designed to work with text data and would not be appropriate for other types of data. To address this, hyperopt- sklearn comes with a few pre-deﬁned spaces of classiﬁers and preprocessing tailored to speciﬁc data types.</p>
</blockquote></td>
</tr>
<tr class="odd">
<td><blockquote>
<p>from hpsklearn import HyperoptEstimator, \</p>
<p>any_sparse_classifier, \</p>
<p>any_text_preprocessing</p>
<p>from hyperopt import tpe</p>
<p>estim = HyperoptEstimator(</p>
<p>algo=tpe .suggest,</p>
<p>classifier=any_sparse_classifier( ’my_clf’ )</p>
<p>preprocessing=any_text_preprocessing(’my_pp’ )</p>
<p>max_evals=200,</p>
<p>trial_timeout=60)</p>
</blockquote></td>
</tr>
<tr class="even">
<td>So far in all of these examples, every hyperparameter available to the model is being searched over. It is also possible for you to specify the values of speciﬁc hyperparameters, and those parameters will remain constant during the search. This could be useful, for example, if you knew you wanted to use whitened PCA data and a degree-3 polynomial kernel SVM.</td>
</tr>
<tr class="odd">
<td><blockquote>
<p>from hpsklearn import HyperoptEstimator, pca, svc_poly</p>
<p>estim = HyperoptEstimator(</p>
<p>preprocessing=[pca(’my_pca’ , whiten=True)],</p>
<p>classifier=svc_poly(’my_poly’ , degree=3))</p>
</blockquote></td>
</tr>
<tr class="even">
<td><blockquote>
<p>It is also possible to specify ranges of individual parameters. This is done using the standard hyperopt syntax. These will override the defaults deﬁned within hyperopt-sklearn.</p>
</blockquote></td>
</tr>
</tbody>
</table>
<blockquote>
<p>from hpsklearn import HyperoptEstimator, pca, sgd</p>
<p>from hyperopt import hp</p>
<p>import numpy as np</p>
<p>5 Hyperopt-Sklearn 105</p>
<p>sgd_loss = hp .pchoice(’loss’ ,</p>
<p>[(0 .50, ’hinge’ ),</p>
<p>(0 .25, ’log’ ),</p>
<p>(0 .25, ’huber’)])</p>
<p>sgd_penalty = hp .choice( ’penalty’ ,</p>
<p>[’l2’ , ’elasticnet’])</p>
<p>sgd_alpha = hp .loguniform( ’alpha’ ,</p>
<p>low=np .log(1e-5),</p>
<p>high=np .log(1) )</p>
<p>estim = HyperoptEstimator(</p>
<p>classifier=sgd( ’my_sgd’ ,</p>
<p>loss=sgd_loss,</p>
<p>penalty=sgd_penalty,</p>
<p>alpha=sgd_alpha) )</p>
</blockquote>
<table>
<tbody>
<tr class="odd">
<td><blockquote>
<p>All of the components available to the user can be found in the components.py ﬁle. A complete working example of using hyperopt-sklearn to ﬁnd a model for the 20 newsgroups data set is shown below.</p>
</blockquote></td>
</tr>
<tr class="even">
<td><blockquote>
<p>from hpsklearn import HyperoptEstimator, tfidf,</p>
<p>any_sparse_classifier</p>
<p>from sklearn .datasets import fetch_20newsgroups</p>
<p>from hyperopt import tpe</p>
<p>import numpy as np</p>
<p># Download data and split training and test sets</p>
<p>train = fetch_20newsgroups(subset=’train’ )</p>
<p>test = fetch_20newsgroups(subset= ’test’ )</p>
<p>X_train = train.data</p>
<p>y_train = train.target</p>
<p>X_test = test.data</p>
<p>y_test = test.target</p>
<p>estim = HyperoptEstimator(</p>
<p>classifier=any_sparse_classifier( ’clf’ ),</p>
<p>preprocessing=[tfidf( ’tfidf’)],</p>
<p>algo=tpe .suggest,</p>
<p>trial_timeout=180)</p>
<p>estim.fit (X_train, y_train)</p>
<p>print (estim .score(X_test, y_test))</p>
<p>print (estim .best_model())</p>
</blockquote></td>
</tr>
</tbody>
</table>
<blockquote>
<p><strong>5.5</strong> <strong>Experiments</strong></p>
<p>We conducted experiments on three data sets to establish that hyperopt-sklearn can ﬁnd accurate models on a range of data sets in a reasonable amount of time. Results were collected on three data sets: MNIST, 20-Newsgroups, and Convex Shapes. MNIST is a well-known data set of 70 K 28 × 28 greyscale images of hand-drawn digits [<a href="#_bookmark528">12</a>]. 20-Newsgroups is a 20-way classiﬁcation data set of 20 K newsgroup</p>
<p><span id="_bookmark18" class="anchor"></span>106 B. Komer et al.</p>
</blockquote>
<p>messages ([<a href="#_bookmark529">13</a>], we did not remove the headers for our experiments). Convex Shapes is a binary classiﬁcation task of distinguishing pictures of convex white-colored regions in small (32 × 32) black-and-white images [<a href="#_bookmark530">11</a>].</p>
<p>Fig. <a href="#_bookmark531">5.2</a> (left) shows that there was no penalty for searching broadly. We performed optimization runs of up to 300 function evaluations searching the subset of the space depicted in Fig.<a href="#_bookmark527">5.1</a>, and compared the quality of solu- tion with specialized searches of speciﬁc classiﬁer types (including best known classiﬁers).</p>
<p>Fig. <a href="#_bookmark531">5.2</a> (right) shows that search could ﬁnd different, good models. This ﬁgure was constructed by running hyperopt-sklearn with different initial con- ditions (number of evaluations, choice of optimization algorithm, and random number seed) and keeping track of what ﬁnal model was chosen after each run. Although support vector machines were always among the best, the parameters of best SVMs looked very different across data sets. For example, on the image data sets (MNIST and Convex) the SVMs chosen never had a sigmoid or lin- ear kernel, while on 20 newsgroups the linear and sigmoid kernel were often best.</p>
<p>Sometimes researchers not familiar with machine learning techniques may simply use the default parameters of the classiﬁers available to them. To look at the effectiveness of hyperopt-sklearn as a drop-in replacement for this approach, a comparison between the performance of the default scikit-learn parameters and a small search (25 evaluations) of the default hyperopt-sklearn space was conducted. The results on the 20 Newsgroups dataset are shown in Fig.<a href="#_bookmark532">5.3</a>. Improved performance over the baseline is observed in all cases, which sug- gests that this search technique is valuable even with a small computational budget.</p>
<blockquote>
<p><strong>5.6</strong> <strong>Discussion</strong> <strong>and</strong> <strong>Future</strong> <strong>Work</strong></p>
</blockquote>
<p>Table <a href="#_bookmark533">5.1</a> lists the test set scores of the best models found by cross-validation, as well as some points of reference from previous work. Hyperopt-sklearn’s scores are relatively good on each data set, indicating that with hyperopt-sklearn’s parameterization, Hyperopt’s optimization algorithms are competitive with human experts.</p>
<p>The model with the best performance on the MNIST Digits data set uses deep artiﬁcial neural networks. Small receptive ﬁelds of convolutional winner- take-all neurons build up the large network. Each neural column becomes an expert on inputs preprocessed in different ways, and the average prediction of 35 deep neural columns to come up with a single ﬁnal prediction [<a href="#_bookmark534">4</a>]. This model is much more advanced than those available in scikit-learn. The previously best known model in the scikit-learn search space is a radial-basis SVM on centered data that scores 98.6%, and hyperopt-sklearn matches that performance [<a href="#_bookmark535">15</a>].</p>
<blockquote>
<p>5 Hyperopt-Sklearn 107</p>
<p><span id="_bookmark533" class="anchor"></span><strong>Table</strong> <strong>5.1</strong> Hyperopt-sklearn scores relative to selections from literature on the three data sets used in our experiments. On MNIST, hyperopt-sklearn is one of the best-scoring methods that does not use image-speciﬁc domain knowledge (these scores and others may be found at <a href="http://yann.lecun.com/exdb/mnist/">http://yann.lecun.</a> <a href="http://yann.lecun.com/exdb/mnist/">com/exdb/mnist/</a>). On 20 Newsgroups, hyperopt-sklearn is competitive with similar approaches from the literature (scores taken from [<a href="#_bookmark536">7</a>]). In the 20 Newsgroups data set, the score reported for hyperopt-sklearn is the weighted-average F1 score provided by sklearn. The other approaches</p>
<p>shown here use the macro-average F1 score. On Convex Shapes, hyperopt-sklearn outperforms previous automated algorithm conﬁguration approaches [<a href="#_bookmark537">6</a>] and manual tuning [<a href="#_bookmark530">11</a>]</p>
</blockquote>
<table>
<tbody>
<tr class="odd">
<td><blockquote>
<p>MNIST</p>
</blockquote></td>
<td><blockquote>
<p>20 Newsgroups</p>
</blockquote></td>
<td><blockquote>
<p>Convex shapes</p>
</blockquote></td>
</tr>
<tr class="even">
<td><blockquote>
<p>Approach</p>
</blockquote></td>
<td><blockquote>
<p>Accuracy</p>
</blockquote></td>
<td><blockquote>
<p>Approach</p>
</blockquote></td>
</tr>
<tr class="odd">
<td><blockquote>
<p>Committee of convnets</p>
</blockquote></td>
<td><blockquote>
<p>99.8%</p>
</blockquote></td>
<td><blockquote>
<p>CFC</p>
</blockquote></td>
</tr>
<tr class="even">
<td><blockquote>
<p><strong>hyperopt-sklearn</strong></p>
</blockquote></td>
<td><blockquote>
<p><strong>98.7%</strong></p>
</blockquote></td>
<td><blockquote>
<p><strong>hyperopt-sklearn</strong></p>
</blockquote></td>
</tr>
<tr class="odd">
<td><blockquote>
<p>libSVM grid search</p>
</blockquote></td>
<td><blockquote>
<p>98.6%</p>
</blockquote></td>
<td><blockquote>
<p>SVMTorch</p>
</blockquote></td>
</tr>
<tr class="even">
<td><blockquote>
<p>Boosted trees</p>
</blockquote></td>
<td><blockquote>
<p>98.5%</p>
</blockquote></td>
<td><blockquote>
<p>LibSVM</p>
</blockquote></td>
</tr>
</tbody>
</table>
<p><img src="./automlgithubpagesimages//media/image211.jpeg" width="442" height="150" /></p>
<blockquote>
<p><span id="_bookmark531" class="anchor"></span><strong>Fig.</strong> <strong>5.2</strong> Left: Best model performance. For each data set, searching the full conﬁguration space (“Any Classiﬁer”) delivered performance approximately on par with a search that was restricted to the best classiﬁer type. Each bar represents the score obtained from a search restricted to that particular classiﬁer. For the “Any Classiﬁer” case there is no restriction on the search space. In all cases 300 hyperparameter evaluations were performed. Score is F1 for 20 Newsgroups, and accuracy for MNIST and Convex Shapes.</p>
<p>Right: Model selection distribution. Looking at the best models from all optimization runs performed on the full search space (Any Classiﬁer, using different initial conditions, and different optimization algorithms) we see that different data sets are handled best by different classiﬁers. SVC was the only classiﬁer ever chosen as the best model for Convex Shapes, and was often found to be best on MNIST and 20 Newsgroups, however the best SVC parameters were very different across data sets</p>
</blockquote>
<p>The CFC model that performed quite well on the 20 newsgroups document classiﬁcation data set is a Class-Feature-Centroid classiﬁer. Centroid approaches are typically inferior to an SVM, due to the centroids found during training being far from the optimal location. The CFC method reported here uses a centroid built from the inter-class term index and the inner-class term index. It uses a novel combination of these indices along with a denormalized cosine measure to calculate the similarity score between the centroid and a text vector [<a href="#_bookmark536">7</a>]. This style of model is not currently implemented in hyperopt-sklearn, and our experiments</p>
<p><img src="./automlgithubpagesimages//media/image212.png" height="25" /><img src="./automlgithubpagesimages//media/image213.png" /><img src="./automlgithubpagesimages//media/image214.png" width="24" /><img src="./automlgithubpagesimages//media/image215.png" width="13" height="172" /><img src="./automlgithubpagesimages//media/image216.png" width="46" height="139" /><img src="./automlgithubpagesimages//media/image217.png" width="46" height="172" /><img src="./automlgithubpagesimages//media/image218.png" width="46" height="176" /><img src="./automlgithubpagesimages//media/image219.png" width="64" /><img src="./automlgithubpagesimages//media/image220.png" width="48" /><img src="./automlgithubpagesimages//media/image221.png" width="19" /><img src="./automlgithubpagesimages//media/image222.png" /><img src="./automlgithubpagesimages//media/image223.png" width="14" /><img src="./automlgithubpagesimages//media/image224.png" /><img src="./automlgithubpagesimages//media/image225.png" width="22" /><img src="./automlgithubpagesimages//media/image226.png" width="19" /><img src="./automlgithubpagesimages//media/image227.png" width="10" /><img src="./automlgithubpagesimages//media/image228.png" /><img src="./automlgithubpagesimages//media/image229.png" width="10" /></p>
<blockquote>
<p>108 B. Komer et al.</p>
<p>suggest that existing hyperopt-sklearn components cannot be assembled to match its level of performance. Perhaps when it is implemented, Hyperopt may ﬁnd a set of parameters that provides even greater classiﬁcation accuracy.</p>
</blockquote>
<p><img src="./automlgithubpagesimages//media/image230.png" width="194" height="20" /></p>
<p><span id="_bookmark532" class="anchor"></span><strong>Fig.</strong> <strong>5.3</strong> Comparison of F1-Score on the 20 Newsgroups dataset using either the default parameters of scikit-learn or the default search space of hyperopt-sklearn. The results from hyperopt-sklearn were obtained from a single run with 25 evaluations, restricted to either Support Vector Classiﬁer, Stochastic Gradient Descent, K-Nearest Neighbors, or Multinomial Naive Bayes</p>
<blockquote>
<p>On the Convex Shapes data set, our Hyperopt-sklearn experiments revealed a more accurate model than was previously believed to exist in any search space, let alone a search space of such standard components. This result underscores the difﬁculty and importance of hyperparameter search.</p>
<p>Hyperopt-sklearn provides many opportunities for future work: more classiﬁers and preprocessing modules could be included in the search space, and there are more ways to combine even the existing components. Other types of data require different preprocessing, and other prediction problems exist beyond classiﬁcation. In expanding the search space, care must be taken to ensure that the beneﬁts of new models outweigh the greater difﬁculty of searching a larger space. There are some parameters that scikit-learn exposes that are more implementation details than actual hyperparameters that affect the ﬁt (such as algorithm and leaf_sizein the KNN model). Care should be taken to identify these parameters in each model and they may need to be treated differently during exploration.</p>
</blockquote>
<p>It is possible for a user to add their own classiﬁer to the search space as long as it ﬁts the scikit-learn interface. This currently requires some understanding of how hyperopt-sklearn’s code is structured and it would be nice to improve the support for this so minimal effort is required by the user. It is also possible for the user to specify alternate scoring methods besides the default accuracy or F-measure, as there can be cases where these are not best suited to the particular problem.</p>
<p><img src="./automlgithubpagesimages//media/image231.png" width="190" /><img src="./automlgithubpagesimages//media/image232.png" width="18" height="133" /><img src="./automlgithubpagesimages//media/image233.png" width="18" height="133" /><img src="./automlgithubpagesimages//media/image234.png" width="46" /><img src="./automlgithubpagesimages//media/image235.png" width="124" height="16" /><img src="./automlgithubpagesimages//media/image236.png" width="184" height="105" /><img src="./automlgithubpagesimages//media/image237.png" width="184" height="112" /><img src="./automlgithubpagesimages//media/image238.png" /><img src="./automlgithubpagesimages//media/image239.png" /><img src="./automlgithubpagesimages//media/image240.png" /><img src="./automlgithubpagesimages//media/image241.png" /><img src="./automlgithubpagesimages//media/image242.png" /><img src="./automlgithubpagesimages//media/image243.png" /><img src="./automlgithubpagesimages//media/image244.png" /><img src="./automlgithubpagesimages//media/image245.png" /><img src="./automlgithubpagesimages//media/image246.png" /><img src="./automlgithubpagesimages//media/image247.png" /><img src="./automlgithubpagesimages//media/image248.png" width="184" /><img src="./automlgithubpagesimages//media/image249.png" width="23" height="137" /><img src="./automlgithubpagesimages//media/image250.png" width="179" height="134" /><img src="./automlgithubpagesimages//media/image251.png" width="45" /><img src="./automlgithubpagesimages//media/image252.png" /><img src="./automlgithubpagesimages//media/image253.png" /><img src="./automlgithubpagesimages//media/image254.png" /><img src="./automlgithubpagesimages//media/image255.png" /><img src="./automlgithubpagesimages//media/image256.png" /><img src="./automlgithubpagesimages//media/image257.png" /><img src="./automlgithubpagesimages//media/image258.png" /><img src="./automlgithubpagesimages//media/image259.png" width="120" height="15" /><img src="./automlgithubpagesimages//media/image260.png" width="23" height="137" /><img src="./automlgithubpagesimages//media/image261.png" width="179" height="134" /><img src="./automlgithubpagesimages//media/image262.png" width="96" height="18" /><img src="./automlgithubpagesimages//media/image263.png" width="177" height="99" /><img src="./automlgithubpagesimages//media/image264.png" /><img src="./automlgithubpagesimages//media/image265.png" /><img src="./automlgithubpagesimages//media/image266.png" /><img src="./automlgithubpagesimages//media/image267.png" /><img src="./automlgithubpagesimages//media/image268.png" /><img src="./automlgithubpagesimages//media/image269.png" /><img src="./automlgithubpagesimages//media/image270.png" /></p>
<blockquote>
<p>5 Hyperopt-Sklearn 109</p>
</blockquote>
<p><img src="./automlgithubpagesimages//media/image271.png" width="137" height="16" /></p>
<p><img src="./automlgithubpagesimages//media/image272.png" width="190" /></p>
<p><img src="./automlgithubpagesimages//media/image273.png" width="46" /></p>
<p><img src="./automlgithubpagesimages//media/image274.png" width="133" height="15" /></p>
<p><img src="./automlgithubpagesimages//media/image275.png" width="177" height="116" /></p>
<p><img src="./automlgithubpagesimages//media/image276.png" width="184" /></p>
<p><img src="./automlgithubpagesimages//media/image277.png" width="45" /></p>
<p><span id="_bookmark538" class="anchor"></span><strong>Fig.</strong> <strong>5.4</strong> Validation loss of models found for each successive parameter evaluation using the 20 Newsgroups dataset and the Any Classiﬁer search domain. <strong>Upper</strong> <strong>Left</strong>: Mean validation loss at each step across different random number seeds for the TPE algorithm. Downward trend indicates more promising regions are explored more often over time. <strong>Upper</strong> <strong>Right</strong>: Mean validation loss for the random algorithm. Flat trend illustrates no learning from previous trials. Large variation in performance across evaluations indicates the problem is very sensitive to hyperparameter tunings. <strong>Lower</strong> <strong>Left</strong>: Minimum validation loss of models found so far for the TPE algorithm. Gradual progress is made on 20 Newsgroups over 300 iterations and gives no indication of convergence. <strong>Lower</strong> <strong>Right</strong>: Minimum validation loss for the random algorithm. Progress is initially rapid for the ﬁrst 40 or so evaluations and then settles for long periods. Improvement still continues, but becomes less likely as time goes on</p>
<p>We have shown here that Hyperopt’s random search, annealing search, and TPE algorithms make Hyperopt-sklearn viable, but the slow convergence in Fig.<a href="#_bookmark538">5.4</a> suggests that other optimization algorithms might be more call-efﬁcient. The devel- opment of Bayesian optimization algorithms is an active research area, and we look forward to looking at how other search algorithms interact with hyperopt-sklearn’s search spaces. Hyperparameter optimization opens up a new art of matching the parameterization of search spaces to the strengths of search algorithms.</p>
<blockquote>
<p>Computational wall time spent on search is of great practical importance, and hyperopt-sklearn currently spends a signiﬁcant amount of time evaluating points that are un-promising. Techniques for recognizing bad performers early could speed up search enormously [<a href="#_bookmark539">5</a>, <a href="#_bookmark540">18</a>].</p>
<p>110 B. Komer et al.</p>
<p><strong>5.7</strong> <strong>Conclusions</strong></p>
</blockquote>
<p>This chapter has introduced Hyperopt-sklearn, a Python package for automated algorithm conﬁguration of standard machine learning algorithms provided by Scikit-Learn. Hyperopt-sklearn provides a uniﬁed interface to a large subset of the machine learning algorithms available in scikit-learn and with the help of Hyperopt’s optimization functions it is able to both rival and surpass human experts in algorithm conﬁguration. We hope that it provides practitioners with a useful tool for the development of machine learning systems, and automated machine learning researchers with benchmarks for future work in algorithm conﬁguration.</p>
<p><strong>Acknowledgements</strong> This research was supported by the NSERC Banting Fellowship program, the NSERC Engage Program and by D-Wave Systems. Thanks also to Hristijan Bogoevski for early drafts of a hyperopt-to-scikit-learn bridge.</p>
<blockquote>
<p><strong>Bibliography</strong></p>
<p>1. J. Bergstra, R. Bardenet, Y. Bengio, and B. Kegl. Algorithms for hyper-parameter optimization, NIPS, 24:2546–2554, 2011.</p>
<p>2. J. Bergstra, D. Yamins, and D. D. Cox. Making a science of model search: Hyperparameter <span id="_bookmark525" class="anchor"></span>optimization in hundreds of dimensions for vision architectures, In Proc. ICML, 2013a.</p>
<p>3. J. Bergstra, D. Yamins, and D. D. Cox. Hyperopt: A Python library for optimizing the <span id="_bookmark534" class="anchor"></span>hyperparameters of machine learning algorithms, SciPy’13, 2013b.</p>
<p>4. D. Ciresan, U. Meier, and J. Schmidhuber. Multi-column Deep Neural Networks for Image Classiﬁcation, IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 3642–</p>
<p><span id="_bookmark539" class="anchor"></span>3649. 2012.</p>
<p>5. T. Domhan, T. Springenberg, F. Hutter. Extrapolating Learning Curves of Deep Neural <span id="_bookmark537" class="anchor"></span>Networks, ICML AutoML Workshop, 2014.</p>
<p>6. K. Eggensperger, M. Feurer, F. Hutter, J. Bergstra, J. Snoek, H. Hoos, and K. Leyton-Brown. Towards an empirical foundation for assessing bayesian optimization of hyperparameters, <span id="_bookmark536" class="anchor"></span>NIPS workshop on Bayesian Optimization in Theory and Practice, 2013.</p>
<p>7. H. Guan, J. Zhou, and M. Guo. A class-feature-centroid classiﬁer for text categorization, Proceedings of the 18th international conference on World wide web, 201–210. ACM, 2009.</p>
<p><span id="_bookmark523" class="anchor"></span>8. M. Hall, E. Frank, G. Holmes, B. Pfahringer, P. Reutemann, and I. H. Witten. The weka data mining software: an update, ACM SIGKDD explorations newsletter, 11(1):10– 18, 2009.</p>
<p>9. F. Hutter, H. Hoos, and K. Leyton-Brown. Sequential model-based optimization for general</p>
<p>algorithm conﬁguration, LION-5, 2011. Extended version as UBC Tech report TR-2010- 10.</p>
<p><span id="_bookmark526" class="anchor"></span>10. B. Komer, J. Bergstra, and C. Eliasmith. Hyperopt-sklearn: automatic hyperparameter conﬁg- <span id="_bookmark530" class="anchor"></span>uration for scikit-learn, ICML AutoML Workshop, 2014.</p>
<p>11. H. Larochelle, D. Erhan, A. Courville, J. Bergstra, and Y. Bengio. An empirical evaluation of deep architectures on problems with many factors of variation, ICML, 473–480, 2007.</p>
<p><span id="_bookmark528" class="anchor"></span>12. Y. LeCun, L. Bottou, Y. Bengio, and P. Haffner. Gradient-based learning applied to document recognition, Proceedings of the IEEE, 86(11):2278–2324, November 1998.</p>
<p><span id="_bookmark529" class="anchor"></span>13. T. Mitchell. 20 newsgroups data set, <a href="http://qwone.com/jason/20Newsgroups/" class="uri">http://qwone.com/jason/20Newsgroups/</a>, 1996.</p>
<p>14. J. Mockus, V. Tiesis, and A. Zilinskas. The application of Bayesian methods for seeking the extremum, L.C.W. Dixon and G.P. Szego, editors, Towards Global Optimization, volume 2, <span id="_bookmark535" class="anchor"></span>pages 117– 129. North Holland, New York, 1978.</p>
<p>15. The MNIST Database of handwritten digits: <a href="http://yann.lecun.com/exdb/mnist/" class="uri">http://yann.lecun.com/exdb/mnist/</a></p>
<p>5 Hyperopt-Sklearn 111</p>
<p><span id="_bookmark524" class="anchor"></span>16. F. Pedregosa, G. Varoquaux, A. Gramfort, V. Michel, B. Thirion, O. Grisel, M. Blondel, P. Prettenhofer, R. Weiss, V. Dubourg, J. Vanderplas, A. Passos, D. Cournapeau, M. Brucher,</p>
<p>M. Perrot, and E. Duchesnay. Scikit-learn: Machine Learning in Python, Journal of Machine Learning Research, 12:2825–2830, 2011.</p>
<p>17. J. Snoek, H. Larochelle, and R. P. Adams. Practical Bayesian optimization of machine learning algorithms, Neural Information Processing Systems, 2012.</p>
<p>18. K. Swersky, J. Snoek, R.P. Adams. Freeze-Thaw Bayesian Optimization, arXiv:1406.3896, <span id="_bookmark540" class="anchor"><span id="_bookmark522" class="anchor"></span></span>2014.</p>
<p>19. C. Thornton, F. Hutter, H. H. Hoos, and K. Leyton-Brown. AutoWEKA: Automated selection and hyper-parameter optimization of classiﬁcation algorithms, KDD 847–855, 2013.</p>
<p><strong>Open</strong> <strong>Access</strong> This chapter is licensed under the terms of the Creative Commons Attribution 4.0 International License <a href="http://creativecommons.org/licenses/by/4.0/">(http://creativecommons.org/licenses/by/4.0/</a>), which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence and indicate if changes were made.</p>
<p>The images or other third party material in this chapter are included in the chapter’s Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the chapter’s Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder.</p>
</blockquote>
<p><img src="./automlgithubpagesimages//media/image278.png" width="75" height="26" /></p>
<p><img src="./automlgithubpagesimages//media/image279.png" width="41" height="41" /><img src="./automlgithubpagesimages//media/image9.jpeg" width="136" /></p>
<blockquote>
<p><span id="_bookmark8" class="anchor"></span><strong>Chapter</strong> <strong>6</strong></p>
<p><strong>Auto-sklearn:</strong> <strong>Efﬁcient</strong> <strong>and</strong> <strong>Robust</strong></p>
<p><strong>Automated</strong> <strong>Machine</strong> <strong>Learning</strong></p>
</blockquote>
<p><img src="./automlgithubpagesimages//media/image280.png" /></p>
<blockquote>
<p><strong>Matthias</strong> <strong>Feurer,</strong> <strong>Aaron</strong> <strong>Klein,</strong> <strong>Katharina</strong> <strong>Eggensperger,</strong></p>
<p><strong>Jost</strong> <strong>Tobias</strong> <strong>Springenberg,</strong> <strong>Manuel</strong> <strong>Blum,</strong> <strong>and</strong> <strong>Frank</strong> <strong>Hutter</strong></p>
</blockquote>
<p><strong>Abstract</strong> The success of machine learning in a broad range of applications has led to an ever-growing demand for machine learning systems that can be used off the shelf by non-experts. To be effective in practice, such systems need to automatically choose a good algorithm and feature preprocessing steps for a new dataset at hand, and also set their respective hyperparameters. Recent work has started to tackle this <em>automated</em> <em>machine</em> <em>learning</em> <em>(AutoML)</em> problem with the help of efﬁcient Bayesian optimization methods. Building on this, we introduce a robust new AutoML system based on the Python machine learning package scikit-learn (using 15 classiﬁers, 14 feature preprocessing methods, and 4 data preprocessing methods, giving rise to a structured hypothesis space with 110 hyperparameters). This system, which we dub <em>Auto-sklearn</em>, improves on existing AutoML methods by automatically taking into account past performance on similar datasets, and by constructing ensembles from the models evaluated during the optimization. Our system won six out of ten phases of the ﬁrst ChaLearn AutoML challenge, and our comprehensive analysis on over 100 diverse datasets shows that it substantially outperforms the previous state of the art in AutoML. We also demonstrate the performance gains due to each of our contributions and derive insights into the effectiveness of the individual components of Auto-sklearn.</p>
<blockquote>
<p><strong>6.1</strong> <strong>Introduction</strong></p>
<p>Machine learning has recently made great strides in many application areas, fueling a growing demand for machine learning systems that can be used effectively by novices in machine learning. Correspondingly, a growing number of commercial</p>
<p>M. Feurer (凶) · A. Klein · K. Eggensperger · J. T. Springenberg · M. Blum</p>
<p>Department of Computer Science, University of Freiburg, Freiburg, Baden-Württemberg, Germany</p>
<p>e-mail: <a href="mailto:feurerm@informatik.uni-freiburg.de">feurerm@informatik.uni-freiburg.de</a></p>
<p>F. Hutter</p>
<p>Department of Computer Science, University of Freiburg, Freiburg, Germany</p>
<p>© The Author(s) 2019</p>
<p>F. Hutter et al. (eds.), <em>Automated</em> <em>Machine</em> <em>Learning</em>, The Springer Series on Challenges in Machine Learning, <a href="https://doi.org/10.1007/978-3-030-05318-5_6" class="uri">https://doi.org/10.1007/978-3-030-05318-5_6</a></p>
<p>114 M. Feurer et al.</p>
<p>enterprises aim to satisfy this demand (e.g., BigML.com, Wise.io, H2O.ai, feedzai.com, RapidMiner.com, Prediction.io, DataRobot.com, Microsoft’s Azure Machine Learning, Google’s Cloud Machine Learning Engine, and Amazon Machine Learning). At its core, every effective machine learning service needs to solve the fundamental problems of deciding which machine learning algorithm to use on a given dataset, whether and how to preprocess its features, and how to set all hyperparameters. This is the problem we address in this work.</p>
</blockquote>
<p>More speciﬁcally, we investigate automated machine learning (AutoML), the problem of automatically (without human input) producing test set predictions for a new dataset within a ﬁxed computational budget. Formally, this AutoML problem can be stated as follows:</p>
<p><strong>Deﬁnition</strong> <strong>1</strong> <strong>(AutoML</strong> <strong>problem)</strong> For i = 1, . . . , n + m, let <strong>x</strong>i denote a feature vector and yi the corresponding target value. Given a training dataset Dtrain = {(<strong>x</strong>1 ,y1), . . . , (<strong>x</strong>n,yn)} and the feature vectors <strong>x</strong>n+1 , . . . , <strong>x</strong>n+m of a test dataset Dtest = {(<strong>x</strong>n+1,yn+1), . . . , (<strong>x</strong>n+m,yn+m)} drawn from the same underlying data distribution, as well as a resource budget b and a loss metric L(·, ·), the AutoML problem is to (automatically) produce accurate test set predictions <img src="./automlgithubpagesimages//media/image281.png" height="12" />n+1 , . . . , <img src="./automlgithubpagesimages//media/image282.png" height="12" />n+m . The loss of a solution <img src="./automlgithubpagesimages//media/image283.png" height="12" />n+1 , . . . , <img src="./automlgithubpagesimages//media/image284.png" height="12" />n+m to the AutoML problem is given by 1<img src="./automlgithubpagesimages//media/image285.jpeg" />m 对<img src="./automlgithubpagesimages//media/image286.png" width="10" height="18" />1 L(<img src="./automlgithubpagesimages//media/image287.png" height="12" />n+j,yn+j).</p>
<blockquote>
<p>In practice, the budget b would comprise computational resources, such as CPU and/or wallclock time and memory usage. This problem deﬁnition reﬂects the setting of the ﬁrst ChaLearn AutoML challenge [<a href="#_bookmark541">23</a>] (also, see Chap.<a href="#_bookmark13">10</a> for a description and analysis of the ﬁrst AutoML challenge). The AutoML system we describe here won six out of ten phases of that challenge.</p>
</blockquote>
<p>Here, we follow and extend the AutoML approach ﬁrst introduced by Auto- WEKA [<a href="#_bookmark542">42</a>]. At its core, this approach combines a highly parametric machine learning framework F with a Bayesian optimization [<a href="#_bookmark543">7</a>,<a href="#_bookmark544">40</a>] method for instantiating F well for a given dataset.</p>
<p>The contribution of this paper is to extend this AutoML approach in various ways that considerably improve its <em>efﬁciency</em> and <em>robustness</em>, based on principles that apply to a wide range of machine learning frameworks (such as those used by the machine learning service providers mentioned above). First, following successful previous work for low dimensional optimization problems [<a href="#_bookmark545">21</a>, <a href="#_bookmark546">22</a>, <a href="#_bookmark547">38</a>], we reason across datasets to identify instantiations of machine learning frameworks that perform well on a new dataset and warmstart Bayesian optimization with them (Sect.<a href="#_bookmark548">6.3.1</a>). Second, we automatically construct ensembles of the models considered by Bayesian optimization (Sect.<a href="#_bookmark549">6.3.2</a>). Third, we carefully design a highly parameterized machine learning framework from high-performing classiﬁers and preprocessors implemented in the popular machine learning framework scikit- learn [<a href="#_bookmark550">36</a>] (Sect.<a href="#_bookmark551">6.4</a>). Finally, we perform an extensive empirical analysis using a diverse collection of datasets to demonstrate that the resulting Auto-sklearn system outperforms previous state-of-the-art AutoML methods (Sect.<a href="#_bookmark552">6.5</a>), to show that each of our contributions leads to substantial performance improvements</p>
<blockquote>
<p>6 Auto-sklearn: Efﬁcient and Robust Automated Machine Learning 115</p>
<p>(Sect.<a href="#_bookmark553">6.6</a>), and to gain insights into the performance of the individual classiﬁers and preprocessors used in Auto-sklearn (Sect.<a href="#_bookmark554">6.7</a>).</p>
</blockquote>
<p>This chapter is an extended version of our 2015 paper introducing Auto-sklearn, published in the <em>proceedings</em> <em>of</em> <em>NeurIPS</em> <em>2015</em> [<a href="#_bookmark555">20</a>].</p>
<blockquote>
<p><strong>6.2</strong> <strong>AutoML</strong> <strong>as</strong> <strong>a</strong> <strong>CASH</strong> <strong>Problem</strong></p>
</blockquote>
<p>We ﬁrst review the formalization of AutoML as a <em>Combined</em> <em>Algorithm</em> <em>Selec-</em> <em>tion</em> <em>and</em> <em>Hyperparameter</em> <em>optimization</em> <em>(CASH)</em> problem used by Auto-WEKA’s AutoML approach. Two important problems in AutoML are that (1) no single machine learning method performs best on all datasets and (2) some machine learn- ing methods (e.g., non-linear SVMs) crucially rely on hyperparameter optimization. The latter problem has been successfully attacked using Bayesian optimization [<a href="#_bookmark543">7</a>, <a href="#_bookmark544">40</a>], which nowadays forms a core component of many AutoML systems. The former problem is intertwined with the latter since the rankings of algorithms depend on whether their hyperparameters are tuned properly. Fortunately, the two problems can efﬁciently be tackled as a single, structured, joint optimization problem:</p>
<p><strong>Deﬁnition</strong> <strong>2</strong> <strong>(CASH)</strong> Let A = {A(1) , . . . , A(R)} be a set of algorithms, and let the hyperparameters of each algorithm A(j) have domain <strong>A</strong>(j) . Further, let Dtrain = {(x1 ,y1), . . . , (xn,yn)} be a training set which is split into K cross-validation folds {D<img src="./automlgithubpagesimages//media/image288.png" width="46" height="20" /> , D<img src="./automlgithubpagesimages//media/image289.png" width="17" height="20" />d} and {D<img src="./automlgithubpagesimages//media/image290.png" width="46" height="20" /> , D<img src="./automlgithubpagesimages//media/image291.png" width="17" height="20" />n} such that D<img src="./automlgithubpagesimages//media/image292.png" width="23" height="20" /> = Dtrain/D<img src="./automlgithubpagesimages//media/image293.png" width="23" height="20" /> for i = 1, . . . , K . Finally, let L(A<img src="./automlgithubpagesimages//media/image294.png" width="13" height="20" />,D<img src="./automlgithubpagesimages//media/image295.png" width="13" height="19" />in,D<img src="./automlgithubpagesimages//media/image296.png" height="19" />lid) denote the loss that algorithm A(j) achieves on D<img src="./automlgithubpagesimages//media/image297.png" width="23" height="20" /> when trained on D<img src="./automlgithubpagesimages//media/image298.png" width="23" height="20" /> with hyperparameters <strong>λ</strong> . Then, the <em>Combined</em> <em>Algorithm</em> <em>Selection</em> <em>and</em> <em>Hyperparameter</em> <em>optimization</em> <em>(CASH)</em> problem is to ﬁnd the joint algorithm and hyperparameter setting that minimizes this loss:</p>
<blockquote>
<p>K</p>
<p>A* , <strong>λ</strong>* ∈ argmin 1<img src="./automlgithubpagesimages//media/image299.jpeg" />K 对 L(A<img src="./automlgithubpagesimages//media/image300.png" width="10" height="19" />,D<img src="./automlgithubpagesimages//media/image301.png" width="10" height="19" />in,D<img src="./automlgithubpagesimages//media/image302.png" height="19" />lid).</p>
<p>(6. 1)</p>
</blockquote>
<p>This CASH problem was ﬁrst tackled by Thornton et al. [<a href="#_bookmark542">42</a>] in the Auto- WEKA system using the machine learning framework WEKA [<a href="#_bookmark556">25</a>] and tree-based Bayesian optimization methods [<a href="#_bookmark557">5</a>,<a href="#_bookmark558">27</a>]. In a nutshell, Bayesian optimization [<a href="#_bookmark543">7</a>] ﬁts a probabilistic model to capture the relationship between hyperparameter settings and their measured performance; it then uses this model to select the most promising hyperparameter setting (trading off exploration of new parts of the space vs. exploitation in known good regions), evaluates that hyperparameter setting, updates the model with the result, and iterates. While Bayesian optimization based on Gaussian process models (e.g., Snoek et al. [<a href="#_bookmark559">41</a>]) performs best in low-dimensional problems with numerical hyperparameters, tree-based models have been shown to be more successful in high-dimensional, structured, and partly discrete prob-</p>
<blockquote>
<p>116 M. Feurer et al.</p>
<p>lems [<a href="#_bookmark560">15</a>]— such as the CASH problem—and are also used in the AutoML system HYPEROPT-SKLEARN [<a href="#_bookmark561">30</a>]. Among the tree-based Bayesian optimization methods, Thornton et al. [<a href="#_bookmark542">42</a>] found the random-forest-based SMAC [<a href="#_bookmark558">27</a>] to outperform the tree Parzen estimator TPE [<a href="#_bookmark557">5</a>], and we therefore use SMAC to solve the CASH problem in this paper. Next to its use of random forests [<a href="#_bookmark562">6</a>], SMAC’s main distinguishing feature is that it allows fast cross-validation by evaluating one fold at a time and discarding poorly-performing hyperparameter settings early.</p>
<p><strong>6.3</strong> <strong>New</strong> <strong>Methods</strong> <strong>for</strong> <strong>Increasing</strong> <strong>Efﬁciency</strong> <strong>and</strong> <strong>Robustness</strong></p>
<p><strong>of</strong> <strong>AutoML</strong></p>
<p>We now discuss our two improvements of the AutoML approach. First, we include a meta-learning step to warmstart the Bayesian optimization procedure, which results in a considerable boost in efﬁciency. Second, we include an automated ensemble construction step, allowing us to use all classiﬁers that were found by Bayesian optimization.</p>
<p>Fig. <a href="#_bookmark563">6.1</a> summarizes the overall AutoML workﬂow, including both of our improvements. We note that we expect their effectiveness to be greater for ﬂexible ML frameworks that offer many degrees of freedom (e.g., many algorithms, hyperparameters, and preprocessing methods).</p>
<p><span id="_bookmark548" class="anchor"></span><em><strong>6.3.1</strong></em> <em><strong>Meta-learningfor</strong></em> <em><strong>Finding</strong></em> <em><strong>Good</strong></em> <em><strong>Instantiations</strong></em></p>
<p><em><strong>of</strong></em> <em><strong>Machine</strong></em> <em><strong>Learning</strong></em> <em><strong>Frameworks</strong></em></p>
</blockquote>
<p>Domain experts derive knowledge from previous tasks: They <em>learn</em> <em>about</em> <em>the</em> <em>per-</em> <em>formance</em> <em>of</em> <em>machine</em> <em>learning</em> <em>algorithms</em>. The area of meta-learning (see Chap.<a href="#_bookmark3">2</a>) mimics this strategy by reasoning about the performance of learning algorithms across datasets. In this work, we apply meta-learning to select instantiations of our given machine learning framework that are likely to perform well on a new dataset. More speciﬁcally, for a large number of datasets, we collect both performance data</p>
<p><img src="./automlgithubpagesimages//media/image304.png" /></p>
<blockquote>
<p><span id="_bookmark563" class="anchor"></span><strong>Fig.</strong> <strong>6.1</strong> Our improved AutoML approach. We add two components to Bayesian hyperparameter optimization of an ML framework: meta-learning for initializing the Bayesian optimizer and automated ensemble construction from conﬁgurations evaluated during optimization</p>
<p>6 Auto-sklearn: Efﬁcient and Robust Automated Machine Learning 117</p>
<p>and a set of <em>meta-features</em>, i.e., characteristics of the dataset that can be computed efﬁciently and that help to determine which algorithm to use on a new dataset.</p>
</blockquote>
<p>This meta-learning approach is complementary to Bayesian optimization for optimizing an ML framework. Meta-learning can quickly suggest some instan- tiations of the ML framework that are likely to perform quite well, but it is unable to provide ﬁne-grained information on performance. In contrast, Bayesian optimization is slow to start for hyperparameter spaces as large as those of entire ML frameworks, but can ﬁne-tune performance over time. We exploit this complementarity by selecting k conﬁgurations based on meta-learning and use their result to seed Bayesian optimization. This approach of warmstarting optimization by meta-learning has already been successfully applied before [<a href="#_bookmark545">21</a>, <a href="#_bookmark546">22</a>, <a href="#_bookmark547">38</a>], but never to an optimization problem as complex as that of searching the space of instantiations of a full-ﬂedged ML framework. Likewise, learning across datasets has also been applied in collaborative Bayesian optimization methods [<a href="#_bookmark564">4</a>, <a href="#_bookmark565">45</a>]; while these approaches are promising, they are so far limited to very few meta-features and cannot yet cope with the high-dimensional partially discrete conﬁguration spaces</p>
<blockquote>
<p>faced in AutoML.</p>
</blockquote>
<p>More precisely, our meta-learning approach works as follows. In an ofﬂine phase, for each machine learning dataset in a dataset repository (in our case 140 datasets from the OpenML [<a href="#_bookmark566">43</a>] repository), we evaluated a set of meta-features (described below) and used Bayesian optimization to determine and store an instantiation of the given ML framework with strong empirical performance for that dataset. (In detail, we ran SMAC [<a href="#_bookmark558">27</a>] for 24 h with 10-fold cross-validation on two thirds of the data and stored the resulting ML framework instantiation which exhibited best performance on the remaining third). Then, given a new dataset D, we compute its meta-features, rank all datasets by their L1 distance to D in meta-feature space and select the stored ML framework instantiations for the k = 25 nearest datasets for evaluation before starting Bayesian optimization with their results.</p>
<blockquote>
<p>To characterize datasets, we implemented a total of 38 meta-features from the literature, including simple, information-theoretic and statistical meta-features [<a href="#_bookmark567">29</a>, <a href="#_bookmark568">33</a>], such as statistics about the number of data points, features, and classes, as well as data skewness, and the entropy of the targets. All meta-features are listed in Table 1 of the original publication’s supplementary material [<a href="#_bookmark555">20</a>]. Notably, we had to exclude the prominent and effective category of landmarking meta-features [<a href="#_bookmark569">37</a>] (which measure the performance of simple base learners), because they were computationally too expensive to be helpful in the online evaluation phase. We note that this meta-learning approach draws its power from the availability of a repository of datasets; due to recent initiatives, such as OpenML [<a href="#_bookmark566">43</a>], we expect the number of available datasets to grow ever larger over time, increasing the importance of meta-learning.</p>
</blockquote>
<p><img src="./automlgithubpagesimages//media/image12.jpeg" width="136" /></p>
<blockquote>
<p>118 M. Feurer et al.</p>
<p><span id="_bookmark549" class="anchor"></span><em><strong>6.3.2</strong></em> <em><strong>Automated</strong></em> <em><strong>Ensemble</strong></em> <em><strong>Construction</strong></em> <em><strong>of</strong></em> <em><strong>Models</strong></em> <em><strong>Evaluated</strong></em></p>
<p><em><strong>During</strong></em> <em><strong>Optimization</strong></em></p>
<p>While Bayesian hyperparameter optimization is data-efﬁcient in ﬁnding the best- performing hyperparameter setting, we note that it is a very wasteful procedure when the goal is simply to make good predictions: all the models it trains during the course of the search are lost, usually including some that perform almost as well as the best. Rather than discarding these models, we propose to store them and to use an efﬁcient post-processing method (which can be run in a second process on-the-ﬂy) to construct an ensemble out of them. This automatic ensemble construction avoids to commit itself to a single hyperparameter setting and is thus more robust (and less prone to overﬁtting) than using the point estimate that standard hyperparameter optimization yields. To our best knowledge, we are the ﬁrst to make this simple observation, which can be applied to improve any Bayesian hyperparameter optimization method.<a href="#_bookmark570">1</a></p>
<p>It is well known that ensembles often outperform individual models [<a href="#_bookmark571">24</a>, <a href="#_bookmark572">31</a>], and that effective ensembles can be created from a library of models [<a href="#_bookmark573">9</a>, <a href="#_bookmark574">10</a>]. Ensembles perform particularly well if the models they are based on (1) are individually strong and (2) make uncorrelated errors [<a href="#_bookmark562">6</a>]. Since this is much more likely when the individual models are different in nature, ensemble building is particularly well suited for combining strong instantiations of a ﬂexible ML framework.</p>
</blockquote>
<p>However, simply building a uniformly weighted ensemble of the models found by Bayesian optimization does <em>not</em> work well. Rather, we found it crucial to adjust these weights using the predictions of all individual models on a hold-out set. We experimented with different approaches to optimize these weights: <em>stacking</em> [<a href="#_bookmark575">44</a>], gradient-free numerical optimization, and the method <em>ensemble</em> <em>selection</em> [<a href="#_bookmark574">10</a>]. While we found both numerical optimization and stacking to overﬁt to the validation set and to be computationally costly, ensemble selection was fast and robust. In a nutshell, ensemble selection (introduced by Caruana et al. [<a href="#_bookmark574">10</a>]) is a greedy procedure that starts from an empty ensemble and then iteratively adds the model that minimizes ensemble validation loss (with uniform weight, but allowing for repetitions). We used this technique in all our experiments—building an ensemble of size 50 using selection with replacement [<a href="#_bookmark574">10</a>]. We calculated the ensemble loss using the same validation set that we use for Bayesian optimization.</p>
<blockquote>
<p><span id="_bookmark570" class="anchor"></span>1 Since the original publication [<a href="#_bookmark555">20</a>] we have learned that Escalante et al. [<a href="#_bookmark576">16</a>] and Bürger and Pauli [<a href="#_bookmark577">8</a>] applied ensembles as a post-processing step of an AutoML system to improve generalization as well. However, both works combined the learned models with a pre-deﬁned strategy and did not adapt the ensemble construction based on the performance of the individual models.</p>
</blockquote>
<p><img src="./automlgithubpagesimages//media/image309.png" width="166" height="14" /><img src="./automlgithubpagesimages//media/image310.png" width="56" /><img src="./automlgithubpagesimages//media/image313.png" width="105" height="23" /><img src="./automlgithubpagesimages//media/image314.png" width="17" /><img src="./automlgithubpagesimages//media/image315.png" width="194" height="64" /><img src="./automlgithubpagesimages//media/image316.png" width="67" height="19" /><img src="./automlgithubpagesimages//media/image317.png" width="76" height="23" /><img src="./automlgithubpagesimages//media/image318.png" width="25" /><img src="./automlgithubpagesimages//media/image319.png" width="45" /><img src="./automlgithubpagesimages//media/image320.png" width="16" /><img src="./automlgithubpagesimages//media/image321.png" width="24" /><img src="./automlgithubpagesimages//media/image322.png" width="32" height="19" /><img src="./automlgithubpagesimages//media/image323.png" width="58" height="21" /><img src="./automlgithubpagesimages//media/image324.png" width="56" height="21" /><img src="./automlgithubpagesimages//media/image325.png" width="23" height="21" /><img src="./automlgithubpagesimages//media/image326.png" width="47" height="21" /><img src="./automlgithubpagesimages//media/image327.png" width="60" height="21" /><img src="./automlgithubpagesimages//media/image328.png" width="36" height="21" /></p>
<blockquote>
<p>6 Auto-sklearn: Efﬁcient and Robust Automated Machine Learning 119</p>
<p><span id="_bookmark551" class="anchor"></span><strong>6.4</strong> <strong>A</strong> <strong>Practical</strong> <strong>Automated</strong> <strong>Machine</strong> <strong>Learning</strong> <strong>System</strong></p>
<p>To design a robust AutoML system, as our underlying ML framework we chose scikit-learn [<a href="#_bookmark550">36</a>], one of the best known and most widely used machine learning libraries. It offers a wide range of well established and efﬁciently-implemented ML algorithms and is easy to use for both experts and beginners. Since our AutoML system closely resembles Auto-WEKA, but—like HYPEROPT-SKLEARN—is based on scikit-learn, we dub it Auto-sklearn.</p>
</blockquote>
<p>Fig. <a href="#_bookmark578">6.2</a> is an illustration Auto-sklearn’s machine learning pipeline and its com- ponents. It comprises 15 classiﬁcation algorithms, 14 preprocessing methods, and 4 data preprocessing methods. We parameterized each of them, which resulted in a space of 110 hyperparameters. Most of these are conditional hyperparameters that are only active if their respective component is selected. We note that SMAC [<a href="#_bookmark558">27</a>] can handle this conditionality natively.</p>
<p>All 15 classiﬁcation algorithms in Auto-sklearn are listed in Table <a href="#_bookmark579">6.1</a>. They fall into different categories, such as general linear models (2 algorithms), support vector machines (2), discriminant analysis (2), nearest neighbors (1), naïve Bayes (3), decision trees (1) and ensembles (4). In contrast to Auto-WEKA [<a href="#_bookmark542">42</a>] (also, see Chap.<a href="#_bookmark6">4</a>for a description of Auto-WEKA), we focused our conﬁguration space on base classiﬁers and excluded meta-models and ensembles that are themselves parameterized by one or more base classiﬁers. While such ensembles increased Auto-WEKA’s number of hyperparameters by almost a factor of ﬁve (to 786), Auto-sklearn “only” features 110 hyperparameters. We instead construct complex ensembles using our post-hoc method from Sect.<a href="#_bookmark549">6.3.2</a>. Compared to Auto-WEKA, this is much more data-efﬁcient: in Auto-WEKA, evaluating the performance of an ensemble with ﬁve components requires the construction and evaluation of ﬁve</p>
<p><img src="./automlgithubpagesimages//media/image329.png" width="35" height="16" /></p>
<p><img src="./automlgithubpagesimages//media/image330.png" width="163" height="37" /></p>
<table>
<tbody>
<tr class="odd">
<td><img src="./automlgithubpagesimages//media/image331.png" width="23" height="10" /></td>
</tr>
</tbody>
</table>
<table>
<tbody>
<tr class="odd">
<td><img src="./automlgithubpagesimages//media/image332.jpeg" width="96" height="25" /></td>
</tr>
</tbody>
</table>
<p><img src="./automlgithubpagesimages//media/image333.png" width="70" height="21" /></p>
<p><strong>Fig.</strong> <strong>6.2</strong> Structured conﬁguration space. Squared boxes denote parent hyperparameters whereas <span id="_bookmark578" class="anchor"></span>boxes with rounded edges are leaf hyperparameters. Grey colored boxes mark active hyperparame- ters which form an example conﬁguration and machine learning pipeline. Each pipeline comprises one <em>feature</em> <em>preprocessor</em>, <em>classiﬁer</em> and up to three <em>data</em> <em>preprocessor</em> methods plus respective hyperparameters</p>
<blockquote>
<p>120 M. Feurer et al.</p>
</blockquote>
<p><span id="_bookmark579" class="anchor"></span><strong>Table</strong> <strong>6.1</strong> Number of hyperparameters for each classiﬁer (top) and feature preprocessing method (bottom) for a <strong>binary</strong> <strong>classiﬁcation</strong> dataset in <strong>dense</strong> representation. Tables for sparse binary classiﬁcation and sparse/dense multiclass classiﬁcation datasets can be found in Section E of the original publication’s supplementary material [<a href="#_bookmark555">20</a>], Tables 2a, 3a, 4a, 2b, 3b and 4b. We distinguish between categorical (cat) hyperparameters with discrete values and continuous (cont) numerical hyperparameters. Numbers in brackets are conditional hyperparameters, which are only relevant when another hyperparameter has a certain value</p>
<table>
<tbody>
<tr class="odd">
<td><blockquote>
<p>Type of Classiﬁer</p>
</blockquote></td>
<td><blockquote>
<p>#λ</p>
</blockquote></td>
<td><blockquote>
<p>cat (cond)</p>
</blockquote></td>
<td><blockquote>
<p>cont (cond)</p>
</blockquote></td>
</tr>
<tr class="even">
<td><blockquote>
<p>AdaBoost (AB)</p>
</blockquote></td>
<td><blockquote>
<p>4</p>
</blockquote></td>
<td><blockquote>
<p>1 (–)</p>
</blockquote></td>
<td><blockquote>
<p>3 (–)</p>
</blockquote></td>
</tr>
<tr class="odd">
<td><blockquote>
<p>Bernoulli naïve Bayes</p>
</blockquote></td>
<td><blockquote>
<p>2</p>
</blockquote></td>
<td><blockquote>
<p>1 (–)</p>
</blockquote></td>
<td><blockquote>
<p>1 (–)</p>
</blockquote></td>
</tr>
<tr class="even">
<td><blockquote>
<p>Decision tree (DT)</p>
</blockquote></td>
<td><blockquote>
<p>4</p>
</blockquote></td>
<td><blockquote>
<p>1 (–)</p>
</blockquote></td>
<td><blockquote>
<p>3 (–)</p>
</blockquote></td>
</tr>
<tr class="odd">
<td><blockquote>
<p>Extremely randomized trees</p>
</blockquote></td>
<td><blockquote>
<p>5</p>
</blockquote></td>
<td><blockquote>
<p>2 (–)</p>
</blockquote></td>
<td><blockquote>
<p>3 (–)</p>
</blockquote></td>
</tr>
<tr class="even">
<td><blockquote>
<p>Gaussian naïve Bayes</p>
</blockquote></td>
<td><blockquote>
<p>–</p>
</blockquote></td>
<td><blockquote>
<p>–</p>
</blockquote></td>
<td><blockquote>
<p>–</p>
</blockquote></td>
</tr>
<tr class="odd">
<td><blockquote>
<p>Gradient boosting (GB)</p>
</blockquote></td>
<td><blockquote>
<p>6</p>
</blockquote></td>
<td><blockquote>
<p>–</p>
</blockquote></td>
<td><blockquote>
<p>6 (–)</p>
</blockquote></td>
</tr>
<tr class="even">
<td><blockquote>
<p>k-nearest neighbors (kNN)</p>
</blockquote></td>
<td><blockquote>
<p>3</p>
</blockquote></td>
<td><blockquote>
<p>2 (–)</p>
</blockquote></td>
<td><blockquote>
<p>1 (–)</p>
</blockquote></td>
</tr>
<tr class="odd">
<td><blockquote>
<p>Linear discriminant analysis (LDA)</p>
</blockquote></td>
<td><blockquote>
<p>4</p>
</blockquote></td>
<td><blockquote>
<p>1 (–)</p>
</blockquote></td>
<td><blockquote>
<p>3 (1)</p>
</blockquote></td>
</tr>
<tr class="even">
<td><blockquote>
<p>Linear SVM</p>
</blockquote></td>
<td><blockquote>
<p>4</p>
</blockquote></td>
<td><blockquote>
<p>2 (–)</p>
</blockquote></td>
<td><blockquote>
<p>2 (–)</p>
</blockquote></td>
</tr>
<tr class="odd">
<td><blockquote>
<p>Kernel SVM</p>
</blockquote></td>
<td><blockquote>
<p>7</p>
</blockquote></td>
<td><blockquote>
<p>2 (-)</p>
</blockquote></td>
<td><blockquote>
<p>5 (2)</p>
</blockquote></td>
</tr>
<tr class="even">
<td><blockquote>
<p>Multinomial naïve Bayes</p>
</blockquote></td>
<td><blockquote>
<p>2</p>
</blockquote></td>
<td><blockquote>
<p>1 (–)</p>
</blockquote></td>
<td><blockquote>
<p>1 (–)</p>
</blockquote></td>
</tr>
<tr class="odd">
<td><blockquote>
<p>Passive aggressive</p>
</blockquote></td>
<td><blockquote>
<p>3</p>
</blockquote></td>
<td><blockquote>
<p>1 (–)</p>
</blockquote></td>
<td><blockquote>
<p>2 (–)</p>
</blockquote></td>
</tr>
<tr class="even">
<td><blockquote>
<p>Quadratic discriminant analysis (QDA)</p>
</blockquote></td>
<td><blockquote>
<p>2</p>
</blockquote></td>
<td><blockquote>
<p>–</p>
</blockquote></td>
<td><blockquote>
<p>2 (–)</p>
</blockquote></td>
</tr>
<tr class="odd">
<td><blockquote>
<p>Random forest (RF)</p>
</blockquote></td>
<td><blockquote>
<p>5</p>
</blockquote></td>
<td><blockquote>
<p>2 (–)</p>
</blockquote></td>
<td><blockquote>
<p>3 (–)</p>
</blockquote></td>
</tr>
<tr class="even">
<td><blockquote>
<p>Linear Classiﬁer (SGD)</p>
</blockquote></td>
<td><blockquote>
<p>10</p>
</blockquote></td>
<td><blockquote>
<p>4 (–)</p>
</blockquote></td>
<td><blockquote>
<p>6 (3)</p>
</blockquote></td>
</tr>
</tbody>
</table>
<table>
<tbody>
<tr class="odd">
<td><blockquote>
<p>Preprocessing method</p>
</blockquote></td>
<td><blockquote>
<p>#λ</p>
</blockquote></td>
<td><blockquote>
<p>cat (cond)</p>
</blockquote></td>
<td><blockquote>
<p>cont (cond)</p>
</blockquote></td>
</tr>
<tr class="even">
<td><blockquote>
<p>Extremely randomized trees preprocessing</p>
</blockquote></td>
<td><blockquote>
<p>5</p>
</blockquote></td>
<td><blockquote>
<p>2 (–)</p>
</blockquote></td>
<td><blockquote>
<p>3 (–)</p>
</blockquote></td>
</tr>
<tr class="odd">
<td><blockquote>
<p>Fast ICA</p>
</blockquote></td>
<td><blockquote>
<p>4</p>
</blockquote></td>
<td><blockquote>
<p>3 (–)</p>
</blockquote></td>
<td><blockquote>
<p>1 (1)</p>
</blockquote></td>
</tr>
<tr class="even">
<td><blockquote>
<p>Feature agglomeration</p>
</blockquote></td>
<td><blockquote>
<p>4</p>
</blockquote></td>
<td><blockquote>
<p>3 ()</p>
</blockquote></td>
<td><blockquote>
<p>1 (–)</p>
</blockquote></td>
</tr>
<tr class="odd">
<td><blockquote>
<p>Kernel PCA</p>
</blockquote></td>
<td><blockquote>
<p>5</p>
</blockquote></td>
<td><blockquote>
<p>1 (–)</p>
</blockquote></td>
<td><blockquote>
<p>4 (3)</p>
</blockquote></td>
</tr>
<tr class="even">
<td><blockquote>
<p>Rand. kitchen sinks</p>
</blockquote></td>
<td><blockquote>
<p>2</p>
</blockquote></td>
<td><blockquote>
<p>–</p>
</blockquote></td>
<td><blockquote>
<p>2 (–)</p>
</blockquote></td>
</tr>
<tr class="odd">
<td><blockquote>
<p>Linear SVM preprocessing</p>
</blockquote></td>
<td><blockquote>
<p>3</p>
</blockquote></td>
<td><blockquote>
<p>1 (–)</p>
</blockquote></td>
<td><blockquote>
<p>2 (–)</p>
</blockquote></td>
</tr>
<tr class="even">
<td><blockquote>
<p>No preprocessing</p>
</blockquote></td>
<td><blockquote>
<p>–</p>
</blockquote></td>
<td><blockquote>
<p>–</p>
</blockquote></td>
<td><blockquote>
<p>–</p>
</blockquote></td>
</tr>
<tr class="odd">
<td><blockquote>
<p>Nystroem sampler</p>
</blockquote></td>
<td><blockquote>
<p>5</p>
</blockquote></td>
<td><blockquote>
<p>1 (–)</p>
</blockquote></td>
<td><blockquote>
<p>4 (3)</p>
</blockquote></td>
</tr>
<tr class="even">
<td><blockquote>
<p>Principal component analysis (PCA)</p>
</blockquote></td>
<td><blockquote>
<p>2</p>
</blockquote></td>
<td><blockquote>
<p>1 (–)</p>
</blockquote></td>
<td><blockquote>
<p>1 (–)</p>
</blockquote></td>
</tr>
<tr class="odd">
<td><blockquote>
<p>Polynomial</p>
</blockquote></td>
<td><blockquote>
<p>3</p>
</blockquote></td>
<td><blockquote>
<p>2 (–)</p>
</blockquote></td>
<td><blockquote>
<p>1 (–)</p>
</blockquote></td>
</tr>
<tr class="even">
<td><blockquote>
<p>Random trees embed.</p>
</blockquote></td>
<td><blockquote>
<p>4</p>
</blockquote></td>
<td><blockquote>
<p>–</p>
</blockquote></td>
<td><blockquote>
<p>4 (–)</p>
</blockquote></td>
</tr>
<tr class="odd">
<td><blockquote>
<p>Select percentile</p>
</blockquote></td>
<td><blockquote>
<p>2</p>
</blockquote></td>
<td><blockquote>
<p>1 (–)</p>
</blockquote></td>
<td><blockquote>
<p>1 (–)</p>
</blockquote></td>
</tr>
<tr class="even">
<td><blockquote>
<p>Select rates</p>
</blockquote></td>
<td><blockquote>
<p>3</p>
</blockquote></td>
<td><blockquote>
<p>2 (–)</p>
</blockquote></td>
<td><blockquote>
<p>1 (–)</p>
</blockquote></td>
</tr>
<tr class="odd">
<td><blockquote>
<p>One-hot encoding</p>
</blockquote></td>
<td><blockquote>
<p>2</p>
</blockquote></td>
<td><blockquote>
<p>1 (–)</p>
</blockquote></td>
<td><blockquote>
<p>1 (1)</p>
</blockquote></td>
</tr>
<tr class="even">
<td><blockquote>
<p>Imputation</p>
</blockquote></td>
<td><blockquote>
<p>1</p>
</blockquote></td>
<td><blockquote>
<p>1 (–)</p>
</blockquote></td>
<td><blockquote>
<p>–</p>
</blockquote></td>
</tr>
<tr class="odd">
<td><blockquote>
<p>Balancing</p>
</blockquote></td>
<td><blockquote>
<p>1</p>
</blockquote></td>
<td><blockquote>
<p>1 (–)</p>
</blockquote></td>
<td><blockquote>
<p>–</p>
</blockquote></td>
</tr>
<tr class="even">
<td><blockquote>
<p>Rescaling</p>
</blockquote></td>
<td><blockquote>
<p>1</p>
</blockquote></td>
<td><blockquote>
<p>1 (–)</p>
</blockquote></td>
<td><blockquote>
<p>–</p>
</blockquote></td>
</tr>
</tbody>
</table>
<blockquote>
<p>6 Auto-sklearn: Efﬁcient and Robust Automated Machine Learning 121</p>
<p>models; in contrast, in Auto-sklearn, ensembles come largely for free, and it is pos- sible to mix and match models evaluated at arbitrary times during the optimization.</p>
<p>The preprocessing methods for datasets in dense representation in Auto-sklearn are listed in Table <a href="#_bookmark579">6.1</a>. They comprise data preprocessors (which change the feature values and are always used when they apply) and feature preprocessors (which change the actual set of features, and only one of which [or none] is used). Data preprocessing includes rescaling of the inputs, imputation of missing values, one-hot encoding and balancing of the target classes. The 14 possible feature preprocessing methods can be categorized into feature selection (2), kernel approximation (2), matrix decomposition (3), embeddings (1), feature clustering (1), polynomial feature expansion (1) and methods that use a classiﬁer for feature selection (2). For example, L1 -regularized linear SVMs ﬁtted to the data can be used for feature selection by eliminating features corresponding to zero-valued model coefﬁcients.</p>
<p>For detailed descriptions of the machine learning algorithms used in Auto- sklearn we refer to Sect. A. 1 and A.2 of the original paper’s supplementary material [<a href="#_bookmark555">20</a>], the scikit-learn documentation [<a href="#_bookmark550">36</a>] and the references therein.</p>
</blockquote>
<p>To make the most of our computational power and not get stuck in a very slow run of a certain combination of preprocessing and machine learning algorithm, we implemented several measures to prevent such long runs. First, we limited the time for each evaluation of an instantiation of the ML framework. We also limited the memory of such evaluations to prevent the operating system from swapping or freezing. When an evaluation went over one of those limits, we automatically terminated it and returned the worst possible score for the given evaluation metric. For some of the models we employed an iterative training procedure; we instrumented these to still return their current performance value when a limit was reached before they were terminated. To further reduce the amount of overly long runs, we forbade several combinations of preprocessors and classiﬁcation methods: in particular, kernel approximation was forbidden to be active in conjunction with non-linear and tree-based methods as well as the KNN algorithm. (SMAC handles such forbidden combinations natively.) For the same reason we also left out feature learning algorithms, such as dictionary learning.</p>
<p>Another issue in hyperparameter optimization is overﬁtting and data resampling since the training data of the AutoML system must be divided into a dataset for training the ML pipeline (training set) and a dataset used to calculate the loss function for Bayesian optimization (validation set). Here we had to trade off between running a more robust cross-validation (which comes at little additional overhead in SMAC) and evaluating models on all cross-validation folds to allow for ensemble construction with these models. Thus, for the tasks with a rigid time limit of 1 h in Sect.<a href="#_bookmark553">6.6</a>, we employed a simple train/test split. In contrast, we were able to employ ten-fold crossvalidation in our 24 and 30 h runs in Sects.<a href="#_bookmark552">6.5</a>and <a href="#_bookmark554">6.7</a>.</p>
<blockquote>
<p>Finally, not every supervised learning task (for example classiﬁcation with multiple targets), can be solved by all of the algorithms available in Auto-sklearn. Thus, given a new dataset, Auto-sklearn preselects the methods that are suitable for the dataset’s properties. Since scikit-learn methods are restricted to numerical input values, we always transformed data by applying a one-hot encoding to categorical features. In order to keep the number of dummy features low, we conﬁgured a</p>
<p>122 M. Feurer et al.</p>
</blockquote>
<p>percentage threshold and a value occurring more rarely than this percentage was transformed to a special <em>other</em> value [<a href="#_bookmark580">35</a>].</p>
<blockquote>
<p><span id="_bookmark552" class="anchor"></span><strong>6.5</strong> <strong>Comparing</strong> <strong>Auto-sklearn</strong> <strong>to</strong> <strong>Auto-WEKA</strong></p>
<p><strong>and</strong> <strong>HYPEROPT-SKLEARN</strong></p>
</blockquote>
<p>As a baseline experiment, we compared the performance of vanilla Auto-sklearn (without our improvements meta-learning and ensemble building) to Auto-WEKA (see Chap. <a href="#_bookmark6">4</a>) and Hyperopt-Sklearn (see Chap. <a href="#_bookmark7">5</a>), reproducing the experimental setup with the 21 datasets of the paper introducing Auto-WEKA [<a href="#_bookmark542">42</a>] (see Table <a href="#_bookmark518">4.1</a> in Chap.<a href="#_bookmark6">4</a>for a description of the datasets). Following the original setup of the Auto- WEKA paper, we used the same train/test splits of the datasets [<a href="#_bookmark581">1</a>], a walltime limit of 30 h, 10-fold cross validation (where the evaluation of each fold was allowed to take 150 min), and 10 independent optimization runs with SMAC on each dataset. As in Auto-WEKA, the evaluation is sped up by SMAC’s intensify procedure, which only schedules runs on new cross validation folds if the conﬁguration currently being evaluated is likely to outperform the so far best performing conﬁguration [<a href="#_bookmark558">27</a>]. We did not modify HYPEROPT-SKLEARN which always uses a 80/20 train/test split. All our experiments ran on Intel Xeon E5-2650 v2 eight-core processors with 2.60 GHz and 4 GiB of RAM. We allowed the machine learning framework to use 3 GiB and reserved the rest for SMAC. All experiments used Auto-WEKA 0.5 and scikit-learn 0. 16. 1.</p>
<p>We present the results of this experiment in Table <a href="#_bookmark582">6.2</a>. Since our setup followed exactly that of the original Auto-WEKA paper, as a sanity check we compared the numbers we achieved for Auto-WEKA ourselves (ﬁrst line in Fig.<a href="#_bookmark582">6.2</a>) to the ones presented by the authors of Auto-WEKA (see Chap.<a href="#_bookmark6">4</a>) and found that overall the results were reasonable. Furthermore, the table shows that Auto-sklearn performed signiﬁcantly better than Auto-WEKA in 6/21 cases, tied it in 12 cases, and lost against it in 3. For the three datasets where Auto-WEKA performed best, we found that in more than 50% of its runs the best classiﬁer it chose is not implemented in scikit-learn (trees with a pruning component). So far, HYPEROPT-SKLEARN is more of a proof-of-concept—inviting the user to adapt the conﬁguration space to her own needs—than a full AutoML system. The current version crashes when presented with sparse data and missing values. It also crashes on Cifar- 10 due to a memory limit which we set for all optimizers to enable a fair comparison. On the 16 datasets on which it ran, it statistically tied the best competing AutoML system in 9 cases and lost against it in 7.</p>
<blockquote>
<p><span id="_bookmark553" class="anchor"></span><strong>6.6</strong> <strong>Evaluation</strong> <strong>of</strong> <strong>the</strong> <strong>Proposed</strong> <strong>AutoML</strong> <strong>Improvements</strong></p>
<p>In order to evaluate the robustness and general applicability of our proposed AutoML system on a broad range of datasets, we gathered 140 binary and multiclass classiﬁcation datasets from the OpenML repository [<a href="#_bookmark566">43</a>], only selecting</p>
<p>6 Auto-sklearn: Efﬁcient and Robust Automated Machine Learning 123</p>
<p><span id="_bookmark582" class="anchor"></span><strong>Table</strong> <strong>6.2</strong> Test set classiﬁcation error of Auto-WEKA (AW), vanilla Auto-sklearn (AS) and HYPEROPT-SKLEARN (HS), as in the original evaluation of Auto-WEKA [<a href="#_bookmark542">42</a>] (see also Sect.<a href="#_bookmark501">4.5</a>). We show median percent test error rate across 100,000 bootstrap samples (based on 10 runs), each sample simulating 4 parallel runs and always picking the best one according to cross-validation performance. Bold numbers indicate the best result. Underlined results are not statistically signiﬁcantly different from the best according to a bootstrap test with p = 0.05</p>
</blockquote>
<table>
<tbody>
<tr class="odd">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td><blockquote>
<p>Cifar-10</p>
</blockquote></td>
<td></td>
<td></td>
<td><blockquote>
<p>Dorothea</p>
</blockquote></td>
<td><blockquote>
<p>German</p>
</blockquote></td>
<td></td>
<td><blockquote>
<p>KDD09</p>
<p>appetency</p>
</blockquote></td>
</tr>
<tr class="even">
<td><blockquote>
<p>AS</p>
</blockquote></td>
<td><blockquote>
<p><strong>73.50</strong></p>
</blockquote></td>
<td><blockquote>
<p><strong>16.00</strong></p>
</blockquote></td>
<td><blockquote>
<p>0.39</p>
</blockquote></td>
<td><blockquote>
<p><strong>51.70</strong></p>
</blockquote></td>
<td><blockquote>
<p><strong>54.81</strong></p>
</blockquote></td>
<td><blockquote>
<p><strong>17.53</strong></p>
</blockquote></td>
<td><blockquote>
<p><strong>5.56</strong></p>
</blockquote></td>
<td><blockquote>
<p><strong>5.51</strong></p>
</blockquote></td>
<td><blockquote>
<p><strong>27.00</strong></p>
</blockquote></td>
<td><blockquote>
<p><strong>1.62</strong></p>
</blockquote></td>
<td><blockquote>
<p><strong>1.74</strong></p>
</blockquote></td>
</tr>
<tr class="odd">
<td><blockquote>
<p>AW</p>
</blockquote></td>
<td><blockquote>
<p><strong>73.50</strong></p>
</blockquote></td>
<td><blockquote>
<p>30.00</p>
</blockquote></td>
<td><blockquote>
<p><strong>0.00</strong></p>
</blockquote></td>
<td><blockquote>
<p>56.95</p>
</blockquote></td>
<td><blockquote>
<p>56.20</p>
</blockquote></td>
<td><blockquote>
<p>21.80</p>
</blockquote></td>
<td><blockquote>
<p>8.33</p>
</blockquote></td>
<td><blockquote>
<p>6.38</p>
</blockquote></td>
<td><blockquote>
<p>28.33</p>
</blockquote></td>
<td><blockquote>
<p>2.29</p>
</blockquote></td>
<td><blockquote>
<p><strong>1.74</strong></p>
</blockquote></td>
</tr>
<tr class="even">
<td><blockquote>
<p>HS</p>
</blockquote></td>
<td><blockquote>
<p>76.21</p>
</blockquote></td>
<td><blockquote>
<p>16.22</p>
</blockquote></td>
<td><blockquote>
<p>0.39</p>
</blockquote></td>
<td><blockquote>
<p>–</p>
</blockquote></td>
<td><blockquote>
<p>57.95</p>
</blockquote></td>
<td><blockquote>
<p>19.18</p>
</blockquote></td>
<td><blockquote>
<p>–</p>
</blockquote></td>
<td><blockquote>
<p>–</p>
</blockquote></td>
<td><blockquote>
<p>27.67</p>
</blockquote></td>
<td><blockquote>
<p>2.29</p>
</blockquote></td>
<td><blockquote>
<p>–</p>
</blockquote></td>
</tr>
<tr class="odd">
<td></td>
<td><blockquote>
<p>KR-vs-KP</p>
</blockquote></td>
<td></td>
<td><blockquote>
<p>MNIST</p>
</blockquote></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td><blockquote>
<p>Waveform</p>
</blockquote></td>
<td><blockquote>
<p>Wine</p>
</blockquote></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td><blockquote>
<p>AS</p>
</blockquote></td>
<td><blockquote>
<p>0.42</p>
</blockquote></td>
<td><blockquote>
<p><strong>12.44</strong></p>
</blockquote></td>
<td><blockquote>
<p>2.84</p>
</blockquote></td>
<td><blockquote>
<p><strong>46.92</strong></p>
</blockquote></td>
<td><blockquote>
<p><strong>7.87</strong></p>
</blockquote></td>
<td><blockquote>
<p><strong>5.24</strong></p>
</blockquote></td>
<td><blockquote>
<p><strong>0.01</strong></p>
</blockquote></td>
<td><blockquote>
<p>14.93</p>
</blockquote></td>
<td><blockquote>
<p>33.76</p>
</blockquote></td>
<td><blockquote>
<p>40.67</p>
</blockquote></td>
<td></td>
</tr>
<tr class="odd">
<td><blockquote>
<p>AW</p>
</blockquote></td>
<td><blockquote>
<p><strong>0.31</strong></p>
</blockquote></td>
<td><blockquote>
<p>18.21</p>
</blockquote></td>
<td><blockquote>
<p>2.84</p>
</blockquote></td>
<td><blockquote>
<p>60.34</p>
</blockquote></td>
<td><blockquote>
<p>8.09</p>
</blockquote></td>
<td><blockquote>
<p>5.24</p>
</blockquote></td>
<td><blockquote>
<p><strong>0.01</strong></p>
</blockquote></td>
<td><blockquote>
<p>14.13</p>
</blockquote></td>
<td><blockquote>
<p><strong>33.36</strong></p>
</blockquote></td>
<td><blockquote>
<p><strong>37.75</strong></p>
</blockquote></td>
<td></td>
</tr>
<tr class="even">
<td><blockquote>
<p>HS</p>
</blockquote></td>
<td><blockquote>
<p>0.42</p>
</blockquote></td>
<td><blockquote>
<p>14.74</p>
</blockquote></td>
<td><blockquote>
<p><strong>2.82</strong></p>
</blockquote></td>
<td><blockquote>
<p>55.79</p>
</blockquote></td>
<td><blockquote>
<p>–</p>
</blockquote></td>
<td><blockquote>
<p>5.87</p>
</blockquote></td>
<td><blockquote>
<p>0.05</p>
</blockquote></td>
<td><blockquote>
<p><strong>14.07</strong></p>
</blockquote></td>
<td><blockquote>
<p>34.72</p>
</blockquote></td>
<td><blockquote>
<p>38.45</p>
</blockquote></td>
<td></td>
</tr>
</tbody>
</table>
<p>datasets with at least 1000 data points to allow robust performance evaluations. These datasets cover a diverse range of applications, such as text classiﬁcation, digit and letter recognition, gene sequence and RNA classiﬁcation, advertisement, particle classiﬁcation for telescope data, and cancer detection in tissue samples. We list all datasets in Table 7 and 8 in the supplementary material of the original publication [<a href="#_bookmark555">20</a>] and provide their unique OpenML identiﬁers for reproducibility. We randomly split each dataset into a two-thirds training and a one-thirds test set. Auto-sklearn could only access the training set, and split this further into two thirds for training and a one third holdout set for computing the validation loss for SMAC. All in all, we used four-ninths of the data to train the machine learning models, two-ninths to calculate their validation loss and the ﬁnal three-ninths to report the test performance of the different AutoML systems we compared. Since the class distribution in many of these datasets is quite imbalanced we evaluated all AutoML methods using a measure called <em>balanced</em> <em>classiﬁcation</em> <em>error</em> <em>rate</em> (BER). We deﬁne balanced error rate as the average of the proportion of wrong classiﬁcations in each class. In comparison to standard classiﬁcation error (the average overall error), this measure (the average of the <em>class-wise</em> error) assigns equal weight to all classes. We note that balanced error or accuracy measures are often used in machine learning competitions, such as the AutoML challenge [<a href="#_bookmark541">23</a>], which is described in Chap.<a href="#_bookmark13">10</a>.</p>
<blockquote>
<p>We performed 10 runs of Auto-sklearn both with and without meta-learning and with and without ensemble building on each of the datasets. To study their</p>
</blockquote>
<p><img src="./automlgithubpagesimages//media/image334.png" height="169" /><img src="./automlgithubpagesimages//media/image335.png" height="169" /><img src="./automlgithubpagesimages//media/image336.png" height="169" /><img src="./automlgithubpagesimages//media/image337.png" /><img src="./automlgithubpagesimages//media/image338.png" /><img src="./automlgithubpagesimages//media/image339.png" height="169" /><img src="./automlgithubpagesimages//media/image340.png" width="405" /><img src="./automlgithubpagesimages//media/image341.png" width="405" /><img src="./automlgithubpagesimages//media/image342.png" /><img src="./automlgithubpagesimages//media/image343.png" /><img src="./automlgithubpagesimages//media/image344.png" width="402" /><img src="./automlgithubpagesimages//media/image345.png" /><img src="./automlgithubpagesimages//media/image346.png" /><img src="./automlgithubpagesimages//media/image347.png" width="112" /><img src="./automlgithubpagesimages//media/image348.png" width="405" height="170" /><img src="./automlgithubpagesimages//media/image349.png" width="112" height="28" /><img src="./automlgithubpagesimages//media/image350.png" width="181" height="15" /><img src="./automlgithubpagesimages//media/image351.png" width="182" height="16" /><img src="./automlgithubpagesimages//media/image352.png" width="11" /><img src="./automlgithubpagesimages//media/image353.png" width="11" height="12" /><img src="./automlgithubpagesimages//media/image354.png" width="407" height="170" /><img src="./automlgithubpagesimages//media/image355.png" width="182" height="46" /></p>
<blockquote>
<p>124 M. Feurer et al.</p>
</blockquote>
<p><img src="./automlgithubpagesimages//media/image356.png" width="406" height="94" /></p>
<blockquote>
<p>2.2</p>
<p>2.0</p>
<p>1.8</p>
</blockquote>
<p>500 1000 1500 2000 2500 3000 3500</p>
<blockquote>
<p>ime [sec]</p>
</blockquote>
<table>
<tbody>
<tr class="odd">
<td><p>3.0</p>
<blockquote>
<p>2.8</p>
<p>2.6</p>
</blockquote>
<p>2.4</p>
<blockquote>
<p>2.2</p>
<p>2.0</p>
<p>1.8</p>
</blockquote></td>
<td><p><img src="./automlgithubpagesimages//media/image357.png" /></p>
<blockquote>
<p>1</p>
<p>10</p>
<p>ime [sec]</p>
</blockquote></td>
</tr>
</tbody>
</table>
<blockquote>
<p><span id="_bookmark583" class="anchor"></span><strong>Fig.</strong> <strong>6.3</strong> Average rank of all four Auto-sklearn variants (ranked by balanced test error rate (BER)) across 140 datasets. Note that ranks are a relative measure of performance (here, the rank of all methods has to add up to 10), and hence an improvement in BER of one method can worsen the rank of another. (Top) Data plotted on a linear x scale. (Bottom) This is the same data as for the upper plot, but on a log x scale. Due to the small additional overhead that meta-learning and ensemble selection cause, vanilla Auto-sklearn is able to achieve the best rank within the ﬁrst 10 s as it produces predictions before the other Auto-sklearn variants ﬁnish training their ﬁrst model. After this, meta-learning quickly takes off</p>
<p>performance under rigid time constraints, and also due to computational resource constraints, we limited the CPU time for each run to 1 h; we also limited the runtime</p>
<p>for evaluating a single model to a tenth of this (6 min).</p>
<p>To not evaluate performance on data sets already used for meta-learning, we performed a leave-one-dataset-out validation: when evaluating on dataset D, we only used meta-information from the 139 other datasets.</p>
<p>Fig. <a href="#_bookmark583">6.3</a> shows the average ranks over time of the four Auto-sklearn versions we tested. We observe that both of our new methods yielded substantial improvements over vanilla Auto-sklearn. The most striking result is that meta-learning yielded</p>
<p>6 Auto-sklearn: Efﬁcient and Robust Automated Machine Learning 125</p>
<p>drastic improvements starting with the ﬁrst conﬁguration it selected and lasting until the end of the experiment. We note that the improvement was most pronounced in the beginning and that over time, vanilla Auto-sklearn also found good solutions without meta-learning, letting it catch up on some datasets (thus improving its overall rank).</p>
<p>Moreover, both of our methods complement each other: our automated ensemble construction improved both vanilla Auto-sklearn and Auto-sklearn with meta- learning. Interestingly, the ensemble’s inﬂuence on the performance started earlier for the meta-learning version. We believe that this is because meta-learning produces better machine learning models earlier, which can be directly combined into a strong ensemble; but when run longer, vanilla Auto-sklearn without meta- learning also beneﬁts from automated ensemble construction.</p>
<p><span id="_bookmark554" class="anchor"></span><strong>6.7</strong> <strong>Detailed</strong> <strong>Analysis</strong> <strong>of</strong> <strong>Auto-sklearn</strong> <strong>Components</strong></p>
<p>We now study Auto-sklearn’s individual classiﬁers and preprocessors, compared to jointly optimizing all methods, in order to obtain insights into their peak performance and robustness. Ideally, we would have liked to study all combinations of a single classiﬁer and a single preprocessor in isolation, but with 15 classiﬁers and 14 preprocessors this was infeasible; rather, when studying the performance of a single classiﬁer, we still optimized over all preprocessors, and vice versa. To obtain a more detailed analysis, we focused on a subset of datasets but extended the conﬁguration budget for optimizing all methods from one hour to one day and to two days for Auto-sklearn. Speciﬁcally, we clustered our 140 datasets with g-means [<a href="#_bookmark584">26</a>] based on the dataset meta-features and used one dataset from each of the resulting 13 clusters. We give a basic description of the datasets in Table <a href="#_bookmark585">6.3</a>. In total, these</p>
<p>extensive experiments required 10.7 CPU years.</p>
</blockquote>
<p>Table <a href="#_bookmark586">6.4</a> compares the results of the various classiﬁcation methods against Auto-sklearn. Overall, as expected, random forests, extremely randomized trees, AdaBoost, and gradient boosting, showed the most robust performance, and SVMs showed strong peak performance for some datasets. Besides a variety of strong classiﬁers, there are also several models which could not compete: The decision tree, passive aggressive, kNN, Gaussian NB, LDA and QDA were statistically signiﬁcantly inferior to the best classiﬁer on most datasets. Finally, the table indicates that no single method was the best choice for all datasets. As shown in the table and also visualized for two example datasets in Fig.<a href="#_bookmark587">6.4</a>, optimizing the joint conﬁguration space of Auto-sklearn led to the most robust performance. A plot of ranks over time (Fig. 2 and 3 in the supplementary material of the original publication [<a href="#_bookmark555">20</a>]) quantiﬁes this across all 13 datasets, showing that Auto-sklearn starts with reasonable but not optimal performance and effectively searches its more general conﬁguration space to converge to the best overall performance over time.</p>
<blockquote>
<p>Table <a href="#_bookmark588">6.5</a>compares the results of the various preprocessors against Auto-sklearn. As for the comparison of classiﬁers above, Auto-sklearn showed the most robust</p>
<p>126 M. Feurer et al.</p>
<p><span id="_bookmark585" class="anchor"></span><strong>Table</strong> <strong>6.3</strong> Representative datasets for the 13 clusters obtained via g-means clustering of the 140 datasets’ meta-feature vectors</p>
</blockquote>
<table>
<tbody>
<tr class="odd">
<td><blockquote>
<p>ID</p>
</blockquote></td>
<td><blockquote>
<p>Name</p>
</blockquote></td>
<td><blockquote>
<p>#Cont</p>
</blockquote></td>
<td><blockquote>
<p>#Nom</p>
</blockquote></td>
<td><blockquote>
<p>#Class</p>
</blockquote></td>
<td><blockquote>
<p>Sparse</p>
</blockquote></td>
<td><blockquote>
<p>Missing Values</p>
</blockquote></td>
<td><blockquote>
<p>|Training|</p>
</blockquote></td>
<td><blockquote>
<p>|Test|</p>
</blockquote></td>
</tr>
<tr class="even">
<td><blockquote>
<p><a href="http://www.openml.org/d/38">38</a></p>
</blockquote></td>
<td><blockquote>
<p>Sick</p>
</blockquote></td>
<td><blockquote>
<p>7</p>
</blockquote></td>
<td><blockquote>
<p>22</p>
</blockquote></td>
<td><blockquote>
<p>2</p>
</blockquote></td>
<td><blockquote>
<p>–</p>
</blockquote></td>
<td><blockquote>
<p>X</p>
</blockquote></td>
<td><blockquote>
<p>2527</p>
</blockquote></td>
<td><blockquote>
<p>1245</p>
</blockquote></td>
</tr>
<tr class="odd">
<td><blockquote>
<p><a href="http://www.openml.org/d/46">46</a></p>
</blockquote></td>
<td><blockquote>
<p>Splice</p>
</blockquote></td>
<td><blockquote>
<p>0</p>
</blockquote></td>
<td><blockquote>
<p>60</p>
</blockquote></td>
<td><blockquote>
<p>3</p>
</blockquote></td>
<td><blockquote>
<p>–</p>
</blockquote></td>
<td><blockquote>
<p>–</p>
</blockquote></td>
<td><blockquote>
<p>2137</p>
</blockquote></td>
<td><blockquote>
<p>1053</p>
</blockquote></td>
</tr>
<tr class="even">
<td><blockquote>
<p><a href="http://www.openml.org/d/179">179</a></p>
</blockquote></td>
<td><blockquote>
<p>Adult</p>
</blockquote></td>
<td><blockquote>
<p>2</p>
</blockquote></td>
<td><blockquote>
<p>12</p>
</blockquote></td>
<td><blockquote>
<p>2</p>
</blockquote></td>
<td><blockquote>
<p>–</p>
</blockquote></td>
<td><blockquote>
<p>X</p>
</blockquote></td>
<td><blockquote>
<p>32,724</p>
</blockquote></td>
<td><blockquote>
<p>16,118</p>
</blockquote></td>
</tr>
<tr class="odd">
<td><blockquote>
<p><a href="http://www.openml.org/d/184">184</a></p>
</blockquote></td>
<td><blockquote>
<p>KROPT</p>
</blockquote></td>
<td><blockquote>
<p>0</p>
</blockquote></td>
<td><blockquote>
<p>6</p>
</blockquote></td>
<td><blockquote>
<p>18</p>
</blockquote></td>
<td><blockquote>
<p>–</p>
</blockquote></td>
<td><blockquote>
<p>–</p>
</blockquote></td>
<td><blockquote>
<p>18,797</p>
</blockquote></td>
<td><blockquote>
<p>9259</p>
</blockquote></td>
</tr>
<tr class="even">
<td><blockquote>
<p><a href="http://www.openml.org/d/554">554</a></p>
</blockquote></td>
<td><blockquote>
<p>MNIST</p>
</blockquote></td>
<td><blockquote>
<p>784</p>
</blockquote></td>
<td><blockquote>
<p>0</p>
</blockquote></td>
<td><blockquote>
<p>10</p>
</blockquote></td>
<td><blockquote>
<p>–</p>
</blockquote></td>
<td><blockquote>
<p>–</p>
</blockquote></td>
<td><blockquote>
<p>46,900</p>
</blockquote></td>
<td><blockquote>
<p>23,100</p>
</blockquote></td>
</tr>
<tr class="odd">
<td><blockquote>
<p><a href="http://www.openml.org/d/772">772</a></p>
</blockquote></td>
<td><blockquote>
<p>Quake</p>
</blockquote></td>
<td><blockquote>
<p>3</p>
</blockquote></td>
<td><blockquote>
<p>0</p>
</blockquote></td>
<td><blockquote>
<p>2</p>
</blockquote></td>
<td><blockquote>
<p>–</p>
</blockquote></td>
<td><blockquote>
<p>–</p>
</blockquote></td>
<td><blockquote>
<p>1459</p>
</blockquote></td>
<td><blockquote>
<p>719</p>
</blockquote></td>
</tr>
<tr class="even">
<td><blockquote>
<p><a href="http://www.openml.org/d/917">917</a></p>
</blockquote></td>
<td><blockquote>
<p>fri_c1_ 1000_25 (binarized)</p>
</blockquote></td>
<td><blockquote>
<p>25</p>
</blockquote></td>
<td><blockquote>
<p>0</p>
</blockquote></td>
<td><blockquote>
<p>2</p>
</blockquote></td>
<td><blockquote>
<p>–</p>
</blockquote></td>
<td><blockquote>
<p>–</p>
</blockquote></td>
<td><blockquote>
<p>670</p>
</blockquote></td>
<td><blockquote>
<p>330</p>
</blockquote></td>
</tr>
<tr class="odd">
<td><blockquote>
<p><a href="http://www.openml.org/d/1049">1049</a></p>
</blockquote></td>
<td><blockquote>
<p>pc4</p>
</blockquote></td>
<td><blockquote>
<p>37</p>
</blockquote></td>
<td><blockquote>
<p>0</p>
</blockquote></td>
<td><blockquote>
<p>2</p>
</blockquote></td>
<td><blockquote>
<p>–</p>
</blockquote></td>
<td><blockquote>
<p>–</p>
</blockquote></td>
<td><blockquote>
<p>976</p>
</blockquote></td>
<td><blockquote>
<p>482</p>
</blockquote></td>
</tr>
<tr class="even">
<td><blockquote>
<p><a href="http://www.openml.org/d/1111">1111</a></p>
</blockquote></td>
<td><blockquote>
<p>KDDCup09</p>
<p>Appetency</p>
</blockquote></td>
<td><blockquote>
<p>192</p>
</blockquote></td>
<td><blockquote>
<p>38</p>
</blockquote></td>
<td><blockquote>
<p>2</p>
</blockquote></td>
<td><blockquote>
<p>–</p>
</blockquote></td>
<td><blockquote>
<p>X</p>
</blockquote></td>
<td><blockquote>
<p>33,500</p>
</blockquote></td>
<td><blockquote>
<p>16,500</p>
</blockquote></td>
</tr>
<tr class="odd">
<td><blockquote>
<p><a href="http://www.openml.org/d/1120">1120</a></p>
</blockquote></td>
<td><blockquote>
<p>Magic Telescope</p>
</blockquote></td>
<td><blockquote>
<p>10</p>
</blockquote></td>
<td><blockquote>
<p>0</p>
</blockquote></td>
<td><blockquote>
<p>2</p>
</blockquote></td>
<td><blockquote>
<p>–</p>
</blockquote></td>
<td><blockquote>
<p>–</p>
</blockquote></td>
<td><blockquote>
<p>12,743</p>
</blockquote></td>
<td><blockquote>
<p>6277</p>
</blockquote></td>
</tr>
<tr class="even">
<td><blockquote>
<p><a href="http://www.openml.org/d/1128">1128</a></p>
</blockquote></td>
<td><blockquote>
<p>OVA Breast</p>
</blockquote></td>
<td><blockquote>
<p>10935</p>
</blockquote></td>
<td><blockquote>
<p>0</p>
</blockquote></td>
<td><blockquote>
<p>2</p>
</blockquote></td>
<td><blockquote>
<p>–</p>
</blockquote></td>
<td><blockquote>
<p>–</p>
</blockquote></td>
<td><blockquote>
<p>1035</p>
</blockquote></td>
<td><blockquote>
<p>510</p>
</blockquote></td>
</tr>
<tr class="odd">
<td><blockquote>
<p><a href="http://www.openml.org/d/293">293</a></p>
</blockquote></td>
<td><blockquote>
<p>Covertype</p>
<p>(binarized)</p>
</blockquote></td>
<td><blockquote>
<p>54</p>
</blockquote></td>
<td><blockquote>
<p>0</p>
</blockquote></td>
<td><blockquote>
<p>2</p>
</blockquote></td>
<td><blockquote>
<p>X</p>
</blockquote></td>
<td><blockquote>
<p>–</p>
</blockquote></td>
<td><blockquote>
<p>389,278</p>
</blockquote></td>
<td><blockquote>
<p>191,734</p>
</blockquote></td>
</tr>
<tr class="even">
<td><blockquote>
<p><a href="http://www.openml.org/d/389">389</a></p>
</blockquote></td>
<td><blockquote>
<p>fbis_wc</p>
</blockquote></td>
<td><blockquote>
<p>2000</p>
</blockquote></td>
<td><blockquote>
<p>0</p>
</blockquote></td>
<td><blockquote>
<p>17</p>
</blockquote></td>
<td><blockquote>
<p>X</p>
</blockquote></td>
<td><blockquote>
<p>–</p>
</blockquote></td>
<td><blockquote>
<p>1651</p>
</blockquote></td>
<td><blockquote>
<p>812</p>
</blockquote></td>
</tr>
</tbody>
</table>
<blockquote>
<p>performance: It performed best on three of the datasets and was not statistically signiﬁcantly worse than the best preprocessor on another 8 of 13.</p>
<p><strong>6.8</strong> <strong>Discussion</strong> <strong>and</strong> <strong>Conclusion</strong></p>
</blockquote>
<p>Having presented our experimental validation, we now conclude this chapter with a brief discussion, a simple usage example of Auto-sklearn, a short review of recent extensions, and concluding remarks.</p>
<blockquote>
<p><em><strong>6.8.1</strong></em> <em><strong>Discussion</strong></em></p>
<p>We demonstrated that our new AutoML system Auto-sklearn performs favorably against the previous state of the art in AutoML, and that our meta-learning and ensemble improvements for AutoML yield further efﬁciency and robustness. This ﬁnding is backed by the fact that Auto-sklearn won three out of ﬁve auto-tracks, including the ﬁnal two, in ChaLearn’s ﬁrst AutoML challenge. In this paper, we did not evaluate the use of Auto-sklearn for interactive machine learning with an expert in the loop and weeks of CPU power, but we note that mode has led to three ﬁrst places in the human (aka Final) track of the ﬁrst ChaLearn AutoML challenge (in</p>
<p><strong>Table</strong> <strong>6.4</strong> Median balanced test error rate (BER) of optimizing Auto-sklearn subspaces for each classiﬁcation method (and all preprocessors), as well as the whole conﬁguration space of Auto-sklearn, on 13 datasets. All optimization runs were allowed to run for 24 h except for Auto-sklearn which ran for 48 h. Bold numbers indicate the best result; underlined results are not statistically signiﬁcantly different from the best according to a bootstrap test using the same setup as for Table <a href="#_bookmark582">6.2</a></p>
</blockquote>
<table>
<tbody>
<tr class="odd">
<td><blockquote>
<p>OpenML dataset</p>
<p>ID</p>
</blockquote></td>
<td><blockquote>
<p>AUTO- SKLEARN</p>
</blockquote></td>
<td><blockquote>
<p>AdaBoost</p>
</blockquote></td>
<td><blockquote>
<p>Bernoulli</p>
<p>naïve</p>
<p>Bayes</p>
</blockquote></td>
<td><blockquote>
<p>Decision</p>
<p>tree</p>
</blockquote></td>
<td><blockquote>
<p>Extreml.</p>
<p>rand.</p>
<p>trees</p>
</blockquote></td>
<td><blockquote>
<p>Gaussian</p>
<p>naïve</p>
<p>Bayes</p>
</blockquote></td>
<td><blockquote>
<p>Gradient</p>
<p>boosting</p>
</blockquote></td>
<td><blockquote>
<p>kNN</p>
</blockquote></td>
<td><blockquote>
<p>LDA</p>
</blockquote></td>
<td><blockquote>
<p>Linear SVM</p>
</blockquote></td>
<td><blockquote>
<p>Kernel SVM</p>
</blockquote></td>
<td><blockquote>
<p>Multi-</p>
<p>nomial naïve Bayes</p>
</blockquote></td>
<td><blockquote>
<p>Passive</p>
<p>aggresive</p>
</blockquote></td>
<td><blockquote>
<p>QDA</p>
</blockquote></td>
<td><blockquote>
<p>Random</p>
<p>forest</p>
</blockquote></td>
<td><blockquote>
<p>Linear Class. (SGD)</p>
</blockquote></td>
</tr>
<tr class="even">
<td><blockquote>
<p><a href="http://www.openml.org/d/38">38</a></p>
</blockquote></td>
<td><blockquote>
<p>2.15</p>
</blockquote></td>
<td><blockquote>
<p>2.68</p>
</blockquote></td>
<td><blockquote>
<p>50.22</p>
</blockquote></td>
<td><blockquote>
<p>2.15</p>
</blockquote></td>
<td><blockquote>
<p>18.06</p>
</blockquote></td>
<td><blockquote>
<p>11.22</p>
</blockquote></td>
<td><blockquote>
<p><strong>1.77</strong></p>
</blockquote></td>
<td><blockquote>
<p>50.00</p>
</blockquote></td>
<td><blockquote>
<p>8.55</p>
</blockquote></td>
<td><blockquote>
<p>16.29</p>
</blockquote></td>
<td><blockquote>
<p>17.89</p>
</blockquote></td>
<td><blockquote>
<p>46.99</p>
</blockquote></td>
<td><blockquote>
<p>50.00</p>
</blockquote></td>
<td><blockquote>
<p>8.78</p>
</blockquote></td>
<td><blockquote>
<p>2.34</p>
</blockquote></td>
<td><blockquote>
<p>15.82</p>
</blockquote></td>
</tr>
<tr class="odd">
<td><blockquote>
<p><a href="http://www.openml.org/d/46">46</a></p>
</blockquote></td>
<td><blockquote>
<p>3.76</p>
</blockquote></td>
<td><blockquote>
<p>4.65</p>
</blockquote></td>
<td><blockquote>
<p>–</p>
</blockquote></td>
<td><blockquote>
<p>5.62</p>
</blockquote></td>
<td><blockquote>
<p>4.74</p>
</blockquote></td>
<td><blockquote>
<p>7.88</p>
</blockquote></td>
<td><blockquote>
<p><strong>3.49</strong></p>
</blockquote></td>
<td><blockquote>
<p>7.57</p>
</blockquote></td>
<td><blockquote>
<p>8.67</p>
</blockquote></td>
<td><blockquote>
<p>8.31</p>
</blockquote></td>
<td><blockquote>
<p>5.36</p>
</blockquote></td>
<td><blockquote>
<p>7.55</p>
</blockquote></td>
<td><blockquote>
<p>9.23</p>
</blockquote></td>
<td><blockquote>
<p>7.57</p>
</blockquote></td>
<td><blockquote>
<p>4.20</p>
</blockquote></td>
<td><blockquote>
<p>7.31</p>
</blockquote></td>
</tr>
<tr class="even">
<td><blockquote>
<p><a href="http://www.openml.org/d/179">179</a></p>
</blockquote></td>
<td><blockquote>
<p><strong>16.99</strong></p>
</blockquote></td>
<td><blockquote>
<p>17.03</p>
</blockquote></td>
<td><blockquote>
<p>19.27</p>
</blockquote></td>
<td><blockquote>
<p>18.31</p>
</blockquote></td>
<td><blockquote>
<p>17.09</p>
</blockquote></td>
<td><blockquote>
<p>21.77</p>
</blockquote></td>
<td><blockquote>
<p>17.00</p>
</blockquote></td>
<td><blockquote>
<p>22.23</p>
</blockquote></td>
<td><blockquote>
<p>18.93</p>
</blockquote></td>
<td><blockquote>
<p>17.30</p>
</blockquote></td>
<td><blockquote>
<p>17.57</p>
</blockquote></td>
<td><blockquote>
<p>18.97</p>
</blockquote></td>
<td><blockquote>
<p>22.29</p>
</blockquote></td>
<td><blockquote>
<p>19.06</p>
</blockquote></td>
<td><blockquote>
<p>17.24</p>
</blockquote></td>
<td><blockquote>
<p>17.01</p>
</blockquote></td>
</tr>
<tr class="odd">
<td><blockquote>
<p><a href="http://www.openml.org/d/184">184</a></p>
</blockquote></td>
<td><blockquote>
<p><strong>10.32</strong></p>
</blockquote></td>
<td><blockquote>
<p>10.52</p>
</blockquote></td>
<td><blockquote>
<p>–</p>
</blockquote></td>
<td><blockquote>
<p>17.46</p>
</blockquote></td>
<td><blockquote>
<p>11.10</p>
</blockquote></td>
<td><blockquote>
<p>64.74</p>
</blockquote></td>
<td><blockquote>
<p>10.42</p>
</blockquote></td>
<td><blockquote>
<p>31.10</p>
</blockquote></td>
<td><blockquote>
<p>35.44</p>
</blockquote></td>
<td><blockquote>
<p>15.76</p>
</blockquote></td>
<td><blockquote>
<p>12.52</p>
</blockquote></td>
<td><blockquote>
<p>27.13</p>
</blockquote></td>
<td><blockquote>
<p>20.01</p>
</blockquote></td>
<td><blockquote>
<p>47.18</p>
</blockquote></td>
<td><blockquote>
<p>10.98</p>
</blockquote></td>
<td><blockquote>
<p>12.76</p>
</blockquote></td>
</tr>
<tr class="even">
<td><blockquote>
<p><a href="http://www.openml.org/d/554">554</a></p>
</blockquote></td>
<td><blockquote>
<p>1.55</p>
</blockquote></td>
<td><blockquote>
<p>2.42</p>
</blockquote></td>
<td><blockquote>
<p>–</p>
</blockquote></td>
<td><blockquote>
<p>12.00</p>
</blockquote></td>
<td><blockquote>
<p>2.91</p>
</blockquote></td>
<td><blockquote>
<p>10.52</p>
</blockquote></td>
<td><blockquote>
<p>3.86</p>
</blockquote></td>
<td><blockquote>
<p>2.68</p>
</blockquote></td>
<td><blockquote>
<p>3.34</p>
</blockquote></td>
<td><blockquote>
<p>2.23</p>
</blockquote></td>
<td><blockquote>
<p><strong>1.50</strong></p>
</blockquote></td>
<td><blockquote>
<p>10.37</p>
</blockquote></td>
<td><blockquote>
<p>100.00</p>
</blockquote></td>
<td><blockquote>
<p>2.75</p>
</blockquote></td>
<td><blockquote>
<p>3.08</p>
</blockquote></td>
<td><blockquote>
<p>2.50</p>
</blockquote></td>
</tr>
<tr class="odd">
<td><blockquote>
<p><a href="http://www.openml.org/d/772">772</a></p>
</blockquote></td>
<td><blockquote>
<p>46.85</p>
</blockquote></td>
<td><blockquote>
<p>49.68</p>
</blockquote></td>
<td><blockquote>
<p>47.90</p>
</blockquote></td>
<td><blockquote>
<p>47.75</p>
</blockquote></td>
<td><blockquote>
<p><strong>45.62</strong></p>
</blockquote></td>
<td><blockquote>
<p>48.83</p>
</blockquote></td>
<td><blockquote>
<p>48.15</p>
</blockquote></td>
<td><blockquote>
<p>48.00</p>
</blockquote></td>
<td><blockquote>
<p>46.74</p>
</blockquote></td>
<td><blockquote>
<p>48.38</p>
</blockquote></td>
<td><blockquote>
<p>48.66</p>
</blockquote></td>
<td><blockquote>
<p>47.21</p>
</blockquote></td>
<td><blockquote>
<p>48.75</p>
</blockquote></td>
<td><blockquote>
<p>47.67</p>
</blockquote></td>
<td><blockquote>
<p>47.71</p>
</blockquote></td>
<td><blockquote>
<p>47.93</p>
</blockquote></td>
</tr>
<tr class="even">
<td><blockquote>
<p><a href="http://www.openml.org/d/917">917</a></p>
</blockquote></td>
<td><blockquote>
<p>10.22</p>
</blockquote></td>
<td><blockquote>
<p>9.11</p>
</blockquote></td>
<td><blockquote>
<p><span id="_bookmark586" class="anchor"></span>25.83</p>
</blockquote></td>
<td><blockquote>
<p>11.00</p>
</blockquote></td>
<td><blockquote>
<p>10.22</p>
</blockquote></td>
<td><blockquote>
<p>33.94</p>
</blockquote></td>
<td><blockquote>
<p>10.11</p>
</blockquote></td>
<td><blockquote>
<p>11.11</p>
</blockquote></td>
<td><blockquote>
<p>34.22</p>
</blockquote></td>
<td><blockquote>
<p>18.67</p>
</blockquote></td>
<td><blockquote>
<p><strong>6.78</strong></p>
</blockquote></td>
<td><blockquote>
<p>25.50</p>
</blockquote></td>
<td><blockquote>
<p>20.67</p>
</blockquote></td>
<td><blockquote>
<p>30.44</p>
</blockquote></td>
<td><blockquote>
<p>10.83</p>
</blockquote></td>
<td><blockquote>
<p>18.33</p>
</blockquote></td>
</tr>
<tr class="odd">
<td><blockquote>
<p><a href="http://www.openml.org/d/1049">1049</a></p>
</blockquote></td>
<td><blockquote>
<p>12.93</p>
</blockquote></td>
<td><blockquote>
<p><strong>12.53</strong></p>
</blockquote></td>
<td><blockquote>
<p>15.50</p>
</blockquote></td>
<td><blockquote>
<p>19.31</p>
</blockquote></td>
<td><blockquote>
<p>17.18</p>
</blockquote></td>
<td><blockquote>
<p>26.23</p>
</blockquote></td>
<td><blockquote>
<p>13.38</p>
</blockquote></td>
<td><blockquote>
<p>23.80</p>
</blockquote></td>
<td><blockquote>
<p>25.12</p>
</blockquote></td>
<td><blockquote>
<p>17.28</p>
</blockquote></td>
<td><blockquote>
<p>21.44</p>
</blockquote></td>
<td><blockquote>
<p>26.40</p>
</blockquote></td>
<td><blockquote>
<p>29.25</p>
</blockquote></td>
<td><blockquote>
<p>21.38</p>
</blockquote></td>
<td><blockquote>
<p>13.75</p>
</blockquote></td>
<td><blockquote>
<p>19.92</p>
</blockquote></td>
</tr>
<tr class="even">
<td><blockquote>
<p><a href="http://www.openml.org/d/1111">1111</a></p>
</blockquote></td>
<td><blockquote>
<p>23.70</p>
</blockquote></td>
<td><blockquote>
<p>23.16</p>
</blockquote></td>
<td><blockquote>
<p>28.40</p>
</blockquote></td>
<td><blockquote>
<p>24.40</p>
</blockquote></td>
<td><blockquote>
<p>24.47</p>
</blockquote></td>
<td><blockquote>
<p>29.59</p>
</blockquote></td>
<td><blockquote>
<p><strong>22.93</strong></p>
</blockquote></td>
<td><blockquote>
<p>50.30</p>
</blockquote></td>
<td><blockquote>
<p>24.11</p>
</blockquote></td>
<td><blockquote>
<p>23.99</p>
</blockquote></td>
<td><blockquote>
<p>23.56</p>
</blockquote></td>
<td><blockquote>
<p>27.67</p>
</blockquote></td>
<td><blockquote>
<p>43.79</p>
</blockquote></td>
<td><blockquote>
<p>25.86</p>
</blockquote></td>
<td><blockquote>
<p>28.06</p>
</blockquote></td>
<td><blockquote>
<p>23.36</p>
</blockquote></td>
</tr>
<tr class="odd">
<td><blockquote>
<p><a href="http://www.openml.org/d/1120">1120</a></p>
</blockquote></td>
<td><blockquote>
<p>13.81</p>
</blockquote></td>
<td><blockquote>
<p><strong>13.54</strong></p>
</blockquote></td>
<td><blockquote>
<p>18.81</p>
</blockquote></td>
<td><blockquote>
<p>17.45</p>
</blockquote></td>
<td><blockquote>
<p>13.86</p>
</blockquote></td>
<td><blockquote>
<p>21.50</p>
</blockquote></td>
<td><blockquote>
<p>13.61</p>
</blockquote></td>
<td><blockquote>
<p>17.23</p>
</blockquote></td>
<td><blockquote>
<p>15.48</p>
</blockquote></td>
<td><blockquote>
<p>14.94</p>
</blockquote></td>
<td><blockquote>
<p>14.17</p>
</blockquote></td>
<td><blockquote>
<p>18.33</p>
</blockquote></td>
<td><blockquote>
<p>16.37</p>
</blockquote></td>
<td><blockquote>
<p>15.62</p>
</blockquote></td>
<td><blockquote>
<p>13.70</p>
</blockquote></td>
<td><blockquote>
<p>14.66</p>
</blockquote></td>
</tr>
<tr class="even">
<td><blockquote>
<p><a href="http://www.openml.org/d/1128">1128</a></p>
</blockquote></td>
<td><blockquote>
<p>4.21</p>
</blockquote></td>
<td><blockquote>
<p>4.89</p>
</blockquote></td>
<td><blockquote>
<p>4.71</p>
</blockquote></td>
<td><blockquote>
<p>9.30</p>
</blockquote></td>
<td><blockquote>
<p>3.89</p>
</blockquote></td>
<td><blockquote>
<p>4.77</p>
</blockquote></td>
<td><blockquote>
<p>4.58</p>
</blockquote></td>
<td><blockquote>
<p>4.59</p>
</blockquote></td>
<td><blockquote>
<p>4.58</p>
</blockquote></td>
<td><blockquote>
<p>4.83</p>
</blockquote></td>
<td><blockquote>
<p>4.59</p>
</blockquote></td>
<td><blockquote>
<p>4.46</p>
</blockquote></td>
<td><blockquote>
<p>5.65</p>
</blockquote></td>
<td><blockquote>
<p>5.59</p>
</blockquote></td>
<td><blockquote>
<p><strong>3.83</strong></p>
</blockquote></td>
<td><blockquote>
<p>4.33</p>
</blockquote></td>
</tr>
<tr class="odd">
<td><blockquote>
<p><a href="http://www.openml.org/d/293">293</a></p>
</blockquote></td>
<td><blockquote>
<p>2.86</p>
</blockquote></td>
<td><blockquote>
<p>4.07</p>
</blockquote></td>
<td><blockquote>
<p>24.30</p>
</blockquote></td>
<td><blockquote>
<p>5.03</p>
</blockquote></td>
<td><blockquote>
<p>3.59</p>
</blockquote></td>
<td><blockquote>
<p>32.44</p>
</blockquote></td>
<td><blockquote>
<p>24.48</p>
</blockquote></td>
<td><blockquote>
<p>4.86</p>
</blockquote></td>
<td><blockquote>
<p>24.40</p>
</blockquote></td>
<td><blockquote>
<p>14.16</p>
</blockquote></td>
<td><blockquote>
<p>100.00</p>
</blockquote></td>
<td><blockquote>
<p>24.20</p>
</blockquote></td>
<td><blockquote>
<p>21.34</p>
</blockquote></td>
<td><blockquote>
<p>28.68</p>
</blockquote></td>
<td><blockquote>
<p><strong>2.57</strong></p>
</blockquote></td>
<td><blockquote>
<p>15.54</p>
</blockquote></td>
</tr>
<tr class="even">
<td><blockquote>
<p><a href="http://www.openml.org/d/389">389</a></p>
</blockquote></td>
<td><blockquote>
<p>19.65</p>
</blockquote></td>
<td><blockquote>
<p>22.98</p>
</blockquote></td>
<td><blockquote>
<p>–</p>
</blockquote></td>
<td><blockquote>
<p>33.14</p>
</blockquote></td>
<td><blockquote>
<p>19.38</p>
</blockquote></td>
<td><blockquote>
<p>29.18</p>
</blockquote></td>
<td><blockquote>
<p>19.20</p>
</blockquote></td>
<td><blockquote>
<p>30.87</p>
</blockquote></td>
<td><blockquote>
<p>19.68</p>
</blockquote></td>
<td><blockquote>
<p><strong>17.95</strong></p>
</blockquote></td>
<td><blockquote>
<p>22.04</p>
</blockquote></td>
<td><blockquote>
<p>20.04</p>
</blockquote></td>
<td><blockquote>
<p>20.14</p>
</blockquote></td>
<td><blockquote>
<p>39.57</p>
</blockquote></td>
<td><blockquote>
<p>20.66</p>
</blockquote></td>
<td><blockquote>
<p>17.99</p>
</blockquote></td>
</tr>
</tbody>
</table>
<p><img src="./automlgithubpagesimages//media/image362.png" width="28" /><img src="./automlgithubpagesimages//media/image363.png" width="18" /><img src="./automlgithubpagesimages//media/image364.png" /><img src="./automlgithubpagesimages//media/image365.png" width="83" /><img src="./automlgithubpagesimages//media/image366.png" width="52" /><img src="./automlgithubpagesimages//media/image367.png" width="23" /><img src="./automlgithubpagesimages//media/image368.png" width="42" /><img src="./automlgithubpagesimages//media/image369.png" width="23" /><img src="./automlgithubpagesimages//media/image370.png" width="10" height="64" /><img src="./automlgithubpagesimages//media/image371.png" width="23" height="137" /><img src="./automlgithubpagesimages//media/image372.png" height="36" /><img src="./automlgithubpagesimages//media/image373.png" height="57" /><img src="./automlgithubpagesimages//media/image374.png" width="14" height="9" /><img src="./automlgithubpagesimages//media/image375.png" width="14" height="9" /><img src="./automlgithubpagesimages//media/image376.png" width="47" /><img src="./automlgithubpagesimages//media/image377.png" width="10" /><img src="./automlgithubpagesimages//media/image378.png" width="28" /><img src="./automlgithubpagesimages//media/image379.png" width="28" /><img src="./automlgithubpagesimages//media/image380.png" width="83" /><img src="./automlgithubpagesimages//media/image381.png" width="52" /><img src="./automlgithubpagesimages//media/image382.png" width="23" /><img src="./automlgithubpagesimages//media/image383.png" width="42" /><img src="./automlgithubpagesimages//media/image384.png" width="23" /><img src="./automlgithubpagesimages//media/image385.png" width="14" height="277" /><img src="./automlgithubpagesimages//media/image386.png" width="10" /></p>
<blockquote>
<p>128 M. Feurer et al.</p>
</blockquote>
<p><img src="./automlgithubpagesimages//media/image387.png" width="404" height="624" /></p>
<p><img src="./automlgithubpagesimages//media/image388.png" width="322" height="9" /></p>
<p><img src="./automlgithubpagesimages//media/image389.png" width="47" /></p>
<p><span id="_bookmark587" class="anchor"></span><strong>Fig.</strong> <strong>6.4</strong> Performance of a subset of classiﬁers compared to Auto-sklearn over time. (Top) MNIST (OpenML dataset ID<a href="http://www.openml.org/d/554">554</a>). (Bottom) Promise pc4 (OpenML dataset ID<a href="http://www.openml.org/d/1049">1049</a>). We show median test error rate and the ﬁfth and 95th percentile over time for optimizing three classiﬁers separately with optimizing the joint space. A plot with all classiﬁers can be found in Fig. 4 in the supplementary material of the original publication [<a href="#_bookmark555">20</a>]. While Auto-sklearn is inferior in the beginning, in the end its performance is close to the best method</p>
<blockquote>
<p><strong>Table</strong> <strong>6.5</strong> Like Table <a href="#_bookmark586">6.4</a>, but instead optimizing subspaces for each preprocessing method (and all classiﬁers)</p>
</blockquote>
<table>
<tbody>
<tr class="odd">
<td><blockquote>
<p>OpenML dataset</p>
<p>ID</p>
</blockquote></td>
<td><blockquote>
<p>AUTO- SKLEARN</p>
</blockquote></td>
<td><blockquote>
<p>Densi-</p>
<p>ﬁer</p>
</blockquote></td>
<td><blockquote>
<p>Extreml.</p>
<p>rand.</p>
<p>trees</p>
<p>prepr.</p>
</blockquote></td>
<td><blockquote>
<p>Fast</p>
<p>ICA</p>
</blockquote></td>
<td><blockquote>
<p>Feature</p>
<p>agglom- eration</p>
</blockquote></td>
<td><blockquote>
<p>Kernel PCA</p>
</blockquote></td>
<td><blockquote>
<p>Rand.</p>
<p>kitchen sinks</p>
</blockquote></td>
<td><blockquote>
<p>Linear</p>
<p>SVM</p>
<p>prepr.</p>
</blockquote></td>
<td><blockquote>
<p>No</p>
<p>preproc.</p>
</blockquote></td>
<td><blockquote>
<p>Nystroem sampler</p>
</blockquote></td>
<td><blockquote>
<p>PCA</p>
</blockquote></td>
<td><blockquote>
<p>Poly- nomial</p>
</blockquote></td>
<td><blockquote>
<p>Random</p>
<p>trees embed.</p>
</blockquote></td>
<td><blockquote>
<p>Select</p>
<p>percentile classiﬁca- tion</p>
</blockquote></td>
<td><blockquote>
<p>Select</p>
<p>rates</p>
</blockquote></td>
<td><blockquote>
<p>Truncated- SVD</p>
</blockquote></td>
</tr>
<tr class="even">
<td><blockquote>
<p><a href="http://www.openml.org/d/38">38</a></p>
</blockquote></td>
<td><blockquote>
<p><strong>2.15</strong></p>
</blockquote></td>
<td><blockquote>
<p>–</p>
</blockquote></td>
<td><blockquote>
<p>4.03</p>
</blockquote></td>
<td><blockquote>
<p>7.27</p>
</blockquote></td>
<td><blockquote>
<p>2.24</p>
</blockquote></td>
<td><blockquote>
<p>5.84</p>
</blockquote></td>
<td><blockquote>
<p>8.57</p>
</blockquote></td>
<td><blockquote>
<p>2.28</p>
</blockquote></td>
<td><blockquote>
<p>2.28</p>
</blockquote></td>
<td><blockquote>
<p>7.70</p>
</blockquote></td>
<td><blockquote>
<p>7.23</p>
</blockquote></td>
<td><blockquote>
<p>2.90</p>
</blockquote></td>
<td><blockquote>
<p>18.50</p>
</blockquote></td>
<td><blockquote>
<p>2.20</p>
</blockquote></td>
<td><blockquote>
<p>2.28</p>
</blockquote></td>
<td><blockquote>
<p>–</p>
</blockquote></td>
</tr>
<tr class="odd">
<td><blockquote>
<p><a href="http://www.openml.org/d/46">46</a></p>
</blockquote></td>
<td><blockquote>
<p><strong>3.76</strong></p>
</blockquote></td>
<td><blockquote>
<p>–</p>
</blockquote></td>
<td><blockquote>
<p>4.98</p>
</blockquote></td>
<td><blockquote>
<p>7.95</p>
</blockquote></td>
<td><blockquote>
<p>4.40</p>
</blockquote></td>
<td><blockquote>
<p>8.74</p>
</blockquote></td>
<td><blockquote>
<p>8.41</p>
</blockquote></td>
<td><blockquote>
<p>4.25</p>
</blockquote></td>
<td><blockquote>
<p>4.52</p>
</blockquote></td>
<td><blockquote>
<p>8.48</p>
</blockquote></td>
<td><blockquote>
<p>8.40</p>
</blockquote></td>
<td><blockquote>
<p>4.21</p>
</blockquote></td>
<td><blockquote>
<p>7.51</p>
</blockquote></td>
<td><blockquote>
<p>4.17</p>
</blockquote></td>
<td><blockquote>
<p>4.68</p>
</blockquote></td>
<td><blockquote>
<p>–</p>
</blockquote></td>
</tr>
<tr class="even">
<td><blockquote>
<p><a href="http://www.openml.org/d/179">179</a></p>
</blockquote></td>
<td><blockquote>
<p>16.99</p>
</blockquote></td>
<td><blockquote>
<p>–</p>
</blockquote></td>
<td><blockquote>
<p>17.83</p>
</blockquote></td>
<td><blockquote>
<p>17.24</p>
</blockquote></td>
<td><blockquote>
<p>16.92</p>
</blockquote></td>
<td><blockquote>
<p>100.00</p>
</blockquote></td>
<td><blockquote>
<p>17.34</p>
</blockquote></td>
<td><blockquote>
<p><strong>16.84</strong></p>
</blockquote></td>
<td><blockquote>
<p>16.97</p>
</blockquote></td>
<td><blockquote>
<p>17.30</p>
</blockquote></td>
<td><blockquote>
<p>17.64</p>
</blockquote></td>
<td><blockquote>
<p>16.94</p>
</blockquote></td>
<td><blockquote>
<p>17.05</p>
</blockquote></td>
<td><blockquote>
<p>17.09</p>
</blockquote></td>
<td><blockquote>
<p>16.86</p>
</blockquote></td>
<td><blockquote>
<p>–</p>
</blockquote></td>
</tr>
<tr class="odd">
<td><blockquote>
<p><a href="http://www.openml.org/d/184">184</a></p>
</blockquote></td>
<td><blockquote>
<p>10.32</p>
</blockquote></td>
<td><blockquote>
<p>–</p>
</blockquote></td>
<td><blockquote>
<p>55.78</p>
</blockquote></td>
<td><blockquote>
<p>19.96</p>
</blockquote></td>
<td><blockquote>
<p>11.31</p>
</blockquote></td>
<td><blockquote>
<p>36.52</p>
</blockquote></td>
<td><blockquote>
<p>28.05</p>
</blockquote></td>
<td><blockquote>
<p><strong>9.92</strong></p>
</blockquote></td>
<td><blockquote>
<p>11.43</p>
</blockquote></td>
<td><blockquote>
<p>25.53</p>
</blockquote></td>
<td><blockquote>
<p>21.15</p>
</blockquote></td>
<td><blockquote>
<p>10.54</p>
</blockquote></td>
<td><blockquote>
<p>12.68</p>
</blockquote></td>
<td><blockquote>
<p>45.03</p>
</blockquote></td>
<td><blockquote>
<p>10.47</p>
</blockquote></td>
<td><blockquote>
<p>–</p>
</blockquote></td>
</tr>
<tr class="even">
<td><blockquote>
<p><a href="http://www.openml.org/d/554">554</a></p>
</blockquote></td>
<td><blockquote>
<p>1.55</p>
</blockquote></td>
<td><blockquote>
<p>–</p>
</blockquote></td>
<td><blockquote>
<p>1.56</p>
</blockquote></td>
<td><blockquote>
<p>2.52</p>
</blockquote></td>
<td><blockquote>
<p>1.65</p>
</blockquote></td>
<td><blockquote>
<p>100.00</p>
</blockquote></td>
<td><blockquote>
<p>100.00</p>
</blockquote></td>
<td><blockquote>
<p>2.21</p>
</blockquote></td>
<td><blockquote>
<p>1.60</p>
</blockquote></td>
<td><blockquote>
<p>2.21</p>
</blockquote></td>
<td><blockquote>
<p>1.65</p>
</blockquote></td>
<td><blockquote>
<p>100.00</p>
</blockquote></td>
<td><blockquote>
<p>3.48</p>
</blockquote></td>
<td><blockquote>
<p><strong>1.46</strong></p>
</blockquote></td>
<td><blockquote>
<p>1.70</p>
</blockquote></td>
<td><blockquote>
<p>–</p>
</blockquote></td>
</tr>
<tr class="odd">
<td><blockquote>
<p><a href="http://www.openml.org/d/772">772</a></p>
</blockquote></td>
<td><blockquote>
<p><strong>46.85</strong></p>
</blockquote></td>
<td><blockquote>
<p>–</p>
</blockquote></td>
<td><blockquote>
<p>47.90</p>
</blockquote></td>
<td><blockquote>
<p>48.65</p>
</blockquote></td>
<td><blockquote>
<p>48.62</p>
</blockquote></td>
<td><blockquote>
<p>47.59</p>
</blockquote></td>
<td><blockquote>
<p>47.68</p>
</blockquote></td>
<td><blockquote>
<p>47.72</p>
</blockquote></td>
<td><blockquote>
<p>48.34</p>
</blockquote></td>
<td><blockquote>
<p>48.06</p>
</blockquote></td>
<td><blockquote>
<p>47.30</p>
</blockquote></td>
<td><blockquote>
<p>48.00</p>
</blockquote></td>
<td><blockquote>
<p>47.84</p>
</blockquote></td>
<td><blockquote>
<p>47.56</p>
</blockquote></td>
<td><blockquote>
<p>48.43</p>
</blockquote></td>
<td><blockquote>
<p>–</p>
</blockquote></td>
</tr>
<tr class="even">
<td><blockquote>
<p><a href="http://www.openml.org/d/917">917</a></p>
</blockquote></td>
<td><blockquote>
<p>10.22</p>
</blockquote></td>
<td><blockquote>
<p>–</p>
</blockquote></td>
<td><blockquote>
<p><strong>8.33</strong></p>
</blockquote></td>
<td><blockquote>
<p>16.06</p>
</blockquote></td>
<td><blockquote>
<p>10.33</p>
</blockquote></td>
<td><blockquote>
<p>20.94</p>
</blockquote></td>
<td><blockquote>
<p>35.44</p>
</blockquote></td>
<td><blockquote>
<p>8.67</p>
</blockquote></td>
<td><blockquote>
<p>9.44</p>
</blockquote></td>
<td><blockquote>
<p>37.83</p>
</blockquote></td>
<td><blockquote>
<p>22.33</p>
</blockquote></td>
<td><blockquote>
<p>9.11</p>
</blockquote></td>
<td><blockquote>
<p>17.67</p>
</blockquote></td>
<td><blockquote>
<p>10.00</p>
</blockquote></td>
<td><blockquote>
<p>10.44</p>
</blockquote></td>
<td><blockquote>
<p>–</p>
</blockquote></td>
</tr>
<tr class="odd">
<td><blockquote>
<p><a href="http://www.openml.org/d/1049">1049</a></p>
</blockquote></td>
<td><blockquote>
<p>12.93</p>
</blockquote></td>
<td><blockquote>
<p><span id="_bookmark588" class="anchor"></span>–</p>
</blockquote></td>
<td><blockquote>
<p>20.36</p>
</blockquote></td>
<td><blockquote>
<p>19.92</p>
</blockquote></td>
<td><blockquote>
<p>13.14</p>
</blockquote></td>
<td><blockquote>
<p>19.57</p>
</blockquote></td>
<td><blockquote>
<p>20.06</p>
</blockquote></td>
<td><blockquote>
<p>13.28</p>
</blockquote></td>
<td><blockquote>
<p>15.84</p>
</blockquote></td>
<td><blockquote>
<p>18.96</p>
</blockquote></td>
<td><blockquote>
<p>17.22</p>
</blockquote></td>
<td><blockquote>
<p>12.95</p>
</blockquote></td>
<td><blockquote>
<p>18.52</p>
</blockquote></td>
<td><blockquote>
<p><strong>11.94</strong></p>
</blockquote></td>
<td><blockquote>
<p>14.38</p>
</blockquote></td>
<td><blockquote>
<p>–</p>
</blockquote></td>
</tr>
<tr class="even">
<td><blockquote>
<p><a href="http://www.openml.org/d/1111">1111</a></p>
</blockquote></td>
<td><blockquote>
<p>23.70</p>
</blockquote></td>
<td><blockquote>
<p>–</p>
</blockquote></td>
<td><blockquote>
<p>23.36</p>
</blockquote></td>
<td><blockquote>
<p>24.69</p>
</blockquote></td>
<td><blockquote>
<p>23.73</p>
</blockquote></td>
<td><blockquote>
<p>100.00</p>
</blockquote></td>
<td><blockquote>
<p>25.25</p>
</blockquote></td>
<td><blockquote>
<p>23.43</p>
</blockquote></td>
<td><blockquote>
<p><strong>22.27</strong></p>
</blockquote></td>
<td><blockquote>
<p>23.95</p>
</blockquote></td>
<td><blockquote>
<p>23.25</p>
</blockquote></td>
<td><blockquote>
<p>26.94</p>
</blockquote></td>
<td><blockquote>
<p>26.68</p>
</blockquote></td>
<td><blockquote>
<p>23.53</p>
</blockquote></td>
<td><blockquote>
<p>23.33</p>
</blockquote></td>
<td><blockquote>
<p>–</p>
</blockquote></td>
</tr>
<tr class="odd">
<td><blockquote>
<p><a href="http://www.openml.org/d/1120">1120</a></p>
</blockquote></td>
<td><blockquote>
<p>13.81</p>
</blockquote></td>
<td><blockquote>
<p>–</p>
</blockquote></td>
<td><blockquote>
<p>16.29</p>
</blockquote></td>
<td><blockquote>
<p>14.22</p>
</blockquote></td>
<td><blockquote>
<p>13.73</p>
</blockquote></td>
<td><blockquote>
<p>14.57</p>
</blockquote></td>
<td><blockquote>
<p>14.82</p>
</blockquote></td>
<td><blockquote>
<p>14.02</p>
</blockquote></td>
<td><blockquote>
<p>13.85</p>
</blockquote></td>
<td><blockquote>
<p>14.66</p>
</blockquote></td>
<td><blockquote>
<p>14.23</p>
</blockquote></td>
<td><blockquote>
<p><strong>13.22</strong></p>
</blockquote></td>
<td><blockquote>
<p>15.03</p>
</blockquote></td>
<td><blockquote>
<p>13.65</p>
</blockquote></td>
<td><blockquote>
<p>13.67</p>
</blockquote></td>
<td><blockquote>
<p>–</p>
</blockquote></td>
</tr>
<tr class="even">
<td><blockquote>
<p><a href="http://www.openml.org/d/1128">1128</a></p>
</blockquote></td>
<td><blockquote>
<p>4.21</p>
</blockquote></td>
<td><blockquote>
<p>–</p>
</blockquote></td>
<td><blockquote>
<p>4.90</p>
</blockquote></td>
<td><blockquote>
<p>4.96</p>
</blockquote></td>
<td><blockquote>
<p>4.76</p>
</blockquote></td>
<td><blockquote>
<p>4.21</p>
</blockquote></td>
<td><blockquote>
<p>5.08</p>
</blockquote></td>
<td><blockquote>
<p>4.52</p>
</blockquote></td>
<td><blockquote>
<p>4.59</p>
</blockquote></td>
<td><blockquote>
<p><strong>4.08</strong></p>
</blockquote></td>
<td><blockquote>
<p>4.59</p>
</blockquote></td>
<td><blockquote>
<p>50.00</p>
</blockquote></td>
<td><blockquote>
<p>9.23</p>
</blockquote></td>
<td><blockquote>
<p>4.33</p>
</blockquote></td>
<td><blockquote>
<p><strong>4.08</strong></p>
</blockquote></td>
<td><blockquote>
<p>–</p>
</blockquote></td>
</tr>
<tr class="odd">
<td><blockquote>
<p><a href="http://www.openml.org/d/293">293</a></p>
</blockquote></td>
<td><blockquote>
<p>2.86</p>
</blockquote></td>
<td><blockquote>
<p>24.40</p>
</blockquote></td>
<td><blockquote>
<p>3.41</p>
</blockquote></td>
<td><blockquote>
<p>–</p>
</blockquote></td>
<td><blockquote>
<p>–</p>
</blockquote></td>
<td><blockquote>
<p>100.00</p>
</blockquote></td>
<td><blockquote>
<p>19.30</p>
</blockquote></td>
<td><blockquote>
<p>3.01</p>
</blockquote></td>
<td><blockquote>
<p><strong>2.66</strong></p>
</blockquote></td>
<td><blockquote>
<p>20.94</p>
</blockquote></td>
<td><blockquote>
<p>–</p>
</blockquote></td>
<td><blockquote>
<p>–</p>
</blockquote></td>
<td><blockquote>
<p>8.05</p>
</blockquote></td>
<td><blockquote>
<p>2.86</p>
</blockquote></td>
<td><blockquote>
<p>2.74</p>
</blockquote></td>
<td><blockquote>
<p>4.05</p>
</blockquote></td>
</tr>
<tr class="even">
<td><blockquote>
<p><a href="http://www.openml.org/d/389">389</a></p>
</blockquote></td>
<td><blockquote>
<p>19.65</p>
</blockquote></td>
<td><blockquote>
<p>20.63</p>
</blockquote></td>
<td><blockquote>
<p>21.40</p>
</blockquote></td>
<td><blockquote>
<p>–</p>
</blockquote></td>
<td><blockquote>
<p>–</p>
</blockquote></td>
<td><blockquote>
<p><strong>17.50</strong></p>
</blockquote></td>
<td><blockquote>
<p>19.66</p>
</blockquote></td>
<td><blockquote>
<p>19.89</p>
</blockquote></td>
<td><blockquote>
<p>20.87</p>
</blockquote></td>
<td><blockquote>
<p>18.46</p>
</blockquote></td>
<td><blockquote>
<p>–</p>
</blockquote></td>
<td><blockquote>
<p>–</p>
</blockquote></td>
<td><blockquote>
<p>44.83</p>
</blockquote></td>
<td><blockquote>
<p>20.17</p>
</blockquote></td>
<td><blockquote>
<p>19.18</p>
</blockquote></td>
<td><blockquote>
<p>21.58</p>
</blockquote></td>
</tr>
</tbody>
</table>
<p><img src="./automlgithubpagesimages//media/image179.jpeg" width="442" /><img src="./automlgithubpagesimages//media/image179.jpeg" width="442" /></p>
<blockquote>
<p>130 M. Feurer et al.</p>
</blockquote>
<p>addition to the auto-tracks, in particular Table<a href="#_bookmark589">10.5</a>, phases Final 0–4). As such, we believe that Auto-sklearn is a promising system for use by both machine learning novices and experts.</p>
<p>Since the publication of the original NeurIPS paper [<a href="#_bookmark555">20</a>], Auto-sklearn has become a standard baseline for new approaches to automated machine learning, such as FLASH [<a href="#_bookmark590">46</a>], RECIPE [<a href="#_bookmark591">39</a>], Hyperband [<a href="#_bookmark592">32</a>], AutoPrognosis [<a href="#_bookmark593">3</a>], ML- PLAN [<a href="#_bookmark594">34</a>], Auto-Stacker [<a href="#_bookmark595">11</a>] and AlphaD3M [<a href="#_bookmark596">13</a>].</p>
<blockquote>
<p><em><strong>6.8.2</strong></em> <em><strong>Usage</strong></em></p>
<p>One important outcome of the research on Auto-sklearn is the <em>auto-sklearn</em> Python package. It is a drop-in replacement for any scikit-learn classiﬁer or regressor, similar to the classiﬁer provided by HYPEROPT-SKLEARN [<a href="#_bookmark561">30</a>] and can be used as follows:</p>
<p>import autosklearn .classification</p>
<p>cls = autosklearn .classification .AutoSklearnClassifier()</p>
<p>cls.fit (X_train, y_train)</p>
<p>predictions = cls .predict(X_test)</p>
<p>Auto-sklearn can be used with any loss function and resampling strategy to estimate the validation loss. Furthermore, it is possible to extend the classiﬁers and preprocessors Auto-sklearn can choose from. Since the initial publication we also added regression support to Auto-sklearn. We develop the package on <a href="https://github.com/automl/auto-sklearn"><em>https://github.com/automl/auto-sklearn</em></a>and it is available via the Python packaging index <a href="https://pypi.org"><em>pypi.org</em></a>. We provide documentation on <a href="https://automl.github.io/auto-sklearn/stable/">automl.github.io/auto-sklearn</a>.</p>
<p><em><strong>6.8.3</strong></em> <em><strong>Extensions</strong></em> <em><strong>in</strong></em> <em><strong>PoSH</strong></em> <em><strong>Auto-sklearn</strong></em></p>
<p>While Auto-sklearn as described in this chapter is limited to handling datasets of relatively modest size, in the context of the most recent AutoML challenge (AutoML 2, run in 2018; see Chap.<a href="#_bookmark13">10</a>), we have extended it towards also handling large datasets effectively. Auto-sklearn was able to handle datasets of several hundred thousand datapoints by using a cluster of 25 CPUs for two days, but not within the 20 min time budget required by the AutoML 2 challenge. As described in detail in a recent workshop paper [<a href="#_bookmark597">18</a>], this implied opening up the methods considered to also include extreme gradient boosting (in particular, XGBoost [<a href="#_bookmark598">12</a>]), using the multi- ﬁdelity approach of successive halving [<a href="#_bookmark599">28</a>] (also described in Chap.<a href="#_bookmark2">1</a>) to solve the CASH problem, and changing our meta-learning approach. We now brieﬂy describe the resulting system, <strong>PoSH</strong> <strong>Auto-sklearn</strong> (short for <em>Portfolio</em> <em>Successive</em> <em>Halving</em>, combined with Auto-sklearn), which obtained the best performance in the 2018 challenge.</p>
<p>6 Auto-sklearn: Efﬁcient and Robust Automated Machine Learning 131</p>
<p>PoSH Auto-sklearn starts by running successive halving with a ﬁxed portfolio of 16 machine learning pipeline conﬁgurations, and if there is time left, it uses the outcome of these runs to warmstart a combination of Bayesian optimization and successive halving. The ﬁxed portfolio of 16 pipelines was obtained by running greedy submodular function maximization to select a strong set of complementary conﬁgurations to optimize the performance obtained on a set of 421 datasets; the candidate conﬁgurations conﬁgured for this optimization were the 421 conﬁgura- tions found by running SMAC [<a href="#_bookmark558">27</a>] on each of these 421 datasets.</p>
<p>The combination of Bayesian optimization and successive halving we used to yield robust results within a short time window is an adaptation of the multi- ﬁdelity hyperparameter optimization method BOHB (Bayesian Optimization and HyperBand) [<a href="#_bookmark600">17</a>] discussed in Chap.<a href="#_bookmark2">1</a>. As budgets for this multiﬁdelity approach, we used the number of iterations for all iterative algorithms, except for the SVM, where we used dataset size as a budget.</p>
<p>Another extension for large datasets that is currently ongoing is our work on automated deep learning; this is discussed in the following chapter on Auto-Net.</p>
<p><em><strong>6.8.4</strong></em> <em><strong>Conclusion</strong></em> <em><strong>and</strong></em> <em><strong>Future</strong></em> <em><strong>Work</strong></em></p>
</blockquote>
<p>Following the AutoML approach taken by Auto-WEKA, we introduced Auto- sklearn, which performs favorably against the previous state of the art in AutoML. We also showed that our meta-learning and ensemble mechanisms improve its efﬁciency and robustness further.</p>
<p>While Auto-sklearn handles the hyperparameter tuning for a user, Auto-sklearn has hyperparameters on its own which inﬂuence its performance for a given time budget, such as the time limits discussed in Sects.<a href="#_bookmark552">6.5</a>,<a href="#_bookmark553">6.6</a>, and<a href="#_bookmark554">6.7</a>, or the resampling strategy used to calculate the loss function. We demonstrated in preliminary work that the choice of the resampling strategy and the selection of timeouts can be cast as a meta-learning problem itself [<a href="#_bookmark601">19</a>], but we would like to extend this to other possible design choices Auto-sklearn users face.</p>
<p>Since the time of writing the original paper, the ﬁeld of meta-learning has progressed a lot, giving access to multiple new methods to include meta information into Bayesian optimization. We expect that using one of the newer methods discussed in Chap.<a href="#_bookmark3">2</a>could substantially improve the optimization procedure.</p>
<p>Finally, having a fully automated procedure that can test hundreds of hyperpa- rameter conﬁgurations puts us at increased risk of overﬁtting to the validation set. To avoid this overﬁtting, we would like to combine Auto-sklearn with one of the techniques discussed in Chap.<a href="#_bookmark2">1</a>, techniques from differential privacy [<a href="#_bookmark602">14</a>], or other techniques yet to be developed.</p>
<blockquote>
<p>132 M. Feurer et al.</p>
</blockquote>
<p><strong>Acknowledgements</strong> This work was supported by the German Research Foundation (DFG), under Priority Programme Autonomous Learning (SPP 1527, grant HU 1900/3- 1), under Emmy Noether grant HU 1900/2- 1, and under the BrainLinks-BrainTools Cluster of Excellence (grant number EXC 1086).</p>
<blockquote>
<p><span id="_bookmark581" class="anchor"></span><strong>Bibliography</strong></p>
<p>1. Auto-WEKA website, <a href="http://www.cs.ubc.ca/labs/beta/Projects/autoweka" class="uri">http://www.cs.ubc.ca/labs/beta/Projects/autoweka</a></p>
<p><span id="_bookmark593" class="anchor"></span>2. Proc. of NeurIPS’15 (2015)</p>
<p>3. Ahmed, A., van der Schaar, M.: AutoPrognosis: Automated clinical prognostic modeling via Bayesian optimization with structured kernel learning. In: Proc. of ICML’18. pp. 139– 148</p>
<p><span id="_bookmark564" class="anchor"></span>(2018)</p>
<p>4. Bardenet, R., Brendel, M., Kégl, B., Sebag, M.: Collaborative hyperparameter tuning. In: Proc. <span id="_bookmark557" class="anchor"></span>of ICML’13. pp. 199–207 (2014)</p>
<p>5. Bergstra, J., Bardenet, R., Bengio, Y., Kégl, B.: Algorithms for hyper-parameter optimization. In: Proc. of NIPS’11. pp. 2546–2554 (2011)</p>
<p><span id="_bookmark543" class="anchor"><span id="_bookmark562" class="anchor"></span></span>6. Breiman, L.: Random forests. MLJ 45, 5–32 (2001)</p>
<p>7. Brochu, E., Cora, V., de Freitas, N.: A tutorial on Bayesian optimization of expensive cost functions, with application to active user modeling and hierarchical reinforcement learning. <span id="_bookmark577" class="anchor"></span>arXiv:1012.2599v1 [cs.LG] (2010)</p>
<p>8. Bürger, F., Pauli, J.: A holistic classiﬁcation optimization framework with feature selection, preprocessing, manifold learning and classiﬁers. In: Proc. of ICPRAM’15. pp. 52–68 (2015)</p>
<p>9. Caruana, R., Munson, A., Niculescu-Mizil, A.: Getting the most out of ensemble selection. In: <span id="_bookmark574" class="anchor"><span id="_bookmark573" class="anchor"></span></span>Proc. of ICDM’06. pp. 828–833 (2006)</p>
<p>10. Caruana, R., Niculescu-Mizil, A., Crew, G., Ksikes, A.: Ensemble selection from libraries of <span id="_bookmark595" class="anchor"></span>models. In: Proc. of ICML’04. p. 18 (2004)</p>
<p>11. Chen, B., Wu, H., Mo, W., Chattopadhyay, I., Lipson, H.: Autostacker: A compositional evolutionary learning system. In: Proc. of GECCO’18 (2018)</p>
<p>12. Chen, T., Guestrin, C.: XGBoost: A scalable tree boosting system. In: Proc. of KDD’16. pp. <span id="_bookmark598" class="anchor"><span id="_bookmark596" class="anchor"></span></span>785–794 (2016)</p>
<p>13. Drori, I., Krishnamurthy, Y., Rampin, R., Lourenco, R., One, J., Cho, K., Silva, C., Freire, J.: AlphaD3M: Machine learning pipeline synthesis. In: ICML AutoML workshop (2018)</p>
<p><span id="_bookmark602" class="anchor"></span>14. Dwork, C., Feldman, V., Hardt, M., Pitassi, T., Reingold, O., Roth, A.: Generalization in adaptive data analysis and holdout reuse. In: Proc. of NIPS’15 [<a href="#_bookmark581">2</a>], pp. 2350–2358</p>
<p><span id="_bookmark560" class="anchor"></span>15. Eggensperger, K., Feurer, M., Hutter, F., Bergstra, J., Snoek, J., Hoos, H., Leyton-Brown, K.: Towards an empirical foundation for assessing Bayesian optimization of hyperparameters. In: NIPS Workshop on Bayesian Optimization in Theory and Practice (2013)</p>
<p>16. Escalante, H., Montes, M., Sucar, E.: Ensemble particle swarm model selection. In: Proc. of <span id="_bookmark600" class="anchor"><span id="_bookmark576" class="anchor"></span></span>IJCNN’10. pp. 1–8. IEEE (Jul 2010)</p>
<p>17. Falkner, S., Klein, A., Hutter, F.: BOHB: Robust and Efﬁcient Hyperparameter Optimization <span id="_bookmark597" class="anchor"></span>at Scale. In: Proc. of ICML’18. pp. 1437– 1446 (2018)</p>
<p>18. Feurer, M., Eggensperger, K., Falkner, S., Lindauer, M., Hutter, F.: Practical automated machine learning for the automl challenge 2018. In: ICML AutoML workshop (2018)</p>
<p>19. Feurer, M., Hutter, F.: Towards further automation in automl. In: ICML AutoML workshop</p>
<p><span id="_bookmark555" class="anchor"><span id="_bookmark601" class="anchor"></span></span>(2018)</p>
<p>20. Feurer, M., Klein, A., Eggensperger, K., Springenberg, J., Blum, M., Hutter, F.: Efﬁcient and robust automated machine learning. In: Proc. of NIPS’15 [<a href="#_bookmark581">2</a>], pp. 2962–2970</p>
<p><span id="_bookmark545" class="anchor"></span>21. Feurer, M., Springenberg, J., Hutter, F.: Initializing Bayesian hyperparameter optimization via meta-learning. In: Proc. of AAAI’15. pp. 1128– 1135 (2015)</p>
<p>6 Auto-sklearn: Efﬁcient and Robust Automated Machine Learning 133</p>
<p><span id="_bookmark546" class="anchor"></span>22. Gomes, T., Prudêncio, R., Soares, C., Rossi, A., Carvalho, A.: Combining meta-learning and search techniques to select parameters for support vector machines. Neurocomputing 75(1), <span id="_bookmark541" class="anchor"></span>3– 13 (2012)</p>
<p>23. Guyon, I., Bennett, K., Cawley, G., Escalante, H., Escalera, S., Ho, T., N.Macià, Ray, B., Saeed, M., Statnikov, A., Viegas, E.: Design of the 2015 ChaLearn AutoML Challenge. In: Proc. of <span id="_bookmark571" class="anchor"></span>IJCNN’15 (2015)</p>
<p>24. Guyon, I., Saffari, A., Dror, G., Cawley, G.: Model selection: Beyond the Bayesian/Frequentist <span id="_bookmark556" class="anchor"></span>divide. JMLR 11, 61–87 (2010)</p>
<p>25. Hall, M., Frank, E., Holmes, G., Pfahringer, B., Reutemann, P., Witten, I.: The WEKA data mining software: An update. ACM SIGKDD Exploratians Newsletter 11(1), 10– 18 (2009)</p>
<p><span id="_bookmark584" class="anchor"></span>26. Hamerly, G., Elkan, C.: Learning the k in k-means. In: Proc. of NIPS’04. pp. 281–288 (2004)</p>
<p><span id="_bookmark558" class="anchor"></span>27. Hutter, F., Hoos, H., Leyton-Brown, K.: Sequential model-based optimization for general <span id="_bookmark599" class="anchor"></span>algorithm conﬁguration. In: Proc. of LION’11. pp. 507–523 (2011)</p>
<p>28. Jamieson, K., Talwalkar, A.: Non-stochastic best arm identiﬁcation and hyperparameter optimization. In: Proc. of AISTATS’16. pp. 240–248 (2016)</p>
<p>29. Kalousis, A.: Algorithm Selection via Meta-Learning. Ph.D. thesis, University of Geneve</p>
<p><span id="_bookmark561" class="anchor"><span id="_bookmark567" class="anchor"></span></span>(2002)</p>
<p>30. Komer, B., Bergstra, J., Eliasmith, C.: Hyperopt-sklearn: Automatic hyperparameter conﬁgu- <span id="_bookmark572" class="anchor"></span>ration for scikit-learn. In: ICML workshop on AutoML (2014)</p>
<p>31. Lacoste, A., Marchand, M., Laviolette, F., Larochelle, H.: Agnostic Bayesian learning of <span id="_bookmark592" class="anchor"></span>ensembles. In: Proc. of ICML’14. pp. 611–619 (2014)</p>
<p>32. Li, L., Jamieson, K., DeSalvo, G., Rostamizadeh, A., Talwalkar, A.: Hyperband: A novel bandit-based approach to hyperparameter optimization. JMLR 18(185), 1–52 (2018)</p>
<p>33. Michie, D., Spiegelhalter, D., Taylor, C., Campbell, J.: Machine Learning, Neural and <span id="_bookmark568" class="anchor"><span id="_bookmark594" class="anchor"></span></span>Statistical Classiﬁcation. Ellis Horwood (1994)</p>
<p>34. Mohr, F., Wever, M., Hüllermeier, E.: Ml-plan: Automated machine learning via hierarchical <span id="_bookmark580" class="anchor"></span>planning. Machine Learning (2018)</p>
<p>35. Niculescu-Mizil, A., Perlich, C., Swirszcz, G., Sindhwani, V., Liu, Y., Melville, P., Wang, D., Xiao, J., Hu, J., Singh, M., Shang, W., Zhu, Y.: Winning the KDD cup orange challenge with ensemble selection. The 2009 Knowledge Discovery in Data Competition pp. 23–34 (2009)</p>
<p><span id="_bookmark550" class="anchor"></span>36. Pedregosa, F., Varoquaux, G., Gramfort, A., Michel, V., Thirion, B., Grisel, O., Blondel, M., Prettenhofer, P., Weiss, R., Dubourg, V., Vanderplas, J., Passos, A., Cournapeau, D., Brucher, M., Perrot, M., Duchesnay, E.: Scikit-learn: Machine learning in Python. JMLR 12, 2825–2830</p>
<p><span id="_bookmark569" class="anchor"></span>(2011)</p>
<p>37. Pfahringer, B., Bensusan, H., Giraud-Carrier, C.: Meta-learning by landmarking various <span id="_bookmark547" class="anchor"></span>learning algorithms. In: Proc. of ICML’00. pp. 743–750 (2000)</p>
<p>38. Reif, M., Shafait, F., Dengel, A.: Meta-learning for evolutionary parameter optimization of <span id="_bookmark591" class="anchor"></span>classiﬁers. Machine Learning 87, 357–380 (2012)</p>
<p>39. de Sá, A., Pinto, W., Oliveira, L., Pappa, G.: RECIPE: a grammar-based framework for automatically evolving classiﬁcation pipelines. In: Proc. of ECGP’17. pp. 246–261 (2017)</p>
</blockquote>
<p><span id="_bookmark544" class="anchor"></span>40. Shahriari, B., Swersky, K., Wang, Z., Adams, R., de Freitas, N.: Taking the human out of the loop: A review of Bayesian optimization. Proceedings of the IEEE 104(1), 148– 175 (2016)</p>
<p><span id="_bookmark559" class="anchor"></span>41. Snoek, J., Larochelle, H., Adams, R.: Practical Bayesian optimization of machine learning <span id="_bookmark542" class="anchor"></span>algorithms. In: Proc. of NIPS’12. pp. 2960–2968 (2012)</p>
<p>42. Thornton, C., Hutter, F., Hoos, H., Leyton-Brown, K.: Auto-WEKA: combined selection and hyperparameter optimization of classiﬁcation algorithms. In: Proc. of KDD’13. pp. 847–855</p>
<blockquote>
<p>(2013)</p>
<p>134 M. Feurer et al.</p>
<p><span id="_bookmark566" class="anchor"></span>43. Vanschoren, J., van Rijn, J., Bischl, B., Torgo, L.: OpenML: Networked science in machine <span id="_bookmark575" class="anchor"></span>learning. SIGKDD Explorations 15(2), 49–60 (2013)</p>
<p><span id="_bookmark565" class="anchor"></span>44. Wolpert, D.: Stacked generalization. Neural Networks 5, 241–259 (1992)</p>
<p>45. Yogatama, D., Mann, G.: Efﬁcient transfer learning method for automatic hyperparameter <span id="_bookmark590" class="anchor"></span>tuning. In: Proc. of AISTATS’14. pp. 1077– 1085 (2014)</p>
<p>46. Zhang, Y., Bahadori, M., Su, H., Sun, J.: FLASH: Fast Bayesian Optimization for Data Analytic Pipelines. In: Proc. of KDD’16. pp. 2065–2074 (2016)</p>
<p><strong>Open</strong> <strong>Access</strong> This chapter is licensed under the terms of the Creative Commons Attribution 4.0 International License <a href="http://creativecommons.org/licenses/by/4.0/">(http://creativecommons.org/licenses/by/4.0/</a>), which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence and indicate if changes were made.</p>
<p>The images or other third party material in this chapter are included in the chapter’s Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the chapter’s Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder.</p>
</blockquote>
<p><img src="./automlgithubpagesimages//media/image390.png" width="75" height="26" /></p>
<p><img src="./automlgithubpagesimages//media/image391.png" width="41" height="41" /><img src="./automlgithubpagesimages//media/image9.jpeg" width="136" /></p>
<blockquote>
<p><span id="_bookmark10" class="anchor"></span><strong>Chapter</strong> <strong>7</strong></p>
<p><strong>Towards</strong> <strong>Automatically-Tuned</strong> <strong>Deep</strong></p>
<p><strong>Neural</strong> <strong>Networks</strong></p>
</blockquote>
<p><img src="./automlgithubpagesimages//media/image392.png" /></p>
<blockquote>
<p><strong>Hector</strong> <strong>Mendoza,</strong> <strong>Aaron</strong> <strong>Klein,</strong> <strong>Matthias</strong> <strong>Feurer,</strong> <strong>Jost</strong> <strong>Tobias</strong> <strong>Springenberg,</strong> <strong>Matthias</strong> <strong>Urban,</strong> <strong>Michael</strong> <strong>Burkart,</strong> <strong>Maximilian</strong> <strong>Dippel,</strong> <strong>Marius</strong> <strong>Lindauer,</strong> <strong>and</strong> <strong>Frank</strong> <strong>Hutter</strong></p>
<p><strong>Abstract</strong> Recent advances in AutoML have led to automated tools that can</p>
</blockquote>
<p>compete with machine learning experts on supervised learning tasks. In this work, we present two versions of Auto-Net, which provide automatically-tuned deep neural networks without any human intervention. The ﬁrst version, Auto-Net 1.0, builds upon ideas from the competition-winning system Auto-sklearn by using the Bayesian Optimization method SMAC and uses Lasagne as the underlying deep learning (DL) library. The more recent Auto-Net 2.0 builds upon a recent combination of Bayesian Optimization and HyperBand, called BOHB, and uses PyTorch as DL library. To the best of our knowledge, Auto-Net 1.0 was the ﬁrst automatically-tuned neural network to win competition datasets against human experts (as part of the ﬁrst AutoML challenge). Further empirical results show that ensembling Auto-Net 1.0 with Auto-sklearn can perform better than either approach alone, and that Auto-Net 2.0 can perform better yet.</p>
<blockquote>
<p><strong>7.1</strong> <strong>Introduction</strong></p>
</blockquote>
<p>Neural networks have signiﬁcantly improved the state of the art on a variety of benchmarks in recent years and opened many new promising research avenues [<a href="#_bookmark603">22</a>, <a href="#_bookmark604">27</a>, <a href="#_bookmark605">36</a>, <a href="#_bookmark606">39</a>, <a href="#_bookmark607">41</a>]. However, neural networks are not easy to use for non-experts since their performance crucially depends on proper settings of a large set of hyperparameters (e.g., learning rate and weight decay) and architecture choices (e.g., number of layers and type of activation functions). Here, we present work</p>
<blockquote>
<p>H. Mendoza · A. Klein · M. Feurer · J. T. Springenberg · M. Urban · M. Burkart · M. Dippel</p>
<p>M. Lindauer</p>
<p>Department of Computer Science, University of Freiburg, Freiburg, Baden-Württemberg, Germany</p>
<p>e-mail: <a href="mailto:fh@informatik.uni-freiburg.de">fh@informatik.uni-freiburg.de</a></p>
<p>F. Hutter (凶)</p>
<p>Department of Computer Science, University of Freiburg, Freiburg, Germany</p>
<p>© The Author(s) 2019</p>
<p>F. Hutter et al. (eds.), <em>Automated</em> <em>Machine</em> <em>Learning</em>, The Springer Series on Challenges in Machine Learning, <a href="https://doi.org/10.1007/978-3-030-05318-5_7" class="uri">https://doi.org/10.1007/978-3-030-05318-5_7</a></p>
<p>136 H. Mendoza et al.</p>
<p>towards effective off-the-shelf neural networks based on approaches from automated</p>
<p>machine learning (AutoML).</p>
</blockquote>
<p>AutoML aims to provide effective off-the-shelf learning systems to free experts and non-experts alike from the tedious and time-consuming tasks of selecting the right algorithm for a dataset at hand, along with the right preprocessing method and the various hyperparameters of all involved components. Thornton et al. [<a href="#_bookmark608">43</a>] phrased this AutoML problem as a combined algorithm selection and hyperpa- rameter optimization (CASH) problem, which aims to identify the combination of algorithm components with the best (cross-)validation performance.</p>
<p>One powerful approach for solving this CASH problem treats this cross- validation performance as an expensive blackbox function and uses Bayesian optimization [<a href="#_bookmark609">4</a>, <a href="#_bookmark610">35</a>] to search for its optimizer. While Bayesian optimization typically uses Gaussian processes [<a href="#_bookmark611">32</a>], these tend to have problems with the special characteristics of the CASH problem (high dimensionality; both categorical and continuous hyperparameters; many conditional hyperparameters, which are only relevant for some instantiations of other hyperparameters). Adapting GPs to handle these characteristics is an active ﬁeld of research [<a href="#_bookmark612">40</a>, <a href="#_bookmark613">44</a>], but so far Bayesian optimization methods using tree-based models [<a href="#_bookmark614">2</a>, <a href="#_bookmark615">17</a>] work best in the CASH setting [<a href="#_bookmark616">9</a>, <a href="#_bookmark608">43</a>].</p>
<p>Auto-Net is modelled after the two prominent AutoML systems Auto- WEKA [<a href="#_bookmark608">43</a>] and Auto-sklearn [<a href="#_bookmark617">11</a>], discussed in Chaps.<a href="#_bookmark6">4</a> and <a href="#_bookmark8">6</a> of this book, respectively. Both of these use the random forest-based Bayesian optimization method SMAC [<a href="#_bookmark615">17</a>] to tackle the CASH problem – to ﬁnd the best instantiation of classiﬁers in WEKA [<a href="#_bookmark618">16</a>] and scikit-learn [<a href="#_bookmark619">30</a>], respectively. Auto-sklearn employs two additional methods to boost performance. Firstly, it uses meta-learning [<a href="#_bookmark620">3</a>] based on experience on previous datasets to start SMAC from good conﬁgurations [<a href="#_bookmark621">12</a>]. Secondly, since the eventual goal is to make the best predictions, it is wasteful to try out dozens of machine learning models and then only use the single best model; instead, Auto-sklearn saves all models evaluated by SMAC and constructs an ensemble of these with the ensemble selection technique [<a href="#_bookmark622">5</a>]. Even though both Auto-WEKA and Auto-sklearn include a wide range of supervised learning methods, neither includes modern neural networks.</p>
<blockquote>
<p>Here, we introduce two versions of a system we dub <em>Auto-Net</em> to ﬁll this gap. Auto-Net 1.0 is based on Theano and has a relatively simple search space, while the more recent Auto-Net 2.0 is implemented in PyTorch and uses a more complex space and more recent advances in DL. A further difference lies in their respective search procedure: Auto-Net 1.0 automatically conﬁgures neural networks with SMAC [<a href="#_bookmark615">17</a>], following the same AutoML approach as Auto-WEKA and Auto- sklearn, while Auto-Net 2.0 builds upon BOHB [<a href="#_bookmark623">10</a>], a combination of Bayesian Optimization (BO) and efﬁcient racing strategies via HyperBand (HB) [<a href="#_bookmark624">23</a>].</p>
</blockquote>
<p>Auto-Net 1.0 achieved the best performance on two datasets in the human expert track of the recent <em>ChaLearn</em> <em>AutoML</em> <em>Challenge</em> [<a href="#_bookmark625">14</a>]. To the best of our knowledge, this is the ﬁrst time that a fully-automatically-tuned neural network won a competition dataset against human experts. Auto-Net 2.0 further improves upon Auto-Net 1.0 on large data sets, showing recent progress in the ﬁeld.</p>
<p><img src="./automlgithubpagesimages//media/image12.jpeg" width="136" /></p>
<blockquote>
<p>7 Towards Automatically-Tuned Deep Neural Networks 137</p>
<p>We describe the conﬁguration space and implementation of Auto-Net 1.0 in Sect.<a href="#_bookmark626">7.2</a> and of Auto-Net 2.0 in Sect.<a href="#_bookmark627">7.3</a>. We then study their performance empirically in Sect.<a href="#_bookmark628">7.4</a> and conclude in Sect.<a href="#_bookmark629">7.5</a>. We omit a thorough discussion of related work and refer to Chap.<a href="#_bookmark4">3</a> of this book for an overview on the extremely active ﬁeld of neural architecture search. Nevertheless, we note that several other recent tools follow Auto-Net’s goal of automating deep learning, such as Auto- Keras [<a href="#_bookmark630">20</a>], Photon-AI, H2O.ai, DEvol or Google’s Cloud AutoML service.</p>
<p>This chapter is an extended version of our 2016 paper introducing Auto-Net, presented at the <em>2016</em> <em>ICML</em> <em>Workshop</em> <em>on</em> <em>AutoML</em> [<a href="#_bookmark631">26</a>].</p>
<p><span id="_bookmark626" class="anchor"></span><strong>7.2</strong> <strong>Auto-Net</strong> <strong>1.0</strong></p>
<p>We now introduce Auto-Net 1.0 and describe its implementation. We chose to implement this ﬁrst version of Auto-Net as an extension of Auto-sklearn [<a href="#_bookmark617">11</a>] by adding a new classiﬁcation (and regression) component; the reason for this choice was that it allows us to leverage existing parts of the machine learning pipeline: feature preprocessing, data preprocessing and ensemble construction. Here, we limit Auto-Net to fully-connected feed-forward neural networks, since they apply to a wide range of different datasets; we defer the extension to other types of neural networks, such as convolutional or recurrent neural networks, to future work. To have access to neural network techniques we use the Python deep learning library Lasagne [<a href="#_bookmark632">6</a>], which is built around Theano [<a href="#_bookmark633">42</a>]. However, we note that in general our approach is independent of the neural network implementation.</p>
</blockquote>
<p>Following [<a href="#_bookmark614">2</a>] and [<a href="#_bookmark634">7</a>], we distinguish between layer-independent <em>network</em> <em>hyper-</em> <em>parameters</em> that control the architecture and training procedure and <em>per-layer</em> <em>hyperparameters</em> that are set for each layer. In total, we optimize 63 hyperparame- ters (see Table <a href="#_bookmark635">7.1</a>), using the same conﬁguration space for all types of supervised learning (binary, multiclass and multilabel classiﬁcation, as well as regression). Sparse datasets also share the same conﬁguration space. (Since neural networks cannot handle datasets in sparse representation out of the box, we transform the data into a dense representation on a per-batch basis prior to feeding it to the neural network.)</p>
<blockquote>
<p>The per-layer hyperparameters of layer k are conditionally dependent on the number of layers being at least k . For practical reasons, we constrain the number of layers to be between one and six: ﬁrstly, we aim to keep the training time of a single conﬁguration low,<a href="#_bookmark636">1</a> and secondly each layer adds eight per-layer hyperparameters to the conﬁguration space, such that allowing additional layers would further complicate the conﬁguration process.</p>
<p>The most common way to optimize the internal weights of neural networks is via stochastic gradient descent (SGD) using partial derivatives calculated with back- propagation. Standard SGD crucially depends on the correct setting of the learning</p>
<p>1We aimed to be able to afford the evaluation of several dozens of conﬁgurations within a time <span id="_bookmark636" class="anchor"></span>budget of two days on a single CPU.</p>
<p><strong>Table</strong> <strong>7.1</strong> Conﬁguration space of Auto-Net. The conﬁguration space for the preprocessing methods can be found in [<a href="#_bookmark617">11</a>]</p>
</blockquote>
<table>
<tbody>
<tr class="odd">
<td></td>
<td><blockquote>
<p>Name</p>
</blockquote></td>
<td><blockquote>
<p>Range</p>
</blockquote></td>
<td><blockquote>
<p>Default</p>
</blockquote></td>
<td><blockquote>
<p>log scale</p>
</blockquote></td>
<td><blockquote>
<p>Type</p>
</blockquote></td>
<td><blockquote>
<p>Conditional</p>
</blockquote></td>
</tr>
<tr class="even">
<td><blockquote>
<p>Network hyperparameters</p>
</blockquote></td>
<td><blockquote>
<p>Batch size</p>
</blockquote></td>
<td><blockquote>
<p>[32, 4096]</p>
</blockquote></td>
<td><blockquote>
<p>32</p>
</blockquote></td>
<td><blockquote>
<p>/</p>
</blockquote></td>
<td><blockquote>
<p>ﬂoat</p>
</blockquote></td>
<td><blockquote>
<p>–</p>
</blockquote></td>
</tr>
<tr class="odd">
<td></td>
<td><blockquote>
<p>Number of updates</p>
</blockquote></td>
<td><blockquote>
<p>[50, 2500]</p>
</blockquote></td>
<td><blockquote>
<p>200</p>
</blockquote></td>
<td><blockquote>
<p>/</p>
</blockquote></td>
<td><blockquote>
<p>int</p>
</blockquote></td>
<td><blockquote>
<p>–</p>
</blockquote></td>
</tr>
<tr class="even">
<td></td>
<td><blockquote>
<p>Number of layers</p>
</blockquote></td>
<td><blockquote>
<p>[1, 6]</p>
</blockquote></td>
<td><blockquote>
<p>1</p>
</blockquote></td>
<td><blockquote>
<p>–</p>
</blockquote></td>
<td><blockquote>
<p>int</p>
</blockquote></td>
<td><blockquote>
<p>–</p>
</blockquote></td>
</tr>
<tr class="odd">
<td></td>
<td><blockquote>
<p>Learning rate</p>
</blockquote></td>
<td><blockquote>
<p>[10−6 , 1.0]</p>
</blockquote></td>
<td><blockquote>
<p>10−2</p>
</blockquote></td>
<td><blockquote>
<p>/</p>
</blockquote></td>
<td><blockquote>
<p>ﬂoat</p>
</blockquote></td>
<td><blockquote>
<p>–</p>
</blockquote></td>
</tr>
<tr class="even">
<td></td>
<td><blockquote>
<p>L2 regularization</p>
</blockquote></td>
<td><blockquote>
<p>[10−7 , 10−2]</p>
</blockquote></td>
<td><blockquote>
<p>10−4</p>
</blockquote></td>
<td><blockquote>
<p>/</p>
</blockquote></td>
<td><blockquote>
<p>ﬂoat</p>
</blockquote></td>
<td><blockquote>
<p>–</p>
</blockquote></td>
</tr>
<tr class="odd">
<td></td>
<td><blockquote>
<p>Dropout output layer</p>
</blockquote></td>
<td><blockquote>
<p>[0.0, 0.99]</p>
</blockquote></td>
<td><blockquote>
<p>0.5</p>
</blockquote></td>
<td><blockquote>
<p>/</p>
</blockquote></td>
<td><blockquote>
<p>ﬂoat</p>
</blockquote></td>
<td><blockquote>
<p>–</p>
</blockquote></td>
</tr>
<tr class="even">
<td></td>
<td><blockquote>
<p>Solver type</p>
</blockquote></td>
<td><blockquote>
<p>{SGD, Momentum, Adam, Adadelta, Adagrad, smorm, Nesterov }</p>
</blockquote></td>
<td><blockquote>
<p>smorm3s</p>
</blockquote></td>
<td><blockquote>
<p>–</p>
</blockquote></td>
<td><blockquote>
<p>cat</p>
</blockquote></td>
<td><blockquote>
<p>–</p>
</blockquote></td>
</tr>
<tr class="odd">
<td></td>
<td><blockquote>
<p>lr-policy</p>
</blockquote></td>
<td><blockquote>
<p>{Fixed, Inv, Exp, Step}</p>
</blockquote></td>
<td><blockquote>
<p>Fixed</p>
</blockquote></td>
<td><blockquote>
<p>–</p>
</blockquote></td>
<td><blockquote>
<p>cat</p>
</blockquote></td>
<td><blockquote>
<p>–</p>
</blockquote></td>
</tr>
<tr class="even">
<td><blockquote>
<p>Conditioned on solver type</p>
</blockquote></td>
<td><blockquote>
<p>1</p>
</blockquote></td>
<td><blockquote>
<p>[10−4 , 10−1]</p>
</blockquote></td>
<td><blockquote>
<p>10−1</p>
</blockquote></td>
<td><blockquote>
<p>/</p>
</blockquote></td>
<td><blockquote>
<p>ﬂoat</p>
</blockquote></td>
<td><blockquote>
<p>/</p>
</blockquote></td>
</tr>
<tr class="odd">
<td></td>
<td><blockquote>
<p>2</p>
</blockquote></td>
<td><blockquote>
<p>[10−4 , 10−1]</p>
</blockquote></td>
<td><blockquote>
<p>10−1</p>
</blockquote></td>
<td><blockquote>
<p>/</p>
</blockquote></td>
<td><blockquote>
<p>ﬂoat</p>
</blockquote></td>
<td><blockquote>
<p>/</p>
</blockquote></td>
</tr>
<tr class="even">
<td></td>
<td><blockquote>
<p>ρ</p>
</blockquote></td>
<td><blockquote>
<p>[0.05, 0.99]</p>
</blockquote></td>
<td><blockquote>
<p>0.95</p>
</blockquote></td>
<td><blockquote>
<p>/</p>
</blockquote></td>
<td><blockquote>
<p>ﬂoat</p>
</blockquote></td>
<td><blockquote>
<p>/</p>
</blockquote></td>
</tr>
<tr class="odd">
<td></td>
<td><blockquote>
<p>Momentum</p>
</blockquote></td>
<td><blockquote>
<p>[0.3, 0.999]</p>
</blockquote></td>
<td><blockquote>
<p>0.9</p>
</blockquote></td>
<td><blockquote>
<p>/</p>
</blockquote></td>
<td><blockquote>
<p>ﬂoat</p>
</blockquote></td>
<td><blockquote>
<p>/</p>
</blockquote></td>
</tr>
<tr class="even">
<td><blockquote>
<p>Conditioned on lr-policy</p>
</blockquote></td>
<td><blockquote>
<p>γ</p>
</blockquote></td>
<td><blockquote>
<p>[10−3 , 10−1]</p>
</blockquote></td>
<td><blockquote>
<p>10−2</p>
</blockquote></td>
<td><blockquote>
<p>/</p>
</blockquote></td>
<td><blockquote>
<p>ﬂoat</p>
</blockquote></td>
<td><blockquote>
<p>/</p>
</blockquote></td>
</tr>
<tr class="odd">
<td></td>
<td><blockquote>
<p>k</p>
</blockquote></td>
<td><blockquote>
<p>[0.0, 1.0]</p>
</blockquote></td>
<td><blockquote>
<p>0.5</p>
</blockquote></td>
<td><blockquote>
<p>–</p>
</blockquote></td>
<td><blockquote>
<p>ﬂoat</p>
</blockquote></td>
<td><blockquote>
<p>/</p>
</blockquote></td>
</tr>
<tr class="even">
<td></td>
<td><blockquote>
<p>s</p>
</blockquote></td>
<td><blockquote>
<p><span id="_bookmark635" class="anchor"></span>[2, 20]</p>
</blockquote></td>
<td><blockquote>
<p>2</p>
</blockquote></td>
<td><blockquote>
<p>–</p>
</blockquote></td>
<td><blockquote>
<p>int</p>
</blockquote></td>
<td><blockquote>
<p>/</p>
</blockquote></td>
</tr>
<tr class="odd">
<td><blockquote>
<p>Per-layer hyperparameters</p>
</blockquote></td>
<td><blockquote>
<p>Activation-type</p>
</blockquote></td>
<td><blockquote>
<p>{Sigmoid, TanH, ScaledTanH, ELU, ReLU, Leaky, Linear}</p>
</blockquote></td>
<td><blockquote>
<p>ReLU</p>
</blockquote></td>
<td><blockquote>
<p>–</p>
</blockquote></td>
<td><blockquote>
<p>cat</p>
</blockquote></td>
<td><blockquote>
<p>/</p>
</blockquote></td>
</tr>
<tr class="even">
<td></td>
<td><blockquote>
<p>Number of units</p>
</blockquote></td>
<td><blockquote>
<p>[64, 4096]</p>
</blockquote></td>
<td><blockquote>
<p>128</p>
</blockquote></td>
<td><blockquote>
<p>/</p>
</blockquote></td>
<td><blockquote>
<p>int</p>
</blockquote></td>
<td><blockquote>
<p>/</p>
</blockquote></td>
</tr>
<tr class="odd">
<td></td>
<td><blockquote>
<p>Dropout in layer</p>
</blockquote></td>
<td><blockquote>
<p>[0.0, 0.99]</p>
</blockquote></td>
<td><blockquote>
<p>0.5</p>
</blockquote></td>
<td><blockquote>
<p>–</p>
</blockquote></td>
<td><blockquote>
<p>ﬂoat</p>
</blockquote></td>
<td><blockquote>
<p>/</p>
</blockquote></td>
</tr>
<tr class="even">
<td></td>
<td><blockquote>
<p>Weight initialization</p>
</blockquote></td>
<td><blockquote>
<p>{Constant, Normal, Uniform, Glorot-Uniform, Glorot-Normal,</p>
<p>He-Normal, He-Uniform, Orthogonal, Sparse}</p>
</blockquote></td>
<td><blockquote>
<p>He-Normal</p>
</blockquote></td>
<td><blockquote>
<p>–</p>
</blockquote></td>
<td><blockquote>
<p>cat</p>
</blockquote></td>
<td><blockquote>
<p>/</p>
</blockquote></td>
</tr>
<tr class="odd">
<td></td>
<td><blockquote>
<p>Std. normal init.</p>
</blockquote></td>
<td><blockquote>
<p>[10−7 , 0. 1]</p>
</blockquote></td>
<td><blockquote>
<p>0.0005</p>
</blockquote></td>
<td><blockquote>
<p>–</p>
</blockquote></td>
<td><blockquote>
<p>ﬂoat</p>
</blockquote></td>
<td><blockquote>
<p>/</p>
</blockquote></td>
</tr>
<tr class="even">
<td></td>
<td><blockquote>
<p>Leakiness</p>
</blockquote></td>
<td><blockquote>
<p>[0.01, 0.99]</p>
</blockquote></td>
<td><blockquote>
<p>1</p>
<p>3</p>
</blockquote></td>
<td><blockquote>
<p>–</p>
</blockquote></td>
<td><blockquote>
<p>ﬂoat</p>
</blockquote></td>
<td><blockquote>
<p>/</p>
</blockquote></td>
</tr>
<tr class="odd">
<td></td>
<td><blockquote>
<p>tanh scale in</p>
</blockquote></td>
<td><blockquote>
<p>[0.5, 1.0]</p>
</blockquote></td>
<td><blockquote>
<p>2/3</p>
</blockquote></td>
<td><blockquote>
<p>–</p>
</blockquote></td>
<td><blockquote>
<p>ﬂoat</p>
</blockquote></td>
<td><blockquote>
<p>/</p>
</blockquote></td>
</tr>
<tr class="even">
<td></td>
<td><blockquote>
<p>tanh scale out</p>
</blockquote></td>
<td><blockquote>
<p>[1. 1, 3.0]</p>
</blockquote></td>
<td><blockquote>
<p>1.7159</p>
</blockquote></td>
<td><blockquote>
<p>/</p>
</blockquote></td>
<td><blockquote>
<p>ﬂoat</p>
</blockquote></td>
<td><blockquote>
<p>/</p>
</blockquote></td>
</tr>
</tbody>
</table>
<blockquote>
<p>7 Towards Automatically-Tuned Deep Neural Networks 139</p>
</blockquote>
<p>rate hyperparameter. To lessen this dependency, various algorithms (solvers) for stochastic gradient descent have been proposed. We include the following well- known methods from the literature in the conﬁguration space of Auto-Net: vanilla stochastic gradient descent (SGD), stochastic gradient descent with momentum (Momentum), Adam [<a href="#_bookmark637">21</a>], Adadelta [<a href="#_bookmark638">48</a>], Nesterov momentum [<a href="#_bookmark639">28</a>] and Adagrad [<a href="#_bookmark640">8</a>]. Additionally, we used a variant of the vSGD optimizer [<a href="#_bookmark641">33</a>], dubbed “smorm”, in which the estimate of the Hessian is replaced by an estimate of the squared gradient (calculated as in the RMSprop procedure). Each of these methods comes with a learning rate α and an own set of hyperparameters, for example Adam’s momentum vectors β 1 and β2 . Each solver’s hyperparameter(s) are only active if the corresponding solver is chosen.</p>
<blockquote>
<p>We also decay the learning rate α over time, using the following policies (which multiply the initial learning rate by a factor αdecay after each epoch t = 0 . . . T ):</p>
<p>• Fixed: αdecay = 1</p>
<p>• Inv: αdecay = (1 + γt)(−k)</p>
<p>• Exp: αdecay = γ t</p>
<p>• Step: αdecay = γ「t/s1</p>
<p>Here, the hyperparameters k, s and γ are conditionally dependent on the choice of the policy.</p>
<p>To search for a strong instantiation in this conditional search space of Auto-Net 1.0, as in Auto-WEKA and Auto-sklearn, we used the random-forest based Bayesian optimization method SMAC [<a href="#_bookmark615">17</a>]. SMAC is an anytime approach that keeps track of the best conﬁguration seen so far and outputs this when terminated.</p>
<p><span id="_bookmark627" class="anchor"></span><strong>7.3</strong> <strong>Auto-Net</strong> <strong>2.0</strong></p>
<p>AutoNet 2.0 differs from AutoNet 1.0 mainly in the following three aspects:</p>
<p>• it uses PyTorch [<a href="#_bookmark642">29</a>] instead of Lasagne as a deep learning library</p>
<p>• it uses a larger conﬁguration space including up-to-date deep learning techniques, modern architectures (such as ResNets) and includes more compact representa- tions of the search space, and</p>
<p>• it applies BOHB [<a href="#_bookmark623">10</a>] instead of SMAC to obtain a well-performing neural network more efﬁciently.</p>
<p>In the following, we will discuss these points in more detail.</p>
</blockquote>
<p>Since the development and maintenance of Lasagne ended last year, we chose a different Python library for Auto-Net 2.0. The most popular deep learning libraries right now are PyTorch [<a href="#_bookmark642">29</a>] and Tensorﬂow [<a href="#_bookmark643">1</a>]. These come with quite similar features and mostly differ in the level of detail they give insight into. For example, PyTorch offers the user the possibility to trace all computations during training. While there are advantages and disadvantages for each of these libraries, we decided</p>
<blockquote>
<p>140 H. Mendoza et al.</p>
<p>to use PyTorch because of its ability to dynamically construct computational graphs. For this reason, we also started referring to Auto-Net 2.0 as Auto-PyTorch.</p>
</blockquote>
<p>The search space of AutoNet 2.0 includes both hyperparameters for module selection (e.g. scheduler type, network architecture) and hyperparameters for each of the speciﬁc modules. It supports different deep learning modules, such as network type, learning rate scheduler, optimizer and regularization technique, as described below. Auto-Net 2.0 is also designed to be easily extended; users can add their own modules to the ones listed below.</p>
<blockquote>
<p>Auto-Net 2.0 currently offers four different network types:</p>
<p><strong>Multi-Layer</strong> <strong>Perceptrons</strong> This is a standard implementation of conventional MLPs extended by dropout layers [<a href="#_bookmark644">38</a>]. Similar as in AutoNet 1.0, each layer of the MLP is parameterized (e.g., number of units and dropout rate).</p>
<p><strong>Residual</strong> <strong>Neural</strong> <strong>Networks</strong> These are deep neural networks that learn residual functions [<a href="#_bookmark645">47</a>], with the difference that we use fully connected layers instead of convolutional ones. As is standard with ResNets, the architecture consists of M groups, each of which stacks N residual blocks in sequence. While the architecture of each block is ﬁxed, the number M of groups, the number of blocks N per group, as well as the width of each group is determined by hyperparameters, as shown in Table <a href="#_bookmark646">7.2</a>.</p>
<p><strong>Shaped</strong> <strong>Multi-Layer</strong> <strong>Perceptrons</strong> To avoid that every layer has its own hyper- parameters (which is an inefﬁcient representation to search), in shaped MLPs the overall shape of the layers is predetermined, e.g. as a funnel, long funnel, diamond, hexagon, brick, or triangle. We followed the shapes from <a href="https://mikkokotila.github.io/slate/#shapes">https://</a> <a href="https://mikkokotila.github.io/slate/#shapes">mikkokotila.github.io/slate/#shapes</a>; Ilya Loshchilov also proposed parameteri- zation by such shapes to us before [<a href="#_bookmark647">25</a>].</p>
<p><strong>Shaped</strong> <strong>Residual</strong> <strong>Networks</strong> A ResNet where the overall shape of the layers is predetermined (e.g. funnel, long funnel, diamond, hexagon, brick, triangle).</p>
</blockquote>
<p>The network types of ResNets and ShapedResNets can also use any of the regularization methods of Shake-Shake [<a href="#_bookmark648">13</a>] and ShakeDrop [<a href="#_bookmark649">46</a>]. MixUp [<a href="#_bookmark650">49</a>] can be used for all networks.</p>
<blockquote>
<p>The optimizers currently supported in Auto-Net 2.0 are Adam [<a href="#_bookmark637">21</a>] and SGD with momentum. Moreover, Auto-Net 2.0 currently offers ﬁve different schedulers that change the optimizer’s learning rate over time (as a function of the number of epochs):</p>
<p><strong>Exponential</strong> This multiplies the learning rate with a constant factor in each</p>
<p>epoch.</p>
<p><strong>Step</strong> This decays the learning rate by a multiplicative factor after a constant number of steps.</p>
<p><strong>Cyclic</strong> This modiﬁes the learning rate in a certain range, alternating between increasing and decreasing [<a href="#_bookmark651">37</a>].</p>
<p><strong>Cosine</strong> <strong>Annealing</strong> <strong>with</strong> <strong>Warm</strong> <strong>Restarts</strong> [<a href="#_bookmark652">24</a>] This learning rate schedule imple- ments multiple phases of convergence. It cools down the learning rate to zero following a cosine decay [<a href="#_bookmark652">24</a>], and after each convergence phase heats it up to start a next phase of convergence, often to a better optimum. The network weights</p>
</blockquote>
<p>7 Towards Automatically-Tuned Deep Neural Networks 141</p>
<blockquote>
<p><span id="_bookmark646" class="anchor"></span><strong>Table</strong> <strong>7.2</strong> Conﬁguration space of Auto-Net 2.0. There are 112 hyperparameters in total</p>
</blockquote>
<table>
<tbody>
<tr class="odd">
<td></td>
<td><blockquote>
<p>Name</p>
</blockquote></td>
<td><blockquote>
<p>Range</p>
</blockquote></td>
<td><blockquote>
<p>Default</p>
</blockquote></td>
<td><blockquote>
<p>Log scale</p>
</blockquote></td>
<td><blockquote>
<p>Type</p>
</blockquote></td>
<td><blockquote>
<p>Conditional</p>
</blockquote></td>
</tr>
<tr class="even">
<td><blockquote>
<p>General</p>
<p>hyperparameters</p>
</blockquote></td>
<td><blockquote>
<p>Batch size</p>
<p>Use mixup</p>
<p>Mixup alpha</p>
<p>Network</p>
<p>Optimizer</p>
<p>Preprocessor</p>
<p>Imputation</p>
<p>Use loss weight strategy Learning rate scheduler</p>
</blockquote></td>
<td><blockquote>
<p>[32, 500]</p>
<p>{True, False}</p>
<p>[0.0, 1.0]</p>
<p>{MLP, ResNet, ShapedMLP, ShapedResNet}</p>
<p>{Adam, SGD}</p>
<p>{nystroem, kernel pca, fast ica, kitchen sinks, truncated svd}</p>
<p>{most frequent, median, mean}</p>
<p>{True, False}</p>
<p>{Step, Exponential, OnPlateau, Cyclic, CosineAnnealing}</p>
</blockquote></td>
<td><blockquote>
<p>32</p>
<p>True</p>
<p>1.0</p>
<p>MLP</p>
<p>Adam</p>
<p>Nystroem Most frequent</p>
<p>True</p>
<p>Step</p>
</blockquote></td>
<td><blockquote>
<p>/</p>
<p>−</p>
<p>−</p>
<p>−</p>
<p>−</p>
<p>−</p>
<p>−</p>
<p>−</p>
<p>−</p>
</blockquote></td>
<td><blockquote>
<p>int</p>
<p>bool</p>
<p>ﬂoat</p>
<p>cat</p>
<p>cat</p>
<p>cat</p>
<p>cat</p>
<p>cat</p>
<p>cat</p>
</blockquote></td>
<td><blockquote>
<p>−</p>
<p>−</p>
<p>/</p>
<p>−</p>
<p>−</p>
<p>−</p>
<p>−</p>
<p>−</p>
<p>−</p>
</blockquote></td>
</tr>
<tr class="odd">
<td><blockquote>
<p><strong>Preprocessor</strong></p>
</blockquote></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td><blockquote>
<p>Nystroem</p>
</blockquote></td>
<td><blockquote>
<p>Coef</p>
<p>Degree</p>
<p>Gamma</p>
<p>Kernel</p>
<p>Num components</p>
</blockquote></td>
<td><blockquote>
<p>[−1.0, 1.0]</p>
<p>[2, 5]</p>
<p>[0.00003, 8.0]</p>
<p>{poly, rbf, sigmoid, cosine}</p>
<p>[50, 10000]</p>
</blockquote></td>
<td><blockquote>
<p>0.0</p>
<p>3</p>
<p>0.1</p>
<p>rbf</p>
<p>100</p>
</blockquote></td>
<td><blockquote>
<p>−</p>
<p>−</p>
<p>/</p>
<p>−</p>
<p>/</p>
</blockquote></td>
<td><blockquote>
<p>ﬂoat</p>
<p>int</p>
<p>ﬂoat</p>
<p>cat</p>
<p>int</p>
</blockquote></td>
<td><blockquote>
<p>/</p>
<p>/</p>
<p>/</p>
<p>/</p>
<p>/</p>
</blockquote></td>
</tr>
<tr class="odd">
<td><blockquote>
<p>Kitchen sinks</p>
</blockquote></td>
<td><blockquote>
<p>Gamma</p>
<p>Num components</p>
</blockquote></td>
<td><blockquote>
<p>[0.00003, 8.0]</p>
<p>[50, 10000]</p>
</blockquote></td>
<td><blockquote>
<p>1.0</p>
<p>100</p>
</blockquote></td>
<td><blockquote>
<p>/</p>
<p>/</p>
</blockquote></td>
<td><blockquote>
<p>ﬂoat</p>
<p>int</p>
</blockquote></td>
<td><blockquote>
<p>/</p>
<p>/</p>
</blockquote></td>
</tr>
<tr class="even">
<td><blockquote>
<p>Truncated SVD</p>
</blockquote></td>
<td><blockquote>
<p>Target dimension</p>
</blockquote></td>
<td><blockquote>
<p>[10, 256]</p>
</blockquote></td>
<td><blockquote>
<p>128</p>
</blockquote></td>
<td><blockquote>
<p>−</p>
</blockquote></td>
<td><blockquote>
<p>int</p>
</blockquote></td>
<td><blockquote>
<p>/</p>
</blockquote></td>
</tr>
<tr class="odd">
<td><blockquote>
<p>Kernel PCA</p>
</blockquote></td>
<td><blockquote>
<p>Coef</p>
<p>Degree</p>
<p>Gamma</p>
<p>Kernel</p>
<p>Num components</p>
</blockquote></td>
<td><blockquote>
<p>[−1.0, 1.0]</p>
<p>[2, 5]</p>
<p>[0.00003, 8.0]</p>
<p>{poly, rbf, sigmoid, cosine}</p>
<p>[50, 10000]</p>
</blockquote></td>
<td><blockquote>
<p>0.0</p>
<p>3</p>
<p>0.1</p>
<p>rbf</p>
<p>100</p>
</blockquote></td>
<td><blockquote>
<p>−</p>
<p>−</p>
<p>/</p>
<p>−</p>
<p>/</p>
</blockquote></td>
<td><blockquote>
<p>ﬂoat</p>
<p>int</p>
<p>ﬂoat</p>
<p>cat</p>
<p>int</p>
</blockquote></td>
<td><blockquote>
<p>/</p>
<p>/</p>
<p>/</p>
<p>/</p>
<p>/</p>
</blockquote></td>
</tr>
<tr class="even">
<td><blockquote>
<p>Fast ICA</p>
</blockquote></td>
<td><blockquote>
<p>Algorithm</p>
<p>Fun</p>
<p>Whiten</p>
<p>Num components</p>
</blockquote></td>
<td><blockquote>
<p>{parallel, deﬂation}</p>
<p>{logcosh, exp, cube}</p>
<p>{True, False}</p>
<p>[10, 2000]</p>
</blockquote></td>
<td><blockquote>
<p>Parallel</p>
<p>Logcosh</p>
<p>True</p>
<p>1005</p>
</blockquote></td>
<td><blockquote>
<p>−</p>
<p>−</p>
<p>−</p>
<p>−</p>
</blockquote></td>
<td><blockquote>
<p>cat</p>
<p>cat</p>
<p>cat</p>
<p>int</p>
</blockquote></td>
<td><blockquote>
<p>/</p>
<p>/</p>
<p>/</p>
<p>/</p>
</blockquote></td>
</tr>
<tr class="odd">
<td><blockquote>
<p><strong>Networks</strong></p>
</blockquote></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td><blockquote>
<p>MLP</p>
</blockquote></td>
<td><blockquote>
<p>Activation function Num layers Num units (for layer i) Dropout (for layer i)</p>
</blockquote></td>
<td><blockquote>
<p>{Sigmoid, Tanh, ReLu}</p>
<p>[1, 15]</p>
<p>[10, 1024]</p>
<p>[0.0, 0.5]</p>
</blockquote></td>
<td><blockquote>
<p>Sigmoid</p>
<p>9</p>
<p>100</p>
<p>0.25</p>
</blockquote></td>
<td><blockquote>
<p>−</p>
<p>−</p>
<p>/</p>
<p>−</p>
</blockquote></td>
<td><blockquote>
<p>cat</p>
<p>int</p>
<p>int</p>
<p>int</p>
</blockquote></td>
<td><blockquote>
<p>/</p>
<p>/</p>
<p>/</p>
<p>/</p>
</blockquote></td>
</tr>
<tr class="odd">
<td><blockquote>
<p>ResNet</p>
</blockquote></td>
<td><blockquote>
<p>Activation function Residual block groups Blocks per group Num units (for group i) Use dropout</p>
<p>Dropout (for group i) Use shake drop Use shake shake Shake drop βmax</p>
</blockquote></td>
<td><blockquote>
<p>{Sigmoid, Tanh, ReLu}</p>
<p>[1, 9]</p>
<p>[1, 4]</p>
<p>[128, 1024]</p>
<p>{True, False}</p>
<p>[0.0, 0.9]</p>
<p>{True, False}</p>
<p>{True, False}</p>
<p>[0.0, 1.0]</p>
</blockquote></td>
<td><blockquote>
<p>Sigmoid</p>
<p>4</p>
<p>2</p>
<p>200</p>
<p>True</p>
<p>0.5</p>
<p>True</p>
<p>True</p>
<p>0.5</p>
</blockquote></td>
<td><blockquote>
<p>−</p>
<p>−</p>
<p>−</p>
<p>/</p>
<p>−</p>
<p>−</p>
<p>−</p>
<p>−</p>
<p>−</p>
</blockquote></td>
<td><blockquote>
<p>cat</p>
<p>int</p>
<p>int</p>
<p>int</p>
<p>bool</p>
<p>int</p>
<p>bool</p>
<p>bool</p>
<p>ﬂoat</p>
</blockquote></td>
<td><blockquote>
<p>/</p>
<p>/</p>
<p>/</p>
<p>/</p>
<p>/</p>
<p>/</p>
<p>/</p>
<p>/</p>
<p>/</p>
</blockquote></td>
</tr>
<tr class="even">
<td><blockquote>
<p>ShapedMLP</p>
</blockquote></td>
<td><blockquote>
<p>Activation function Num layers Max units per layer Network shape Max dropout per layer Dropout shape</p>
</blockquote></td>
<td><blockquote>
<p>{Sigmoid, Tanh, ReLu}</p>
<p>[3, 15]</p>
<p>[10, 1024]</p>
<p>{Funnel, LongFunnel, Diamond, Hexagon, Brick, Triangle, Stairs}</p>
<p>[0.0, 0.6</p>
<p>{Funnel, LongFunnel, Diamond, Hexagon, Brick, Triangle, Stairs}</p>
</blockquote></td>
<td><blockquote>
<p>Sigmoid</p>
<p>9</p>
<p>200</p>
<p>Funnel</p>
<p>0.2</p>
<p>Funnel</p>
</blockquote></td>
<td><blockquote>
<p>−</p>
<p>−</p>
<p>/</p>
<p>−</p>
<p>−</p>
<p>−</p>
</blockquote></td>
<td><blockquote>
<p>cat</p>
<p>int</p>
<p>int</p>
<p>cat</p>
<p>ﬂoat</p>
<p>cat</p>
</blockquote></td>
<td><blockquote>
<p>/</p>
<p>/</p>
<p>/</p>
<p>/</p>
<p>/</p>
<p>/</p>
</blockquote></td>
</tr>
<tr class="odd">
<td><blockquote>
<p>Shaped ResNet</p>
</blockquote></td>
<td><blockquote>
<p>Activation function</p>
<p>Num layers</p>
<p>Blocks per layer Use dropout Max units per layer Network shape Max dropout per layer Dropout shape Use shake drop Use shake shake Shake drop βmax</p>
</blockquote></td>
<td><blockquote>
<p>{Sigmoid, Tanh, ReLu}</p>
<p>[3, 9]</p>
<p>[1, 4]</p>
<p>{True, False}</p>
<p>[10, 1024]</p>
<p>{Funnel, LongFunnel, Diamond, Hexagon, Brick, Triangle, Stairs}</p>
<p>[0.0, 0.6</p>
<p>{Funnel, LongFunnel, Diamond, Hexagon, Brick, Triangle, Stairs}</p>
<p>{True, False}</p>
<p>{True, False}</p>
<p>[0.0, 1.0]</p>
</blockquote></td>
<td><blockquote>
<p>Sigmoid</p>
<p>4</p>
<p>2</p>
<p>True</p>
<p>200</p>
<p>Funnel</p>
<p>0.2</p>
<p>Funnel</p>
<p>True</p>
<p>True</p>
<p>0.5</p>
</blockquote></td>
<td><blockquote>
<p>−</p>
<p>−</p>
<p>−</p>
<p>−</p>
<p>/</p>
<p>−</p>
<p>−</p>
<p>−</p>
<p>−</p>
<p>−</p>
<p>−</p>
</blockquote></td>
<td><blockquote>
<p>cat</p>
<p>int</p>
<p>int</p>
<p>bool</p>
<p>int</p>
<p>cat</p>
<p>ﬂoat</p>
<p>cat</p>
<p>bool</p>
<p>bool</p>
<p>ﬂoat</p>
</blockquote></td>
<td><blockquote>
<p>/</p>
<p>/</p>
<p>/</p>
<p>/</p>
<p>/</p>
<p>/</p>
<p>/</p>
<p>/</p>
<p>/</p>
<p>/</p>
<p>/</p>
</blockquote></td>
</tr>
<tr class="even">
<td><blockquote>
<p><strong>Optimizers</strong></p>
</blockquote></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td><blockquote>
<p>Adam</p>
</blockquote></td>
<td><blockquote>
<p>Learning rate</p>
<p>Weight decay</p>
</blockquote></td>
<td><blockquote>
<p>[0.0001, 0.1]</p>
<p>[0.0001, 0.1]</p>
</blockquote></td>
<td><blockquote>
<p>0.003</p>
<p>0.05</p>
</blockquote></td>
<td><blockquote>
<p>/</p>
<p>−</p>
</blockquote></td>
<td><blockquote>
<p>ﬂoat</p>
<p>ﬂoat</p>
</blockquote></td>
<td><blockquote>
<p>/</p>
<p>/</p>
</blockquote></td>
</tr>
<tr class="even">
<td><blockquote>
<p>SGD</p>
</blockquote></td>
<td><blockquote>
<p>Learning rate</p>
<p>Weight decay</p>
<p>Momentum</p>
</blockquote></td>
<td><blockquote>
<p>[0.0001, 0.1]</p>
<p>[0.0001, 0.1]</p>
<p>[0.1, 0.9]</p>
</blockquote></td>
<td><blockquote>
<p>0.003</p>
<p>0.05</p>
<p>0.3</p>
</blockquote></td>
<td><blockquote>
<p>/</p>
<p>−</p>
<p>/</p>
</blockquote></td>
<td><blockquote>
<p>ﬂoat</p>
<p>ﬂoat</p>
<p>ﬂoat</p>
</blockquote></td>
<td><blockquote>
<p>/</p>
<p>/</p>
<p>/</p>
</blockquote></td>
</tr>
<tr class="odd">
<td><blockquote>
<p><strong>Schedulers</strong></p>
</blockquote></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td><blockquote>
<p>Step</p>
</blockquote></td>
<td><blockquote>
<p>V</p>
<p>Step size</p>
</blockquote></td>
<td><blockquote>
<p>[0.001, 0.9]</p>
<p>[1, 10]</p>
</blockquote></td>
<td><blockquote>
<p>0.4505</p>
<p>6</p>
</blockquote></td>
<td><blockquote>
<p>−</p>
<p>−</p>
</blockquote></td>
<td><blockquote>
<p>ﬂoat</p>
<p>int</p>
</blockquote></td>
<td><blockquote>
<p>/</p>
<p>/</p>
</blockquote></td>
</tr>
<tr class="odd">
<td><blockquote>
<p>Exponential</p>
</blockquote></td>
<td><blockquote>
<p>V</p>
</blockquote></td>
<td><blockquote>
<p>[0.8, 0.9999]</p>
</blockquote></td>
<td><blockquote>
<p>0.89995</p>
</blockquote></td>
<td><blockquote>
<p>−</p>
</blockquote></td>
<td><blockquote>
<p>ﬂoat</p>
</blockquote></td>
<td><blockquote>
<p>/</p>
</blockquote></td>
</tr>
<tr class="even">
<td><blockquote>
<p>OnPlateau</p>
</blockquote></td>
<td><blockquote>
<p>V</p>
<p>Patience</p>
</blockquote></td>
<td><blockquote>
<p>[0.05, 0.5]</p>
<p>[3, 10]</p>
</blockquote></td>
<td><blockquote>
<p>0.275</p>
<p>6</p>
</blockquote></td>
<td><blockquote>
<p>−</p>
<p>−</p>
</blockquote></td>
<td><blockquote>
<p>ﬂoat</p>
<p>int</p>
</blockquote></td>
<td><blockquote>
<p>/</p>
<p>/</p>
</blockquote></td>
</tr>
<tr class="odd">
<td><blockquote>
<p>Cyclic</p>
</blockquote></td>
<td><blockquote>
<p>Cycle length</p>
<p>Max factor</p>
<p>Min factor</p>
</blockquote></td>
<td><blockquote>
<p>[3, 10]</p>
<p>[1.0, 2.0]</p>
<p>[0.001, 1.0]</p>
</blockquote></td>
<td><blockquote>
<p>6</p>
<p>1.5</p>
<p>0.5</p>
</blockquote></td>
<td><blockquote>
<p>−</p>
<p>−</p>
<p>−</p>
</blockquote></td>
<td><blockquote>
<p>int</p>
<p>ﬂoat</p>
<p>ﬂoat</p>
</blockquote></td>
<td><blockquote>
<p>/</p>
<p>/</p>
<p>/</p>
</blockquote></td>
</tr>
<tr class="even">
<td><blockquote>
<p>Cosine</p>
<p>annealing</p>
</blockquote></td>
<td><blockquote>
<p>T0</p>
<p>Tmult</p>
</blockquote></td>
<td><blockquote>
<p>[1, 20]</p>
<p>[1.0, 2.0]</p>
</blockquote></td>
<td><blockquote>
<p>10</p>
<p>1.5</p>
</blockquote></td>
<td><blockquote>
<p>−</p>
<p>−</p>
</blockquote></td>
<td><blockquote>
<p>int</p>
<p>ﬂoat</p>
</blockquote></td>
<td><blockquote>
<p>/</p>
<p>/</p>
</blockquote></td>
</tr>
</tbody>
</table>
<blockquote>
<p>142 H. Mendoza et al.</p>
<p>are not modiﬁed when heating up the learning rate, such that the next phase of convergence is warm-started.</p>
<p><strong>OnPlateau</strong> <a href="#_bookmark653">This scheduler2</a> changes the learning rate whenever a metric stops improving; speciﬁcally, it multiplies the current learning rate with a factor γ if there was no improvement after p epochs.</p>
<p>Similar to Auto-Net 1.0, Auto-Net 2.0 can search over pre-processing techniques. Auto-Net 2.0 currently supports Nyström [<a href="#_bookmark654">45</a>], Kernel principal component analysis [<a href="#_bookmark655">34</a>], fast independent component analysis [<a href="#_bookmark656">18</a>], random kitchen sinks [<a href="#_bookmark657">31</a>] and trun- cated singular value decomposition [<a href="#_bookmark658">15</a>]. Users can specify a list of pre-processing techniques to be taken into account and can also choose between different balancing and normalization strategies (for balancing strategies only weighting the loss is available, and for normalization strategies, min-max normalization and standard- ization are supported). In contrast to Auto-Net 1.0, Auto-Net 2.0 does not build an ensemble at the end (although this feature will likely be added soon). All hyperparameters of Auto-Net 2.0 with their respective ranges and default values can be found in Table <a href="#_bookmark646">7.2</a>.</p>
<p>As optimizer for this highly conditional space, we used BOHB (<strong>B</strong>ayesian <strong>O</strong>ptimization with <strong>H</strong>yper<strong>B</strong>and) [<a href="#_bookmark623">10</a>], which combines conventional Bayesian opti- mization with the bandit-based strategy Hyperband [<a href="#_bookmark624">23</a>] to substantially improve its efﬁciency. Like Hyperband, BOHB uses repeated runs of Successive Halving [<a href="#_bookmark659">19</a>] to invest most runtime in promising neural networks and stops training neural networks with poor performance early. Like in Bayesian optimization, BOHB learns which kinds of neural networks yield good results. Speciﬁcally, like the BO method TPE [<a href="#_bookmark614">2</a>], BOHB uses a kernel density estimator (KDE) to describe regions of high performance in the space of neural networks (architectures and hyperparameter settings) and trades off exploration versus exploitation using this KDE. One of the advantages of BOHB is that it is easily parallelizable, achieving almost linear speedups with an increasing number of workers [<a href="#_bookmark623">10</a>].</p>
<p>As a budget for BOHB we can either handle epochs or (wallclock) time in minutes; by default we use runtime, but users can freely adapt the different budget parameters. An example usage is shown in Algorithm <a href="#_bookmark660">1</a>. Similar to Auto-sklearn, Auto-Net is built as a plugin estimator for scikit-learn. Users have to provide a training set and a performance metric (e.g., accuracy). Optionally, they might</p>
</blockquote>
<table>
<tbody>
<tr class="odd">
<td><blockquote>
<p><span id="_bookmark660" class="anchor"></span><strong>Algorithm</strong> <strong>1</strong> Example usage of Auto-Net 2.0</p>
</blockquote></td>
</tr>
<tr class="even">
<td><blockquote>
<p><strong>from</strong> autonet <strong>import</strong> AutoNetClassiﬁcation</p>
<p>cls = AutoNetClassiﬁcation(min_budget=5, max_budget=20, max_runtime=120) cls.ﬁt(X_train, Y_train)</p>
<p>predictions = cls.predict(X_test)</p>
</blockquote></td>
</tr>
</tbody>
</table>
<blockquote>
<p>7 Towards Automatically-Tuned Deep Neural Networks 143</p>
<p>specify a validation and testset. The validation set is used during training to get a measure for the performance of the network and to train the KDE models of BOHB.</p>
<p><span id="_bookmark628" class="anchor"></span><strong>7.4</strong> <strong>Experiments</strong></p>
</blockquote>
<p>We now empirically evaluate our methods. Our implementations of Auto-Net run on both CPUs and GPUs, but since neural networks heavily employ matrix operations they run much faster on GPUs. Our CPU-based experiments were run on a compute cluster, each node of which has two eight-core Intel Xeon E5-2650 v2 CPUs, running at 2.6 GHz, and a shared memory of 64 GB. Our GPU-based experiments</p>
<blockquote>
<p>were run on a compute cluster, each node of which has four GeForce GTX TITAN X GPUs.</p>
<p><span id="_bookmark661" class="anchor"></span><em><strong>7.4.1</strong></em> <em><strong>Baseline</strong></em> <em><strong>Evaluation</strong></em> <em><strong>of</strong></em> <em><strong>Auto-Net</strong></em> <em><strong>1.0</strong></em> <em><strong>and</strong></em> <em><strong>Auto-sklearn</strong></em></p>
<p>In our ﬁrst experiment, we compare different instantiations of Auto-Net 1.0 on the ﬁve datasets of phase 0 of the AutoML challenge. First, we use the CPU-based and GPU-based versions to study the difference of running NNs on different hardware. Second, we allow the combination of neural networks with the models from Auto- sklearn. Third, we also run Auto-sklearn without neural networks as a baseline.</p>
<p>On each dataset, we performed 10 one-day runs of each method, allowing up to 100 min for the evaluation of a single conﬁguration by ﬁve-fold cross-validation on the training set. For each time step of each run, following [<a href="#_bookmark617">11</a>] we constructed an ensemble from the models it had evaluated so far and plot the test error of that ensemble over time. In practice, we would either use a separate process to calculate the ensembles in parallel or compute them after the optimization process.</p>
</blockquote>
<p>Fig. <a href="#_bookmark662">7.1</a> shows the results on two of the ﬁve datasets. First, we note that the GPU-based version of Auto-Net was consistently about an order of magnitude faster than the CPU-based version. Within the given ﬁxed compute budget, the CPU-based version consistently performed worst, whereas the GPU-based version performed best on the newsgroups dataset (see Fig.<a href="#_bookmark662">7.1</a>a), tied with Auto-sklearn on 3 of the other datasets, and performed worse on one. Despite the fact that the CPU-based Auto-Net was very slow, in 3/5 cases the combination of Auto-sklearn and CPU- based Auto-Net still improved over Auto-sklearn; this can, for example, be observed for the dorothea dataset in Fig.<a href="#_bookmark662">7.1</a>b.</p>
<blockquote>
<p><em><strong>7.4.2</strong></em> <em><strong>Resultsfor</strong></em> <em><strong>AutoML</strong></em> <em><strong>Competition</strong></em> <em><strong>Datasets</strong></em></p>
<p>Having developed Auto-Net 1.0 during the ﬁrst AutoML challenge, we used a combination of Auto-sklearn and GPU-based Auto-Net for the last two phases</p>
<p>144 H. Mendoza et al.</p>
</blockquote>
<p><img src="./automlgithubpagesimages//media/image393.jpeg" width="440" height="191" /></p>
<blockquote>
<p><span id="_bookmark662" class="anchor"></span><strong>Fig.</strong> <strong>7.1</strong> Results for the four methods on two datasets from <em>Tweakathon0</em> of the AutoML challenge. We show errors on the competition’s validation set (not the test set since its true labels are not available), with our methods only having access to the training set. To avoid clutter, we plot mean error ± 1/4 standard deviations over the 10 runs of each method. (<strong>a</strong>) newsgroups dataset. (<strong>b</strong>) dorothea dataset</p>
</blockquote>
<p><img src="./automlgithubpagesimages//media/image394.jpeg" width="441" height="126" /></p>
<blockquote>
<p><span id="_bookmark663" class="anchor"></span><strong>Fig.</strong> <strong>7.2</strong> Ofﬁcial AutoML human expert track competition results for the three datasets for which we used Auto-Net. We only show the top 10 entries. (<strong>a</strong>) alexis dataset. (<strong>b</strong>) yolanda dataset.</p>
<p>(<strong>c</strong>) tania dataset</p>
</blockquote>
<p>to win the respective human expert tracks. Auto-sklearn has been developed for much longer and is much more robust than Auto-Net, so for 4/5 datasets in the 3rd phase and 3/5 datasets in the 4th phase Auto-sklearn performed best by itself and we only submitted its results. Here, we discuss the three datasets for which we used Auto-Net. Fig. <a href="#_bookmark663">7.2</a>shows the ofﬁcial AutoML human expert track competition results for the three datasets for which we used Auto-Net. The alexis dataset was part of the 3rd phase (“advanced phase”) of the challenge. For this, we ran Auto-Net on ﬁve GPUs in parallel (using SMAC in shared-model mode) for 18 h. Our submission included an automatically-constructed ensemble of 39 models and clearly outperformed all human experts, reaching an AUC score of 90%, while the best human competitor (Ideal Intel Analytics) only reached 80%. To our best knowledge, this is the ﬁrst time an automatically-constructed neural network won a competition dataset. The yolanda and tania datasets were part of the 4th phase (“expert phase”) of the challenge. For yolanda, we ran Auto-Net for 48 h</p>
<p><img src="./automlgithubpagesimages//media/image395.png" height="19" /><img src="./automlgithubpagesimages//media/image396.png" width="33" /><img src="./automlgithubpagesimages//media/image397.png" width="71" height="39" /></p>
<blockquote>
<p><span id="_bookmark20" class="anchor"></span>7 Towards Automatically-Tuned Deep Neural Networks 145</p>
</blockquote>
<table>
<tbody>
<tr class="odd">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td><blockquote>
<p><img src="./automlgithubpagesimages//media/image398.png" width="353" height="264" /><img src="./automlgithubpagesimages//media/image399.png" /> <img src="./automlgithubpagesimages//media/image400.png" /> Aut</p>
</blockquote></td>
<td>oNet-GP</td>
<td>U</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td><img src="./automlgithubpagesimages//media/image401.png" /></td>
<td><p><img src="./automlgithubpagesimages//media/image402.png" /></p>
<p><img src="./automlgithubpagesimages//media/image403.png" /></p></td>
<td><blockquote>
<p>Aut Aut Aut</p>
</blockquote></td>
<td><p>oNet-CP</p>
<p>oNet+Au</p>
<p>osklearn</p></td>
<td><p>U</p>
<p>toskle</p></td>
<td>arn</td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<blockquote>
<p>104</p>
<p>time [sec]</p>
<p><span id="_bookmark664" class="anchor"></span><strong>Fig.</strong> <strong>7.3</strong> Performance on the tania dataset over time. We show cross-validation performance on the training set since the true labels for the competition’s validation or test set are not available. To avoid clutter, we plot mean error ± 1/4 standard deviations over the 10 runs of each method</p>
<p>on eight GPUs and automatically constructed an ensemble of ﬁve neural networks, achieving a close third place. For tania, we ran Auto-Net for 48 h on eight GPUs along with Auto-sklearn on 25 CPUs, and in the end our automated ensembling script constructed an ensemble of eight 1-layer neural networks, two 2-layer neural networks, and one logistic regression model trained with SGD. This ensemble won the ﬁrst place on the tania dataset.</p>
</blockquote>
<p>For the tania dataset, we also repeated the experiments from Sect.<a href="#_bookmark661">7.4.1</a>. Fig. <a href="#_bookmark664">7.3</a> shows that for this dataset Auto-Net performed clearly better than Auto- sklearn, even when only running on CPUs. The GPU-based variant of Auto-Net performed best.</p>
<blockquote>
<p><em><strong>7.4.3</strong></em> <em><strong>Comparing</strong></em> <em><strong>AutoNet</strong></em> <em><strong>1.0</strong></em> <em><strong>and</strong></em> <em><strong>2.0</strong></em></p>
</blockquote>
<p>Finally, we show an illustrative comparison between Auto-Net 1.0 and 2.0. We note that Auto-Net 2.0 has a much more comprehensive search space than Auto-Net 1.0, and we therefore expect it to perform better on large datasets given enough time. We also expect that searching the larger space is harder than searching Auto-Net 1.0’s smaller space; however, since Auto-Net 2.0 uses the efﬁcient multi-ﬁdelity optimizer BOHB to terminate poorly-performing neural networks early on, it may nevertheless obtain strong anytime performance. On the other hand, Auto-Net 2.0</p>
<blockquote>
<p>146 H. Mendoza et al.</p>
<p><span id="_bookmark665" class="anchor"></span><strong>Table</strong> <strong>7.3</strong> Error metric of different Auto-Net versions, run for different times, all on CPU. We compare Auto-Net 1.0, ensembles of Auto-Net 1.0 and Auto-sklearn, Auto-Net 2.0 with one worker, and Auto-Net 2.0 with four workers. All results are means across 10 runs of each system. We show errors on the competition’s validation set (not the test set since its true labels are not available), with our methods only having access to the training set</p>
</blockquote>
<table>
<tbody>
<tr class="odd">
<td></td>
<td><blockquote>
<p>newsgroups</p>
</blockquote></td>
<td><blockquote>
<p>dorothea</p>
</blockquote></td>
</tr>
<tr class="even">
<td></td>
<td><blockquote>
<p>103 s</p>
</blockquote></td>
<td><blockquote>
<p>104 s</p>
</blockquote></td>
</tr>
<tr class="odd">
<td><blockquote>
<p>Auto-Net 1.0</p>
</blockquote></td>
<td><blockquote>
<p>0.99</p>
</blockquote></td>
<td><blockquote>
<p>0.98</p>
</blockquote></td>
</tr>
<tr class="even">
<td><blockquote>
<p>Auto-sklearn + Auto-Net 1.0</p>
</blockquote></td>
<td><blockquote>
<p>0.94</p>
</blockquote></td>
<td><blockquote>
<p>0.76</p>
</blockquote></td>
</tr>
<tr class="odd">
<td><blockquote>
<p>Auto-Net 2.0: 1 worker</p>
</blockquote></td>
<td><blockquote>
<p>1.0</p>
</blockquote></td>
<td><blockquote>
<p>0.67</p>
</blockquote></td>
</tr>
<tr class="even">
<td><blockquote>
<p>Auto-Net 2.0: 4 workers</p>
</blockquote></td>
<td><blockquote>
<p>0.89</p>
</blockquote></td>
<td><blockquote>
<p>0.57</p>
</blockquote></td>
</tr>
</tbody>
</table>
<blockquote>
<p>so far does not implement ensembling, and due to this missing regularization component and its larger hypothesis space, it may be more prone to overﬁtting than</p>
<p>Auto-Net 1.0.</p>
<p>In order to test these expectations about performance on different-sized datasets, we used a medium-sized dataset (newsgroups, with 13k training data points) and a small one (dorothea, with 800 training data points). The results are presented in Table <a href="#_bookmark665">7.3</a>.</p>
</blockquote>
<p>On the medium-sized dataset newsgroups, Auto-Net 2.0 performed much better than Auto-Net 1.0, and using four workers also led to strong speedups on top of this, making Auto-Net 2.0 competitive to the ensemble of Auto-sklearn and Auto-Net 1.0. We found that despite Auto-Net 2.0’s larger search space its anytime performance (using the multi-ﬁdelity method BOHB) was better than that of Auto- Net 1.0 (using the blackbox optimization method SMAC). On the small dataset dorothea, Auto-Net 2.0 also performed better than Auto-Net 1.0 early on, but given enough time Auto-Net 1.0 performed slightly better. We attribute this to the lack of ensembling in Auto-Net 2.0, combined with its larger search space.</p>
<blockquote>
<p><span id="_bookmark629" class="anchor"></span><strong>7.5</strong> <strong>Conclusion</strong></p>
<p>We presented Auto-Net, which provides automatically-tuned deep neural networks without any human intervention. Even though neural networks show superior performance on many datasets, for traditional data sets with manually-deﬁned features they do not always perform best. However, we showed that, even in cases where other methods perform better, combining Auto-Net with Auto-sklearn to an ensemble often leads to an equal or better performance than either approach alone.</p>
</blockquote>
<p>Finally, we reported results on three datasets from the AutoML challenge’s human expert track, for which Auto-Net won one third place and two ﬁrst places. We showed that ensembles of Auto-sklearn and Auto-Net can get users the best of both worlds and quite often improve over the individual tools. First experiments on the new Auto-Net 2.0 showed that using a more comprehensive search space, combined with BOHB as an optimizer yields promising results.</p>
<blockquote>
<p>7 Towards Automatically-Tuned Deep Neural Networks 147</p>
<p>In future work, we aim to extend Auto-Net to more general neural network architectures, including convolutional and recurrent neural networks.</p>
</blockquote>
<p><strong>Acknowledgements</strong> This work has partly been supported by the European Research Council (ERC) under the European Union’s Horizon 2020 research and innovation programme under grant no. 716721.</p>
<blockquote>
<p><span id="_bookmark643" class="anchor"></span><strong>Bibliography</strong></p>
<p>1. Abadi, M., Barham, P., Chen, J., Chen, Z., Davis, A., Dean, J., Devin, M., Ghemawat, S., Irving, G., Isard, M., Kudlur, M., Levenberg, J., Monga, R., Moore, S., Murray, D., Steiner, B., Tucker, P., Vasudevan, V., Warden, P., Wicke, M., Yu, Y., Zheng, X.: Tensorﬂow: A system for large-scale machine learning. In: 12th USENIX Symposium on Operating Systems Design and Implementation (OSDI 16). pp. 265–283 (2016), <a href="https://www.usenix.org/system/files/conference/osdi16/osdi16-abadi.pdf">https://www.usenix.org/system/</a> <span id="_bookmark614" class="anchor"></span><a href="https://www.usenix.org/system/files/conference/osdi16/osdi16-abadi.pdf">ﬁles/conference/osdi16/osdi16-abadi.pdf</a></p>
<p>2. Bergstra, J., Bardenet, R., Bengio, Y., Kégl, B.: Algorithms for hyper-parameter optimization. In: Shawe-Taylor, J., Zemel, R., Bartlett, P., Pereira, F., Weinberger, K. (eds.) Proceedings of the 25th International Conference on Advances in Neural Information Processing Systems <span id="_bookmark620" class="anchor"></span>(NIPS’11). pp. 2546–2554 (2011)</p>
<p>3. Brazdil, P., Giraud-Carrier, C., Soares, C., Vilalta, R.: Metalearning: Applications to Data <span id="_bookmark609" class="anchor"></span>Mining. Springer Publishing Company, Incorporated, 1 edn. (2008)</p>
<p>4. Brochu, E., Cora, V., de Freitas, N.: A tutorial on Bayesian optimization of expensive cost functions, with application to active user modeling and hierarchical reinforcement learning. <span id="_bookmark622" class="anchor"></span>Computing Research Repository (CoRR) abs/1012.2599 (2010)</p>
<p>5. Caruana, R., Niculescu-Mizil, A., Crew, G., Ksikes, A.: Ensemble selection from libraries of models. In: In Proceedings of the 21st International Conference on Machine Learning. pp. <span id="_bookmark632" class="anchor"></span>137– 144. ACM Press (2004)</p>
<p>6. Dieleman, S., Schlüter, J., Raffel, C., Olson, E., Sønderby, S., Nouri, D., Maturana, D., Thoma, M., Battenberg, E., Kelly, J., Fauw, J.D., Heilman, M., diogo149, McFee, B., Weideman, H., takacsg84, peterderivaz, Jon, instagibbs, Rasul, K., CongLiu, Britefury, Degrave, J.: Lasagne: <span id="_bookmark634" class="anchor"></span>First release. (Aug 2015), <a href="https://doi.org/10.5281/zenodo.27878" class="uri">https://doi.org/10.5281/zenodo.27878</a></p>
<p>7. Domhan, T., Springenberg, J.T., Hutter, F.: Speeding up automatic hyperparameter optimiza- tion of deep neural networks by extrapolation of learning curves. In: Yang, Q., Wooldridge,</p>
<p>M. (eds.) Proceedings of the 25th International Joint Conference on Artiﬁcial Intelligence <span id="_bookmark640" class="anchor"></span>(IJCAI’15). pp. 3460–3468 (2015)</p>
<p>8. Duchi, J., Hazan, E., Singer, Y.: Adaptive subgradient methods for online learning and stochastic optimization. J. Mach. Learn. Res. 12, 2121–2159 (Jul 2011)</p>
<p><span id="_bookmark616" class="anchor"></span>9. Eggensperger, K., Feurer, M., Hutter, F., Bergstra, J., Snoek, J., Hoos, H., Leyton-Brown, K.: Towards an empirical foundation for assessing Bayesian optimization of hyperparameters. In: NIPS Workshop on Bayesian Optimization in Theory and Practice (BayesOpt’13) (2013)</p>
<p><span id="_bookmark623" class="anchor"></span>10. Falkner, S., Klein, A., Hutter, F.: Combining hyperband and bayesian optimization. In: NIPS</p>
<p><span id="_bookmark617" class="anchor"></span>2017 Bayesian Optimization Workshop (Dec 2017)</p>
<p>11. Feurer, M., Klein, A., Eggensperger, K., Springenberg, J.T., Blum, M., Hutter, F.: Efﬁcient and robust automated machine learning. In: Cortes, C., Lawrence, N., Lee, D., Sugiyama, M., Garnett, R. (eds.) Proceedings of the 29th International Conference on Advances in Neural <span id="_bookmark621" class="anchor"></span>Information Processing Systems (NIPS’15) (2015)</p>
<p>12. Feurer, M., Springenberg, T., Hutter, F.: Initializing Bayesian hyperparameter optimization via meta-learning. In: Bonet, B., Koenig, S. (eds.) Proceedings of the Twenty-nineth National Conference on Artiﬁcial Intelligence (AAAI’15). pp. 1128– 1135. AAAI Press (2015)</p>
<p><span id="_bookmark648" class="anchor"></span>13. Gastaldi, X.: Shake-shake regularization. CoRR abs/1705.07485 (2017)</p>
<p>148 H. Mendoza et al.</p>
<p><span id="_bookmark625" class="anchor"></span>14. Guyon, I., Bennett, K., Cawley, G., Escalante, H.J., Escalera, S., Ho, T.K., Macià, N., Ray, B., Saeed, M., Statnikov, A., Viegas, E.: Design of the 2015 chalearn automl challenge. In: 2015 <span id="_bookmark658" class="anchor"></span>International Joint Conference on Neural Networks (IJCNN). pp. 1–8 (July 2015)</p>
<p>15. Halko, N., Martinsson, P., Tropp, J.: Finding structure with randomness: Stochastic algorithms <span id="_bookmark618" class="anchor"></span>for constructing approximate matrix decompositions (2009)</p>
<p>16. Hall, M., Frank, E., Holmes, G., Pfahringer, B., Reutemann, P., Witten, I.: The WEKA data <span id="_bookmark615" class="anchor"></span>mining software: An update. SIGKDD Explorations 11(1), 10– 18 (2009)</p>
<p>17. Hutter, F., Hoos, H., Leyton-Brown, K.: Sequential model-based optimization for general algorithm conﬁguration. In: Coello, C. (ed.) Proceedings of the Fifth International Conference on Learning and Intelligent Optimization (LION’11). Lecture Notes in Computer Science, vol. <span id="_bookmark656" class="anchor"></span>6683, pp. 507–523. Springer-Verlag (2011)</p>
<p>18. Hyvärinen, A., Oja, E.: Independent component analysis: algorithms and applications. Neural <span id="_bookmark659" class="anchor"></span>networks 13(4–5), 411–430 (2000)</p>
<p>19. Jamieson, K., Talwalkar, A.: Non-stochastic best arm identiﬁcation and hyperparameter opti- mization. In: Gretton, A., Robert, C. (eds.) Proceedings of the 19th International Conference on Artiﬁcial Intelligence and Statistics, AISTATS. JMLR Workshop and Conference Proceedings, <span id="_bookmark630" class="anchor"></span>vol. 51, pp. 240–248. JMLR.org (2016)</p>
</blockquote>
<p>20. Jin, H., Song, Q., Hu, X.: Efﬁcient neural architecture search with network morphism. CoRR <span id="_bookmark637" class="anchor"></span>abs/1806. 10282 (2018)</p>
<p>21. Kingma, D., Ba, J.: Adam: A method for stochastic optimization. In: Proceedings of the <span id="_bookmark603" class="anchor"></span>International Conference on Learning Representations (2015)</p>
<p>22. Krizhevsky, A., Sutskever, I., Hinton, G.: ImageNet classiﬁcation with deep convolutional neural networks. In: Bartlett, P., Pereira, F., Burges, C., Bottou, L., Weinberger, K. (eds.) Pro- ceedings of the 26th International Conference on Advances in Neural Information Processing <span id="_bookmark624" class="anchor"></span>Systems (NIPS’12). pp. 1097– 1105 (2012)</p>
<p>23. Li, L., Jamieson, K., DeSalvo, G., Rostamizadeh, A., Talwalkar, A.: Hyperband: A novel bandit-based approach to hyperparameter optimization. Journal of Machine Learning Research <span id="_bookmark652" class="anchor"></span>18, 185:1– 185:52 (2017)</p>
<p>24. Loshchilov, I., Hutter, F.: Sgdr: Stochastic gradient descent with warm restarts. In: International Conference on Learning Representations (ICLR) 2017 Conference Track (2017)</p>
<p><span id="_bookmark631" class="anchor"><span id="_bookmark647" class="anchor"></span></span>25. Loshchilov, I.: Personal communication (2017)</p>
<p>26. Mendoza, H., Klein, A., Feurer, M., Springenberg, J., Hutter, F.: Towards automatically-tuned <span id="_bookmark604" class="anchor"></span>neural networks. In: ICML 2016 AutoML Workshop (2016)</p>
<p>27. Mnih, V., Kavukcuoglu, K., Silver, D., Rusu, A.A., Veness, J., Bellemare, M.G., Graves, A., Riedmiller, M., Fidjeland, A.K., Ostrovski, G., Petersen, S., Beattie, C., Sadik, A., Antonoglou, I., King, H., Kumaran, D., Wierstra, D., Legg, S., Hassabis, D.: Human-level control through <span id="_bookmark639" class="anchor"></span>deep reinforcement learning. Nature 518, 529–533 (2015)</p>
<p>28. Nesterov, Y.: A method of solving a convex programming problem with convergence rate <span id="_bookmark642" class="anchor"></span>O(1/sqr(k)). Soviet Mathematics Doklady 27, 372–376 (1983)</p>
<p>29. Paszke, A., Gross, S., Chintala, S., Chanan, G., Yang, E., DeVito, Z., Lin, Z., Desmaison, A., Antiga, L., Lerer, A.: Automatic differentiation in pytorch. In: Autodiff Workshop at NIPS</p>
<blockquote>
<p><span id="_bookmark619" class="anchor"></span>(2017)</p>
<p>30. Pedregosa, F., Varoquaux, G., Gramfort, A., Michel, V., Thirion, B., Grisel, O., Blondel, M., Prettenhofer, P., Weiss, R., Dubourg, V., Vanderplas, J., Passos, A., Cournapeau, D., Brucher, M., Perrot, M., Duchesnay, E.: Scikit-learn: Machine learning in Python. Journal of Machine <span id="_bookmark657" class="anchor"></span>Learning Research 12, 2825–2830 (2011)</p>
<p>31. Rahimi, A., Recht, B.: Weighted sums of random kitchen sinks: Replacing minimization with randomization in learning. In: Advances in neural information processing systems. pp. 1313– <span id="_bookmark611" class="anchor"><span id="_bookmark641" class="anchor"></span></span>1320 (2009)</p>
<p>32. Rasmussen, C., Williams, C.: Gaussian Processes for Machine Learning. The MIT Press (2006)</p>
<p>33. Schaul, T., Zhang, S., LeCun, Y.: No More Pesky Learning Rates. In: Dasgupta, S., McAllester,</p>
<p>D. (eds.) Proceedings of the 30th International Conference on Machine Learning (ICML’13). <span id="_bookmark655" class="anchor"></span>Omnipress (2014)</p>
<p>34. Schölkopf, B., Smola, A., Müller, K.: Kernel principal component analysis. In: International Conference on Artiﬁcial Neural Networks. pp. 583–588. Springer (1997)</p>
<p>7 Towards Automatically-Tuned Deep Neural Networks 149</p>
<p><span id="_bookmark610" class="anchor"></span>35. Shahriari, B., Swersky, K., Wang, Z., Adams, R., de Freitas, N.: Taking the human out of the <span id="_bookmark605" class="anchor"></span>loop: A Review of Bayesian Optimization. Proc. of the IEEE 104(1) (12/2015 2016)</p>
<p>36. Silver, D., Huang, A., Maddison, C.J., Guez, A., Sifre, L., van den Driessche, G., Schrittwieser, J., Antonoglou, I., Panneershelvam, V., Lanctot, M., Dieleman, S., Grewe, D., Nham, J., Kalchbrenner, N., Sutskever, I., Lillicrap, T., Leach, M., Kavukcuoglu, K., Graepel, T., Hassabis, D.: Mastering the game of go with deep neural networks and tree search. Nature <span id="_bookmark651" class="anchor"></span>529, 484–503 (2016)</p>
<p>37. Smith, L.N.: Cyclical learning rates for training neural networks. In: Applications of Computer <span id="_bookmark644" class="anchor"></span>Vision (WACV), 2017 IEEE Winter Conference on. pp. 464–472. IEEE (2017)</p>
<p>38. Srivastava, N., Hinton, G., Krizhevsky, A., Sutskever, I., Salakhutdinov, R.: Dropout: a simple way to prevent neural networks from overﬁtting. The Journal of Machine Learning Research <span id="_bookmark606" class="anchor"></span>15(1), 1929– 1958 (2014)</p>
<p>39. Sutskever, I., Vinyals, O., Le, Q.V.: Sequence to sequence learning with neural networks. CoRR <span id="_bookmark612" class="anchor"></span>abs/1409.3215 (2014), <a href="http://arxiv.org/abs/1409.3215" class="uri">http://arxiv.org/abs/1409.3215</a></p>
<p>40. Swersky, K., Duvenaud, D., Snoek, J., Hutter, F., Osborne, M.: Raiders of the lost architecture: Kernels for Bayesian optimization in conditional parameter spaces. In: NIPS Workshop on <span id="_bookmark607" class="anchor"></span>Bayesian Optimization in Theory and Practice (BayesOpt’13) (2013)</p>
<p>41. Taigman, Y., Yang, M., Ranzato, M., Wolf, L.: Deepface: Closing the gap to human-level performance in face veriﬁcation. In: Proceedings of the International Conference on Computer Vision and Pattern Recognition (CVPR’14). pp. 1701– 1708. IEEE Computer Society Press</p>
<p><span id="_bookmark633" class="anchor"></span>(2014)</p>
<p>42. Theano Development Team: Theano: A Python framework for fast computation of mathemat- ical expressions. Computing Research Repository (CoRR) abs/1605.02688 (may 2016)</p>
<p><span id="_bookmark608" class="anchor"></span>43. Thornton, C., Hutter, F., Hoos, H., Leyton-Brown, K.: Auto-WEKA: combined selection and hyperparameter optimization of classiﬁcation algorithms. In: I.Dhillon, Koren, Y., Ghani, R., Senator, T., Bradley, P., Parekh, R., He, J., Grossman, R., Uthurusamy, R. (eds.) The 19th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD’13). pp. <span id="_bookmark613" class="anchor"></span>847–855. ACM Press (2013)</p>
<p>44. Wang, Z., Hutter, F., Zoghi, M., Matheson, D., de Feitas, N.: Bayesian optimization in a billion dimensions via random embeddings. Journal of Artiﬁcial Intelligence Research 55, 361–387</p>
<p><span id="_bookmark654" class="anchor"></span>(2016)</p>
<p>45. Williams, C., Seeger, M.: Using the nyström method to speed up kernel machines. In: Advances <span id="_bookmark649" class="anchor"></span>in neural information processing systems. pp. 682–688 (2001)</p>
<p>46. Yamada, Y., Iwamura, M., Kise, K.: Shakedrop regularization. CoRR abs/1802.02375 (2018)</p>
<p><span id="_bookmark645" class="anchor"></span>47. Zagoruyko, S., Komodakis, N.: Wide residual networks. CoRR abs/1605.07146 (2016)</p>
<p>48. Zeiler, M.: ADADELTA: an adaptive learning rate method. CoRR abs/1212.5701 (2012),<a href="http://arxiv.org/abs/1212.5701">http://</a> <span id="_bookmark638" class="anchor"><span id="_bookmark650" class="anchor"></span></span><a href="http://arxiv.org/abs/1212.5701">arxiv.org/abs/1212.5701</a></p>
<p>49. Zhang, H., Cissé, M., Dauphin, Y., Lopez-Paz, D.: mixup: Beyond empirical risk minimization. CoRR abs/1710.09412 (2017)</p>
<p><strong>Open</strong> <strong>Access</strong> This chapter is licensed under the terms of the Creative Commons Attribution 4.0 International License <a href="http://creativecommons.org/licenses/by/4.0/">(http://creativecommons.org/licenses/by/4.0/</a>), which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence and indicate if changes were made.</p>
<p>The images or other third party material in this chapter are included in the chapter’s Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the chapter’s Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder.</p>
</blockquote>
<p><img src="./automlgithubpagesimages//media/image404.png" width="75" height="26" /></p>
<p><img src="./automlgithubpagesimages//media/image405.png" width="41" height="41" /><img src="./automlgithubpagesimages//media/image9.jpeg" width="136" /></p>
<blockquote>
<p><span id="_bookmark11" class="anchor"></span><strong>Chapter</strong> <strong>8</strong></p>
<p><strong>TPOT:</strong> <strong>A</strong> <strong>Tree-Based</strong> <strong>Pipeline</strong></p>
</blockquote>
<p><img src="./automlgithubpagesimages//media/image406.png" /></p>
<blockquote>
<p><strong>Optimization</strong> <strong>Tool</strong> <strong>for</strong> <strong>Automating</strong></p>
<p><strong>Machine</strong> <strong>Learning</strong></p>
<p><strong>Randal</strong> <strong>S.</strong> <strong>Olson</strong> <strong>and</strong> <strong>Jason</strong> <strong>H.</strong> <strong>Moore</strong></p>
<p><strong>Abstract</strong> As data science becomes increasingly mainstream, there will be an ever-growing demand for data science tools that are more accessible, ﬂexible, and scalable. In response to this demand, automated machine learning (AutoML) researchers have begun building systems that automate the process of designing and optimizing machine learning pipelines. In this chapter we present TPOT v0.3, an open source genetic programming-based AutoML system that optimizes a series of feature preprocessors and machine learning models with the goal of maximizing classiﬁcation accuracy on a supervised classiﬁcation task. We benchmark TPOT on a series of 150 supervised classiﬁcation tasks and ﬁnd that it signiﬁcantly outperforms a basic machine learning analysis in 21 of them, while experiencing minimal degradation in accuracy on 4 of the benchmarks—all without any domain knowledge nor human input. As such, genetic programming-based AutoML systems show considerable promise in the AutoML domain.</p>
<p><strong>8.1</strong> <strong>Introduction</strong></p>
<p>Machine learning is commonly described as a “ﬁeld of study that gives computers the ability to learn without being explicitly programmed” [<a href="#_bookmark666">19</a>]. Despite this common claim, experienced machine learning practitioners know that designing effective machine learning pipelines is often a tedious endeavor, and typically requires considerable experience with machine learning algorithms, expert knowledge of the problem domain, and time-intensive brute force search to accomplish [<a href="#_bookmark667">13</a>]. Thus, contrary to what machine learning enthusiasts would have us believe, machine learning still requires considerable explicit programming.</p>
<p>R. S. Olson (凶)</p>
<p>Life Epigenetics, Minneapolis, MN, USA</p>
<p>e-mail: <a href="mailto:rso@randalolson.com">rso@randalolson.com</a></p>
<p>J. H. Moore</p>
<p>Institute for Biomedical Informatics, University of Pennsylvania, Philadelphia, PA, USA</p>
<p>© The Author(s) 2019</p>
<p>F. Hutter et al. (eds.), <em>Automated</em> <em>Machine</em> <em>Learning</em>, The Springer Series on Challenges in Machine Learning, <a href="https://doi.org/10.1007/978-3-030-05318-5_8" class="uri">https://doi.org/10.1007/978-3-030-05318-5_8</a></p>
<p>152 R. S. Olson and J. H. Moore</p>
</blockquote>
<p>In response to this challenge, several automated machine learning methods have been developed over the years [<a href="#_bookmark668">10</a>]. Over the past several years, we have been developing a Tree-based Pipeline Optimization Tool (TPOT) that automatically designs and optimizes machine learning pipelines for a given problem domain [<a href="#_bookmark669">16</a>], without any need for human intervention. In short, TPOT optimizes machine learning pipelines using a version of genetic programming (GP), a well-known evolutionary computation technique for automatically constructing computer pro- grams [<a href="#_bookmark670">1</a>]. Previously, we demonstrated that combining GP with Pareto optimization enables TPOT to automatically construct high-accuracy <em>and</em> compact pipelines that consistently outperform basic machine learning analyses [<a href="#_bookmark667">13</a>]. In this chapter, we extend that benchmark to include 150 supervised classiﬁcation tasks and evaluate TPOT in a wide variety of application domains ranging from genetic analyses to image classiﬁcation and more.</p>
<p>This chapter is an extended version of our 2016 paper introducing TPOT, presented at the <em>2016</em> <em>ICML</em> <em>Workshop</em> <em>on</em> <em>AutoML</em> [<a href="#_bookmark671">15</a>].</p>
<blockquote>
<p><strong>8.2</strong> <strong>Methods</strong></p>
</blockquote>
<p>In the following sections, we provide an overview of the Tree-based Pipeline Optimization Tool (TPOT) v0.3, including the machine learning operators used as genetic programming (GP) primitives, the tree-based pipelines used to combine the primitives into working machine learning pipelines, and the GP algorithm used to evolve said tree-based pipelines. We follow with a description of the datasets used to evaluate the latest version of TPOT in this chapter. TPOT is an open source project on GitHub, and the underlying Python code can be found at <a href="https://github.com/rhiever/tpot">https://github.com/</a> <a href="https://github.com/rhiever/tpot">rhiever/tpot</a>.</p>
<p><em><strong>8.2.1</strong></em> <em><strong>Machine</strong></em> <em><strong>Learning</strong></em> <em><strong>Pipeline</strong></em> <em><strong>Operators</strong></em></p>
<p>At its core, TPOT is a wrapper for the Python machine learning package, scikit- learn [<a href="#_bookmark672">17</a>]. Thus, each machine learning pipeline operator (i.e., GP primitive) in TPOT corresponds to a machine learning algorithm, such as a supervised classiﬁcation model or standard feature scaler. All implementations of the machine learning algorithms listed below are from scikit-learn (except XGBoost), and we refer to the scikit-learn documentation [<a href="#_bookmark672">17</a>] and [<a href="#_bookmark673">9</a>] for detailed explanations of the machine learning algorithms used in TPOT.</p>
<p><strong>Supervised</strong> <strong>Classiﬁcation</strong> <strong>Operators</strong> DecisionTree, RandomForest, eXtreme Gradient Boosting Classiﬁer (from XGBoost, [<a href="#_bookmark674">3</a>]), LogisticRegression, and KNearestNeighborClassiﬁer. Classiﬁcation operators store the classiﬁer’s predictions as a new feature as well as the classiﬁcation for the pipeline.</p>
<p><img src="./automlgithubpagesimages//media/image407.png" width="24" /><img src="./automlgithubpagesimages//media/image408.png" width="81" /><img src="./automlgithubpagesimages//media/image409.png" width="56" /><img src="./automlgithubpagesimages//media/image410.png" width="71" height="71" /><img src="./automlgithubpagesimages//media/image411.png" /><img src="./automlgithubpagesimages//media/image412.png" width="25" /><img src="./automlgithubpagesimages//media/image413.png" width="25" /><img src="./automlgithubpagesimages//media/image414.png" /><img src="./automlgithubpagesimages//media/image417.png" width="27" /><img src="./automlgithubpagesimages//media/image418.png" width="63" /><img src="./automlgithubpagesimages//media/image419.png" width="64" /></p>
<blockquote>
<p>8 TPOT: A Tree-Based Pipeline Optimization Tool for Automating Machine Learning 153</p>
</blockquote>
<p><img src="./automlgithubpagesimages//media/image420.png" /></p>
<p><img src="./automlgithubpagesimages//media/image421.png" /></p>
<p><img src="./automlgithubpagesimages//media/image422.png" /></p>
<blockquote>
<p><span id="_bookmark675" class="anchor"></span><strong>Fig.</strong> <strong>8.1</strong> An example tree-based pipeline from TPOT. Each circle corresponds to a machine learning operator, and the arrows indicate the direction of the data ﬂow</p>
<p><strong>Feature</strong> <strong>Preprocessing</strong> <strong>Operators</strong> StandardScaler, RobustScaler, MinMaxScaler, MaxAbsScaler, RandomizedPCA [<a href="#_bookmark676">12</a>], Binarizer, and PolynomialFeatures. Prepro- cessing operators modify the dataset in some way and return the modiﬁed dataset.</p>
</blockquote>
<p><strong>Feature</strong> <strong>Selection</strong> <strong>Operators</strong> VarianceThreshold, SelectKBest, SelectPercentile, SelectFwe, and Recursive Feature Elimination (RFE). Feature selection operators reduce the number of features in the dataset using some criteria and return the modiﬁed dataset.</p>
<p>We also include an operator that combines disparate datasets, as demonstrated in Fig.<a href="#_bookmark675">8.1</a>, which allows multiple modiﬁed variants of the dataset to be combined into a single dataset. Additionally, TPOT v0.3 does not include missing value imputation operators, and therefore does not support datasets with missing data. Lastly, we provide integer and ﬂoat terminals to parameterize the various operators, such as the number of neighbors k in the k-Nearest Neighbors Classiﬁer.</p>
<p><em><strong>8.2.2</strong></em> <em><strong>Constructing</strong></em> <em><strong>Tree-Based</strong></em> <em><strong>Pipelines</strong></em></p>
<p>To combine these operators into a machine learning pipeline, we treat them as GP primitives and construct GP trees from them. Fig. <a href="#_bookmark675">8.1</a> shows an example tree-based pipeline, where two copies of the dataset are provided to the pipeline, modiﬁed in a successive manner by each operator, combined into a single dataset, and ﬁnally used to make classiﬁcations. Other than the restriction that every pipeline must have a classiﬁer as its ﬁnal operator, it is possible to construct arbitrarily shaped machine learning pipelines that can act on multiple copies of the dataset. Thus, GP trees provide an inherently ﬂexible representation of machine learning pipelines.</p>
<p><img src="./automlgithubpagesimages//media/image12.jpeg" width="136" /></p>
<blockquote>
<p>154 R. S. Olson and J. H. Moore</p>
</blockquote>
<p>In order for these tree-based pipelines to operate, we store three additional variables for each record in the dataset. The “class” variable indicates the true label for each record, and is used when evaluating the accuracy of each pipeline. The “guess” variable indicates the pipeline’s latest guess for each record, where the predictions from the ﬁnal classiﬁcation operator in the pipeline are stored as the “guess” . Finally, the “group” variable indicates whether the record is to be used as a part of the internal training or testing set, such that the tree-based pipelines are only trained on the training data and evaluated on the testing data. We note that the dataset provided to TPOT as training data is further split into an internal stratiﬁed 75%/25% training/testing set.</p>
<blockquote>
<p><em><strong>8.2.3</strong></em> <em><strong>Optimizing</strong></em> <em><strong>Tree-Based</strong></em> <em><strong>Pipelines</strong></em></p>
<p>To automatically generate and optimize these tree-based pipelines, we use a genetic programming (GP) algorithm [<a href="#_bookmark670">1</a>] as implemented in the Python package DEAP [<a href="#_bookmark677">7</a>]. The TPOT GP algorithm follows a standard GP process: To begin, the GP algorithm generates 100 random tree-based pipelines and evaluates their balanced cross- validation accuracy on the dataset. For every generation of the GP algorithm, the algorithm selects the top 20 pipelines in the population according to the NSGA- II selection scheme [<a href="#_bookmark678">4</a>], where pipelines are selected to simultaneously maximize classiﬁcation accuracy on the dataset while minimizing the number of operators in the pipeline. Each of the top 20 selected pipelines produce ﬁve copies (i.e., offspring) into the next generation’s population, 5% of those offspring cross over with another offspring using one-point crossover, then 90% of the remaining unaffected offspring are randomly changed by a point, insert, or shrink mutation (1/3 chance of each). Every generation, the algorithm updates a Pareto front of the non-dominated solutions [<a href="#_bookmark678">4</a>] discovered at any point in the GP run. The algorithm repeats this evaluate-select-crossover-mutate process for 100 generations—adding and tuning pipeline operators that improve classiﬁcation accuracy and pruning operators that degrade classiﬁcation accuracy—at which point the algorithm selects the highest-accuracy pipeline from the Pareto front as the representative “best” pipeline from the run.</p>
<p><em><strong>8.2.4</strong></em> <em><strong>Benchmark</strong></em> <em><strong>Data</strong></em></p>
<p>We compiled 150 supervised classiﬁcation benchmarks<a href="#_bookmark679">1</a> from a wide variety of sources, including the UCI machine learning repository [<a href="#_bookmark680">11</a>], a large preexisting benchmark repository from [<a href="#_bookmark681">18</a>], and simulated genetic analysis datasets from [<a href="#_bookmark682">20</a>].</p>
<p><span id="_bookmark679" class="anchor"></span>1Benchmark data at<a href="https://github.com/EpistasisLab/penn-ml-benchmarks" class="uri">https://github.com/EpistasisLab/penn-ml-benchmarks</a></p>
</blockquote>
<p><img src="./automlgithubpagesimages//media/image12.jpeg" width="136" /></p>
<blockquote>
<p>8 TPOT: A Tree-Based Pipeline Optimization Tool for Automating Machine Learning 155</p>
<p>These benchmark datasets range from 60 to 60,000 records, few to hundreds of features, and include binary as well as multi-class supervised classiﬁcation problems. We selected datasets from a wide range of application domains, including genetic analysis, image classiﬁcation, time series analysis, and many more. Thus, this benchmark—called the Penn Machine Learning Benchmark (PMLB) [<a href="#_bookmark683">14</a>]— represents a comprehensive suite of tests with which to evaluate automated machine learning systems.</p>
<p><strong>8.3</strong> <strong>Results</strong></p>
<p>To evaluate TPOT, we ran 30 replicates of it on each of the 150 benchmarks, where each replicate had 8 h to complete 100 generations of optimization (i.e., 100 × 100 = 10,000 pipeline evaluations). In each replicate, we divided the dataset into a stratiﬁed 75%/25% training/testing split and used a distinct random number generator seed for each split and subsequent TPOT run.</p>
<p>In order to provide a reasonable control as a baseline comparison, we similarly evaluated 30 replicates of a Random Forest with 500 trees on the 150 benchmarks, which is meant to represent a basic machine learning analysis that a novice practitioner would perform. We also ran 30 replicates of a version of TPOT that randomly generates and evaluates the same number of pipelines (10,000), which is meant to represent a random search in the TPOT pipeline space. In all cases, we measured accuracy of the resulting pipelines or models as balanced accuracy [<a href="#_bookmark684">21</a>], which corrects for class frequency imbalances in datasets by computing the accuracy on a per-class basis then averaging the per-class accuracies. In the remainder of this chapter, we refer to “balanced accuracy” as simply “accuracy.”</p>
<p>Shown in Fig.<a href="#_bookmark685">8.2</a>, the average performance of TPOT and a Random Forest with 500 trees is similar on most of the datasets. Overall, TPOT discovered pipelines that perform statistically signiﬁcantly better than a Random Forest on 21 benchmarks, signiﬁcantly worse on 4 benchmarks, and had no statistically signiﬁcant difference on 125 benchmarks. (We determined statistical signiﬁcance using a Wilcoxon rank- sum test, where we used a conservative Bonferroni-corrected p-value threshold of &lt; 0.000333 (0.05<img src="./automlgithubpagesimages//media/image423.jpeg" width="0" />150) for signiﬁcance.) In Fig.<a href="#_bookmark686">8.3</a>, we show the distributions of accuracies on the 25 benchmarks that had signiﬁcant differences, where the benchmarks are sorted by the difference in median accuracy between the two experiments.</p>
<p>Notably, the majority of TPOT’s improvements on the benchmarks are quite large, with several ranging from 10% to 60% median accuracy improvement over a Random Forest analysis. In contrast, the 4 benchmarks where TPOT experienced a degradation in median accuracy ranged from only 2–5% accuracy degradation. In some cases, TPOT’s improvements were made by discovering useful feature preprocessors that allow the models to better classify the data,<a href="#_bookmark687">2</a> e.g., TPOT</p>
<p><span id="_bookmark687" class="anchor"></span>2Full list:<a href="https://gist.github.com/rhiever/578cc9c686ffd873f46bca29406dde1d" class="uri">https://gist.github.com/rhiever/578cc9c686ffd873f46bca29406dde1d</a></p>
</blockquote>
<p><img src="./automlgithubpagesimages//media/image424.png" height="329" /><img src="./automlgithubpagesimages//media/image425.png" height="329" /><img src="./automlgithubpagesimages//media/image426.png" height="329" /><img src="./automlgithubpagesimages//media/image427.png" height="329" /><img src="./automlgithubpagesimages//media/image428.png" height="329" /><img src="./automlgithubpagesimages//media/image429.png" height="329" /><img src="./automlgithubpagesimages//media/image430.png" /><img src="./automlgithubpagesimages//media/image431.png" /><img src="./automlgithubpagesimages//media/image432.png" /><img src="./automlgithubpagesimages//media/image433.png" /><img src="./automlgithubpagesimages//media/image434.png" /><img src="./automlgithubpagesimages//media/image435.png" /><img src="./automlgithubpagesimages//media/image436.png" /><img src="./automlgithubpagesimages//media/image437.png" width="28" /><img src="./automlgithubpagesimages//media/image438.png" height="329" /><img src="./automlgithubpagesimages//media/image439.png" height="31" /><img src="./automlgithubpagesimages//media/image440.png" width="63" height="74" /><img src="./automlgithubpagesimages//media/image441.png" width="102" height="148" /><img src="./automlgithubpagesimages//media/image442.png" width="78" height="70" /><img src="./automlgithubpagesimages//media/image443.png" width="26" height="37" /><img src="./automlgithubpagesimages//media/image444.png" width="49" height="46" /><img src="./automlgithubpagesimages//media/image445.png" width="163" height="149" /><img src="./automlgithubpagesimages//media/image446.png" width="54" height="60" /><img src="./automlgithubpagesimages//media/image447.png" width="137" height="145" /><img src="./automlgithubpagesimages//media/image448.png" width="111" height="98" /><img src="./automlgithubpagesimages//media/image449.png" width="128" height="135" /><img src="./automlgithubpagesimages//media/image450.png" width="98" height="111" /><img src="./automlgithubpagesimages//media/image451.png" width="322" height="126" /><img src="./automlgithubpagesimages//media/image452.png" width="95" height="97" /><img src="./automlgithubpagesimages//media/image453.png" width="168" height="166" /><img src="./automlgithubpagesimages//media/image454.png" /><img src="./automlgithubpagesimages//media/image455.png" width="101" height="117" /><img src="./automlgithubpagesimages//media/image456.png" width="24" /><img src="./automlgithubpagesimages//media/image457.png" width="159" height="160" /><img src="./automlgithubpagesimages//media/image458.png" /><img src="./automlgithubpagesimages//media/image459.png" width="120" height="126" /><img src="./automlgithubpagesimages//media/image460.png" width="353" height="335" /><img src="./automlgithubpagesimages//media/image461.png" /><img src="./automlgithubpagesimages//media/image462.png" /><img src="./automlgithubpagesimages//media/image463.png" /><img src="./automlgithubpagesimages//media/image464.png" width="10" height="10" /><img src="./automlgithubpagesimages//media/image465.png" width="20" height="20" /><img src="./automlgithubpagesimages//media/image466.png" /><img src="./automlgithubpagesimages//media/image467.png" width="23" height="23" /><img src="./automlgithubpagesimages//media/image468.png" width="10" height="10" /><img src="./automlgithubpagesimages//media/image469.png" /><img src="./automlgithubpagesimages//media/image470.png" /><img src="./automlgithubpagesimages//media/image471.png" /><img src="./automlgithubpagesimages//media/image472.png" width="326" height="330" /><img src="./automlgithubpagesimages//media/image473.png" width="14" height="30" /><img src="./automlgithubpagesimages//media/image474.png" width="18" height="30" /><img src="./automlgithubpagesimages//media/image475.png" width="18" height="30" /><img src="./automlgithubpagesimages//media/image476.png" width="28" height="30" /><img src="./automlgithubpagesimages//media/image477.png" width="152" height="252" /><img src="./automlgithubpagesimages//media/image478.png" width="55" height="31" /><img src="./automlgithubpagesimages//media/image479.png" width="10" height="10" /><img src="./automlgithubpagesimages//media/image480.png" width="10" height="10" /><img src="./automlgithubpagesimages//media/image481.png" width="56" height="329" /><img src="./automlgithubpagesimages//media/image482.png" /><img src="./automlgithubpagesimages//media/image483.png" width="16" height="16" /><img src="./automlgithubpagesimages//media/image484.png" width="16" height="16" /><img src="./automlgithubpagesimages//media/image485.png" width="56" height="250" /><img src="./automlgithubpagesimages//media/image486.png" width="12" /><img src="./automlgithubpagesimages//media/image487.png" width="17" /><img src="./automlgithubpagesimages//media/image488.png" width="17" /><img src="./automlgithubpagesimages//media/image489.png" width="17" /><img src="./automlgithubpagesimages//media/image490.png" width="17" /></p>
<blockquote>
<p>156 R. S. Olson and J. H. Moore</p>
</blockquote>
<p><img src="./automlgithubpagesimages//media/image491.png" width="326" height="57" /></p>
<p><img src="./automlgithubpagesimages//media/image492.png" height="124" /></p>
<p><img src="./automlgithubpagesimages//media/image493.png" width="21" /></p>
<p><img src="./automlgithubpagesimages//media/image494.png" width="159" /></p>
<blockquote>
<p><span id="_bookmark685" class="anchor"></span><strong>Fig.</strong> <strong>8.2</strong> Scatter plot showing the median balanced accuracies of TPOT and a Random Forest with 500 trees on the 150 benchmark datasets. Each dot represents the accuracies on one benchmark dataset, and the diagonal line represents the line of parity (i.e., when both algorithms achieve the same accuracy score). Dots above the line represent datasets where TPOT performed better than the Random Forest, and dots below the line represent datasets where Random Forests performed better</p>
<p>discovered that applying a RandomizedPCA feature preprocessor prior to modeling the “Hill_valley” benchmarks allows Random Forests to classify the dataset with near-perfect accuracy. In other cases, TPOT’s improvements were made by applying a different model to the benchmark, e.g., TPOT discovered that a k-nearest-neighbor classiﬁer with k = 10 neighbors can classify the “parity5” benchmark, whereas a Random Forest consistently achieved 0% accuracy on the same benchmark.</p>
</blockquote>
<p>When we compared TPOT to a version of TPOT that uses random search (“TPOT Random” in Fig.<a href="#_bookmark686">8.3</a>), we found that random search typically discovered pipelines that achieve comparable accuracy to pipelines discovered by TPOT, except in the “dis” benchmark where TPOT consistently discovered better-performing pipelines. For 17 of the presented benchmarks, none of the random search runs ﬁnished within</p>
<blockquote>
<p>8 TPOT: A Tree-Based Pipeline Optimization Tool for Automating Machine Learning 157</p>
</blockquote>
<p><img src="./automlgithubpagesimages//media/image495.png" width="440" height="590" /></p>
<p><span id="_bookmark686" class="anchor"></span><strong>Fig.</strong> <strong>8.3</strong> Box plots showing the distribution of balanced accuracies for the 25 benchmarks with a signiﬁcant difference in median accuracy between TPOT and a Random Forest with 500 trees. Each box plot represents 30 replicates, the inner line shows the median, the notches represent the bootstrapped 95% conﬁdence interval of the median, the ends of the box represent the ﬁrst and third quartiles, and the dots represent outliers</p>
<blockquote>
<p>158 R. S. Olson and J. H. Moore</p>
</blockquote>
<p>24 h, which we indicated by leaving the box plot blank in Fig.<a href="#_bookmark686">8.3</a>. We found that random search often generated needlessly complex pipelines for the benchmark problems, even when a simple pipeline with a tuned model was sufﬁcient to classify the benchmark problem. Thus, even if random search can sometimes perform as well as TPOT in terms of accuracy, performing a guided search for pipelines that achieve high accuracy with as few pipeline operations as possible still offers considerable advantages in terms of search run-time, model complexity, and model interpretability.</p>
<blockquote>
<p><strong>8.4</strong> <strong>Conclusions</strong> <strong>and</strong> <strong>Future</strong> <strong>Work</strong></p>
</blockquote>
<p>We benchmarked the Tree-based Pipeline Optimization Tool (TPOT) v0.3 on 150 supervised classiﬁcation datasets and found that it discovers machine learning pipelines that can outperform a basic machine learning analysis on several bench- marks. In particular, we note that TPOT discovered these pipelines without any domain knowledge nor human input. As such, TPOT shows considerable promise in the automated machine learning (AutoML) domain and we will continue to reﬁne TPOT until it consistently discovers human-competitive machine learning pipelines.</p>
<p>We discuss some of these future reﬁnements below.</p>
<p>First, we will explore methods to provide sensible initialization [<a href="#_bookmark688">8</a>] for genetic programming (GP)-based AutoML systems such as TPOT. For example, we can use meta-learning techniques to intelligently match pipeline conﬁgurations that may work well on the particular problem being solved [<a href="#_bookmark689">6</a>]. In brief, meta-learning harnesses information from previous machine learning runs to predict how well each pipeline conﬁguration will work on a particular dataset. To place datasets on a standard scale, meta-learning algorithms compute meta-features from the datasets, such as dataset size, the number of features, and various aspects about the features, which are then used to map dataset meta-features to corresponding pipeline conﬁgurations that may work well on datasets with those meta-features. Such an intelligent meta-learning algorithm is likely to improve the TPOT sensible initialization process.</p>
<p>Furthermore, we will attempt to characterize the ideal “shape” of a machine learning pipeline. In auto-sklearn, [<a href="#_bookmark690">5</a>] imposed a short and ﬁxed pipeline structure of a data preprocessor, a feature preprocessor, and a model. In another GP- based AutoML system, [<a href="#_bookmark691">22</a>] allowed the GP algorithm to design arbitrarily-shaped pipelines and found that complex pipelines with several preprocessors and models were useful for signal processing problems. Thus, it may be vital to allow AutoML systems to design arbitrarily-shaped pipelines if they are to achieve human-level competitiveness.</p>
<blockquote>
<p>Finally, genetic programming (GP) optimization methods are typically criticized for optimizing a large population of solutions, which can sometimes be slow and wasteful for certain optimization problems. Instead, it is possible to turn GP’s purported weakness into a strength by creating an ensemble out of the GP</p>
<p>8 TPOT: A Tree-Based Pipeline Optimization Tool for Automating Machine Learning 159</p>
</blockquote>
<p>populations. Bhowan et al. [<a href="#_bookmark692">2</a>] explored one such population ensemble method previously with a standard GP algorithm and showed that it signiﬁcantly improved performance, and it is a natural extension to create ensembles out of TPOT’s population of machine learning pipelines.</p>
<p>In conclusion, these experiments demonstrate that there is much to be gained from taking a model-agnostic approach to machine learning and allowing the machine to automatically discover what series of preprocessors and models work best for a given problem domain. As such, AutoML stands to revolutionize data science by automating some of the most tedious—yet most important—aspects of machine learning.</p>
<blockquote>
<p><span id="_bookmark670" class="anchor"></span><strong>Bibliography</strong></p>
<p>1. Banzhaf, W., Nordin, P., Keller, R.E., Francone, F.D.: Genetic Programming: An Introduction. <span id="_bookmark692" class="anchor"></span>Morgan Kaufmann, San Meateo, CA, USA (1998)</p>
<p>2. Bhowan, U., Johnston, M., Zhang, M., Yao, X.: Evolving diverse ensembles using genetic programming for classiﬁcation with unbalanced data. Trans. Evol. Comp 17(3), 368–386 (Jun <span id="_bookmark674" class="anchor"></span>2013)</p>
<p>3. Chen, T., Guestrin, C.: Xgboost: A scalable tree boosting system. In: Proceedings of the 22Nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. pp. 785–</p>
<p><span id="_bookmark678" class="anchor"></span>794. KDD ’16, ACM, New York, NY, USA (2016)</p>
<p>4. Deb, K., Pratap, A., Agarwal, S., Meyarivan, T.: A fast and elitist multiobjective genetic algorithm: NSGA-II. IEEE Transactions on Evolutionary Computation 6, 182– 197 (2002)</p>
<p><span id="_bookmark690" class="anchor"></span>5. Feurer, M., Klein, A., Eggensperger, K., Springenberg, J., Blum, M., Hutter, F.: Efﬁcient and robust automated machine learning. In: Cortes, C., Lawrence, N., Lee, D., Sugiyama, M., Garnett, R. (eds.) Advances in Neural Information Processing Systems 28, pp. 2944–2952. <span id="_bookmark689" class="anchor"></span>Curran Associates, Inc. (2015)</p>
<p>6. Feurer, M., Springenberg, J.T., Hutter, F.: Initializing bayesian hyperparameter optimization via meta-learning. In: Proceedings of the 29th AAAI Conference on Artiﬁcial Intelligence, <span id="_bookmark677" class="anchor"></span>January 25–30, 2015, Austin, Texas, USA. pp. 1128– 1135 (2015)</p>
<p>7. Fortin, F.A., De Rainville, F.M., Gardner, M.A., Parizeau, M., Gagné, C.: DEAP: Evolutionary Algorithms Made Easy. Journal of Machine Learning Research 13, 2171–2175 (2012)</p>
<p><span id="_bookmark688" class="anchor"></span>8. Greene, C.S., White, B.C., Moore, J.H.: An expert knowledge-guided mutation operator for genome-wide genetic analysis using genetic programming. In: Pattern Recognition in <span id="_bookmark673" class="anchor"></span>Bioinformatics, pp. 30–40. Springer Berlin Heidelberg (2007)</p>
<p>9. Hastie, T.J., Tibshirani, R.J., Friedman, J.H.: The Elements of Statistical Learning: Data <span id="_bookmark668" class="anchor"></span>Mining, Inference, and Prediction. Springer, New York, NY, USA (2009)</p>
<p>10. Hutter, F., Lücke, J., Schmidt-Thieme, L.: Beyond Manual Tuning of Hyperparameters. KI - <span id="_bookmark680" class="anchor"></span>Künstliche Intelligenz 29, 329–337 (2015)</p>
<p>11. Lichman, M.: UCI machine learning repository (2013), <a href="http://archive.ics.uci.edu/ml" class="uri">http://archive.ics.uci.edu/ml</a></p>
<p><span id="_bookmark676" class="anchor"></span>12. Martinsson, P.G., Rokhlin, V., Tygert, M.: A randomized algorithm for the decomposition of matrices. Applied and Computational Harmonic Analysis 30, 47–68 (2011)</p>
<p><span id="_bookmark667" class="anchor"></span>13. Olson, R.S., Bartley, N., Urbanowicz, R.J., Moore, J.H.: Evaluation of a tree-based pipeline optimization tool for automating data science. In: Proceedings of the Genetic and Evolutionary Computation Conference 2016. pp. 485–492. GECCO ’16, ACM, New York, NY, USA (2016)</p>
<p><span id="_bookmark683" class="anchor"></span>14. Olson, R.S., La Cava, W., Orzechowski, P., Urbanowicz, R.J., Moore, J.H.: PMLB: A Large Benchmark Suite for Machine Learning Evaluation and Comparison. arXiv e-print. <a href="https://arxiv.org/abs/1703.00512">https://</a> <a href="https://arxiv.org/abs/1703.00512">arxiv.org/abs/1703.00512</a> (2017)</p>
<p>160 R. S. Olson and J. H. Moore</p>
<p><span id="_bookmark671" class="anchor"></span>15. Olson, R.S., Moore, J.H.: Tpot: A tree-based pipeline optimization tool for automating machine learning. In: Hutter, F., Kotthoff, L., Vanschoren, J. (eds.) Proceedings of the Workshop on Automatic Machine Learning. Proceedings of Machine Learning Research, vol. 64, pp. 66–74. PMLR, New York, New York, USA (24 Jun 2016), <a href="http://proceedings.mlr.press/v64/olson_tpot_2016.html">http://proceedings.mlr.press/v64/olson_</a> <span id="_bookmark669" class="anchor"></span><a href="http://proceedings.mlr.press/v64/olson_tpot_2016.html">tpot_2016.html</a></p>
<p>16. Olson, R.S., Urbanowicz, R.J., Andrews, P.C., Lavender, N.A., Kidd, L.C., Moore, J.H.: Applications of Evolutionary Computation: 19th European Conference, EvoApplications 2016, Porto, Portugal, March 30 — April 1, 2016, Proceedings, Part I, chap. Automating Biomedical Data Science Through Tree-Based Pipeline Optimization, pp. 123– 137. Springer International <span id="_bookmark672" class="anchor"></span>Publishing (2016)</p>
<p>17. Pedregosa, F., Varoquaux, G., Gramfort, A., Michel, V., Thirion, B., Grisel, O., Blondel, M., Prettenhofer, P., Weiss, R., Dubourg, V., Vanderplas, J., Passos, A., Cournapeau, D., Brucher, M., Perrot, M., Duchesnay, E.: Scikit-learn: Machine learning in Python. Journal of Machine <span id="_bookmark681" class="anchor"></span>Learning Research 12, 2825–2830 (2011)</p>
<p>18. Reif, M.: A comprehensive dataset for evaluating approaches of various meta-learning tasks. In: First International Conference on Pattern Recognition and Methods (ICPRAM) (2012)</p>
<p>19. Simon, P.: Too big to ignore: the business case for big data. Wiley &amp; SAS Business Series, <span id="_bookmark666" class="anchor"><span id="_bookmark682" class="anchor"></span></span>Wiley, New Delhi (2013)</p>
<p>20. Urbanowicz, R.J., Kiralis, J., Sinnott-Armstrong, N.A., Heberling, T., Fisher, J.M., Moore, J.H.: GAMETES: a fast, direct algorithm for generating pure, strict, epistatic models with <span id="_bookmark684" class="anchor"></span>random architectures. BioData Mining 5 (2012)</p>
<p>21. Velez, D.R., White, B.C., Motsinger, A.A., Bush, W.S., Ritchie, M.D., Williams, S.M., Moore, J.H.: A balanced accuracy function for epistasis modeling in imbalanced datasets using multifactor dimensionality reduction. Genetic Epidemiology 31(4), 306–315 (2007)</p>
<p><span id="_bookmark691" class="anchor"></span>22. Zutty, J., Long, D., Adams, H., Bennett, G., Baxter, C.: Multiple objective vector-based genetic programming using human-derived primitives. In: Proceedings of the 2015 Annual Conference on Genetic and Evolutionary Computation. pp. 1127– 1134. GECCO ’15, ACM, New York, NY, USA (2015)</p>
<p><strong>Open</strong> <strong>Access</strong> This chapter is licensed under the terms of the Creative Commons Attribution 4.0 International License <a href="http://creativecommons.org/licenses/by/4.0/">(http://creativecommons.org/licenses/by/4.0/</a>), which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence and indicate if changes were made.</p>
<p>The images or other third party material in this chapter are included in the chapter’s Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the chapter’s Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder.</p>
</blockquote>
<p><img src="./automlgithubpagesimages//media/image496.png" width="75" height="26" /></p>
<p><img src="./automlgithubpagesimages//media/image497.png" width="41" height="41" /><img src="./automlgithubpagesimages//media/image12.jpeg" width="136" /></p>
<blockquote>
<p><span id="_bookmark12" class="anchor"></span><strong>Chapter</strong> <strong>9</strong></p>
<p><strong>The</strong> <strong>Automatic</strong> <strong>Statistician</strong></p>
</blockquote>
<p><img src="./automlgithubpagesimages//media/image498.png" /></p>
<blockquote>
<p><strong>Christian</strong> <strong>Steinruecken,</strong> <strong>Emma</strong> <strong>Smith,</strong> <strong>David</strong> <strong>Janz,</strong> <strong>James</strong> <strong>Lloyd,</strong> <strong>and</strong> <strong>Zoubin</strong> <strong>Ghahramani</strong></p>
<p><strong>Abstract</strong> The Automatic Statistician project aims to automate data science, pro- ducing predictions and human-readable reports from raw datasets with minimal human intervention. Alongside basic graphs and statistics, the generated reports contain a curation of high-level insights about the dataset that are obtained from (1) an automated construction of models for the dataset, (2) a comparison of these models, and (3) a software component that turns these results into natural language descriptions. This chapter describes the common architecture of such Automatic Statistician systems, and discusses some of the design decisions and technical challenges.</p>
<p><strong>9.1</strong> <strong>Introduction</strong></p>
<p>Machine Learning (ML) and data science are closely related ﬁelds of research, that are focused on the development of algorithms for automated learning from data. These algorithms also underpin many of the recent advances in artiﬁcial intelligence (AI), which have had a tremendous impact in industry, ushering in a new golden age of AI. However, many of the current approaches to machine learning, data science,</p>
<p>and AI, suffer from a set of important but related limitations.</p>
</blockquote>
<p>Firstly, many of the approaches used are complicated black-boxes that are difﬁcult to interpret, understand, debug, and trust. This lack of interpretability hampers the deployment of ML systems. For example, consider the major legal, technical and ethical consequences of using an uninterpretable black-box system that arrives at a prediction or decision related to a medical condition, a criminal justice setting, or in a self-driving car. The realisation that black-box ML methods are severely limited in such settings has led to major efforts to develop “explainable AI”, and systems that offer interpretability, trust, and transparency.</p>
<blockquote>
<p>C. Steinruecken (凶) · E. Smith · D. Janz · J. Lloyd · Z. Ghahramani</p>
<p>Department of Engineering, University of Cambridge, Cambridge, UK</p>
<p>e-mail: <a href="mailto:tcs27@cam.ac.uk">tcs27@cam.ac.uk</a></p>
<p>© The Author(s) 2019</p>
<p>F. Hutter et al. (eds.), <em>Automated</em> <em>Machine</em> <em>Learning</em>, The Springer Series on Challenges in Machine Learning, <a href="https://doi.org/10.1007/978-3-030-05318-5_9" class="uri">https://doi.org/10.1007/978-3-030-05318-5_9</a></p>
<p>162 C. Steinruecken et al.</p>
</blockquote>
<p>Secondly, the development of ML systems has turned into a cottage industry where ML experts tackle problems by hand-designing solutions that often reﬂect a set of ad-hoc manual decisions, or the preferences and biases of the expert. It is ironic that machine learning, a ﬁeld dedicated to building systems that automatically learn from data, is so dependent on human experts and manual tuning of models and learning algorithms. Manual search over possible models and methods can result in solutions that are sub-optimal across any number of metrics. Moreover, the tremendous imbalance between the supply of experts and the demand for data science and ML solutions is likely resulting in many missed opportunities for applications that could have a major beneﬁt for society.</p>
<blockquote>
<p>The vision of the Automatic Statistician is to automate many aspects of data analysis, model discovery, and explanation. In a sense, the goal is to develop an <em>AI</em> <em>for</em> <em>data</em> <em>science</em> – a system that can reason about patterns in data and explain them to the user. Ideally, given some raw data, such a system should be able to:</p>
<p>• automate the process of feature selection and transformation,</p>
<p>• deal with the messiness of real data, including missing values, outliers, and different types and encodings of variables,</p>
<p>• search over a large space of models so as to automatically discover a good model that captures any reliable patterns in the data,</p>
<p>• ﬁnd such a model while avoiding both overﬁtting and underﬁtting,</p>
<p>• explain the patterns that have been found to the user, ideally by having a conversation with the user about the data, and</p>
<p>• do all of this in a manner that is efﬁcient and robust with respect to constraints on compute time, memory, amount of data, and other relevant resources.</p>
</blockquote>
<p>While this agenda is obviously a very ambitious one, the work to date on the Automatic Statistician project has made progress on many of the above desiderata. In particular, the ability to discover plausible models from data and to explain these discoveries in plain English, is one of the distinguishing features of the Automatic Statistician [<a href="#_bookmark693">18</a>]. Such a feature could be useful to almost any ﬁeld or endeavour that is reliant on extracting knowledge from data.</p>
<p>In contrast to much of the machine learning literature that has been focused on extracting increasing performance improvements on pattern recognition problems (using techniques such as kernel methods, random forests, or deep learning), the Automatic Statistician needs to build models that are composed of interpretable components, and to have a principled way of representing uncertainty about model structures given data. It also needs to be able to give reasonable answers not just for big data sets, but also for small ones.</p>
<p><img src="./automlgithubpagesimages//media/image499.png" /><img src="./automlgithubpagesimages//media/image500.png" width="44" height="21" /><img src="./automlgithubpagesimages//media/image501.png" /><img src="./automlgithubpagesimages//media/image502.png" /><img src="./automlgithubpagesimages//media/image503.png" width="10" height="21" /><img src="./automlgithubpagesimages//media/image504.png" height="21" /><img src="./automlgithubpagesimages//media/image505.png" /><img src="./automlgithubpagesimages//media/image506.png" width="46" height="22" /><img src="./automlgithubpagesimages//media/image507.png" /><img src="./automlgithubpagesimages//media/image508.png" width="46" height="22" /></p>
<blockquote>
<p>9 The Automatic Statistician 163</p>
</blockquote>
<p><img src="./automlgithubpagesimages//media/image509.png" /></p>
<p><span id="_bookmark694" class="anchor"></span><strong>Fig.</strong> <strong>9.1</strong> A simpliﬁed ﬂow diagram outlining the operation of a report-writing Automatic Statisti- cian. Models for the data are automatically constructed (from the open-ended language of models), and evaluated on the data. This evaluation is done in a way that allows models to be compared to each other. The best models are then inspected to produce a report. Each model can be used to make extrapolations or predictions from the data, and the construction blue-print of the model can be turned into a human-readable description. For some models, it is also possible to generate <em>model</em> <em>criticism</em>, and report on where the modelling assumptions do not match the data well</p>
<blockquote>
<p><strong>9.2</strong> <strong>Basic</strong> <strong>Anatomy</strong> <strong>of</strong> <strong>an</strong> <strong>Automatic</strong> <strong>Statistician</strong></p>
<p>At the heart of the Automatic Statistician is the idea that a good solution to the above challenges can be obtained by working in the framework of <em>model-based</em> <em>machine</em> <em>learning</em> [<a href="#_bookmark695">2</a>, <a href="#_bookmark696">9</a>]. In model-based ML, the basic idea is that probabilistic models are explanations for patterns in data, and that the probabilistic framework (or Bayesian Occam’s razor) can be used to discover models that avoid both overﬁtting and underﬁtting [<a href="#_bookmark697">21</a>]. Bayesian approaches provide an elegant way of trading off the complexity of the model and the complexity of the data, and probabilistic models are compositional and interpretable as described previously. Moreover, the model-based philosophy maintains that tasks such as data pre-processing and transformation are all parts of the model and should ideally all be conducted at once [<a href="#_bookmark698">35</a>].</p>
<p>An Automatic Statistician contains the following key ingredients:</p>
<p>1. <strong>An</strong> <strong>open-ended</strong> <strong>language</strong> <strong>of</strong> <strong>models</strong> – expressive enough to capture real-world phenomena, and to allow applying the techniques used by human statisticians and data scientists.</p>
<p>2. <strong>A</strong> <strong>search</strong> <strong>procedure</strong> to efﬁciently explore the language of models.</p>
<p>3. <strong>A</strong> <strong>principled</strong> <strong>method</strong> <strong>of</strong> <strong>evaluating</strong> <strong>models</strong>, trading off complexity, ﬁt to data, <span id="_bookmark699" class="anchor"></span>and resource usage.</p>
<p>4. <strong>A</strong> <strong>procedure</strong> <strong>to</strong> <strong>automatically</strong> <strong>explain</strong> <strong>the</strong> <strong>models</strong>, making the assumptions of the models explicit in a way that is simultaneously accurate and intelligible to non-experts.</p>
</blockquote>
<p>Fig. <a href="#_bookmark694">9.1</a> shows a high-level overview of how these components could be used to produce a basic version of a report-writing Automatic Statistician.</p>
<blockquote>
<p>As will be discussed later in this chapter, it is possible to build Automatic <a href="#_bookmark699">Statistician systems that exchange ingredient (4</a>) for procedures that produce other</p>
<p>164 C. Steinruecken et al.</p>
<p>desirable outputs, for example raw predictions or decisions. In such cases, the language, search, and evaluation components may be modiﬁed appropriately to prioritise the chosen objective.</p>
<p><em><strong>9.2.1</strong></em> <em><strong>Related</strong></em> <em><strong>Work</strong></em></p>
</blockquote>
<p>Important earlier work includes statistical expert systems [<a href="#_bookmark700">11</a>, <a href="#_bookmark701">37</a>], and equation learning [<a href="#_bookmark702">26</a>,<a href="#_bookmark703">27</a>]. The <em>Robot</em> <em>Scientist</em> [<a href="#_bookmark704">16</a>] integrates machine learning and scientiﬁc discovery in a closed loop with an experimental platform in microbiology to automate the design and execution of new experiments. <em>Auto-WEKA</em> [<a href="#_bookmark705">17</a>, <a href="#_bookmark706">33</a>] and <em>Auto-sklearn</em> [<a href="#_bookmark707">6</a>] are projects that automate learning classiﬁers, making heavy use of Bayesian optimisation techniques. Efforts to automate the application of machine learning methods to data have recently gained momentum, and may ultimately result in practical AI systems for data science.</p>
<blockquote>
<p><strong>9.3</strong> <strong>An</strong> <strong>Automatic</strong> <strong>Statistician</strong> <strong>for</strong> <strong>Time</strong> <strong>Series</strong> <strong>Data</strong></p>
<p>Automatic Statistician systems can be deﬁned for a variety of different objectives, and can be based on different underlying model families. We’ll start by describing one such system, and discuss the wider taxonomy later, with notes on common design elements and general architecture.</p>
<p>An early Automatic Statistician for one-dimensional regression tasks was described by Lloyd et al. [<a href="#_bookmark693">18</a>]. Their system, called <em>Automatic</em> <em>Bayesian</em> <em>Covariance</em> <em>Discovery</em> <em>(ABCD)</em>, uses an open-ended language of Gaussian process models through a compositional grammar over kernels. A Gaussian process (GP) deﬁnes a distribution over functions, and the parameters of the GP – its mean and its kernel – determine the properties of the functions [<a href="#_bookmark708">25</a>]. There is a broad choice of available kernels that induce function distributions with particular properties; for example distributions over functions that are linear, polynomial, periodic, or uncorrelated noise. A pictorial overview of this system is shown in Fig.<a href="#_bookmark709">9.2</a>.</p>
<p><em><strong>9.3.1</strong></em> <em><strong>The</strong></em> <em><strong>Grammar</strong></em> <em><strong>over</strong></em> <em><strong>Kernels</strong></em></p>
<p>As mentioned above, a grammar over GP kernels makes it possible to represent many interesting properties of functions, and gives a systematic way of constructing distributions over such functions. This grammar over kernels is compositional: it comprises a set of ﬁxed <em>base</em> <em>kernels</em>, and <em>kernel</em> <em>operators</em> that make it possible to compose new kernels from existing ones. This grammar was carefully chosen to be <em>interpretable</em>: each expression in the grammar deﬁnes a kernel that can be described with a simple but descriptive set of words in human language.</p>
<p>9 The Automatic Statistician 165</p>
</blockquote>
<p><img src="./automlgithubpagesimages//media/image510.jpeg" width="442" height="232" /></p>
<blockquote>
<p><span id="_bookmark709" class="anchor"></span><strong>Fig.</strong> <strong>9.2</strong> A ﬂow diagram describing a report-writing Automatic Statistician for time-series data. (<strong>a</strong>) The input to the system is data, in this case represented as time series. (<strong>b</strong>) The system searches over a grammar of models to discover a good interpretation of the data, using Bayesian inference to score models. (<strong>c</strong>) Components of the model discovered are translated into English phrases. (<strong>d</strong>) The end result is a report with text, ﬁgures and tables, describing in detail what has been inferred about the data, including a section on model checking and criticism [<a href="#_bookmark710">8</a>, <a href="#_bookmark711">20</a>]</p>
<p>The base kernels in the grammar are: C (constant), LIN (linear), SE (squared exponential), PER (periodic), and WN (white noise). The kernel operators are: + (addition), × (multiplication), and CP (a change point operator), deﬁned as follows:</p>
<p>(k1 + k2)(x, x\) = k1 (x, x\) + k2 (x, x\)</p>
<p>(k1 × k2)(x, x )\ = k1 (x, x\) × k2 (x, x )\</p>
<p>CP (k1 ,k2) (x, x\) = k1 (x, x\)σ(x)σ(x\) + k2 (x, x\)(1 − σ(x)) (1 − σ(x\))</p>
<p>where σ(x) = 1<img src="./automlgithubpagesimages//media/image511.jpeg" />2 (1 + tanh <img src="./automlgithubpagesimages//media/image512.png" width="13" height="19" />) is a sigmoidal function, and l and s are parameters of the change point. The base kernels can be arbitrarily combined using the above operators to produce new kernels.</p>
<p>The inﬁnite space of kernels deﬁned by this grammar allows a large class of interesting distributions over functions to be searched, evaluated, and described in an automated way. This type of grammar was ﬁrst described in [<a href="#_bookmark712">10</a>] for matrix factorization problems, and then reﬁned in [<a href="#_bookmark713">5</a>] and [<a href="#_bookmark693">18</a>] for GP models.</p>
</blockquote>
<p><em><strong>9.3.2</strong></em> <em><strong>The</strong></em> <em><strong>Search</strong></em> <em><strong>and</strong></em> <em><strong>Evaluation</strong></em> <em><strong>Procedure</strong></em></p>
<blockquote>
<p>ABCD performs a greedy search over the space of models (as deﬁned by the grammar). The kernel parameters of each proposed model are optimised by a</p>
<p>166 C. Steinruecken et al.</p>
<p>conjugate-gradient method; the model with optimised parameters is then evaluated using the Bayesian Information Criterion [<a href="#_bookmark714">29</a>]:</p>
</blockquote>
<p>BIC (M) = −2log p (D | M) + |M|log N (9. 1)</p>
<blockquote>
<p>where M is the optimised model, p (D | M) is the marginal likelihood of the model integrating out the latent GP function, |M| is the number of kernel parameters in M , and N is the size of the dataset. The Bayesian Information Criterion trades off model complexity and ﬁt to the data, and approximates the full marginal likelihood (which integrates out latent functions and hyperparameters).</p>
<p>The best-scoring model in each round is used to construct new proposed models, either by: (1) expanding the kernel with production rules from the grammar, such as introducing a sum, product, or change point; or (2) mutating the kernel by swapping out a base kernel for a different one. The new set of proposed kernels is then evaluated in the next round. It is possible with the above rules that a kernel expression gets proposed several times, but a well-implemented system will keep records and only ever evaluate each expression once. The search and evaluation procedure stops either when the score of all newly proposed models is worse than the best model from the previous round, or when a pre-deﬁned search depth is exceeded.</p>
<p>This greedy search procedure is not guaranteed to ﬁnd the best model in the language for any given dataset: a better model might be hiding in one of the subtrees that weren’t expanded out. Finding the globally best model isn’t usually essential, as long as a good interpretable models is found in a reasonable amount of time. There are other ways of conducting the search and evaluation of models. For example, Malkomes et al. [<a href="#_bookmark715">22</a>] describe a kernel search procedure based on Bayesian optimisation. Janz et al. [<a href="#_bookmark716">14</a>] implemented a kernel search method using particle ﬁltering and Hamiltonian Monte Carlo.</p>
</blockquote>
<p><em><strong>9.3.3</strong></em> <em><strong>Generating</strong></em> <em><strong>Descriptions</strong></em> <em><strong>in</strong></em> <em><strong>Natural</strong></em> <em><strong>Language</strong></em></p>
<blockquote>
<p>When the search procedure terminates, it produces a list of kernel expressions and their scores on the dataset. The expression with the best score is then used to generate a natural-language description. To convert a kernel to a description in natural language, the kernel is ﬁrst converted to a canonical form, using the following process:</p>
<p>1. Nested sums and products are ﬂattened into a sum of products form.</p>
<p>2. Some products of kernels can be simpliﬁed into base kernels with modiﬁed parameters, for example: SE × SE → SE∗ , C × k → k∗ for any k, and WN × k → WN∗ for any k ∈ {C, SE, WN, PER}.</p>
</blockquote>
<p><img src="./automlgithubpagesimages//media/image513.jpeg" height="51" /></p>
<blockquote>
<p>9 The Automatic Statistician 167</p>
</blockquote>
<p>After applying these rules, the kernel expression is a sum of product terms, where each product term has the following canonical form:</p>
<p>k ×uLIN(m) ×u<strong>σ</strong> (n) (9.2)</p>
<blockquote>
<p>m n</p>
<p>where <strong>σ</strong> (x, x\) = σ(x) σ(x\) is a product of two sigmoid functions, and k has one of the following forms: 1, WN, C, SE, ujPER(j ), or SE ×uj PER(j ) . The notation uj k(j ) stands for products of kernels, each with separate parameters.</p>
</blockquote>
<p>In this canonical form, the kernel is a sum of products, and the number of terms in the sum is described ﬁrst: “The structure search algorithm has identiﬁed N additive components in the data.” This sentence is then followed by a description of each additive component (i.e. each product in the sum), using the following algorithm:</p>
<blockquote>
<p>1. Choose <em>one</em> of the kernels in the product to be the noun descriptor. A heuristic recommended by Lloyd et al. [<a href="#_bookmark693">18</a>] is to pick according to the following preference: PER &gt; {C, SE, WN} &gt;ujLIN(j ) &gt;uj<strong>σ</strong>(j ), where PER is the most preferred.</p>
<p>2. Convert the chosen kernel type to a string using this table:</p>
<p>WN “uncorrelated noise”</p>
<p>PER “periodic function”</p>
<p>C “constant”</p>
<p>SE</p>
</blockquote>
<p>LIN</p>
<blockquote>
<p>uj LIN(j )</p>
</blockquote>
<p>“smooth function”</p>
<p>“linear function”</p>
<p>“polynomial”</p>
<blockquote>
<p>3. The other kernels in the product are converted to <em>post-modiﬁer</em> expressions that are appended to the noun descriptor. The post modiﬁers are converted using this table:</p>
</blockquote>
<table>
<tbody>
<tr class="odd">
<td><blockquote>
<p>SE</p>
</blockquote></td>
<td><blockquote>
<p>“whose shape changes smoothly”</p>
</blockquote></td>
</tr>
<tr class="even">
<td>PER</td>
<td><blockquote>
<p>“modulated by a periodic function”</p>
</blockquote></td>
</tr>
<tr class="odd">
<td>LIN</td>
<td><blockquote>
<p>“with linearly varying amplitude”</p>
</blockquote></td>
</tr>
<tr class="even">
<td><blockquote>
<p>uj LIN(j )</p>
</blockquote></td>
<td><blockquote>
<p>“with polynomially varying amplitude”</p>
</blockquote></td>
</tr>
<tr class="odd">
<td><blockquote>
<p>uj <strong>σ</strong> (j )</p>
</blockquote></td>
<td><blockquote>
<p>“which applies from / until [changepoint]”</p>
</blockquote></td>
</tr>
</tbody>
</table>
<p>4. Further reﬁnements to the description are possible, including insights from kernel parameters, or extra information calculated from the data. Some of these reﬁnements are described in [<a href="#_bookmark693">18</a>].</p>
<p>More details on the translation of kernel expressions to natural language can be found in [<a href="#_bookmark693">18</a>] and [<a href="#_bookmark717">19</a>]. An example extract from a generated report is shown in Fig.<a href="#_bookmark718">9.3</a>.</p>
<p><img src="./automlgithubpagesimages//media/image514.png" width="193" height="79" /></p>
<blockquote>
<p>168 C. Steinruecken et al.</p>
<p>This component is approximately periodic with a period of 10.8 years. Across periods the shape of this function varies smoothly with a typical lengthscale of 36.9 years. The shape of this function within each period is very smooth and resembles a sinusoid. This component applies until 1643 and</p>
<p>from 1716 onwards.</p>
<p>This component explains 71.5% of the residual variance; this increases the total variance explained from 72.8% to 92.3%. The addition of this component reduces the cross validated MAE by 16.82% from 0.18 to 0.15.</p>
<p>0.6</p>
<p>0.4</p>
<p>0.2</p>
<p>0</p>
<p>−0.2</p>
<p>−0.4</p>
<p>−0.6</p>
<p>−0.8</p>
<p>Posterior of component 4</p>
</blockquote>
<table>
<tbody>
<tr class="odd">
<td></td>
</tr>
</tbody>
</table>
<blockquote>
<p>1650 1700 1750 1800 1850 1900 1950 2000</p>
<p>Sum of components up to component 4</p>
<p>1362</p>
</blockquote>
<p>1361.5</p>
<blockquote>
<p>1361</p>
</blockquote>
<p>1360.5</p>
<blockquote>
<p>1360</p>
<p>1650 1700 1750 1800 1850 1900 1950 2000</p>
<p><span id="_bookmark718" class="anchor"></span><strong>Fig.</strong> <strong>9.3</strong> Extract from an automatically generated report that describes the model components discovered by ABCD. This part of the report isolates and describes the approximately 11-year sunspot cycle, also noting its disappearance during the sixteenth century, a time period known as the Maunder minimum. (This ﬁgure is reproduced from [<a href="#_bookmark693">18</a>])</p>
<p><em><strong>9.3.4</strong></em> <em><strong>Comparison</strong></em> <em><strong>with</strong></em> <em><strong>Humans</strong></em></p>
<p>An interesting question to consider is to what extent predictions made by an Automated Statistician (such as the ABCD algorithm) are human-like, and how they compare to predictions made with other methods that are also based on Gaussian processes. To answer that question, Schulz et al. [<a href="#_bookmark719">28</a>] presented participants with the task of extrapolating from a given set of data, and choosing a preferred extrapolation from a given set. The results were encouraging for composite kernel search in two ways: Firstly, the participants preferred the extrapolations made by ABCD over those made with Spectral Kernels [<a href="#_bookmark720">36</a>], and over those made with a simple RBF (radial basis function) kernel. Secondly, when human participants were asked to extrapolate the data themselves, their predictions were most similar to those given by ABCD’s composite search procedure.</p>
<p>One of the design goals of a report-writing Automatic Statistician is the ability to explain its ﬁndings in terms that are understandable by humans. The system described earlier restricts itself to a space of models that can be explained in human language using simple terms, even though this design choice may come at the cost of predictive accuracy. In general, it is not straight-forward to measure the interpretability of machine learning systems; one possible framework is suggested by Doshi-Velez and Kim [<a href="#_bookmark721">4</a>]. We note in passing that not all machine learning systems require such functionality. For example, when the results of a system have little impact on society, especially in terms of social norms and interactions, it is acceptable to optimise for performance or accuracy instead (e.g. recognising post codes for automatic mail sorting).</p>
<p>9 The Automatic Statistician 169</p>
<p><strong>9.4</strong> <strong>Other</strong> <strong>Automatic</strong> <strong>Statistician</strong> <strong>Systems</strong></p>
<p>The ability to generate human-readable reports is perhaps one of the distinguishing features of Automatic Statistician systems. But, as mentioned earlier, software of this nature can serve other purposes as well. For example, users might be interested in raw predictions from the data (with or without explanations), or they might want the system to make data-driven decisions directly on their behalf.</p>
<p>Also, it is possible to build Automatic Statistician systems for model families that are different from Gaussian processes or grammars. For example, we built Automated Statistician systems for regression [<a href="#_bookmark713">5</a>, <a href="#_bookmark693">18</a>], classiﬁcation [<a href="#_bookmark722">12</a>, <a href="#_bookmark723">23</a>], univariate and multivariate data; systems based on various different model classes, and systems with and without intelligent resource control. This section discusses some of the design elements that are shared across many Automatic Statistician systems.</p>
</blockquote>
<p><em><strong>9.4.1</strong></em> <em><strong>Core</strong></em> <em><strong>Components</strong></em></p>
<blockquote>
<p>One of the key tasks that an Automatic Statistician has to perform is to select, evaluate, and compare models. These types of task can be run concurrently, but they have interdependencies. For example, the evaluation of one set of models might inﬂuence the selection of the next set of models.</p>
<p>Most generally, the <strong>selection</strong> <strong>strategy</strong> component in our system is responsible for choosing models to evaluate: it might choose from a ﬁxed or open-ended family of models, or it might generate and reﬁne models based on the evaluation and comparison of previously chosen models. Sometimes, the <em>types</em> of the variables in the dataset (whether inferred from the data or annotated by the user) inﬂuence which models might be chosen by the selection strategy. For example, one might want to distinguish continuous and discrete data, and to use different treatments for categorical and ordinal data.</p>
<p>The <strong>model</strong> <strong>evaluation</strong> task trains a given model on part of the user-supplied dataset, and then produces a score by testing the model on held-out data. Some models do not require a separate training phase and can produce a log-likelihood for the entire dataset directly. Model evaluation is probably one of the most important tasks to parallelise: at any given time, multiple selected models can be evaluated simultaneously, on multiple CPUs or even multiple computers.</p>
<p>The <strong>report</strong> <strong>curator</strong> component is the piece of software that decides which results to include in the ﬁnal report. For example, it might include sections that describe the best ﬁtting models, along with extrapolations, graphs, or data tables. Depending on the evaluation results, the report curator might choose to include additional material, such as data falsiﬁcation/model criticism sections, recommendations, or a summary. In some systems the deliverable might be something other than a report, such as raw predictions, parameter settings, or model source code.</p>
<p>170 C. Steinruecken et al.</p>
<p>In interactive systems, a <strong>data</strong> <strong>loading</strong> <strong>stage</strong> provides an instant summary about the uploaded dataset, and allows the user to correct any assumptions about the format of the data. The user can make type annotations, remove columns from the dataset, choose an output variable (e.g. for classiﬁcation), and specify the analyses that should be run.</p>
</blockquote>
<p><em><strong>9.4.2</strong></em> <em><strong>Design</strong></em> <em><strong>Challenges</strong></em></p>
<blockquote>
<p><strong>9.4.2.1</strong> <strong>User</strong> <strong>Interaction</strong></p>
<p>While the aim of an Automatic Statistician is to automate <em>all</em> aspects of data handling (from low-level tasks such as formatting and clean-up, to high-level tasks such as model construction, evaluation, and criticism), it is also useful to give users the option to interact with the system and inﬂuence the choices it makes. For example, users might want to specify which parts or which aspects of the data they are interested in, and which parts can be ignored. Some users might want to choose the family of models that the system will consider in the model construction or evaluation phase. Finally, the system may want to engage in a dialogue with the user to explore or explain what it found in the data. Such interactivity needs to be supported by the underlying system.</p>
<p><strong>9.4.2.2</strong> <strong>Missing</strong> <strong>and</strong> <strong>Messy</strong> <strong>Data</strong></p>
<p>A common problem with real-world datasets is that they may have missing or corrupt entries, unit or formatting inconsistencies, or other kinds of defects. These kinds of defects may require some pre-processing of the data, and while many decisions could be made automatically, some might beneﬁt from interaction with the user. Good models can handle missing data directly, and as long as the missing data is detected correctly by the data loading stage, everything should be ﬁne. But there are some data models that cannot handle missing data natively. In such cases, it might be useful to perform <em>data</em> <em>imputation</em> to feed these models a version of the dataset that has the missing values ﬁlled in. This imputation task itself is performed by a model that is trained on the data. Examples of such techniques include e.g. MissForest [<a href="#_bookmark724">31</a>], MissPaLasso [<a href="#_bookmark725">30</a>], mice [<a href="#_bookmark726">3</a>], KNNimpute [<a href="#_bookmark727">34</a>], and Bayesian approaches [<a href="#_bookmark728">1</a>, <a href="#_bookmark729">7</a>].</p>
<p><strong>9.4.2.3</strong> <strong>Resource</strong> <strong>Allocation</strong></p>
<p>Another important aspect of an Automatic Statistician is <em>resource</em> <em>usage</em>. For example, a user might only have a limited number of CPU cores available, or might be interested to get the best possible report within a ﬁxed time limit,</p>
<p>9 The Automatic Statistician 171</p>
<p>e.g. before a given deadline. To make good model selection and evaluation choices, an intelligent system might take into account such resource constraints. The ability to do so will affect the overall usability of the system.</p>
</blockquote>
<p>Even when there are no direct constraints on computation time, CPU cores, or memory usage, an intelligent system might beneﬁt from allocating resources to models whose evaluation is promising for the chosen deliverable. Such functionality can be implemented for models that support some form of gradual evaluation, for example by training incrementally on increasingly large subsets of the dataset. One of our systems used a variant of Freeze-thaw Bayesian optimisation [<a href="#_bookmark730">32</a>] for this purpose.</p>
<blockquote>
<p><strong>9.5</strong> <strong>Conclusion</strong></p>
<p>Our society has entered an era of abundant data. Analysis and exploration of the data is essential for harnessing the beneﬁts of this growing resource. Unfortunately, the growth of data currently outpaces our ability to analyse it, especially because this task still largely rests on human experts. But many aspects of machine learning and data analysis can be automated, and one guiding principle in pursuit of this goal is to “apply machine learning to itself” .</p>
</blockquote>
<p>The Automatic Statistician project aims to automate data science by taking care of all aspects of data analysis, from data pre-processing, modelling and evaluation, to the generation of useful and transparent results. All these tasks should be performed in a way that requires little user expertise, minimises the amount of user interaction, and makes intelligent and controlled use of computational resources.</p>
<p>While this aim is ambitious, and a lot of the work still needs to happen, encouraging progress has been made towards the creation of such automated systems. Multiple Automatic Statistician systems have been built, each with slight differences in purpose and underlying technology, but they all share the same intent and much of the same design philosophy. We hope that the creation of such instruments will bring the ability to gain insights from data to a larger group of people, and help empower society to make great use of our data resources.</p>
<p><strong>Acknowledgements</strong> The authors would like to thank Tameem Adel Hesham, Lars Kotthoff, and Frank Hutter for helpful feedback.</p>
<blockquote>
<p><span id="_bookmark728" class="anchor"></span><strong>Bibliography</strong></p>
<p>1. Allingham, J.U.: Unsupervised automatic dataset repair. Master’s thesis in advanced computer science, Computer Laboratory, University of Cambridge (2018)</p>
<p>2. Bishop, C.M.: Pattern recognition and machine learning. Information science and statistics, <span id="_bookmark695" class="anchor"><span id="_bookmark726" class="anchor"></span></span>Springer (2006)</p>
<p>3. van Buuren, S., Groothuis-Oudshoorn, K.: mice: Multivariate imputation by chained equa- <span id="_bookmark721" class="anchor"></span>tions in R. Journal of Statistical Software 45(3) (2011)</p>
<p>4. Doshi-Velez, F., Kim, B.: Towards a rigorous science of interpretable machine learning (Mar 2017), <a href="http://arxiv.org/abs/1702.08608" class="uri">http://arxiv.org/abs/1702.08608</a></p>
<p>172 C. Steinruecken et al.</p>
<p><span id="_bookmark713" class="anchor"></span>5. Duvenaud, D., Lloyd, J.R., Grosse, R., Tenenbaum, J.B., Ghahramani, Z.: Structure discovery in nonparametric regression through compositional kernel search. In: Proceedings of the 30th <span id="_bookmark707" class="anchor"></span>International Conference on Machine Learning (Jun 2013)</p>
<p>6. Feurer, M., Klein, A., Eggensperger, K., Springenberg, J., Blum, M., Hutter, F.: Efﬁcient and robust automated machine learning. In: Cortes, C., Lawrence, N.D., Lee, D.D., Sugiyama, M., Garnett, R. (eds.) Advances in Neural Information Processing Systems 28, pp. 2962–2970. <span id="_bookmark729" class="anchor"></span>Curran Associates, Inc. (2015)</p>
<p>7. Garriga Alonso, A.: Probability density imputation of missing data with Gaussian Mixture <span id="_bookmark710" class="anchor"></span>Models. MSc thesis, University of Oxford (2017)</p>
<p>8. Gelman, A., Carlin, J.B., Stern, H.S., Dunson, D.B., Vehtari, A., Rubin, D.B.: Bayesian Data Analysis, Third Edition. Chapman &amp; Hall/CRC Texts in Statistical Science. Taylor &amp; Francis</p>
<p><span id="_bookmark696" class="anchor"></span>(2013)</p>
<p>9. Ghahramani, Z.: Probabilistic machine learning and artiﬁcial intelligence. Nature 521, 452– <span id="_bookmark712" class="anchor"></span>459 (2015)</p>
<p>10. Grosse, R.B., Salakhutdinov, R., Tenenbaum, J.B.: Exploiting compositionality to explore a large space of model structures. In: Uncertainty in Artiﬁcial Intelligence (2012)</p>
<p>11. Hand, D.J.: Patterns in statistical strategy. In: Gale, W.A. (ed.) Artiﬁcial intelligence and <span id="_bookmark700" class="anchor"><span id="_bookmark722" class="anchor"></span></span>statistics (1986)</p>
<p>12. He, Q.: The Automatic Statistician for Classiﬁcation. Master’s thesis, Department of Engineer- ing, University of Cambridge (May 2016)</p>
<p>13. Hwang, Y., Tong, A., Choi, J.: Automatic construction of nonparametric relational regression models for multiple time series. In: Balcan, M.F., Weinberger, K.Q. (eds.) ICML 2016: Proceedings of the 33rd International Conference on Machine Learning. Proceedings of <span id="_bookmark716" class="anchor"></span>Machine Learning Research, vol. 48, pp. 3030–3039. PLMR (2016)</p>
<p>14. Janz, D., Paige, B., Rainforth, T., van de Meent, J.W., Wood, F.: Probabilistic structure discovery in time series data (2016), <a href="https://arxiv.org/abs/1611.06863" class="uri">https://arxiv.org/abs/1611.06863</a></p>
<p>15. Kim, H., Teh, Y.W.: Scaling up the Automatic Statistician: Scalable structure discovery using Gaussian processes. In: Storkey, A., Perez-Cruz, F. (eds.) Proceedings of the 21st International Conference on Artiﬁcial Intelligence and Statistics. Proceedings of Machine <span id="_bookmark704" class="anchor"></span>Learning Research, vol. 84, pp. 575–584. PLMR (2018)</p>
<p>16. King, R.D., Whelan, K.E., Jones, F.M., Reiser, P.G.K., Bryant, C.H., Muggleton, S.H., Kell, D.B., Oliver, S.G.: Functional genomic hypothesis generation and experimentation by a robot <span id="_bookmark705" class="anchor"></span>scientist. Nature 427(6971), 247–252 (2004)</p>
<p>17. Kotthoff, L., Thornton, C., Hoos, H.H., Hutter, F., Leyton-Brown, K.: Auto-WEKA 2.0: Automatic model selection and hyperparameter optimization in WEKA. Journal of Machine <span id="_bookmark693" class="anchor"></span>Learning Research 18(25), 1–5 (2017)</p>
<p>18. Lloyd, J.R., Duvenaud, D., Grosse, R., Tenenbaum, J.B., Ghahramani, Z.: Automatic construc- tion and natural-language description of nonparametric regression models. In: Twenty-Eighth <span id="_bookmark717" class="anchor"></span>AAAI Conference on Artiﬁcial Intelligence (AAAI-14) (2014)</p>
<p>19. Lloyd, J.R.: Representation, learning, description and criticism of probabilistic models with applications to networks, functions and relational data. Ph.D. thesis, Department of Engineer- <span id="_bookmark711" class="anchor"></span>ing, University of Cambridge (Dec 2014)</p>
</blockquote>
<p>20. Lloyd, J.R., Ghahramani, Z.: Statistical model criticism using kernel two sample tests. In: Cortes, C., Lawrence, N.D., Lee, D.D., Sugiyama, M., Garnett, R. (eds.) Advances in Neural Information Processing Systems 28. pp. 829–837. Curran Associates, Inc. (2015)</p>
<p><span id="_bookmark697" class="anchor"></span>21. MacKay, D.J.C.: Bayesian interpolation. Neural Computation 4(3), 415–447 (1992), see [<a href="#_bookmark731">24</a>] <span id="_bookmark715" class="anchor"></span>for additional discussion and illustration.</p>
<p>22. Malkomes, G., Schaff, C., Garnett, R.: Bayesian optimization for automated model selection. In: Lee, D.D., Sugiyama, M., von Luxburg, U., Guyon, I., Garnett, R. (eds.) Advances in Neural Information Processing Systems 29, pp. 2900–2908. Curran Associates, Inc. (2016)</p>
<p><span id="_bookmark723" class="anchor"></span>23. Mrkši<img src="./automlgithubpagesimages//media/image515.png" height="12" />, N.: Kernel Structure Discovery for Gaussian Process Classiﬁcation. Master’s thesis, <span id="_bookmark731" class="anchor"></span>Computer Laboratory, University of Cambridge (Jun 2014)</p>
<p>24. Murray, I., Ghahramani, Z.: A note on the evidence and Bayesian Occam’s razor. Tech. Rep. GCNU-TR 2005-003, Gatsby Computational Neuroscience Unit, University College London</p>
<blockquote>
<p>(2005)</p>
<p>9 The Automatic Statistician 173</p>
<p><span id="_bookmark708" class="anchor"></span>25. Rasmussen, C.E., Williams, C.K.I.: Gaussian Processes for Machine Learning. MIT Press</p>
<p><span id="_bookmark702" class="anchor"></span>(2006), <a href="http://www.gaussianprocess.org/gpml/" class="uri">http://www.gaussianprocess.org/gpml/</a></p>
<p>26. Schmidt, M., Lipson, H.: Distilling free-form natural laws from experimental data. Science <span id="_bookmark703" class="anchor"></span>324(5923), 81–85 (2009)</p>
<p>27. Schmidt, M., Lipson, H.: Symbolic regression of implicit equations. In: Riolo, R., O’Reilly, U.M., McConaghy, T. (eds.) Genetic Programming Theory and Practice VII, pp. 73–85. <span id="_bookmark719" class="anchor"></span>Springer, Boston, MA (2010)</p>
<p>28. Schulz, E., Tenenbaum, J., Duvenaud, D.K., Speekenbrink, M., Gershman, S.J.: Probing the compositionality of intuitive functions. In: Lee, D.D., Sugiyama, M., von Luxburg, U., Guyon, I., Garnett, R. (eds.) Advances in Neural Information Processing Systems 29, pp. 3729–3737. <span id="_bookmark714" class="anchor"></span>Curran Associates, Inc. (2016)</p>
<p>29. Schwarz, G.: Estimating the dimension of a model. The Annals of Statistics 6(2), 461–464</p>
<p><span id="_bookmark725" class="anchor"></span>(1978)</p>
<p>30. Städler, N., Stekhoven, D.J., Bühlmann, P.: Pattern alternating maximization algorithm for missing data in high-dimensional problems. Journal of Machine Learning Research 15, 1903– <span id="_bookmark724" class="anchor"></span>1928 (Jun 2014)</p>
<p>31. Stekhoven, D.J., Bühlmann, P.: MissForest – non-parametric missing value imputation for mixed-type data. Bioinformatics 28(1), 112– 118 (Nov 2011)</p>
<p>32. Swersky, K., Snoek, J., Adams, R.P.: Freeze-thaw Bayesian optimization (Jun 2014), <a href="http://arxiv.org/abs/1406.3896">http://</a> <span id="_bookmark730" class="anchor"><span id="_bookmark706" class="anchor"></span></span><a href="http://arxiv.org/abs/1406.3896">arxiv.org/abs/1406.3896</a></p>
<p>33. Thornton, C., Hutter, F., Hoos, H.H., Leyton-Brown, K.: Auto-WEKA: Combined selection and hyperparameter optimization of classiﬁcation algorithms. In: Proceedings of the 19th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. pp. 847–855. <span id="_bookmark727" class="anchor"></span>KDD ’13, ACM, New York, NY, USA (2013)</p>
<p>34. Troyanskaya, O., Cantor, M., Sherlock, G., Brown, P., Hastie, T., Tibshirani, R., Botstein, D., Altman, R.B.: Missing value estimation methods for DNA microarrays. Bioinformatics pp. <span id="_bookmark698" class="anchor"></span>520–525 (Jun 2001)</p>
<p>35. Valera, I., Ghahramani, Z.: Automatic discovery of the statistical types of variables in a dataset. In: Precup, D., Teh, Y.W. (eds.) ICML 2017: Proceedings of the 34th International Conference on Machine Learning. Proceedings of Machine Learning Research, vol. 70, pp. 3521–3529. <span id="_bookmark720" class="anchor"></span>PLMR (2017)</p>
<p>36. Wilson, A.G., Adams, R.P.: Gaussian process kernels for pattern discovery and extrapolation. In: Dasgupta, S., McAllester, D. (eds.) ICML 2013: Proceedings of the 30th International Conference on Machine Learning. JLMR Proceedings, vol. 28, pp. 1067– 1075. JLMR.org (Jun <span id="_bookmark701" class="anchor"></span>2013)</p>
<p>37. Wolstenholme, D.E., O’Brien, C.M., Nelder, J.A.: GLIMPSE: a knowledge-based front end for statistical analysis. Knowledge-Based Systems 1(3), 173– 178 (1988)</p>
<p><strong>Open</strong> <strong>Access</strong> This chapter is licensed under the terms of the Creative Commons Attribution 4.0 International License <a href="http://creativecommons.org/licenses/by/4.0/">(http://creativecommons.org/licenses/by/4.0/</a>), which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence and indicate if changes were made.</p>
<p>The images or other third party material in this chapter are included in the chapter’s Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the chapter’s Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder.</p>
</blockquote>
<p><img src="./automlgithubpagesimages//media/image516.png" width="75" height="26" /></p>
<p><span id="_bookmark9" class="anchor"></span><strong>Part</strong> <strong>III</strong></p>
<p><strong>AutoML</strong> <strong>Challenges</strong></p>
<p><img src="./automlgithubpagesimages//media/image517.png" width="41" height="41" /><img src="./automlgithubpagesimages//media/image518.jpeg" width="136" /></p>
<blockquote>
<p><span id="_bookmark13" class="anchor"></span><strong>Chapter</strong> <strong>10</strong></p>
<p><strong>Analysis</strong> <strong>of</strong> <strong>the</strong> <strong>AutoML</strong> <strong>Challenge</strong> <strong>Series</strong></p>
<p><strong>2015–2018</strong></p>
</blockquote>
<p><img src="./automlgithubpagesimages//media/image519.png" /></p>
<blockquote>
<p><strong>Isabelle</strong> <strong>Guyon,</strong> <strong>Lisheng</strong> <strong>Sun-Hosoya,</strong> <strong>Marc</strong> <strong>Boullé,</strong> <strong>Hugo</strong> <strong>Jair</strong> <strong>Escalante,</strong> <strong>Sergio</strong> <strong>Escalera</strong> <a href="https://orcid.org/0000-0003-0617-8873"><img src="./automlgithubpagesimages//media/image520.png" width="13" height="11" /></a><strong>,</strong> <strong>Zhengying</strong> <strong>Liu,</strong> <strong>Damir</strong> <strong>Jajetic,</strong> <strong>Bisakha</strong> <strong>Ray,</strong> <strong>Mehreen</strong> <strong>Saeed,</strong> <strong>Michèle</strong> <strong>Sebag,</strong> <strong>Alexander</strong> <strong>Statnikov,</strong> <strong>Wei-Wei</strong> <strong>Tu,</strong> <strong>and</strong> <strong>Evelyne</strong> <strong>Viegas</strong></p>
</blockquote>
<p><strong>Abstract</strong> The ChaLearn AutoML Challenge (The authors are in alphabetical order of last name, except the ﬁrst author who did most of the writing and the second author who produced most of the numerical analyses and plots.) (NIPS 2015 – ICML 2016) consisted of six rounds of a machine learning competition of progressive difﬁculty, subject to limited computational resources. It was followed by</p>
<blockquote>
<p>I. Guyon (凶)</p>
<p>University of Paris-Sud, Orsay, France</p>
<p>INRIA, University of Paris-Saclay, Paris, France</p>
<p>ChaLearn and ClopiNet, Berkeley, CA, USA</p>
<p>e-mail: <a href="mailto:guyon@chalearn.org">guyon@chalearn.org</a></p>
<p>L. Sun-Hosoya · Z. Liu</p>
<p>Laboratoire de Recherche en Informatique, University of Paris-Sud, Orsay, France University of Paris-Saclay, Paris, France</p>
<p>M. Boullé</p>
<p>Machine Learning Group, Orange Labs, Lannion, France</p>
<p>H. J. Escalante</p>
<p>Computational Sciences Department, INAOE and ChaLearn, Tonantzintla, Mexico</p>
<p>S. Escalera</p>
<p>Computer Vision Center, University of Barcelona, Barcelona, Spain</p>
<p>D. Jajetic</p>
<p>IN2, Zagreb, Croatia</p>
<p>B. Ray</p>
<p>Langone Medical Center, New York University, New York, NY, USA</p>
<p>M. Saeed</p>
<p>Department of Computer Science, National University of Computer and Emerging Sciences, Islamabad, Pakistan</p>
<p>M. Sebag</p>
<p>Laboratoire de Recherche en Informatique, CNRS, Paris, France</p>
<p>University of Paris-Saclay, Paris, France</p>
<p>© The Author(s) 2019</p>
<p>F. Hutter et al. (eds.), <em>Automated</em> <em>Machine</em> <em>Learning</em>, The Springer Series on Challenges in Machine Learning, <a href="https://doi.org/10.1007/978-3-030-05318-5_10" class="uri">https://doi.org/10.1007/978-3-030-05318-5_10</a></p>
</blockquote>
<p><img src="./automlgithubpagesimages//media/image9.jpeg" width="136" /></p>
<blockquote>
<p>178 I. Guyon et al.</p>
</blockquote>
<p>a one-round AutoML challenge (PAKDD 2018). The AutoML setting differs from former model selection/hyper-parameter selection challenges, such as the one we previously organized for NIPS 2006: the participants aim to develop fully automated and computationally efﬁcient systems, capable of being trained and tested without human intervention, with code submission. This chapter analyzes the results of these competitions and provides details about the datasets, which were not revealed to the participants. The solutions of the winners are systematically benchmarked over all datasets of all rounds and compared with canonical machine learning algorithms available in scikit-learn. All materials discussed in this chapter (data and code) have been made publicly available at <a href="http://automl.chalearn.org/" class="uri">http://automl.chalearn.org/</a>.</p>
<blockquote>
<p><strong>10.1</strong> <strong>Introduction</strong></p>
<p>Until about 10 years ago, machine learning (ML) was a discipline little known to the public. For ML scientists, it was a “seller’s market”: they were producing hosts of algorithms in search for applications and were constantly looking for new interesting datasets. Large internet corporations accumulating massive amounts of data such as Google, Facebook, Microsoft and Amazon have popularized the use of ML and data science competitions have engaged a new generation of young scientists in this wake. Nowadays, government and corporations keep identifying new applications of ML and with the increased availability of open data, we have switched to a “buyer’s market”: everyone seems to be in need of a learning machine. Unfortunately however, learning machines are not yet fully automatic: it is still difﬁcult to ﬁgure out which software applies to which problem, how to horseshoe-ﬁt data into a software and how to select (hyper-)parameters properly. The ambition of the ChaLearn AutoML challenge series is to channel the energy of the ML community to reduce step by step the need for human intervention in applying ML to a wide variety of practical problems.</p>
<p>Full automation is an unbounded problem since there can always be novel settings, which have never been encountered before. Our ﬁrst challenges AutoML1 were limited to:</p>
<p>• <strong>Supervised</strong> <strong>learning</strong> problems (classiﬁcation and regression).</p>
<p>• <strong>Feature</strong> <strong>vector</strong> representations.</p>
<p>• <strong>Homogeneous</strong> <strong>datasets</strong> (same distribution in the training, validation, and test set).</p>
<p>A. Statnikov</p>
<p>SoFi San Francisc, California, USA</p>
<p>W.-W. Tu</p>
<p>4Paradigm, Beijing, Republic of China</p>
<p>E. Viegas</p>
<p>Microsoft Research, Redmond, WA, USA</p>
<p>10 Analysis of the AutoML Challenge Series 2015–2018 179</p>
<p>• <strong>Medium</strong> <strong>size</strong> <strong>datasets</strong> of less than 200 MBytes.</p>
<p>• <strong>Limited</strong> <strong>computer</strong> <strong>resources</strong> with execution times of less than 20 min per dataset on an 8 core x86_64 machine with 56 GB RAM.</p>
<p>We excluded unsupervised learning, active learning, transfer learning, and causal discovery problems, which are all very dear to us and have been addressed in past ChaLearn challenges [<a href="#_bookmark732">31</a>], but which require each a different evaluation setting, thus making result comparisons very difﬁcult. We did not exclude the treatment of video, images, text, and more generally time series and the selected datasets actually contain several instances of such modalities. However, they were ﬁrst preprocessed in a feature representation, thus de-emphasizing feature learning. Still, learning from data pre-processed in feature-based representations already covers a lot of grounds and a fully automated method resolving this restricted problem would already be a major advance in the ﬁeld.</p>
<p>Within this constrained setting, we included a variety of difﬁculties:</p>
<p>• <strong>Different</strong> <strong>data</strong> <strong>distributions:</strong> the intrinsic/geometrical complexity of the dataset.</p>
<p>• <strong>Different</strong> <strong>tasks:</strong> regression, binary classiﬁcation, multi-class classiﬁcation, multi-label classiﬁcation.</p>
<p>• <strong>Different</strong> <strong>scoring</strong> <strong>metrics:</strong> AUC, BAC, MSE, F1, etc. (see Sect.<a href="#_bookmark733">10.4.2</a>).</p>
<p>• <strong>Class</strong> <strong>balance:</strong> Balanced or unbalanced class proportions.</p>
<p>• <strong>Sparsity:</strong> Full matrices or sparse matrices.</p>
<p>• <strong>Missing</strong> <strong>values:</strong> Presence or absence of missing values.</p>
<p>• <strong>Categorical</strong> <strong>variables:</strong> Presence or absence of categorical variables.</p>
<p>• <strong>Irrelevant</strong> <strong>variables:</strong> Presence or absence of additional irrelevant variables (distractors).</p>
<p>• <strong>Number</strong> Ptr <strong>of</strong> <strong>training</strong> <strong>examples:</strong> Small or large number of training examples.</p>
<p>• <strong>Number</strong> N <strong>of</strong> <strong>variables/features:</strong> Small or large number of variables.</p>
<p>• <strong>Ratio</strong> Ptr/N <strong>of</strong> <strong>the</strong> <strong>training</strong> <strong>data</strong> <strong>matrix:</strong> Ptr &gt; N, Ptr = N or Ptr &lt; N .</p>
</blockquote>
<p>In this setting, the participants had to face many modeling/hyper-parameter choices. Some other, equally important, aspects of automating machine learning were not addressed in this challenge and are left for future research. Those include data “ingestion” and formatting, pre-processing and feature/representation learning, detection and handling of skewed/biased data, inhomogeneous, drifting, multi- modal, or multi-view data (hinging on transfer learning), matching algorithms to problems (which may include supervised, unsupervised, or reinforcement learning, or other settings), acquisition of new data (active learning, query learning, rein- forcement learning, causal experimentation), management of large volumes of data including the creation of appropriately-sized and stratiﬁed training, validation, and test sets, selection of algorithms that satisfy arbitrary resource constraints at training and run time, the ability to generate and reuse workﬂows, and generating meaningful reports.</p>
<p><img src="./automlgithubpagesimages//media/image9.jpeg" width="136" /></p>
<blockquote>
<p>180 I. Guyon et al.</p>
<p>This challenge series started with the NIPS 2006 “model selection game”<a href="#_bookmark734">1</a> [<a href="#_bookmark735">37</a>], where the participants were provided with a machine learning toolbox based on the Matlab toolkit CLOP [<a href="#_bookmark736">1</a>] built on top of the “Spider” package [<a href="#_bookmark737">69</a>]. The toolkit provided a ﬂexible way of building models by combining preprocessing, feature selection, classiﬁcation and post-processing modules, also enabling the building of ensembles of classiﬁers. The goal of the game was to build the best hyper- model: the focus was on model selection, not on the development of new algorithms. All problems were feature-based binary classiﬁcation problems. Five datasets were provided. The participants had to submit the schema of their model. The model selection game conﬁrmed the effectiveness of cross-validation (the winner invented a new variant called cross-indexing) and emphasized the need to focus more on search effectiveness with the deployment of novel search techniques such as particle swarm optimization.</p>
</blockquote>
<p>New in the 2015/2016 AutoML challenge, we introduced the notion of “task”: each dataset was supplied with a particular scoring metric to be optimized and a time budget. We initially intended to vary widely the time budget from dataset to dataset in an arbitrary way. We ended up ﬁxing it to 20 min for practical reasons (except for Round 0 where the time budget ranged from 100 to 300 s). However, because the datasets varied in size, this put pressure on the participants to manage their allotted time. Other elements of novelty included the freedom of submitting any Linux executable. This was made possible by using automatic execution on the open-source platform Codalab.<a href="#_bookmark738">2</a> To help the participants we provided a starting kit in Python based on the scikit-learn library [<a href="#_bookmark739">55</a>].<a href="#_bookmark740">3</a> This induced many of them to write a wrapper around scikit-learn. This has been the strategy of the winning entry “auto-sklearn” [<a href="#_bookmark741">25</a>–<a href="#_bookmark742">28</a>].<a href="#_bookmark743">4</a> Following the AutoML challenge, we organized a “beat auto-sklearn” game on a single dataset (madeline), in which the participants could provide hyper-parameters “by hand” to try to beat auto-sklearn. But nobody could beat auto-sklearn! Not even their designers. The participants could submit a json ﬁle which describes a sklearn model and hyper-parameter settings, via a GUI interface. This interface allows researchers who want to compare their search methods with auto-sklearn to use the exact same set of hyper-models.</p>
<blockquote>
<p>A large number of satellite events including bootcamps, summer schools, and workshops have been organized in 2015/2016 around the AutoML challenge.<a href="#_bookmark744">5</a>The AutoML challenge was part of the ofﬁcial selection of the competition program of</p>
<p>IJCNN 2015 and 2016 and the results were discussed at the AutoML and CiML</p>
<p>workshops at ICML and NIPS in 2015 and 2016. Several publications accompanied these events: in [<a href="#_bookmark745">33</a>] we describe the details of the design of the AutoML challenge.<a href="#_bookmark746">6</a></p>
<p><span id="_bookmark734" class="anchor"><span id="_bookmark738" class="anchor"></span></span>1<a href="http://clopinet.com/isabelle/Projects/NIPS2006/" class="uri">http://clopinet.com/isabelle/Projects/NIPS2006/</a></p>
<p><span id="_bookmark740" class="anchor"></span>2<a href="http://competitions.codalab.org" class="uri">http://competitions.codalab.org</a></p>
<p><span id="_bookmark743" class="anchor"></span>3<a href="http://scikit-learn.org/" class="uri">http://scikit-learn.org/</a></p>
<p><span id="_bookmark744" class="anchor"></span>4<a href="https://automl.github.io/auto-sklearn/stable/" class="uri">https://automl.github.io/auto-sklearn/stable/</a></p>
<p><span id="_bookmark746" class="anchor"></span>5 See<a href="http://automl.chalearn.org" class="uri">http://automl.chalearn.org</a></p>
<p>6<a href="http://codalab.org/AutoML" class="uri">http://codalab.org/AutoML</a></p>
</blockquote>
<p><img src="./automlgithubpagesimages//media/image12.jpeg" width="136" /></p>
<blockquote>
<p>10 Analysis of the AutoML Challenge Series 2015–2018 181</p>
<p>In [<a href="#_bookmark747">32</a>] and [<a href="#_bookmark748">34</a>] we review milestone and ﬁnal results presented at the ICML 2015 and 2016 AutoML workshops. The 2015/2016 AutoML challenge had 6 rounds introducing 5 datasets each. We also organized a follow-up event for the PAKDD <a href="#_bookmark749">conference 20187</a> in only 2 phases, with 5 datasets in the development phase and 5 datasets in the ﬁnal “blind test” round.</p>
<p>Going beyond the former published analyses, this chapter presents systematic studies of the winning solutions on all the datasets of the challenge and conducts comparisons with commonly used learning machines implemented in scikit-learn. It provides unpublished details about the datasets and reﬂective analyses.</p>
<p>This chapter is in part based on material that has appeared previously [<a href="#_bookmark747">32</a>–<a href="#_bookmark748">34</a>,<a href="#_bookmark750">36</a>]. This chapter is complemented by a 46-page online appendix that can be accessed from the book’s webpage: <a href="http://automl.org/book" class="uri">http://automl.org/book</a>.</p>
<p><span id="_bookmark751" class="anchor"></span><strong>10.2</strong> <strong>Problem</strong> <strong>Formalization</strong> <strong>and</strong> <strong>Overview</strong></p>
<p><em><strong>10.2.1</strong></em> <em><strong>Scope</strong></em> <em><strong>of</strong></em> <em><strong>the</strong></em> <em><strong>Problem</strong></em></p>
<p>This challenge series focuses on supervised learning in ML and, in particular, solv- ing classiﬁcation and regression problems, without any further human intervention, within given constraints. To this end, we released a large number of datasets pre- formatted in given feature representations (i.e., each example consists of a ﬁxed number of numerical coefﬁcients; more in Sect.<a href="#_bookmark752">10.3</a>).</p>
<p>The distinction between input and output variables is not always made in ML applications. For instance, in recommender systems, the problem is often stated as making predictions of missing values for every variable rather than predicting the values of a particular variable [<a href="#_bookmark753">58</a>]. In unsupervised learning [<a href="#_bookmark754">30</a>], the purpose is to explain data in a simple and compact way, eventually involving inferred latent variables (e.g., class membership produced by a clustering algorithm).</p>
<p>We consider only the strict supervised learning setting where data present them- selves as identically and independently distributed input-output pairs. The models used are limited to ﬁxed-length vectorial representations, excluding problems of time series prediction. Text, speech, and video processing tasks included in the chal- lenge have been preprocessed into suitable ﬁxed-length vectorial representations.</p>
<p>The difﬁculty of the proposed tasks lies in the data complexity (class imbalance, sparsity, missing values, categorical variables). The testbed is composed of data from a wide variety of domains. Although there exist ML toolkits that can tackle all of these problems, it still requires considerable human effort to ﬁnd, for a given dataset, task, evaluation metric, the methods and hyper-parameter settings that maximize performance subject to a computational constraint. The participant challenge is to create the <em>perfect</em> <em>black</em> <em>box</em> that removes human interaction, alleviating the shortage of data scientists in the coming decade.</p>
<p><span id="_bookmark749" class="anchor"></span>7<a href="https://www.4paradigm.com/competition/pakdd2018" class="uri">https://www.4paradigm.com/competition/pakdd2018</a></p>
<p>182 I. Guyon et al.</p>
</blockquote>
<p><em><strong>10.2.2</strong></em> <em><strong>Full</strong></em> <em><strong>Model</strong></em> <em><strong>Selection</strong></em></p>
<p>We refer to participant solutions as <em>hyper-models</em> to indicate that they are built from simpler components. For instance, for classiﬁcation problems, participants might consider a hyper-model that combines several classiﬁcation techniques such as nearest neighbors, linear models, kernel methods, neural networks, and random forests. More complex hyper-models may also include preprocessing, feature construction, and feature selection modules.</p>
<blockquote>
<p>Generally, a predictive model of the form y = f(<strong>x</strong>;<strong>α</strong>) has:</p>
<p>• a set of parameters <strong>α</strong> = [α0 ,α 1 ,α2 , . . . , αn];</p>
<p>• a learning algorithm (referred to as trainer), which serves to optimize the parameters using training data;</p>
<p>• a trained model (referred to as predictor) of the form y = f(<strong>x</strong>) produced by the trainer;</p>
<p>• a clear objective function J(f), which can be used to assess the model’s performance on test data.</p>
</blockquote>
<p>Consider now the model hypothesis space deﬁned by a vector <strong>θ</strong> = [θ1 ,θ2 , . . . , θn] of hyper-parameters. The hyper-parameter vector may include not only parameters corresponding to switching between alternative models, but also modeling choices such as preprocessing parameters, type of kernel in a kernel method, number of units and layers in a neural network, or training algorithm regularization parameters [<a href="#_bookmark755">59</a>]. Some authors refer to this problem as <em>full</em> <em>model</em> <em>selection</em> [<a href="#_bookmark756">24</a>, <a href="#_bookmark757">62</a>], others as the CASH problem (Combined Algorithm Selection and Hyperparameter optimization) [<a href="#_bookmark758">65</a>]. We will denote hyper-models as</p>
<p>y = f(<strong>x</strong>; <strong>θ</strong>) = f(<strong>x</strong>; <strong>α</strong>(<strong>θ</strong>), <strong>θ</strong>), (10. 1)</p>
<blockquote>
<p>where the model parameter vector <strong>α</strong> is an implicit function of the hyper-parameter vector <strong>θ</strong> obtained by using a trainer for a ﬁxed value of <strong>θ</strong>, and training data composed of input-output pairs {<strong>x</strong>i,yi}. The participants have to devise algorithms capable of training the hyper-parameters <strong>θ</strong> . This may require intelligent sampling of the hyper-parameter space and splitting the available training data into subsets for both training and evaluating the predictive power of solutions—one or multiple times.</p>
</blockquote>
<p>As an optimization problem, model selection is a bi-level optimization pro- gram [<a href="#_bookmark759">7</a>, <a href="#_bookmark760">18</a>, <a href="#_bookmark761">19</a>]; there is a lower objective J1 to train the parameters <strong>α</strong> of the model, and an upper objective J2 to train the hyper-parameters <strong>θ</strong>, both optimized simultaneously (see Fig.<a href="#_bookmark762">10.1</a>). As a statistics problem, model selection is a problem of multiple testing in which error bars on performance prediction e degrade with the number of models/hyper-parameters tried or, more generally, the complexity of the hyper-model C2(<strong>θ</strong>). A key aspect of AutoML is to avoid overﬁtting the upper-level objective J2 by regularizing it, much in the same way as lower level objectives J1 are regularized.</p>
<p><img src="./automlgithubpagesimages//media/image521.png" width="24" height="12" /><img src="./automlgithubpagesimages//media/image522.png" width="24" height="12" /></p>
<blockquote>
<p>10 Analysis of the AutoML Challenge Series 2015–2018 183</p>
<p>Hyperparameters (<img src="./automlgithubpagesimages//media/image523.png" />)</p>
<p><img src="./automlgithubpagesimages//media/image524.png" width="177" height="100" />Hyperparameters</p>
</blockquote>
<p>argmin <img src="./automlgithubpagesimages//media/image529.png" />1tr [f( . ; <img src="./automlgithubpagesimages//media/image530.png" /> , <img src="./automlgithubpagesimages//media/image531.png" />)]</p>
<blockquote>
<p><img src="./automlgithubpagesimages//media/image532.png" /></p>
</blockquote>
<table>
<tbody>
<tr class="odd">
<td><blockquote>
<p><img src="./automlgithubpagesimages//media/image533.png" width="98" height="47" />Parameters (<img src="./automlgithubpagesimages//media/image534.png" />)</p>
</blockquote></td>
</tr>
</tbody>
</table>
<blockquote>
<p>(b)</p>
</blockquote>
<p><span id="_bookmark762" class="anchor"></span><strong>Fig.</strong> <strong>10.1</strong> <strong>Bi-level</strong> <strong>optimization.</strong> (<strong>a</strong>) Representation of a learning machine with parameters and hyper-parameters to be adjusted. (<strong>b</strong>) De-coupling of parameter and hyper-parameter adjustment in two levels. The upper level objective J2 optimizes the hyper-parameters <strong>θ</strong> ; the lower objective J1 optimizes the parameters <strong>α</strong></p>
<p>The problem setting also lends itself to using ensemble methods, which let several “simple” models vote to make the ﬁnal decision [<a href="#_bookmark763">15</a>, <a href="#_bookmark764">16</a>, <a href="#_bookmark765">29</a>]. In this case, the parameters <strong>θ</strong> may be interpreted as voting weights. For simplicity we lump all parameters in a single vector, but more elaborate structures, such as trees or graphs can be used to deﬁne the hyper-parameter space [<a href="#_bookmark766">66</a>].</p>
<p><em><strong>10.2.3</strong></em> <em><strong>Optimization</strong></em> <em><strong>of</strong></em> <em><strong>Hyper-parameters</strong></em></p>
<p>Everyone who has worked with data has had to face some common modeling choices: scaling, normalization, missing value imputation, variable coding (for categorical variables), variable discretization, degree of nonlinearity and model architecture, among others. ML has managed to reduce the number of hyper- parameters and produce <em>black-boxes</em> to perform tasks such as classiﬁcation and regression [<a href="#_bookmark767">21</a>, <a href="#_bookmark768">40</a>]. Still, any real-world problem requires at least some preparation of the data before it can be ﬁtted into an “automatic” method, hence requiring some modeling choices. There has been much progress on end-to-end automated ML for more complex tasks such as text, image, video, and speech processing with deep- learning methods [<a href="#_bookmark769">6</a>]. However, even these methods have many modeling choices and hyper-parameters.</p>
<p>While producing models for a diverse range of applications has been a focus of the ML community, little effort has been devoted to the optimization of hyper- parameters. Common practices that include <em>trial</em> <em>and</em> <em>error</em> and grid search may lead to overﬁtting models for small datasets or underﬁtting models for large datasets. By overﬁtting we mean producing models that perform well on training data but perform poorly on unseen data, i.e., models that do not generalize. By underﬁtting</p>
<blockquote>
<p>184 I. Guyon et al.</p>
</blockquote>
<p>we mean selecting too simple a model, which does not capture the complexity of the data, and hence performs poorly both on training and test data. Despite well- optimized off-the-shelf algorithms for optimizing parameters, end-users are still responsible for organizing their numerical experiments to identify the best of a number of models under consideration. Due to lack of time and resources, they often perform model/hyper-parameter selection with ad hoc techniques. Ioannidis and Langford [<a href="#_bookmark770">42</a>, <a href="#_bookmark771">47</a>] examine fundamental, common mistakes such as poor con- struction of training/test splits, inappropriate model complexity, hyper-parameter selection using test sets, misuse of computational resources, and misleading test metrics, which may invalidate an entire study. Participants must avoid these ﬂaws and devise systems that can be blind-tested.</p>
<blockquote>
<p>An additional twist of our problem setting is that code is tested with limited computational resources. That is, for each task an arbitrary limit on execution time is ﬁxed and a maximum amount of memory is provided. This places a constraint on the participant to produce a solution in a given time, and hence to optimize the model search from a computational point of view. In summary, participants have to jointly address the problem of over-ﬁtting/under-ﬁtting and the problem of efﬁcient search for an optimal solution, as stated in [<a href="#_bookmark772">43</a>]. In practice, the computational constraints have turned out to be far more challenging to challenge participants than the problem of overﬁtting. Thus the main contributions have been to devise novel efﬁcient search techniques with cutting-edge optimization methods.</p>
</blockquote>
<p><em><strong>10.2.4</strong></em> <em><strong>Strategies</strong></em> <em><strong>of</strong></em> <em><strong>Model</strong></em> <em><strong>Search</strong></em></p>
<blockquote>
<p>Most practitioners use heuristics such as grid search or uniform sampling to sample <strong>θ</strong> space, and use k-fold cross-validation as the upper-level objective J2 [<a href="#_bookmark773">20</a>]. In</p>
</blockquote>
<p><img src="./automlgithubpagesimages//media/image535.png" /></p>
<blockquote>
<p>(a) Filter (b) Wrapper (c) Embedded</p>
</blockquote>
<p><strong>Fig.</strong> <strong>10.2</strong> <strong>Approaches</strong> <strong>to</strong> <strong>two-level</strong> <strong>inference.</strong> (<strong>a</strong>) <strong>Filter</strong> <strong>methods</strong> select the hyper-parameters <span id="_bookmark774" class="anchor"></span>without adjusting the learner parameters. (No arrows indicates no parameter training.) (<strong>b</strong>) <strong>Wrapper</strong> <strong>methods</strong> select the hyper-parameters using trained learners, treating them as black- boxes. (<strong>c</strong>) <strong>Embedded</strong> <strong>methods</strong> use knowledge of the learner structure and/or parameters to guide the hyper-parameter search</p>
<blockquote>
<p>10 Analysis of the AutoML Challenge Series 2015–2018 185</p>
</blockquote>
<p>this framework, the optimization of <strong>θ</strong> is not performed sequentially [<a href="#_bookmark775">8</a>]. All the parameters are sampled along a regular scheme, usually in linear or log scale. This leads to a number of possibilities that exponentially increases with the dimension of <strong>θ</strong> . k-fold cross-validation consists of splitting the dataset into k folds; (k − 1) folds are used for training and the remaining fold is used for testing; eventually, the average of the test scores obtained on the k folds is reported. Note that some ML toolkits currently support cross-validation. There is a lack of principled guidelines to determine the number of grid points and the value of k (with the exception of [<a href="#_bookmark773">20</a>]), and there is no guidance for regularizing J2, yet this simple method is a good baseline approach.</p>
<blockquote>
<p>Efforts have been made to optimize continuous hyper-parameters with bilevel optimization methods, using either the k-fold cross-validation estimator [<a href="#_bookmark759">7</a>, <a href="#_bookmark776">50</a>] or the leave-one-out estimator as the upper-level objective J2 . The leave-one-out estimator may be efﬁciently computed, in closed form, as a by-product of training only one predictor on all the training examples (e.g., virtual-leave-one-out [<a href="#_bookmark777">38</a>]). The method was improved by adding a regularization of J2 [<a href="#_bookmark778">17</a>]. Gradient descent has been used to accelerate the search, by making a local quadratic approximation of J2 [<a href="#_bookmark779">44</a>]. In some cases, the full J2(<strong>θ</strong> ) can be computed from a few key examples [<a href="#_bookmark780">39</a>, <a href="#_bookmark781">54</a>]. Other approaches minimize an <em>approximation</em> or an <em>upper</em> <em>bound</em> of the leave-one-out error, instead of its exact form [<a href="#_bookmark782">53</a>, <a href="#_bookmark783">68</a>]. Nevertheless, these methods are still limited to speciﬁc models and continuous hyper-parameters.</p>
</blockquote>
<p>An early attempt at full model selection was the <em>pattern</em> <em>search</em> method that uses k-fold cross-validation for J2 . It explores the hyper-parameter space by steps of the same magnitude, and when no change in any parameter further decreases J2, the step size is halved and the process repeated until the steps are deemed sufﬁciently small [<a href="#_bookmark784">49</a>]. Escalante et al. [<a href="#_bookmark756">24</a>] addressed the full model selection problem using Particle Swarm Optimization, which optimizes a problem by having a population of candidate solutions (particles), and moving these particles around the hyper- parameter space using the particle’s position and velocity. k-fold cross-validation is also used for J2 . This approach retrieved the winning model in ∼76% of the cases. Overﬁtting was controlled heuristically with early stopping and the proportion of training and validation data was not optimized. Although progress has been made in experimental design to reduce the risk of overﬁtting [<a href="#_bookmark770">42</a>, <a href="#_bookmark771">47</a>], in particular by splitting data in a principled way [<a href="#_bookmark785">61</a>], to our knowledge, no one has addressed the problem of optimally splitting data.</p>
<blockquote>
<p>While regularizing the second level of inference is a recent addition to the frequentist ML community, it has been an intrinsic part of Bayesian modeling via the notion of hyper-prior. Some methods of multi-level optimization combine importance sampling and Monte-Carlo Markov Chains [<a href="#_bookmark786">2</a>]. The ﬁeld of Bayesian hyper-parameter optimization has rapidly developed and yielded promising results, in particular by using Gaussian processes to model generalization performance [<a href="#_bookmark787">60</a>, <a href="#_bookmark788">63</a>]. But Tree-structured Parzen Estimator (TPE) approaches modeling P(<strong>x</strong>|y) and P(y) rather than modeling P(y|<strong>x</strong>) directly [<a href="#_bookmark789">9</a>, <a href="#_bookmark790">10</a>] have been found to outperform GP-based Bayesian optimization for structured optimization problems with many hyperparameters including discrete ones [<a href="#_bookmark791">23</a>]. The central idea of these methods is to ﬁt J2(<strong>θ</strong> ) to a smooth function in an attempt to reduce variance and to estimate the</p>
<p>186 I. Guyon et al.</p>
<p>variance in regions of the hyper-parameter space that are under-sampled to guide the search towards regions of high variance. These methods are inspirational and some of the ideas can be adopted in the frequentist setting. For instance, the random- forest-based SMAC algorithm [<a href="#_bookmark792">41</a>], which has helped speed up both local search and tree search algorithms by orders of magnitude on certain instance distributions, has also been found to be very effective for the hyper-parameter optimization of machine learning algorithms, scaling better to high dimensions and discrete input dimensions than other algorithms [<a href="#_bookmark791">23</a>]. We also notice that Bayesian optimization methods are often combined with other techniques such as meta-learning and ensemble methods [<a href="#_bookmark741">25</a>] in order to gain advantage in some challenge settings with a time limit [<a href="#_bookmark747">32</a>]. Some of these methods consider jointly the two-level optimization and take time cost as a critical guidance for hyper-parameter search [<a href="#_bookmark793">45</a>, <a href="#_bookmark794">64</a>].</p>
<p>Besides Bayesian optimization, several other families of approaches exist in the literature and have gained much attention with the recent rise of deep learning. Ideas borrowed from <em>reinforcement</em> <em>learning</em> have recently been used to construct optimal neural network architectures [<a href="#_bookmark795">4</a>,<a href="#_bookmark796">70</a>]. These approaches formulate the hyper- parameter optimization problem in a reinforcement learning ﬂavor, with for example states being the actual hyper-parameter setting (e.g., network architecture), actions being adding or deleting a module (e.g., a CNN layer or a pooling layer), and reward being the validation accuracy. They can then apply off-the-shelf reinforcement learning algorithms (e.g., RENFORCE, Q-learning, Monte-Carlo Tree Search) to solve the problem. Other architecture search methods use <em>evolutionary</em> algorithms [<a href="#_bookmark797">3</a>, <a href="#_bookmark798">57</a>]. These approaches consider a set (population) of hyper-parameter settings (individuals), modify (mutate and reproduce) and eliminate unpromising settings according to their cross-validation score (ﬁtness). After several generations, the global quality of the population increases. One important common point of rein- forcement learning and evolutionary algorithms is that they both deal with the exploration-exploitation trade-off. Despite the impressive results, these approaches require a huge amount of computational resources and some (especially evolution- ary algorithms) are hard to scale. Pham et al. [<a href="#_bookmark799">56</a>] recently proposed weight sharing among child models to speed up the process considerably [<a href="#_bookmark796">70</a>] while achieving comparable results.</p>
<p>Note that splitting the problem of parameter ﬁtting into two levels can be extended to more levels, at the expense of extra complexity—i.e., need for a hier- archy of data splits to perform multiple or nested cross-validation [<a href="#_bookmark800">22</a>], insufﬁcient data to train and validate at the different levels, and increase of the computational load.</p>
</blockquote>
<p>Table <a href="#_bookmark801">10.1</a> shows a typical example of multi-level parameter optimization in a frequentist setting. We assume that we are using an ML toolbox with two learning machines: Kridge (kernel ridge regression) and Neural (a neural network a.k.a. “deep learning” model). At the top level we use a test procedure to assess the performance of the ﬁnal model (this is not an inference level). The top-level inference algorithm Validation({GridCV(Kridge, MSE), GridCV(Neural, MSE)}, MSE) is decomposed into its elements recursively. Validation uses the data split D = [DTr,DVa ] to compare the learning machines Kridge and Neural (trained</p>
<blockquote>
<p>10 Analysis of the AutoML Challenge Series 2015–2018 187</p>
<p><span id="_bookmark801" class="anchor"></span><strong>Table</strong> <strong>10.1</strong> <strong>Typical</strong> <strong>example</strong> <strong>of</strong> <strong>multi-level</strong> <strong>inference</strong> <strong>algorithm.</strong> The top-level algorithm Vali- dation({GridCV(Kridge, MSE), GridCV(Neural, MSE)}, MSE) is decomposed into its elements recursively. Calling the method “train” on it using data DTrV a results in a function f , then tested with test(f,MSE,DTe ). The notation [.]CV indicates that results are averages over multiple data splits (cross-validation). NA means “not applicable” . A model family F of parameters <strong>α</strong> and hyper-parameters <strong>θ</strong> is represented as f(<strong>θ</strong> , <strong>α</strong>). We derogate to the usual convention of putting hyper-parameters last, the hyper-parameters are listed in decreasing order of inference level. F, thought of as a bottom level algorithm, does not perform any training: train(f(<strong>θ</strong> , <strong>α</strong>)) just returns the function f(<strong>x</strong>; <strong>θ</strong> , <strong>α</strong>)</p>
</blockquote>
<table>
<tbody>
<tr class="odd">
<td><blockquote>
<p>Level</p>
</blockquote></td>
<td><blockquote>
<p>Algorithm</p>
</blockquote></td>
<td><blockquote>
<p>Parameters</p>
</blockquote></td>
<td><blockquote>
<p>Optimization performed</p>
</blockquote></td>
<td><blockquote>
<p>Data split</p>
</blockquote></td>
</tr>
<tr class="even">
<td></td>
<td></td>
<td><blockquote>
<p>Fixed</p>
</blockquote></td>
<td><blockquote>
<p>Varying</p>
</blockquote></td>
<td></td>
</tr>
<tr class="odd">
<td><blockquote>
<p>NA</p>
</blockquote></td>
<td><blockquote>
<p>f</p>
</blockquote></td>
<td><blockquote>
<p>All</p>
</blockquote></td>
<td><blockquote>
<p>All</p>
</blockquote></td>
<td><blockquote>
<p>Performance assessment</p>
<p>(no inference)</p>
</blockquote></td>
</tr>
<tr class="even">
<td><blockquote>
<p>4</p>
</blockquote></td>
<td><blockquote>
<p>Validation</p>
</blockquote></td>
<td><blockquote>
<p>None</p>
</blockquote></td>
<td><blockquote>
<p>All</p>
</blockquote></td>
<td><blockquote>
<p>Final algorithm</p>
<p>selection using</p>
<p>validation data</p>
</blockquote></td>
</tr>
<tr class="odd">
<td><blockquote>
<p>3</p>
</blockquote></td>
<td><blockquote>
<p>GridCV</p>
</blockquote></td>
<td><blockquote>
<p>Model index i</p>
</blockquote></td>
<td><blockquote>
<p><strong>θ</strong> ,γ, <strong>α</strong></p>
</blockquote></td>
<td><blockquote>
<p>10-fold CV on regularly sampled values of <strong>θ</strong></p>
</blockquote></td>
</tr>
<tr class="even">
<td><blockquote>
<p>2</p>
</blockquote></td>
<td><blockquote>
<p>Kridge(<strong>θ</strong> )</p>
<p>Neural(<strong>θ</strong> )</p>
</blockquote></td>
<td><blockquote>
<p>i, <strong>θ</strong></p>
</blockquote></td>
<td><blockquote>
<p>γ, <strong>α</strong></p>
</blockquote></td>
<td><blockquote>
<p>Virtual LOO CV to</p>
<p>select regularization parameter γ</p>
</blockquote></td>
</tr>
<tr class="odd">
<td><blockquote>
<p>1</p>
</blockquote></td>
<td><blockquote>
<p>Kridge(<strong>θ</strong> ,γ ) Neural(<strong>θ</strong> ,γ )</p>
</blockquote></td>
<td><blockquote>
<p>i, <strong>θ</strong>,γ</p>
</blockquote></td>
<td><blockquote>
<p><strong>α</strong></p>
</blockquote></td>
<td><blockquote>
<p>Matrix inversion of</p>
<p>gradient descent to</p>
<p>compute <strong>α</strong></p>
</blockquote></td>
</tr>
<tr class="even">
<td><blockquote>
<p>0</p>
</blockquote></td>
<td><blockquote>
<p>Kridge(<strong>θ</strong> ,γ, <strong>α</strong>) Neural(<strong>θ</strong> ,γ, <strong>α</strong>)</p>
</blockquote></td>
<td><blockquote>
<p>All</p>
</blockquote></td>
<td><blockquote>
<p>None</p>
</blockquote></td>
<td><blockquote>
<p>NA</p>
</blockquote></td>
</tr>
</tbody>
</table>
<p>using DTr on the validation set DVa, using the mean-square error) (MSE) evaluation function. The algorithm GridCV, a grid search with 10-fold cross-validation (CV) MSE evaluation function, then optimizes the hyper-parameters <strong>θ</strong> . Internally, both Kridge and Neural use virtual leave-one-out (LOO) cross-validation to adjust γ and a classical L2 regularized risk functional to adjust <strong>α</strong> .</p>
<p>Borrowing from the conventional classiﬁcation of feature selection methods [<a href="#_bookmark802">11</a>, <a href="#_bookmark777">38</a>, <a href="#_bookmark803">46</a>], model search strategies can be categorized into ﬁlters, wrappers, and embedded methods (see Fig.<a href="#_bookmark774">10.2</a>). <strong>Filters</strong> are methods for narrowing down the model space, without training the learner. Such methods include prepro- cessing, feature construction, kernel design, architecture design, choice of prior or regularizers, choice of noise model, and ﬁlter methods for feature selection. Although some ﬁlters use training data, many incorporate human prior knowledge of the task or knowledge compiled from previous tasks. Recently, [<a href="#_bookmark804">5</a>] proposed to apply collaborative ﬁltering methods to model search. <strong>Wrapper</strong> <strong>methods</strong> consider learners as a black-box capable of learning from examples and making predictions once trained. They operate with a search algorithm in the hyper-parameter space (grid search or stochastic search) and an evaluation function assessing the trained learner’s performance (cross-validation error or Bayesian evidence). <strong>Embedded</strong> <strong>methods</strong> are similar to wrappers, but they exploit the knowledge of the machine</p>
<blockquote>
<p>188 I. Guyon et al.</p>
<p>learning algorithm to make the search more efﬁcient. For instance, some embedded methods compute the leave-one-out solution in a closed form, without leaving anything out, i.e., by performing a single model training on all the training data (e.g., [<a href="#_bookmark777">38</a>]). Other embedded methods jointly optimize parameters and hyper-parameters [<a href="#_bookmark779">44</a>, <a href="#_bookmark776">50</a>, <a href="#_bookmark805">51</a>].</p>
</blockquote>
<p>In summary, many authors focus only on the efﬁciency of search, ignoring the problem of overﬁtting the second level objective J2, which is often chosen to be k-fold cross-validation with an arbitrary value for k . Bayesian methods introduce techniques of overﬁtting avoidance via the notion of hyper-priors, but at the expense of making assumptions on how the data were generated and without providing guarantees of performance. In all the prior approaches to full model selection we know of, there is no attempt to treat the problem as the optimization of a regularized functional J2 with respect to both (1) modeling choices and (2) data split. Much remains to be done to jointly address statistical and computational issues. The AutoML challenge series offers benchmarks to compare and contrast methods addressing these problems, free of the inventor/evaluator bias.</p>
<blockquote>
<p><span id="_bookmark752" class="anchor"></span><strong>10.3</strong> <strong>Data</strong></p>
</blockquote>
<p>We gathered a ﬁrst pool of 70 datasets during the summer 2014 with the help of numerous collaborators and ended up selecting 30 datasets for the 2015/2016 challenge (see Table <a href="#_bookmark806">10.2</a> and the online appendix), chosen to illustrate a wide variety of domains of applications: biology and medicine, ecology, energy and sustainability management, image, text, audio, speech, video and other sensor data processing, internet social media management and advertising, market analysis and ﬁnancial prediction. We preprocessed data to obtain feature representations (i.e., each example consists of a ﬁxed number of numerical coefﬁcients). Text, speech, and video processing tasks were included in the challenge, but not in their native variable-length representations.</p>
<blockquote>
<p>For the 2018 challenge, three datasets from the ﬁrst pool (but unused in the ﬁrst challenge) were selected and seven new datasets collected by the new organizers and sponsors were added (see Table <a href="#_bookmark807">10.3</a>and the online appendix).</p>
<p>Some datasets were obtained from public sources, but they were reformatted into new representations to conceal their identity, except for the ﬁnal round of the 2015/2016 challenge and the ﬁnal phase of the 2018 challenge, which included completely new data.</p>
<p>In the 2015/2016 challenge, data difﬁculty progressively increased from round to round. Round 0 introduced ﬁve (public) datasets from previous challenges illustrating the various difﬁculties encountered in subsequent rounds:</p>
<p><strong>Novice</strong> Binary classiﬁcation problems only. No missing data; no categorical features; moderate number of features (&lt;2,000); balanced classes. Challenge</p>
<p><strong>Table</strong> <strong>10.2</strong> <strong>Datasets</strong> <strong>of</strong> <strong>the</strong> <strong>2015/2016</strong> <strong>AutoML</strong> <strong>challenge.</strong> <em>C</em> number of classes, <em>Cbal</em> class balance, <em>Sparse</em> sparsity, <em>Miss</em> fraction of missing values, <em>Cat</em> categorical variables, <em>Irr</em> fraction of irrelevant variables, <em>Pte,</em> <em>Pva,</em> <em>Ptr</em> number of examples of the test, validation, and training sets, respectively, <em>N</em> number of features, <em>Ptr/N</em> aspect ratio of the dataset</p>
</blockquote>
<table>
<tbody>
<tr class="odd">
<td><blockquote>
<p>Rnd</p>
</blockquote></td>
<td><blockquote>
<p>DATASET</p>
</blockquote></td>
<td><blockquote>
<p>Task</p>
</blockquote></td>
<td><blockquote>
<p>Metric</p>
</blockquote></td>
<td><blockquote>
<p>Time</p>
</blockquote></td>
<td><blockquote>
<p>C</p>
</blockquote></td>
<td><blockquote>
<p>Cbal</p>
</blockquote></td>
<td><blockquote>
<p>Sparse</p>
</blockquote></td>
<td><blockquote>
<p>Miss</p>
</blockquote></td>
<td><blockquote>
<p>Cat</p>
</blockquote></td>
<td><blockquote>
<p>Irr</p>
</blockquote></td>
<td><blockquote>
<p>Pte</p>
</blockquote></td>
<td><blockquote>
<p>Pva</p>
</blockquote></td>
<td><blockquote>
<p>Ptr</p>
</blockquote></td>
<td><blockquote>
<p>N</p>
</blockquote></td>
<td><blockquote>
<p>Ptr/N</p>
</blockquote></td>
</tr>
<tr class="even">
<td><blockquote>
<p>0</p>
<p>0</p>
<p>0</p>
<p>0</p>
<p>0</p>
</blockquote></td>
<td><blockquote>
<p>1 ADULT</p>
<p>2 CADATA</p>
<p>3 DIGITS</p>
<p>4 DOROTHEA</p>
<p>5 NEWSGROUPS</p>
</blockquote></td>
<td><blockquote>
<p>multilabel regression multiclass binary multiclass</p>
</blockquote></td>
<td><blockquote>
<p>F1</p>
<p>R2</p>
<p>BAC</p>
<p>AUC</p>
<p>PAC</p>
</blockquote></td>
<td><blockquote>
<p>300</p>
<p>200</p>
<p>300</p>
<p>100</p>
<p>300</p>
</blockquote></td>
<td><blockquote>
<p>3</p>
<p>0</p>
<p>10</p>
<p>2</p>
<p>20</p>
</blockquote></td>
<td><blockquote>
<p>1</p>
<p>NaN</p>
<p>1</p>
<p>0.46</p>
<p>1</p>
</blockquote></td>
<td><blockquote>
<p>0.16</p>
<p>0</p>
<p>0.42</p>
<p>0.99</p>
<p>1</p>
</blockquote></td>
<td><blockquote>
<p>0.011</p>
<p>0</p>
<p>0</p>
<p>0</p>
<p>0</p>
</blockquote></td>
<td><blockquote>
<p>1</p>
<p>0</p>
<p>0</p>
<p>0</p>
<p>0</p>
</blockquote></td>
<td><blockquote>
<p>0.5</p>
<p>0.5</p>
<p>0.5</p>
<p>0.5</p>
<p>0</p>
</blockquote></td>
<td><blockquote>
<p>9768</p>
<p>10,640</p>
<p>35,000</p>
<p>800</p>
<p>3755</p>
</blockquote></td>
<td><blockquote>
<p>4884</p>
<p>5000</p>
<p>20,000</p>
<p>350</p>
<p>1877</p>
</blockquote></td>
<td><blockquote>
<p>34,190</p>
<p>5000</p>
<p>15,000</p>
<p>800</p>
<p>13,142</p>
</blockquote></td>
<td><blockquote>
<p>24</p>
<p>16</p>
<p>1568</p>
<p>100,000</p>
<p>61,188</p>
</blockquote></td>
<td><blockquote>
<p>1424.58 312.5 9.57 0.01 0.21</p>
</blockquote></td>
</tr>
<tr class="odd">
<td><blockquote>
<p>1</p>
<p>1</p>
<p>1</p>
<p>1</p>
<p>1</p>
</blockquote></td>
<td><blockquote>
<p>1 CHRISTINE</p>
<p>2 JASMINE</p>
<p>3 MADELINE</p>
<p>4 PHILIPPINE</p>
<p>5 SYLVINE</p>
</blockquote></td>
<td><blockquote>
<p>binary</p>
<p>binary</p>
<p>binary</p>
<p>binary</p>
<p>binary</p>
</blockquote></td>
<td><blockquote>
<p>BAC</p>
<p>BAC</p>
<p>BAC</p>
<p>BAC</p>
<p>BAC</p>
</blockquote></td>
<td><blockquote>
<p><img src="./automlgithubpagesimages//media/image537.png" width="35" height="53" />1200</p>
<p>1200</p>
<p>1200</p>
<p>1200</p>
<p>1200</p>
</blockquote></td>
<td><blockquote>
<p>2</p>
<p>2</p>
<p>2</p>
<p>2</p>
<p>2</p>
</blockquote></td>
<td><blockquote>
<p>1</p>
<p>1</p>
<p>1</p>
<p>1</p>
<p>1</p>
</blockquote></td>
<td><blockquote>
<p>0.071 0.78 1.2e-06 0.0012 0.01</p>
</blockquote></td>
<td><blockquote>
<p>0</p>
<p>0</p>
<p>0</p>
<p>0</p>
<p>0</p>
</blockquote></td>
<td><blockquote>
<p>0</p>
<p>0</p>
<p>0</p>
<p>0</p>
<p>0</p>
</blockquote></td>
<td><blockquote>
<p>0.5</p>
<p>0.5</p>
<p>0.92</p>
<p>0.5</p>
<p>0.5</p>
</blockquote></td>
<td><blockquote>
<p>2084</p>
<p>1756</p>
<p>3240</p>
<p>4664</p>
<p>10,244</p>
</blockquote></td>
<td><blockquote>
<p>834</p>
<p>526</p>
<p>1080</p>
<p>1166</p>
<p>5124</p>
</blockquote></td>
<td><blockquote>
<p>5418</p>
<p>2984</p>
<p>3140</p>
<p>5832</p>
<p>5124</p>
</blockquote></td>
<td><blockquote>
<p>1636</p>
<p>144</p>
<p>259</p>
<p>308</p>
<p>20</p>
</blockquote></td>
<td><blockquote>
<p>3.31</p>
<p>20.72</p>
<p>12.12</p>
<p>18.94</p>
<p>256.2</p>
</blockquote></td>
</tr>
<tr class="even">
<td><blockquote>
<p>2</p>
<p>2</p>
<p>2</p>
<p>2</p>
<p>2</p>
</blockquote></td>
<td><blockquote>
<p>1 ALBERT</p>
<p>2 DILBERT</p>
<p>3 FABERT</p>
<p>4 ROBERT</p>
<p>5 VOLKERT</p>
</blockquote></td>
<td><blockquote>
<p>binary multiclass multiclass multiclass multiclass</p>
</blockquote></td>
<td><blockquote>
<p>F1</p>
<p>PAC</p>
<p>PAC</p>
<p>BAC</p>
<p>PAC</p>
</blockquote></td>
<td><blockquote>
<p><img src="./automlgithubpagesimages//media/image538.png" width="35" height="53" />1200</p>
<p>1200</p>
<p>1200</p>
<p>1200</p>
<p>1200</p>
</blockquote></td>
<td><blockquote>
<p>2</p>
<p>5</p>
<p>7</p>
<p>10</p>
<p>10</p>
</blockquote></td>
<td><blockquote>
<p>1</p>
<p>1</p>
<p>0.96</p>
<p>1</p>
<p>0.89</p>
</blockquote></td>
<td><blockquote>
<p>0.049</p>
<p>0</p>
<p>0.99</p>
<p>0.01</p>
<p>0.34</p>
</blockquote></td>
<td><blockquote>
<p>0.14</p>
<p>0</p>
<p>0</p>
<p>0</p>
<p>0</p>
</blockquote></td>
<td><blockquote>
<p>1</p>
<p>0</p>
<p>0</p>
<p>0</p>
<p>0</p>
</blockquote></td>
<td><blockquote>
<p>0.5</p>
<p>0.16</p>
<p>0.5</p>
<p>0</p>
<p>0</p>
</blockquote></td>
<td><blockquote>
<p>51,048</p>
<p>9720</p>
<p>2354</p>
<p>5000</p>
<p>7000</p>
</blockquote></td>
<td><blockquote>
<p>25,526</p>
<p>4860</p>
<p>1177</p>
<p>2000</p>
<p>3500</p>
</blockquote></td>
<td><blockquote>
<p>425,240</p>
<p>10,000</p>
<p>8237</p>
<p>10,000</p>
<p>58,310</p>
</blockquote></td>
<td><blockquote>
<p>78</p>
<p>2000</p>
<p>800</p>
<p>7200</p>
<p>180</p>
</blockquote></td>
<td><blockquote>
<p>5451.79</p>
<p>5</p>
<p>10.3</p>
<p>1.39</p>
<p>323.94</p>
</blockquote></td>
</tr>
<tr class="odd">
<td><blockquote>
<p>3</p>
<p>3</p>
<p>3</p>
<p>3</p>
<p>3</p>
</blockquote></td>
<td><blockquote>
<p>1 ALEXIS</p>
<p>2 DIONIS</p>
<p>3 GRIGORIS</p>
<p>4 JANNIS</p>
<p>5 WALLIS</p>
</blockquote></td>
<td><blockquote>
<p>multilabel multiclass multilabel <span id="_bookmark806" class="anchor"></span>multiclass multiclass</p>
</blockquote></td>
<td><blockquote>
<p>AUC</p>
<p>BAC</p>
<p>AUC</p>
<p>BAC</p>
<p>AUC</p>
</blockquote></td>
<td><blockquote>
<p>1200</p>
<p>1200</p>
<p>1200</p>
<p>1200</p>
<p>1200</p>
</blockquote></td>
<td><blockquote>
<p>18</p>
<p>355</p>
<p>91</p>
<p>4</p>
<p>11</p>
</blockquote></td>
<td><blockquote>
<p>0.92</p>
<p>1</p>
<p>0.87</p>
<p>0.8</p>
<p>0.91</p>
</blockquote></td>
<td><blockquote>
<p>0.98</p>
<p>0.11</p>
<p>1 7.3e-05 1</p>
</blockquote></td>
<td><blockquote>
<p>0</p>
<p>0</p>
<p>0</p>
<p>0</p>
<p>0</p>
</blockquote></td>
<td><blockquote>
<p>0</p>
<p>0</p>
<p>0</p>
<p>0</p>
<p>0</p>
</blockquote></td>
<td><blockquote>
<p>0</p>
<p>0</p>
<p>0</p>
<p>0.5</p>
<p>0</p>
</blockquote></td>
<td><blockquote>
<p>15,569</p>
<p>12,000</p>
<p>9920</p>
<p>9851</p>
<p>8196</p>
</blockquote></td>
<td><blockquote>
<p>7784</p>
<p>6000</p>
<p>6486</p>
<p>4926</p>
<p>4098</p>
</blockquote></td>
<td><blockquote>
<p>54,491</p>
<p>416,188</p>
<p>45,400</p>
<p>83,733</p>
<p>10,000</p>
</blockquote></td>
<td><blockquote>
<p>5000</p>
<p>60</p>
<p>301,561</p>
<p>54</p>
<p>193,731</p>
</blockquote></td>
<td><blockquote>
<p>10.9</p>
<p>6936.47</p>
<p>0.15</p>
<p>1550.61</p>
<p>0.05</p>
</blockquote></td>
</tr>
<tr class="even">
<td><blockquote>
<p>4</p>
<p>4</p>
<p>4</p>
<p>4</p>
<p>4</p>
</blockquote></td>
<td><blockquote>
<p>1 EVITA</p>
<p>2 FLORA</p>
<p>3 HELENA</p>
<p>4 TANIA</p>
<p>5 YOLANDA</p>
</blockquote></td>
<td><blockquote>
<p>binary regression multiclass multilabel regression</p>
</blockquote></td>
<td><blockquote>
<p>AUC</p>
<p>ABS</p>
<p>BAC</p>
<p>PAC</p>
<p>R2</p>
</blockquote></td>
<td><blockquote>
<p>1200</p>
<p>1200</p>
<p>1200</p>
<p>1200</p>
<p>1200</p>
</blockquote></td>
<td><blockquote>
<p>2</p>
<p>0</p>
<p>100</p>
<p>95</p>
<p>0</p>
</blockquote></td>
<td><blockquote>
<p>0.21</p>
<p>NaN</p>
<p>0.9</p>
<p>0.79</p>
<p>NaN</p>
</blockquote></td>
<td><blockquote>
<p>0.91</p>
<p>0.99</p>
<p>6e-05</p>
<p>1</p>
<p>1e-07</p>
</blockquote></td>
<td><blockquote>
<p>0</p>
<p>0</p>
<p>0</p>
<p>0</p>
<p>0</p>
</blockquote></td>
<td><blockquote>
<p>0</p>
<p>0</p>
<p>0</p>
<p>0</p>
<p>0</p>
</blockquote></td>
<td><blockquote>
<p>0.46</p>
<p>0.25</p>
<p>0</p>
<p>0</p>
<p>0.1</p>
</blockquote></td>
<td><blockquote>
<p>14,000</p>
<p>2000</p>
<p>18,628</p>
<p>44,635</p>
<p>30,000</p>
</blockquote></td>
<td><blockquote>
<p>8000</p>
<p>2000</p>
<p>9314</p>
<p>22,514</p>
<p>30,000</p>
</blockquote></td>
<td><blockquote>
<p>20,000</p>
<p>15,000</p>
<p>65,196</p>
<p>157,599</p>
<p>400,000</p>
</blockquote></td>
<td><blockquote>
<p>3000</p>
<p>200,000</p>
<p>27</p>
<p>47,236</p>
<p>100</p>
</blockquote></td>
<td><blockquote>
<p>6.67</p>
<p>0.08</p>
<p>2414.67</p>
<p>3.34</p>
<p>4000</p>
</blockquote></td>
</tr>
<tr class="odd">
<td><blockquote>
<p>5</p>
<p>5</p>
<p>5</p>
<p>5</p>
<p>5</p>
</blockquote></td>
<td><blockquote>
<p>1 ARTURO</p>
<p>2 CARLO</p>
<p>3 MARCO</p>
<p>4 PABLO</p>
<p>5 WALDO</p>
</blockquote></td>
<td><blockquote>
<p>multiclass binary multilabel regression multiclass</p>
</blockquote></td>
<td><blockquote>
<p>F1</p>
<p>PAC</p>
<p>AUC</p>
<p>ABS</p>
<p>BAC</p>
</blockquote></td>
<td><blockquote>
<p>1200</p>
<p>1200</p>
<p>1200</p>
<p>1200</p>
<p>1200</p>
</blockquote></td>
<td><blockquote>
<p>20</p>
<p>2</p>
<p>24</p>
<p>0</p>
<p>4</p>
</blockquote></td>
<td><blockquote>
<p>1 0.097 0.76 NaN 1</p>
</blockquote></td>
<td><blockquote>
<p>0.82</p>
<p>0.0027</p>
<p>0.99</p>
<p>0.11</p>
<p>0.029</p>
</blockquote></td>
<td><blockquote>
<p>0</p>
<p>0</p>
<p>0</p>
<p>0</p>
<p>0</p>
</blockquote></td>
<td><blockquote>
<p>0</p>
<p>0</p>
<p>0</p>
<p>0</p>
<p>1</p>
</blockquote></td>
<td><blockquote>
<p>0.5</p>
<p>0.5</p>
<p>0</p>
<p>0.5</p>
<p>0.5</p>
</blockquote></td>
<td><blockquote>
<p>2733</p>
<p>10,000</p>
<p>20,482</p>
<p>23,565</p>
<p>2430</p>
</blockquote></td>
<td><blockquote>
<p>1366</p>
<p>10,000</p>
<p>20,482</p>
<p>23,565</p>
<p>2430</p>
</blockquote></td>
<td><blockquote>
<p>9565</p>
<p>50,000</p>
<p>163,860</p>
<p>188,524</p>
<p>19,439</p>
</blockquote></td>
<td><blockquote>
<p>400</p>
<p>1070</p>
<p>15,299</p>
<p>120</p>
<p>270</p>
</blockquote></td>
<td><blockquote>
<p>23.91</p>
<p>46.73</p>
<p>10.71</p>
<p>1571.03</p>
<p>72</p>
</blockquote></td>
</tr>
</tbody>
</table>
<p><img src="./automlgithubpagesimages//media/image12.jpeg" width="136" /></p>
<blockquote>
<p>190 I. Guyon et al.</p>
<p><span id="_bookmark807" class="anchor"></span><strong>Table</strong> <strong>10.3</strong> <strong>Datasets</strong> <strong>of</strong> <strong>the</strong> <strong>2018</strong> <strong>AutoML</strong> <strong>challenge.</strong> All tasks are binary classiﬁcation problems. The metric is the AUC for all tasks. The time budget is also the same for all datasets (1200 s). Phase 1 was the development phase and phase 2 the ﬁnal “blind test” phase</p>
</blockquote>
<table>
<tbody>
<tr class="odd">
<td><blockquote>
<p>Phase</p>
</blockquote></td>
<td><blockquote>
<p>DATASET</p>
</blockquote></td>
<td><blockquote>
<p>Cbal</p>
</blockquote></td>
<td><blockquote>
<p>Sparse</p>
</blockquote></td>
<td><blockquote>
<p>Miss</p>
</blockquote></td>
<td><blockquote>
<p>Cat</p>
</blockquote></td>
<td><blockquote>
<p>Irr</p>
</blockquote></td>
<td><blockquote>
<p>Pte</p>
</blockquote></td>
<td><blockquote>
<p>Pva</p>
</blockquote></td>
<td><blockquote>
<p>Ptr</p>
</blockquote></td>
<td><blockquote>
<p>N</p>
</blockquote></td>
<td><blockquote>
<p>Ptr/N</p>
</blockquote></td>
</tr>
<tr class="even">
<td><blockquote>
<p>1</p>
<p>1</p>
<p>1</p>
<p>1</p>
<p>1</p>
</blockquote></td>
<td><blockquote>
<p>1 ADA</p>
<p>2 ARCENE</p>
<p>3 GINA</p>
<p>4 GUILLERMO</p>
<p>5 RL</p>
</blockquote></td>
<td><blockquote>
<p>1</p>
<p>0.22</p>
<p>1</p>
<p>0.33</p>
<p>0.10</p>
</blockquote></td>
<td><blockquote>
<p>0.67</p>
<p>0.54</p>
<p>0.03</p>
<p>0.53</p>
<p>0</p>
</blockquote></td>
<td><blockquote>
<p>0</p>
<p>0</p>
<p>0.31</p>
<p>0</p>
<p>0.11</p>
</blockquote></td>
<td><blockquote>
<p>0</p>
<p>0</p>
<p>0</p>
<p>0</p>
<p>1</p>
</blockquote></td>
<td><blockquote>
<p>0</p>
<p>0</p>
<p>0</p>
<p>0</p>
<p>0</p>
</blockquote></td>
<td><blockquote>
<p>41,471</p>
<p>700</p>
<p>31,532</p>
<p>5000</p>
<p>24,803</p>
</blockquote></td>
<td><blockquote>
<p>415</p>
<p>100</p>
<p>315</p>
<p>5000</p>
<p>0</p>
</blockquote></td>
<td><blockquote>
<p>4147</p>
<p>100</p>
<p>3153</p>
<p>20,000</p>
<p>31,406</p>
</blockquote></td>
<td><blockquote>
<p>48</p>
<p>10,000</p>
<p>970</p>
<p>4296</p>
<p>22</p>
</blockquote></td>
<td><blockquote>
<p>86.39</p>
<p>0.01</p>
<p>3.25</p>
<p>4.65</p>
<p>1427.5</p>
</blockquote></td>
</tr>
<tr class="odd">
<td><blockquote>
<p>2</p>
<p>2</p>
<p>2</p>
<p>2</p>
<p>2</p>
</blockquote></td>
<td><blockquote>
<p>1 PM</p>
<p>2 RH</p>
<p>3 RI</p>
<p>4 RICCARDO</p>
<p>5 RM</p>
</blockquote></td>
<td><blockquote>
<p>0.01 0.04 0.02 0.67 0.001</p>
</blockquote></td>
<td><blockquote>
<p>0</p>
<p>0.41</p>
<p>0.09</p>
<p>0.51</p>
<p>0</p>
</blockquote></td>
<td><blockquote>
<p>0.11</p>
<p>0</p>
<p>0.26</p>
<p>0</p>
<p>0.11</p>
</blockquote></td>
<td><blockquote>
<p>1</p>
<p>1</p>
<p>1</p>
<p>0</p>
<p>1</p>
</blockquote></td>
<td><blockquote>
<p>0</p>
<p>0</p>
<p>0</p>
<p>0</p>
<p>0</p>
</blockquote></td>
<td><blockquote>
<p>20,000</p>
<p>28,544</p>
<p>26,744</p>
<p>5000</p>
<p>26,961</p>
</blockquote></td>
<td><blockquote>
<p>0</p>
<p>0</p>
<p>0</p>
<p>5000</p>
<p>0</p>
</blockquote></td>
<td><blockquote>
<p>29,964</p>
<p>31,498</p>
<p>30,562</p>
<p>20,000</p>
<p>28,278</p>
</blockquote></td>
<td><blockquote>
<p>89</p>
<p>76</p>
<p>113</p>
<p>4296</p>
<p>89</p>
</blockquote></td>
<td><blockquote>
<p>224.71</p>
<p>414.44</p>
<p>270.46</p>
<p>4.65</p>
<p>317.73</p>
</blockquote></td>
</tr>
</tbody>
</table>
<blockquote>
<p>lies in dealing with sparse and full matrices, presence of irrelevant variables, and various Ptr/N .</p>
<p><strong>Intermediate</strong> Binary and multi-class classiﬁcation problems. Challenge lies in dealing with unbalanced classes, number of classes, missing values, categorical variables, and up to 7,000 features.</p>
<p><strong>Advanced</strong> Binary, multi-class, and multi-label classiﬁcation problems. Challenge lies in dealing with up to 300,000 features.</p>
<p><strong>Expert</strong> Classiﬁcation and regression problems. Challenge lies in dealing with the entire range of data complexity.</p>
<p><strong>Master</strong> Classiﬁcation and regression problems of all difﬁculties. Challenge lies in learning from completely new datasets.</p>
<p>The datasets of the 2018 challenge were all binary classiﬁcation problems. Validation partitions were not used because of the design of this challenge, even when they were available for some tasks. The three reused datasets had similar difﬁculty as those of rounds 1 and 2 of the 2015/2016 challenge. However, the seven new data sets introduced difﬁculties that were not present in the former challenge. Most notably an extreme class imbalance, presence of categorical features and a temporal dependency among instances that could be exploited by participants to develop their methods.<a href="#_bookmark808">8</a> The datasets from both challenges are downloadable from <a href="http://automl.chalearn.org/data" class="uri">http://automl.chalearn.org/data</a>.</p>
<p><strong>10.4</strong> <strong>Challenge</strong> <strong>Protocol</strong></p>
<p>In this section, we describe design choices we made to ensure the thoroughness and fairness of the evaluation. As previously indicated, we focus on supervised learning tasks (classiﬁcation and regression problems), without any human intervention,</p>
<p><span id="_bookmark808" class="anchor"></span>8In RL, PM, RH, RI and RM datasets instances were chronologically sorted, this information was made available to participants and could be used for developing their methods.</p>
<p>10 Analysis of the AutoML Challenge Series 2015–2018 191</p>
</blockquote>
<p>within given time and computer resource constraints (Sect.<a href="#_bookmark809">10.4.1</a>), and given a particular metric (Sect.<a href="#_bookmark733">10.4.2</a>), which varies from dataset to dataset. During the challenges, the identity and description of the datasets is concealed (except in the very ﬁrst round or phase where sample data is distributed) to avoid the use of domain knowledge and to push participants to design fully automated ML solutions. In the 2015/2016 AutoML challenge, the datasets were introduced in a series of rounds (Sect.<a href="#_bookmark810">10.4.3</a>), alternating periods of code development (Tweakathon phases) and blind tests of code without human intervention (AutoML phases). Either results or code could be submitted during development phases, but code had to be submitted to be part of the AutoML “blind test” ranking. In the 2018 edition of the AutoML challenge, the protocol was simpliﬁed. We had only one round in two phases: a development phase in which 5 datasets were released for practice purposes, and a ﬁnal “blind test” phase with 5 new datasets that were never used before.</p>
<p><span id="_bookmark809" class="anchor"></span><em><strong>10.4.1</strong></em> <em><strong>Time</strong></em> <em><strong>Budget</strong></em> <em><strong>and</strong></em> <em><strong>Computational</strong></em> <em><strong>Resources</strong></em></p>
<p>The Codalab platform provides computational resources shared by all participants. We used up to 10 compute workers processing in parallel the queue of submissions made by participants. Each compute worker was equipped with 8 cores x86_64. Memory was increased from 24 to 56 GB after round 3 of the 2015/2016 AutoML challenge. For the 2018 AutoML challenge computing resources were reduced, as we wanted to motivate the development of more efﬁcient yet effective AutoML solutions. We used 6 compute workers processing in parallel the queue of submissions. Each compute worker was equipped with 2 cores x86_64 and 8 GB of memory.</p>
<p>To ensure fairness, when a code submission was evaluated, a compute worker was dedicated to processing that submission only, and its execution time was limited to a given time budget (which may vary from dataset to dataset). The time budget was provided to the participants with each dataset in its <em>info</em> ﬁle. It was generally set to 1200 s (20 min) per dataset, for practical reasons, except in the ﬁrst phase of the ﬁrst round. However, the participants did not know this ahead of time and therefore their code had to be capable to manage a given time budget. The participants who submitted results instead of code were not constrained by the time budget since their code was run on their own platform. This was potentially advantageous for entries counting towards the Final phases (immediately following a Tweakathon). Participants wishing to also enter the AutoML (blind testing) phases, which required submitting code, could submit both results and code (simultaneously). When results were submitted, they were used as entries in the on-going phase. They did not need to be produced by the submitted code; i.e., if a participant did not want to share personal code, he/she could submit the sample code provided by the organizers together with his/her results. The code was automatically forwarded to the AutoML phases for “blind testing” . In AutoML phases, result submission was not possible.</p>
<blockquote>
<p>192 I. Guyon et al.</p>
<p>The participants were encouraged to save and submit intermediate results so we could draw learning curves. This was not exploited during the challenge. But we study learning curves in this chapter to evaluate the capabilities of algorithms to quickly attain good performances.</p>
</blockquote>
<p><span id="_bookmark733" class="anchor"></span><em><strong>10.4.2</strong></em> <em><strong>Scoring</strong></em> <em><strong>Metrics</strong></em></p>
<p>The scores are computed by comparing submitted predictions to reference target values. For each sample i, i = 1 : P (where P is the size of the validation set or of the test set), the target value is a continuous numeric coefﬁcient yi for regression problems, a binary indicator in {0, 1} for two-class problems, or a vector of binary indicators [yil] in {0, 1} for multi-class or multi-label classiﬁcation problems (one per class l). The participants had to submit prediction values matching as closely as possible the target values, in the form of a continuous numeric coefﬁcient qi for regression problems and a vector of numeric coefﬁcients [qil] in the range [0, 1] for multi-class or multi-label classiﬁcation problems (one per class l).</p>
<p>The provided starting kit contains an implementation in Python of all scoring metrics used to evaluate the entries. Each dataset has its own scoring criterion speciﬁed in its <em>info</em> ﬁle. All scores are normalized such that the expected value of the score for a random prediction, based on class prior probabilities, is 0 and the optimal score is 1. Multi-label problems are treated as multiple binary classiﬁcation problems and are evaluated using the average of the scores of each binary classiﬁcation subproblem.</p>
<blockquote>
<p>We ﬁrst deﬁne the notation ( · ) for the average over all samples P indexed by i .</p>
<p>That is,</p>
<p>P</p>
<p>(yi) = (1/P )对(yi).</p>
<p>i=1</p>
<p>The score metrics are deﬁned as follows:</p>
<p><strong>R2</strong> The coefﬁcient of determination is used for regression problems only. The metric is based on the mean squared error (MSE) and the variance (VAR), and computed as</p>
</blockquote>
<p>R2 = 1 − <em>MSE</em>/<em>VAR</em>, (10.3)</p>
<blockquote>
<p>where <em>MSE</em> = ((yi − qi)2 ) and <em>VAR</em> = ((yi − m)2 ), with m = (yi) .</p>
<p><strong>ABS</strong> This coefﬁcient is similar to R2 but based on the mean absolute error (MAE) and the mean absolute deviation (MAD), and computed as</p>
</blockquote>
<p><em>ABS</em> = 1 − <em>MAE</em>/<em>MAD</em>, (10.4)</p>
<blockquote>
<p>10 Analysis of the AutoML Challenge Series 2015–2018 193</p>
<p>where <em>MAE</em> = (abs(yi − qi)) and <em>MAD</em> = (abs(yi − m)) .</p>
</blockquote>
<p><strong>BAC</strong> Balanced accuracy is the average of class-wise accuracy for classiﬁcation problems—and the average of <em>sensitivity</em> (true positive rate) and <em>speciﬁcity</em> (true negative rate) for binary classiﬁcation:</p>
<blockquote>
<p><img src="./automlgithubpagesimages//media/image539.png" height="15" />1<img src="./automlgithubpagesimages//media/image540.jpeg" />2 [<em>TP</em><img src="./automlgithubpagesimages//media/image541.jpeg" /><em>P</em> <em>BAC</em> = <img src="./automlgithubpagesimages//media/image542.png" height="27" />1<img src="./automlgithubpagesimages//media/image543.jpeg" />C</p>
</blockquote>
<p>( i =1</p>
<p>+ <em>TN</em><img src="./automlgithubpagesimages//media/image544.jpeg" /><em>N</em>],</p>
<blockquote>
<p><em>TP</em>i</p>
<p><em>N</em>i ,</p>
</blockquote>
<p>for binary</p>
<p>for multi-class</p>
<blockquote>
<p>(10.5)</p>
<p>where <em>P</em> (<em>N</em>) is the number of positive (negative) examples, <em>TP</em> (<em>TN</em>) is the number of well classiﬁed positive (negative) examples, C is the number of classes, <em>TP</em>i is the number of well classiﬁed examples of class i and Ni the number of examples of class i .</p>
</blockquote>
<p>For binary classiﬁcation problems, the class-wise accuracy is the fraction of correct class predictions when qi is thresholded at 0.5, for each class. For multi- label problems, the class-wise accuracy is averaged over all classes. For multi-class problems, the predictions are binarized by selecting the class with maximum prediction value arg maxl qil before computing the class-wise accuracy.</p>
<blockquote>
<p>We normalize the metric as follows:</p>
</blockquote>
<p>|<em>BAC</em>| = (<em>BAC</em> − R)/(1 − R), (10.6)</p>
<p>where R is the expected value of BAC for random predictions (i.e., R = 0.5 for binary classiﬁcation and R = (1/C) for C -class problems).</p>
<p><strong>AUC</strong> The area under the ROC curve is used for ranking and binary classiﬁcation problems. The ROC curve is the curve of <em>sensitivity</em> vs. <em>1-speciﬁcity</em> at various prediction thresholds. The AUC and BAC values are the same for binary predictions. The AUC is calculated for each class separately before averaging over all classes.</p>
<p>We normalize the metric as</p>
<blockquote>
<p>|AUC| = 2AUC − 1.</p>
<p>(10.7)</p>
<p><strong>F1</strong> <strong>score</strong> The harmonic mean of precision and recall is computed as F1 = 2 ∗ (<em>precision</em> ∗ <em>recall</em>)/(<em>precision</em> + <em>recall</em>),</p>
<p><em>precision</em> = <em>true</em> <em>positive</em>/(<em>true</em> <em>positive</em> +<em>false</em> <em>positive</em>)</p>
<p><em>recall</em> = <em>true</em> <em>positive</em>/(<em>true</em> <em>positive</em> +<em>false</em> <em>negative</em>)</p>
<p>(10.8) (10.9)</p>
<p>(10. 10)</p>
<p>Prediction thresholding and class averaging is handled similarly as in BAC. We normalize the metric as follows:</p>
<p>194 I. Guyon et al.</p>
</blockquote>
<p>|F 1| = (F 1 − R)/(1 − R), (10. 11)</p>
<blockquote>
<p>where R is the expected value of F1 for random predictions (see BAC).</p>
</blockquote>
<p><strong>PAC</strong> Probabilistic accuracy is based on the cross-entropy (or log loss) and com- puted as</p>
<blockquote>
<p><em>PAC</em> = exp(−<em>CE</em>),</p>
<p><img src="./automlgithubpagesimages//media/image545.png" height="20" />average对l log(qil), for multi-class</p>
<p><em>CE</em> = −(yi log(qi),</p>
<p><img src="./automlgithubpagesimages//media/image546.png" height="20" />+(1 − yi) log(1 − qi)) , for binary and multi-label</p>
<p>(10. 12)</p>
<p>(10. 13)</p>
<p>Class averaging is performed after taking the exponential in the multi-label case.</p>
</blockquote>
<p>We normalize the metric as follows:</p>
<p>|<em>PAC</em>| = (<em>PAC</em> − R)/(1 − R), (10. 14)</p>
<blockquote>
<p>where R is the score obtained using qi = (yi) or qil = (yil) (i.e., using as predictions the fraction of positive class examples, as an estimate of the prior probability).</p>
</blockquote>
<p>Note that the normalization of R2, ABS, and PAC uses the average target value qi = (yi) or qil = (yil) . In contrast, the normalization of BAC, AUC, and F1 uses a random prediction of one of the classes with uniform probability.</p>
<blockquote>
<p>Only R2 and ABS are meaningful for regression; we compute the other metrics for completeness by replacing the target values with binary values after thresholding them in the mid-range.</p>
</blockquote>
<p><span id="_bookmark810" class="anchor"></span><em><strong>10.4.3</strong></em> <em><strong>Rounds</strong></em> <em><strong>and</strong></em> <em><strong>Phases</strong></em> <em><strong>in</strong></em> <em><strong>the</strong></em> <em><strong>2015/2016</strong></em> <em><strong>Challenge</strong></em></p>
<blockquote>
<p>The 2015/2016 challenge was run in multiple phases grouped in six rounds. Round 0 (Preparation) was a practice round using publicly available datasets. It was followed by ﬁve rounds of progressive difﬁculty (Novice, Intermediate, Advanced, Expert, and Master). Except for rounds 0 and 5, all rounds included three phases that alternated AutoML and Tweakathons contests. These phases are described in Table <a href="#_bookmark811">10.4</a>.</p>
</blockquote>
<p>Submissions were made in Tweakathon phases only. The results of the latest submission were shown on the leaderboard and such submission automatically migrated to the following phase. In this way, the code of participants who abandoned before the end of the challenge had a chance to be tested in subsequent rounds and phases. New participants could enter at any time. Prizes were awarded in phases marked with a * during which there was no submission. To participate in phase AutoML[n], code had to be submitted in Tweakathon[n- 1].</p>
<blockquote>
<p>10 Analysis of the AutoML Challenge Series 2015–2018 195</p>
<p><span id="_bookmark811" class="anchor"></span><strong>Table</strong> <strong>10.4</strong> <strong>Phases</strong> <strong>of</strong> <strong>round</strong> <strong>n</strong> <strong>in</strong> <strong>the</strong> <strong>2015/2016</strong> <strong>challenge.</strong> For each dataset, one labeled training set is provided and two unlabeled sets (validation set and test set) are provided for testing</p>
</blockquote>
<table>
<tbody>
<tr class="odd">
<td><blockquote>
<p>Phase in round</p>
<p>[n]</p>
</blockquote></td>
<td><blockquote>
<p>Goal</p>
</blockquote></td>
<td><blockquote>
<p>Duration</p>
</blockquote></td>
<td><blockquote>
<p>Submissions</p>
</blockquote></td>
<td><blockquote>
<p>Data</p>
</blockquote></td>
<td><blockquote>
<p>Leader-board scores</p>
</blockquote></td>
<td><blockquote>
<p>Prizes</p>
</blockquote></td>
</tr>
<tr class="even">
<td><blockquote>
<p>* AutoML[n]</p>
</blockquote></td>
<td><blockquote>
<p>Blind</p>
<p>test</p>
<p>of code</p>
</blockquote></td>
<td><blockquote>
<p>Short</p>
</blockquote></td>
<td><blockquote>
<p>NONE</p>
<p>(code</p>
<p>migrated)</p>
</blockquote></td>
<td><blockquote>
<p>New datasets, not downloadable</p>
</blockquote></td>
<td><blockquote>
<p>Test</p>
<p>set</p>
<p>results</p>
</blockquote></td>
<td><blockquote>
<p>Yes</p>
</blockquote></td>
</tr>
<tr class="odd">
<td><blockquote>
<p>Tweakathon[n]</p>
</blockquote></td>
<td><blockquote>
<p>Manual</p>
<p>tweaking</p>
</blockquote></td>
<td><blockquote>
<p>Months</p>
</blockquote></td>
<td><blockquote>
<p>Code and/</p>
<p>or results</p>
</blockquote></td>
<td><blockquote>
<p>Datasets</p>
<p>downloadable</p>
</blockquote></td>
<td><blockquote>
<p>Validation</p>
<p>set results</p>
</blockquote></td>
<td><blockquote>
<p>No</p>
</blockquote></td>
</tr>
<tr class="even">
<td><blockquote>
<p>* Final[n]</p>
</blockquote></td>
<td><blockquote>
<p>Results of</p>
<p>Tweakathon</p>
<p>revealed</p>
</blockquote></td>
<td><blockquote>
<p>Short</p>
</blockquote></td>
<td><blockquote>
<p>NONE</p>
<p>(results</p>
<p>migrated)</p>
</blockquote></td>
<td><blockquote>
<p>NA</p>
</blockquote></td>
<td><blockquote>
<p>Test</p>
<p>set</p>
<p>results</p>
</blockquote></td>
<td><blockquote>
<p>Yes</p>
</blockquote></td>
</tr>
</tbody>
</table>
<blockquote>
<p>In order to encourage participants to try GPUs and deep learning, a GPU track sponsored by NVIDIA was included in Round 4.</p>
<p>To participate in the Final[n], code or results had to be submitted in Tweakathon[n]. If both code and (well-formatted) results were submitted, the results were used for scoring rather than rerunning the code in Tweakathon[n] and Final[n]. The code was executed when results were unavailable or not well formatted. Thus, there was no disadvantage in submitting both results and code. If a participant submitted both results and code, different methods could be used to enter the Tweakathon/Final phases and the AutoML phases. Submissions were made only during Tweakathons, with a maximum of ﬁve submissions per day. Immediate feedback was provided on the leaderboard on validation data. The participants were</p>
<p>ranked on the basis of test performance during the Final and AutoML phases.</p>
<p>We provided baseline software using the ML library scikit-learn [<a href="#_bookmark739">55</a>]. It uses ensemble methods, which improve over time by adding more base learners. Other than the number of base learners, the default hyper-parameter settings were used. The participants were not obliged to use the Python language nor the main Python script we gave as an example. However, most participants found it convenient to use the main python script, which managed the sparse format, the any-time learning settings and the scoring metrics. Many limited themselves to search for the best model in the scikit-learn library. This shows the importance of providing a good starting kit, but also the danger of biasing results towards particular solutions.</p>
<p><em><strong>10.4.4</strong></em> <em><strong>Phases</strong></em> <em><strong>in</strong></em> <em><strong>the</strong></em> <em><strong>2018</strong></em> <em><strong>Challenge</strong></em></p>
</blockquote>
<p>The 2015/2016 AutoML challenge was very long and few teams participated in all rounds. Further, even though there was no obligation to participate in previous rounds to enter new rounds, new potential participants felt they would be at a disadvantage. Hence, we believe it is preferable to organize recurrent yearly events, each with their own workshop and publication opportunity. This provides a good balance between competition and collaboration.</p>
<blockquote>
<p>196 I. Guyon et al.</p>
<p>In 2018, we organized a single round of AutoML competition in two phases. In this simpliﬁed protocol, the participants could practice on ﬁve datasets during the ﬁrst (development) phase, by either submitting code or results. Their performances were revealed immediately, as they became available, on the leaderboard.</p>
</blockquote>
<p>The last submission of the development phase was automatically forwarded to the second phase: the AutoML “blind test” phase. In this second phase, which was the only one counting towards the prizes, the participants’ code was automatically evaluated on ﬁve new datasets on the Codalab platform. The datasets were not revealed to the participants. Hence, submissions that did not include code capable of being trained and tested automatically were not ranked in the ﬁnal phase and could not compete towards the prizes.</p>
<blockquote>
<p>We provided the same starting kit as in the AutoML 2015/2016 challenge, but the participants also had access to the code of the winners of the previous challenge.</p>
<p><strong>10.5</strong> <strong>Results</strong></p>
<p>This section provides a brief description of the results obtained during both challenges, explains the methods used by the participants and their elements of novelty, and provides the analysis of post-challenge experiments conducted to answer speciﬁc questions on the effectiveness of model search techniques.</p>
</blockquote>
<p><em><strong>10.5.1</strong></em> <em><strong>Scores</strong></em> <em><strong>Obtained</strong></em> <em><strong>in</strong></em> <em><strong>the</strong></em> <em><strong>2015/2016</strong></em> <em><strong>Challenge</strong></em></p>
<blockquote>
<p>The 2015/2016 challenge lasted 18 months (December 8, 2014 to May 1, 2016). By the end of the challenge, practical solutions were obtained and open-sourced, such as the solution of the winners [<a href="#_bookmark741">25</a>].</p>
</blockquote>
<p>Table<a href="#_bookmark589">10.5</a>presents the results on the test set in the AutoML phases (blind testing) and the Final phases (one time testing on the test set revealed at the end of the Tweakathon phases). Ties were broken by giving preference to the participant who submitted ﬁrst. The table only reports the results of the top-ranking participants. We also show in Fig.<a href="#_bookmark812">10.3</a>a comparison of the leaderboard performances of all participants. We plot in Fig.<a href="#_bookmark812">10.3</a>a the Tweakathon performances on the ﬁnal test set vs. those on the validation set, which reveals no signiﬁcant overﬁtting to the validation set, except for a few outliers. In Fig.<a href="#_bookmark812">10.3</a>b we report the performance in AutoML result (blind testing) vs. Tweakathon ﬁnal test results (manual adjustments possible). We see that many entries were made in phase 1 (binary classiﬁcation) and then participation declined as the tasks became harder. Some participants put a lot of effort in Tweakathons and far exceeded their AutoML performances (e.g. Djajetic and AAD Freiburg).</p>
<p>There is still room for improvement by manual tweaking and/or additional com- putational resources, as revealed by the signiﬁcant differences remaining between Tweakathon and AutoML (blind testing) results (Table <a href="#_bookmark589">10.5</a> and Fig.<a href="#_bookmark812">10.3</a>b). In</p>
<blockquote>
<p>10 Analysis of the AutoML Challenge Series 2015–2018 197</p>
<p><span id="_bookmark589" class="anchor"></span><strong>Table</strong> <strong>10.5</strong> <strong>Results</strong> <strong>of</strong> <strong>the</strong> <strong>2015/2016</strong> <strong>challenge</strong> <strong>winners.</strong> &lt; R &gt; is the average rank over all ﬁve data sets of the round and it was used to rank the participants. &lt; S &gt; is the average score over the ﬁve data sets of the round. UP is the percent increase in performance between the average perfor- mance of the winners in the AutoML phase and the Final phase of the same round. The GPU track was run in round 4. Team names are abbreviated as follows: <em>aad</em> aad_freiburg, <em>djaj</em> djajetic, <em>marc</em> marc.boulle, <em>tadej</em> tadejs, <em>abhi</em> abhishek4, <em>ideal</em> ideal.intel.analytics, <em>mat</em> matthias.vonrohr, <em>lisheng</em> lise_sun, <em>asml</em> amsl.intel.com, <em>jlr44</em> backstreet.bayes, <em>post</em> postech.mlg_exbrain, <em>ref</em> reference</p>
</blockquote>
<table>
<tbody>
<tr class="odd">
<td><blockquote>
<p>Rnd</p>
</blockquote></td>
<td></td>
<td><blockquote>
<p><strong>AutoML</strong></p>
<p>Ended Winners &lt; R &gt; &lt; S &gt;</p>
</blockquote></td>
<td><blockquote>
<p>Ended</p>
</blockquote></td>
<td><blockquote>
<p><strong>Final</strong></p>
<p>Winners &lt; R &gt; &lt; S &gt;</p>
</blockquote></td>
<td></td>
<td><blockquote>
<p>UP (%)</p>
</blockquote></td>
</tr>
<tr class="even">
<td><blockquote>
<p>0</p>
</blockquote></td>
<td></td>
<td><blockquote>
<p>NA</p>
</blockquote></td>
<td><blockquote>
<p>NA</p>
</blockquote></td>
<td><blockquote>
<p>NA</p>
</blockquote></td>
<td><blockquote>
<p>NA</p>
</blockquote></td>
<td><blockquote>
<p>02/14/15</p>
</blockquote></td>
</tr>
<tr class="odd">
<td><blockquote>
<p>1</p>
</blockquote></td>
<td></td>
<td><blockquote>
<p>02/15/15</p>
</blockquote></td>
<td><blockquote>
<p>1. aad</p>
<p>2. jrl44</p>
<p>3. tadej</p>
</blockquote></td>
<td><blockquote>
<p>2.80</p>
<p>3.80</p>
<p>4.20</p>
</blockquote></td>
<td><blockquote>
<p>0.6401 0.6226 0.6456</p>
</blockquote></td>
<td><blockquote>
<p>06/14/15</p>
</blockquote></td>
</tr>
<tr class="even">
<td><blockquote>
<p>2</p>
</blockquote></td>
<td></td>
<td><blockquote>
<p>06/15/15</p>
</blockquote></td>
<td><blockquote>
<p>1. jrl44</p>
<p>2. aad</p>
<p>3. mat</p>
</blockquote></td>
<td><blockquote>
<p>1.80</p>
<p>3.40</p>
<p>4.40</p>
</blockquote></td>
<td><blockquote>
<p>0.4320 0.3529 0.3449</p>
</blockquote></td>
<td><blockquote>
<p>11/14/15</p>
</blockquote></td>
</tr>
<tr class="odd">
<td><blockquote>
<p>3</p>
</blockquote></td>
<td></td>
<td><blockquote>
<p>11/15/15</p>
</blockquote></td>
<td><blockquote>
<p>1. djaj</p>
<p>2. NA</p>
<p>3. NA</p>
</blockquote></td>
<td><blockquote>
<p>2.40</p>
<p>NA</p>
<p>NA</p>
</blockquote></td>
<td><blockquote>
<p>0.0901 NA NA</p>
</blockquote></td>
<td><blockquote>
<p>02/19/16</p>
</blockquote></td>
</tr>
<tr class="even">
<td><blockquote>
<p>4</p>
</blockquote></td>
<td></td>
<td><blockquote>
<p>02/20/16</p>
</blockquote></td>
<td><blockquote>
<p>1. aad</p>
<p>2. djaj</p>
<p>3. marc</p>
</blockquote></td>
<td><blockquote>
<p>2.20</p>
<p>2.20</p>
<p>2.60</p>
</blockquote></td>
<td><blockquote>
<p>0.3881 0.3841 0.3815</p>
</blockquote></td>
<td><blockquote>
<p>05/1/16</p>
</blockquote></td>
</tr>
<tr class="odd">
<td><blockquote>
<p>G</p>
<p>P</p>
<p>U</p>
</blockquote></td>
<td></td>
<td><blockquote>
<p>NA</p>
</blockquote></td>
<td><blockquote>
<p>NA</p>
</blockquote></td>
<td><blockquote>
<p>NA</p>
</blockquote></td>
<td><blockquote>
<p>NA</p>
</blockquote></td>
<td><blockquote>
<p>05/1/16</p>
</blockquote></td>
</tr>
<tr class="even">
<td><blockquote>
<p>5</p>
</blockquote></td>
<td></td>
<td><blockquote>
<p>05/1/16</p>
</blockquote></td>
<td><blockquote>
<p>1. aad</p>
<p>2. djaj</p>
<p>3. post</p>
</blockquote></td>
<td><blockquote>
<p>1.60</p>
<p>2.60</p>
<p>4.60</p>
</blockquote></td>
<td><blockquote>
<p>0.5282 0.5379 0.4150</p>
</blockquote></td>
<td><blockquote>
<p>NA</p>
</blockquote></td>
</tr>
</tbody>
</table>
<p><img src="./automlgithubpagesimages//media/image547.jpeg" width="440" height="173" /></p>
<blockquote>
<p><strong>Fig.</strong> <strong>10.3</strong> <strong>Performances</strong> <strong>of</strong> <strong>all</strong> <strong>participants</strong> <strong>in</strong> <strong>the</strong> <strong>2015/2016</strong> <strong>challenge.</strong> We show the last entry <span id="_bookmark812" class="anchor"></span>of all participants in all phases of the 2015/2016 challenge on all datasets from the competition leaderboards. The symbols are color coded by round, as in Table <a href="#_bookmark589">10.5</a>. (<strong>a</strong>) <strong>Overﬁtting</strong> <strong>in</strong> <strong>Tweakathons?</strong> We plot the performance on the ﬁnal test set vs. the performance on the validation set. The validation performances were visible to the participants on the leaderboard while they were tuning their models. The ﬁnal test set performances were only revealed at the end of the Tweakathon. Except for a few outliers, most participants did not overﬁt the leaderboard. (<strong>b</strong>) <strong>Gap</strong> <strong>between</strong> <strong>AutoML</strong> <strong>and</strong> <strong>Tweakathons?</strong> We plot the Tweakathons vs. AutoML performance to visualize improvements obtained by manual tweaking and additional computational resources available in Tweakathons. Points above the diagonal indicate such improvements</p>
<p>198 I. Guyon et al.</p>
<p>Round 3, all but one participant failed to turn in working solutions during blind testing, because of the introduction of sparse datasets. Fortunately, the participants recovered, and, by the end of the challenge, several submissions were capable of returning solutions on all the datasets of the challenge. But learning schemas can still be optimized because, even discarding Round 3, there is a 15–35% performance gap between AutoML phases (blind testing with computational constraints) and Tweakathon phases (human intervention and additional compute power). The GPU track offered (in round 4 only) a platform for trying Deep Learning methods. This allowed the participants to demonstrate that, given additional compute power, deep learning methods were competitive with the best solutions of the CPU track. However, no Deep Learning method was competitive with the limited compute power and time budget offered in the CPU track.</p>
<p><em><strong>10.5.2</strong></em> <em><strong>Scores</strong></em> <em><strong>Obtained</strong></em> <em><strong>in</strong></em> <em><strong>the</strong></em> <em><strong>2018</strong></em> <em><strong>Challenge</strong></em></p>
<p>The 2018 challenge lasted 4 months (November 30, 2017 to March 31, 2018). As in the previous challenge, top-ranked solutions were obtained and open sourced. Table <a href="#_bookmark813">10.6</a> shows the results of both phases of the 2018 challenge. As a reminder, this challenge had a feedback phase and a blind test phase, the performances of the winners in each phase are reported.</p>
<p>Performance in this challenge was slightly lower than that observed in the previous edition. This was due to the difﬁculty of the tasks (see below) and the fact that data sets in the feedback phase included three deceiving datasets (associated to tasks from previous challenges, but not necessarily similar to the data sets used in the blind test phase) out of ﬁve. We decided to proceed this way to emulate a realistic AutoML setting. Although harder, several teams succeeded at returning submissions performing better than chance.</p>
<p>The winner of the challenge was the same team that won the 2015/2016 AutoML challenge: AAD Freiburg [<a href="#_bookmark742">28</a>]. The 2018 challenge helped to incrementally improve the solution devised by this team in the previous challenge. Interestingly, the second- placed team in the challenge proposed a solution that is similar in spirit to that of the winning team. For this challenge, there was a triple tie in the third place, prizes</p>
</blockquote>
<p><span id="_bookmark813" class="anchor"></span><strong>Table</strong> <strong>10.6</strong> <strong>Results</strong> <strong>of</strong> <strong>the</strong> <strong>2018</strong> <strong>challenge</strong> <strong>winners.</strong> Each phase was run on ﬁve different datasets. We show the winners of the AutoML (blind test) phase and for comparison their performances in the Feedback phase. The full tables can be found at <a href="https://competitions.codalab.org/competitions/17767">https://competitions.codalab.org/competitions/</a> <a href="https://competitions.codalab.org/competitions/17767">17767</a></p>
<table>
<tbody>
<tr class="odd">
<td><blockquote>
<p>Ended <img src="./automlgithubpagesimages//media/image548.png" height="11" /></p>
</blockquote></td>
<td><blockquote>
<p><strong>2.</strong> <strong>AutoML</strong> <strong>phase</strong></p>
<p>Winners <img src="./automlgithubpagesimages//media/image549.png" height="11" /> &lt; R &gt;</p>
</blockquote></td>
<td><blockquote>
<p><img src="./automlgithubpagesimages//media/image550.png" height="11" /> &lt; S &gt;</p>
</blockquote></td>
<td></td>
<td><blockquote>
<p><strong>1.</strong> <strong>Feedback</strong> <strong>phase</strong></p>
<p>Ended <img src="./automlgithubpagesimages//media/image551.png" height="11" /> Performance <img src="./automlgithubpagesimages//media/image552.png" height="11" /> &lt; R &gt;</p>
</blockquote></td>
<td><blockquote>
<p><img src="./automlgithubpagesimages//media/image553.png" height="11" /> &lt; S &gt;</p>
</blockquote></td>
<td></td>
</tr>
</tbody>
</table>
<table>
<tbody>
<tr class="odd">
<td><blockquote>
<p>03/31/18</p>
</blockquote></td>
<td><blockquote>
<p>1. aad freiburg</p>
<p>2. narnars0</p>
<p>3. wlWangl</p>
<p>3. thanhdng</p>
<p>3. Malik</p>
</blockquote></td>
<td><blockquote>
<p>2.80</p>
<p>3.80</p>
<p>5.40</p>
<p>5.40</p>
<p>5.40</p>
</blockquote></td>
<td><blockquote>
<p>0.4341 0.4180 0.3857 0.3874 0.3863</p>
</blockquote></td>
<td></td>
<td><blockquote>
<p>03/12/18</p>
</blockquote></td>
<td><blockquote>
<p>aad freiburg</p>
<p>narnars0</p>
<p>wlWangl</p>
<p>thanhdng</p>
<p>Malik</p>
</blockquote></td>
<td><blockquote>
<p>9.0</p>
<p>4.40</p>
<p>4.40</p>
<p>14.0</p>
<p>13.8</p>
</blockquote></td>
<td><blockquote>
<p>0.7422 0.7324 0.8029 0.6845 0.7116</p>
</blockquote></td>
<td></td>
</tr>
</tbody>
</table>
<blockquote>
<p>10 Analysis of the AutoML Challenge Series 2015–2018 199</p>
</blockquote>
<p><img src="./automlgithubpagesimages//media/image554.jpeg" width="440" height="175" /></p>
<p><span id="_bookmark814" class="anchor"></span><strong>Fig.</strong> <strong>10.4</strong> <strong>Distribution</strong> <strong>of</strong> <strong>performance</strong> <strong>on</strong> <strong>the</strong> <strong>datasets</strong> <strong>of</strong> <strong>the</strong> <strong>2015/2016</strong> <strong>challenge</strong> <strong>(violin</strong> <strong>plots).</strong> We show for each dataset the performances of participants at the end of AutoML and Tweakathon phases, as revealed on the leaderboard. The median and quartiles are represented by horizontal notches. The distribution proﬁle (as ﬁtted with a kernel method) and its mirror image are represented vertically by the gray shaded area. We show in red the median performance over all datasets and the corresponding quartiles. (<strong>a</strong>) <strong>AutoML</strong> <strong>(blind</strong> <strong>testing).</strong> The ﬁrst 5 datasets were provided for development purpose only and were not used for blind testing in an AutoML phase. In round 3, the code of many participants failed because of computational limits. (<strong>b</strong>) <strong>Tweakathon</strong> <strong>(manual</strong> <strong>tweaking).</strong> The last ﬁve datasets were only used for ﬁnal blind testing and the data were never revealed for a Tweakathon. Round 3 was not particularly difﬁcult with additional compute power and memory</p>
<p>were split among the tied teams. Among the winners, two teams used the starting kit. Most of the other teams used either the starting kit or the solution open sourced by the AAD Freiburg team in the 2015/2016 challenge.</p>
<p><em><strong>10.5.3</strong></em> <em><strong>Difﬁculty</strong></em> <em><strong>of</strong></em> <em><strong>Datasets/Tasks</strong></em></p>
<blockquote>
<p>In this section, we assess dataset difﬁculty, or rather <em>task</em> <em>difﬁculty</em> since the par- ticipants had to solve prediction problems for given datasets, performance metrics, and computational time constraints. The tasks of the challenge presented a variety of difﬁculties, but those were not equally represented (Tables <a href="#_bookmark806">10.2</a>and <a href="#_bookmark807">10.3</a>):</p>
<p>• <strong>Categorical</strong> <strong>variables</strong> <strong>and</strong> <strong>missing</strong> <strong>data.</strong> Few datasets had categorical variables in the 2015/2016 challenge (ADULT, ALBERT, and WALDO), and not very many variables were categorical in those datasets. Likewise, very few datasets had missing values (ADULT and ALBERT) and those included only a few missing values. So neither categorical variables nor missing data presented a real difﬁculty in this challenge, though ALBERT turned out to be one of the most difﬁcult datasets because it was also one of the largest ones. This situation changed drastically for the 2018 challenge where ﬁve out of the ten datasets included categorical variables (RL, PM, RI, RH and RM) and missing values</p>
<p>200 I. Guyon et al.</p>
</blockquote>
<p><img src="./automlgithubpagesimages//media/image555.jpeg" width="401" height="275" /></p>
<p><span id="_bookmark815" class="anchor"></span><strong>Fig.</strong> <strong>10.5</strong> <strong>Difﬁculty</strong> <strong>of</strong> <strong>tasks</strong> <strong>in</strong> <strong>the</strong> <strong>2015/2016</strong> <strong>challenge.</strong> We consider two indicators of task difﬁculty (dataset, metric, and time budget are factored into the task): intrinsic difﬁculty (estimated by the performance of the winners) and modeling difﬁculty (difference between the performance of the winner and a baseline method, here Selective Naive Bayes (SNB)). The best tasks should have a relatively low intrinsic difﬁculty and a high modeling difﬁculty to separate participants well</p>
<blockquote>
<p>(GINA, PM, RL, RI and RM). These were among the main aspects that caused the low performance of most methods in the blind test phase.</p>
<p>• <strong>Large</strong> <strong>number</strong> <strong>of</strong> <strong>classes.</strong> Only one dataset had a large number of classes (DIONIS with 355 classes). This dataset turned out to be difﬁcult for participants, particularly because it is also large and has unbalanced classes. However, datasets with large number of classes are not well represented in this challenge. HELENA, which has the second largest number of classes (100 classes), did not stand out as a particularly difﬁcult dataset. However, in general, multi-class problems were found to be more difﬁcult than binary classiﬁcation problems.</p>
<p>• <strong>Regression.</strong> We had only four regression problems: CADATA, FLORA, YOLANDA, PABLO.</p>
<p>• <strong>Sparse</strong> <strong>data.</strong> A signiﬁcant number of datasets had sparse data (DOROTHEA, FABERT, ALEXIS, WALLIS, GRIGORIS, EVITA, FLORA, TANIA, ARTURO, MARCO). Several of them turned out to be difﬁcult, particularly ALEXIS, WALLIS, and GRIGORIS, which are large datasets in sparse format, which cause memory problems when they were introduced in round 3 of the 2015/2016 challenge. We later increased the amount of memory on the servers and similar datasets introduced in later phases caused less difﬁculty.</p>
<p>• <strong>Large</strong> <strong>datasets.</strong> We expected the ratio of the number N of features over the number Ptr of training examples to be a particular difﬁculty (because of the risk</p>
<p>10 Analysis of the AutoML Challenge Series 2015–2018 201</p>
</blockquote>
<p><img src="./automlgithubpagesimages//media/image556.jpeg" width="442" height="174" /></p>
<p><span id="_bookmark816" class="anchor"></span><strong>Fig.</strong> <strong>10.6</strong> <strong>Modeling</strong> <strong>Difﬁculty</strong> <strong>vs.</strong> <strong>intrinsic</strong> <strong>difﬁculty</strong>. For the AutoML phases of the 2015/2016 challenge, we plot an indicator of modeling difﬁculty vs. and indicator of intrinsic difﬁculty of datasets (leaderboard highest score). (<strong>a</strong>) Modeling difﬁculty is estimated by the score of the best untuned model (over KNN, NaiveBayes, RandomForest and SGD (LINEAR)). (<strong>b</strong>) Modeling difﬁculty is estimated by the score of the Selective Naive Bayes (SNB) model. In all cases, higher scores are better and negative/NaN scores are replaced by zero. The horizontal and vertical separation lines represent the medians. The lower right quadrant represents the datasets with low intrinsic difﬁculty and high modeling difﬁculty: those are the best datasets for benchmarking purposes</p>
<p><img src="./automlgithubpagesimages//media/image557.jpeg" width="440" height="248" /></p>
<p><span id="_bookmark817" class="anchor"></span><strong>Fig.</strong> <strong>10.7</strong> <strong>Meta-features</strong> <strong>most</strong> <strong>predictive</strong> <strong>of</strong> <strong>dataset</strong> <strong>intrinsic</strong> <strong>difﬁculty</strong> <strong>(2015/2016</strong> <strong>challenge</strong> <strong>data).</strong> Meta-feature GINI importances are computed by a random forest regressor, trained to predict the highest participant leaderboard score using meta-features of datasets. Description of these meta-features can be found in Table 1 of the supplementary material of <a href="#_bookmark741">[25</a>]. Blue and red colors respectively correspond to positive and negative correlations (Pearson correlations between meta features and score medians)</p>
<p><img src="./automlgithubpagesimages//media/image12.jpeg" width="136" /></p>
<blockquote>
<p>202 I. Guyon et al.</p>
<p>of overﬁtting), but modern machine learning algorithm are robust against over- ﬁtting. The main difﬁculty was rather the PRODUCT N * Ptr . Most participants attempted to load the entire dataset in memory and convert sparse matrices into full matrices. This took very long and then caused loss in performances or pro- gram failures. Large datasets with N *Ptr &gt; 20. 106 include ALBERT, <strong>ALEXIS</strong>, DIONIS, <strong>GRIGORIS,</strong> <strong>WALLIS,</strong> <strong>EVITA,</strong> <strong>FLORA,</strong> <strong>TANIA,</strong> <strong>MARCO</strong>, GINA, GUILLERMO, PM, RH, RI, RICCARDO, RM. Those overlap signiﬁcantly with the datasets with sparse data (in bold). For the 2018 challenge, all data sets in the ﬁnal phase exceeded this threshold, and this was the reason of why the code from several teams failed to ﬁnish within the time budget. Only ALBERT and DIONIS were “truly” large (few features, but over 400,000 training examples).</p>
<p>• <strong>Presence</strong> <strong>of</strong> <strong>probes:</strong> Some datasets had a certain proportion of distractor features or irrelevant variables (probes). Those were obtained by randomly permuting the values of real features. Two-third of the datasets contained probes ADULT, CADATA, DIGITS, DOROTHEA, CHRISTINE, JASMINE, MADELINE, PHILIPPINE, SYLVINE, ALBERT, DILBERT, FABERT, JAN- NIS, EVITA, FLORA, YOLANDA, ARTURO, CARLO, PABLO, WALDO. This allowed us in part to make datasets that were in the public domain less recognizable.</p>
<p>• <strong>Type</strong> <strong>of</strong> <strong>metric:</strong> We used six metrics, as deﬁned in Sect.<a href="#_bookmark733">10.4.2</a>. The distribution of tasks in which they were used was not uniform: BAC (11), AUC (6), F1 (3), and PAC (6) for classiﬁcation, and R2 (2) and ABS (2) for regression. This is because not all metrics lend themselves naturally to all types of applications.</p>
<p>• <strong>Time</strong> <strong>budget:</strong> Although in round 0 we experimented with giving different time budgets for the various datasets, we ended up assigning 1200 s (20 min) to all datasets in all other rounds. Because the datasets varied in size, this put more constraints on large datasets.</p>
<p>• <strong>Class</strong> <strong>imbalance:</strong> This was not a difﬁculty found in the 2015/2016 datasets. However, extreme class imbalance was the main difﬁculty for the 2018 edition. Imbalance ratios lower or equal to 1– 10 were present in RL, PM, RH, RI, and <strong>RM</strong> datasets, in the latter data set class imbalance was as extreme as 1– 1000. This was the reason why the performance of teams was low.</p>
<p>Fig. <a href="#_bookmark814">10.4</a>gives a ﬁrst view of dataset/task difﬁculty for the 2015/2016 challenge. It captures, in a schematic way, the distribution of the participants’ performance in all rounds on test data, in both AutoML and Tweakathon phases. One can see that the median performance over all datasets improves between AutoML and Tweakathon, as can be expected. Correspondingly, the average spread in performance (quartile)</p>
<p>decreases. Let us take a closer look at the AutoML phases: The “accident” of round 3 in which many methods failed in blind testing is visible (introduction of sparse matrices and larger datasets).<a href="#_bookmark818">9</a>Round 2 (multi-class classiﬁcation) appears to have also introduced a signiﬁcantly higher degree of difﬁculty than round 1 (binary</p>
<p><span id="_bookmark818" class="anchor"></span>9Examples of sparse datasets were provided in round 0, but they were of smaller size.</p>
</blockquote>
<p><img src="./automlgithubpagesimages//media/image12.jpeg" width="136" /></p>
<blockquote>
<p>10 Analysis of the AutoML Challenge Series 2015–2018 203</p>
<p>classiﬁcation). In round 4, two regression problems were introduced (FLORA and YOLANDA), but it does not seem that regression was found signiﬁcantly harder than multiclass classiﬁcation. In round 5 no novelty was introduced. We can observe that, after round 3, the dataset median scores are scattered around the overall median. Looking at the corresponding scores in the Tweakathon phases, one can remark that, once the participants recovered from their surprise, round 3 was not particularly difﬁcult for them. Rounds 2 and 4 were comparatively more difﬁcult.</p>
</blockquote>
<p>For the datasets used in the 2018 challenge, the tasks’ difﬁculty was clearly associated with extreme class imbalance, inclusion of categorical variables and high dimensionality in terms of N × Ptr . However, for the 2015/2016 challenge data sets we found that it was generally difﬁcult to guess what makes a task easy or hard, except for dataset size, which pushed participants to the frontier of the hardware capabilities and forced them to improve the computational efﬁciency of their methods. Binary classiﬁcation problems (and multi-label problems) are intrinsically “easier” than multiclass problems, for which “guessing” has a lower probability of success. This partially explains the higher median performance in rounds 1 and 3, which are dominated by binary and multi-label classiﬁcation problems. There is not a large enough number of datasets illustrating each type of other difﬁculties to draw other conclusions.</p>
<blockquote>
<p>We ventured however to try to ﬁnd summary statistics capturing overall takes difﬁculty. If one assumes that data are generated from an <em>i.i.d.</em><a href="#_bookmark819">10</a>process of the type:</p>
<p>y = F(<strong>x</strong>,noise)</p>
<p>where y is the target value, <strong>x</strong> is the input feature vector, F is a function, and noise is some random noise drawn from an unknown distribution, then the difﬁculty of the learning problem can be separated in two aspects:</p>
<p>1. <strong>Intrinsic</strong> <strong>difﬁculty</strong>, linked to the amount of noise or the signal to noise ratio. Given an inﬁnite amount of data and an unbiased learning machine <img src="./automlgithubpagesimages//media/image558.png" height="12" /> capable of identifying F , the prediction performances cannot exceed a given maximum value, corresponding to <img src="./automlgithubpagesimages//media/image559.png" height="12" /> = F .</p>
<p>2. <strong>Modeling</strong> <strong>difﬁculty</strong>, linked to the bias and variance of estimators <img src="./automlgithubpagesimages//media/image560.png" height="12" />, in connection with the limited amount of training data and limited computational resources, and the possibly large number or parameters and hyper-parameters to estimate.</p>
<p>Evaluating the intrinsic difﬁculty is impossible unless we know F . Our best approximation of F is the winners’ solution. <strong>We</strong> <strong>use</strong> <strong>therefore</strong> <strong>the</strong> <strong>winners’</strong> <strong>performance</strong> <strong>as</strong> <strong>an</strong> <strong>estimator</strong> <strong>of</strong> <strong>the</strong> <strong>best</strong> <strong>achievable</strong> <strong>performance.</strong> This estimator may have both bias and variance: it is possibly biased because the winners may be under-ﬁtting training data; it may have variance because of the limited amount of</p>
<p><span id="_bookmark819" class="anchor"></span>10Independently and Identically Distributed samples.</p>
<p>204 I. Guyon et al.</p>
<p>test data. Under-ﬁtting is difﬁcult to test. Its symptoms may be that the variance or the entropy of the predictions is less than those of the target values.</p>
</blockquote>
<p>Evaluating the modeling difﬁculty is also impossible unless we know F and the model class. In the absence of knowledge on the model class, data scientists often use generic predictive models, agnostic with respect to the data generating process. Such models range from very basic models that are highly biased towards “simplicity” and smoothness of predictions (e.g., regularized linear models) to highly versatile unbiased models that can learn any function given enough data (e.g., ensembles of decision trees). To indirectly assess modeling difﬁculty, we resorted to use the difference in performance between <em>the</em> <em>method</em> <em>of</em> <em>the</em> <em>challenge</em> <em>winner</em> and that of (a) the best of four “untuned” basic models (taken from classical techniques provided in the scikit-learn library [<a href="#_bookmark739">55</a>] with default hyper-parameters) or (b) Selective Naive Bayes (SNB) [<a href="#_bookmark820">12</a>, <a href="#_bookmark821">13</a>], a highly regularized model (biased towards simplicity), providing a very robust and simple baseline.</p>
<blockquote>
<p>Figs. <a href="#_bookmark815">10.5</a> and <a href="#_bookmark816">10.6</a> give representations of our estimates of intrinsic and modeling difﬁculties for the 2015/2016 challenge datasets. It can be seen that the datasets of round 0 were among the easiest (except perhaps NEWSGROUP). Those were relatively small (and well-known) datasets. Surprisingly, the datasets of round 3 were also rather easy, despite the fact that most participants failed on them when they were introduced (largely because of memory limitations: scikit- learn algorithms were not optimized for sparse datasets and it was not possible to ﬁt in memory the data matrix converted to a dense matrix). Two datasets have a small intrinsic difﬁculty but a large modeling difﬁculty: MADELINE and DILBERT. MADELINE is an artiﬁcial dataset that is very non-linear (clusters or 2 classes positioned on the vertices of a hyper-cube in a 5 dimensional space) and therefore very difﬁcult for Naïve Bayes. DILBERT is an image recognition dataset with images of objects rotated in all sorts of positions, also very difﬁcult for Naïve Bayes. The datasets of the last 2 phases seem to have a large intrinsic difﬁculty compared to the modeling difﬁculty. But this can be deceiving because the datasets are new to the machine learning community and the performances of the winners may still be far from the best attainable performance.</p>
<p>We attempted to predict the intrinsic difﬁculty (as measured by the winners’ performance) from the set of meta features used by AAD Freiburg for meta- learning [<a href="#_bookmark741">25</a>], which are part of OpenML [<a href="#_bookmark822">67</a>], using a Random Forest classiﬁer and ranked the meta features in order of importance (most selected by RF). The list of meta features is provided in the online appendix. The three meta-features that predict dataset difﬁculty best (Fig.<a href="#_bookmark817">10.7</a>) are:</p>
<p>• LandmarkDecisionTree: performance of a decision tree classiﬁer.</p>
<p>• Landmark1NN: performance of a nearest neighbor classiﬁer.</p>
<p>• SkewnessMin: min over skewness of all features. Skewness measures the symmetry of a distribution. A positive skewness value means that there is more weight in the left tail of the distribution.</p>
</blockquote>
<p><img src="./automlgithubpagesimages//media/image12.jpeg" width="136" /></p>
<blockquote>
<p>10 Analysis of the AutoML Challenge Series 2015–2018 205</p>
<p><em><strong>10.5.4</strong></em> <em><strong>Hyper-parameter</strong></em> <em><strong>Optimization</strong></em></p>
</blockquote>
<p>Many participants used the scikit-learn (sklearn) package, including the winning group AAD Freiburg, which produced the auto-sklearn software. We used the auto-sklearn API to conduct post-challenge systematic studies of the effectiveness of hyper-parameter optimization. We compared the performances obtained with default hyper-parameter settings in scikit-learn and with hyper-parameters opti- mized with auto-sklearn,<a href="#_bookmark823">11</a> both within the time budgets as imposed during the challenge, for four “representative” basic methods: k-nearest neighbors (KNN), naive Bayes (NB), Random Forest (RF), and a linear model trained with stochastic gradient descent (SGD-linear<a href="#_bookmark824">12</a>). The results are shown in Fig.<a href="#_bookmark825">10.8</a>. We see that hyper-parameter optimization usually improves performance, but not always. The advantage of hyper-parameter tuning comes mostly from its ﬂexibility of switching the optimization metric to the one imposed by the task and from ﬁnding hyper- parameters that work well given the current dataset and metric. However, in some cases it was not possible to perform hyper-parameter optimization within the time budget due to the data set size (score ≤ 0). Thus, there remains future work on how</p>
<p><img src="./automlgithubpagesimages//media/image561.jpeg" width="401" height="272" /></p>
<blockquote>
<p><span id="_bookmark825" class="anchor"></span><strong>Fig.</strong> <strong>10.8</strong> <strong>Hyper-parameter</strong> <strong>tuning</strong> <strong>(2015/2016</strong> <strong>challenge</strong> <strong>data).</strong> We compare the performances obtained with default hyper-parameters and those with hyper-parameters optimized with auto- sklearn, within the same time budgets as given during the challenge. The performances of predictors which failed to return results in the allotted time are replaced by zero. Note that returning a prediction of chance level also resulted in a score of zero</p>
<p><span id="_bookmark823" class="anchor"><span id="_bookmark824" class="anchor"></span></span>11We use sklearn 0. 16. 1 and auto-sklearn 0.4.0 to mimic the challenge environment.</p>
<p>12We set the loss of SGD to be ‘log’ in scikit-learn for these experiments.</p>
<p>206 I. Guyon et al.</p>
<p>to perform thorough hyper-parameter tuning given rigid time constraints and huge datasets (Fig.<a href="#_bookmark825">10.8</a>).</p>
<p>We also compared the performances obtained with different scoring metrics (Fig.<a href="#_bookmark826">10.9</a>). Basic methods do not give a choice of metrics to be optimized, but auto- sklearn post-ﬁtted the metrics of the challenge tasks. Consequently, when “common metrics” (BAC and R2) are used, the method of the challenge winners, which is not optimized for BAC/R2, does not usually outperform basic methods. Conversely, when the metrics of the challenge are used, there is often a clear gap between the basic methods and the winners, but not always (RF-auto usually shows a comparable performance, sometimes even outperforms the winners).</p>
<p><em><strong>10.5.5</strong></em> <em><strong>Meta-learning</strong></em></p>
</blockquote>
<p>One question is whether meta-learning [<a href="#_bookmark827">14</a>] is possible, that is learning to predict whether a given classiﬁer will perform well on future datasets (without actually training it), based on its past performances on other datasets. We investigated whether it is possible to predict which basic method will perform best based on the meta-learning features of auto-sklearn (see the online appendix). We removed the “Landmark” features from the set of meta features because those are performances of basic predictors (albeit rather poor ones with many missing values), which would lead to a form of “data leakage” .</p>
<blockquote>
<p>We used four basic predictors:</p>
</blockquote>
<p><img src="./automlgithubpagesimages//media/image562.jpeg" width="442" height="160" /></p>
<blockquote>
<p><strong>Fig.</strong> <strong>10.9</strong> <strong>Comparison</strong> <strong>of</strong> <strong>metrics</strong> <strong>(2015/2016</strong> <strong>challenge).</strong> (<strong>a</strong>) We used the metrics of the <span id="_bookmark826" class="anchor"></span>challenge. (<strong>b</strong>) We used the normalized balanced accuracy for all classiﬁcation problems and the R2 metric for regression problems. By comparing the two ﬁgures, we can see that the winner remains top-ranking in most cases, regardless of the metric. There is no basic method that dominates all others. Although RF-auto (Random Forest with optimized HP) is very strong, it is sometimes outperformed by other methods. Plain linear model SGD-def sometimes wins when common metrics are used, but the winners perform better with the metrics of the challenge. Overall, the technique of the winners proved to be effective</p>
<p>10 Analysis of the AutoML Challenge Series 2015–2018 207</p>
</blockquote>
<p><img src="./automlgithubpagesimages//media/image563.jpeg" width="339" height="597" /></p>
<p><span id="_bookmark828" class="anchor"></span><strong>Fig.</strong> <strong>10.10</strong> <strong>Linear</strong> <strong>discriminant</strong> <strong>analysis.</strong> (<strong>a</strong>) <strong>Dataset</strong> <strong>scatter</strong> <strong>plot</strong> <strong>in</strong> <strong>principal</strong> <strong>axes</strong>. We have trained a LDA using X = meta features, except landmarks; y = which model won of four basic models (NB, SGD-linear, KNN, RF). The performance of the basic models is measured using the common metrics. The models were trained with default hyper-parameters. In the space of the two ﬁrst LDA components, each point represents one dataset. The colors denote the winning basic models. The opacity reﬂects the scores of the corresponding winning model (more opaque is better). (<strong>b</strong>) <strong>Meta</strong> <strong>feature</strong> <strong>importances</strong> computed as scaling factors of each LDA component</p>
<blockquote>
<p>208 I. Guyon et al.</p>
<p>• NB: Naive Bayes</p>
<p>• SGD-linear: Linear model (trained with stochastic gradient descent)</p>
<p>• KNN: K-nearest neighbors</p>
<p>• RF: Random Forest</p>
<p>We used the implementation of the scikit-learn library with default hyper-parameter settings. In Fig.<a href="#_bookmark828">10.10</a>, we show the two ﬁrst Linear Discriminant Analysis (LDA) components, when training an LDA classiﬁer on the meta-features to predict which basic classiﬁer will perform best. The methods separate into three distinct clusters, one of them grouping the non-linear methods that are poorly separated (KNN and RF) and the two others being NB and linear-SGD.</p>
<p>The features that are most predictive all have to do with “ClassProbability” and “PercentageOfMissingValues”, indicating that the class imbalance and/or large number of classes (in a multi-class problem) and the percentage of missing values might be important, but there is a high chance of overﬁtting as indicated by an unstable ranking of the best features under resampling of the training data.</p>
<p><em><strong>10.5.6</strong></em> <em><strong>Methods</strong></em> <em><strong>Used</strong></em> <em><strong>in</strong></em> <em><strong>the</strong></em> <em><strong>Challenges</strong></em></p>
</blockquote>
<p>A brief <strong>description</strong> <strong>of</strong> <strong>methods</strong> used in both challenges is provided in the online appendix, together with the results of a survey on methods that we conducted after the challenges. In light of the overview of Sect.<a href="#_bookmark751">10.2</a> and the results presented in the previous section, we may wonder whether a dominant methodology for solving the AutoML problem has emerged and whether particular technical solutions were widely adopted. In this section we call “model space” the set of all models under consideration. We call “basic models” (also called elsewhere “simple models”, “individual models”, “base learners”) the member of a library of models from which our hyper-models of model ensembles are built.</p>
<blockquote>
<p><strong>Ensembling:</strong> <strong>dealing</strong> <strong>with</strong> <strong>over-ﬁtting</strong> <strong>and</strong> <strong>any-time</strong> <strong>learning</strong> Ensembling is the big AutoML challenge series winner since it is used by over 80% of the participants and by all the top-ranking ones. While a few years ago the hottest issue in model selection and hyper-parameter optimization was over-ﬁtting, in present days the problem seems to have been largely avoided by using ensembling techniques. In the 2015/2016 challenge, we varied the ratio of number of training examples over number of variables (Ptr/N) by several orders of magnitude. Five datasets had a ratio Ptr/N lower than one (dorothea, newsgroup, grigoris, wallis, and ﬂora), which is a case lending itself particularly to over-ﬁtting. Although Ptr/N is the most predictive variable of the median performance of the participants, there is no indication that the datasets with Ptr/N &lt; 1 were particularly difﬁcult for the partic- ipants (Fig.<a href="#_bookmark815">10.5</a>). Ensembles of predictors have the additional beneﬁt of addressing in a simple way the “any-time learning” problem by growing progressively a bigger ensemble of predictors, improving performance over time. All trained predictors are usually incorporated in the ensemble. For instance, if cross-validation is used, the</p>
<p>10 Analysis of the AutoML Challenge Series 2015–2018 209</p>
</blockquote>
<p>predictors of all folds are directly incorporated in the ensemble, which saves the computational time of retraining a single model on the best HP selected and may yield more robust solutions (though slightly more biased due to the smaller sample size). The approaches differ in the way they weigh the contributions of the various predictors. Some methods use the same weight for all predictors (this is the case of bagging methods such as Random Forest and of Bayesian methods that sample predictors according to their posterior probability in model space). Some methods assess the weights of the predictors as part of learning (this is the case of boosting methods, for instance). One simple and effective method to create ensembles of heterogeneous models was proposed by [<a href="#_bookmark764">16</a>]. It was used successfully in several past challenges, e.g., [<a href="#_bookmark829">52</a>] and is the method implemented by the aad_freibug team, one of the strongest participants in both challenges [<a href="#_bookmark741">25</a>]. The method consists in cycling several times over all trained model and incorporating in the ensemble at each cycle the model which most improves the performance of the ensemble. Models vote with weight 1, but they can be incorporated multiple times, which de facto results in weighting them. This method permits to recompute very fast the weights of the models if cross-validated predictions are saved. Moreover, the method allows optimizing the ensemble for any metric by post-ﬁtting the predictions of the ensemble to the desired metric (an aspect which was important in this challenge).</p>
<p><strong>Model</strong> <strong>evaluation:</strong> <strong>cross-validation</strong> <strong>or</strong> <strong>simple</strong> <strong>validation</strong> Evaluating the pre- dictive accuracy of models is a critical and necessary building block of any model selection of ensembling method. Model selection criteria computed from the predictive accuracy of basic models evaluated from training data, by training a single time on all the training data (possibly at the expense of minor additional calculations), such as performance bounds, were not used at all, as was already the case in previous challenges we organized [<a href="#_bookmark830">35</a>]. Cross-validation was widely used, particularly K-fold cross-validation. However, basic models were often “cheaply” evaluated on just one fold to allow quickly discarding non-promising areas of model space. This is a technique used more and more frequently to help speed up search. Another speed-up strategy is to train on a subset of the training examples and monitor the learning curve. The “freeze-thaw” strategy [<a href="#_bookmark794">64</a>] halts training of models that do not look promising on the basis of the learning curve, but may restart training them at a later point. This was used, e.g., by [<a href="#_bookmark831">48</a>] in the 2015/2016 challenge.</p>
<p><strong>Model</strong> <strong>space:</strong> <strong>Homogeneous</strong> <strong>vs.</strong> <strong>heterogeneous</strong> An unsettled question is whether one should search a large or small model space. The challenge did not allow us to give a deﬁnite answer to this question. Most participants opted for searching a relatively large model space, including a wide variety of models found in the scikit- learn library. Yet, one of the strongest entrants (the Intel team) submitted results simply obtained with a boosted decision tree (i.e., consisting of a homogeneous set of weak learners/basic models). Clearly, it sufﬁces to use just one machine learning approach that is a universal approximator to be able to learn anything, given enough training data. So why include several? It is a question of rate of convergence: how fast we climb the learning curve. Including stronger basic models is one way to climb the learning curve faster. Our post-challenge experiments (Fig.<a href="#_bookmark826">10.9</a>) reveal</p>
<blockquote>
<p>210 I. Guyon et al.</p>
<p>that the scikit-learn version of Random Forest (an ensemble of homogeneous basic models—decision trees) does not usually perform as well as the winners’ version, hinting that there is a lot of know-how in the Intel solution, which is also based on ensembles of decision tree, that is not captured by a basic ensemble of decision trees such as RF. We hope that more principled research will be conducted on this topic in the future.</p>
</blockquote>
<p><strong>Search</strong> <strong>strategies:</strong> <strong>Filter,</strong> <strong>wrapper,</strong> <strong>and</strong> <strong>embedded</strong> <strong>methods</strong> With the availability of powerful machine learning toolkits like scikit-learn (on which the starting kit was based), the temptation is great to implement <strong>all-wrapper</strong> <strong>methods</strong> to solve the CASH (or “full model selection”) problem. Indeed, most participants went that route. Although a number of ways of optimizing hyper-parameters with <strong>embedded</strong> <strong>methods</strong> for several basic classiﬁers have been published [<a href="#_bookmark830">35</a>], they each require changing the implementation of the basic methods, which is time-consuming and error-prone compared to using already debugged and well-optimized library version of the methods. Hence practitioners are reluctant to invest development time in the implementation of embedded methods. A notable exception is the software of marc .boulle, which offers a self-contained hyper-parameter free solution based on Naive Bayes, which includes re-coding of variables (grouping or discretization) and variable selection. See the online appendix.</p>
<p><strong>Multi-level</strong> <strong>optimization</strong> Another interesting issue is whether multiple levels of hyper-parameters should be considered for reasons of computational effectiveness or overﬁtting avoidance. In the Bayesian setting, for instance, it is quite feasible to consider a hierarchy of parameters/hyper-parameters and several levels of priors/hyper-priors. However, it seems that for practical computational reasons, in the AutoML challenges, the participants use a shallow organization of hyper- parameter space and avoid nested cross-validation loops.</p>
<p><strong>Time</strong> <strong>management:</strong> <strong>Exploration</strong> <strong>vs.</strong> <strong>exploitation</strong> <strong>tradeoff</strong> With a tight time budget, efﬁcient search strategies must be put into place to monitor the explo- ration/exploitation tradeoff. To compare strategies, we show in the online appendix learning curves for two top ranking participants who adopted very different methods: <em>Abhishek</em> and <em>aad_freiburg</em>. The former uses heuristic methods based on prior human experience while the latter initializes search with models predicted to be best suited by meta-learning, then performs Bayesian optimization of hyper- parameters. <em>Abhishek</em> seems to often start with a better solution but explores less effectively. In contrast, <em>aad_freiburg</em> starts lower but often ends up with a better solution. Some elements of randomness in the search are useful to arrive at better solutions.</p>
<p><strong>Preprocessing</strong> <strong>and</strong> <strong>feature</strong> <strong>selection</strong> The datasets had intrinsic difﬁculties that could be in part addressed by preprocessing or special modiﬁcations of algorithms: sparsity, missing values, categorical variables, and irrelevant variables. Yet it appears that among the top-ranking participants, preprocessing has not been a focus of attention. They relied on the simple heuristics provided in the starting kit: replacing missing values by the median and adding a missingness indicator variable,</p>
<blockquote>
<p>10 Analysis of the AutoML Challenge Series 2015–2018 211</p>
<p>one-hot-encoding of categorical variables. Simple normalizations were used. The irrelevant variables were ignored by 2/3 of the participants and no use of feature selection was made by top-ranking participants. The methods used that involve ensembling seem to be intrinsically robust against irrelevant variables. More details from the fact sheets are found in the online appendix.</p>
<p><strong>Unsupervised</strong> <strong>learning</strong> Despite the recent regain of interest in unsupervised learning spurred by the Deep Learning community, in the AutoML challenge series, unsupervised learning is not widely used, except for the use of classical space dimensionality reduction techniques such as ICA and PCA. See the online appendix for more details.</p>
<p><strong>Transfer</strong> <strong>learning</strong> <strong>and</strong> <strong>meta</strong> <strong>learning</strong> To our knowledge, only <em>aad_freiburg</em> relied on meta-learning to initialize their hyper-parameter search. To that end, they used datasets of OpenML.<a href="#_bookmark832">13</a> The number of datasets released and the diversity of tasks did not allow the participants to perform effective transfer learning or meta learning.</p>
<p><strong>Deep</strong> <strong>learning</strong> The type of computations resources available in AutoML phases ruled out the use of Deep Learning, except in the GPU track. However, even in that track, the Deep Learning methods did not come out ahead. One exception is <em>aad_freiburg</em>, who used Deep Learning in Tweakathon rounds three and four and found it to be helpful for the datasets Alexis, Tania and Yolanda.</p>
<p><strong>Task</strong> <strong>and</strong> <strong>metric</strong> <strong>optimization</strong> There were four types of tasks (regression, binary classiﬁcation, multi-class classiﬁcation, and multi-label classiﬁcation) and six scoring metrics (R2, ABS, BAC, AUC, F1, and PAC). Moreover, class balance and number of classes varied a lot for classiﬁcation problems. Moderate effort has been put into designing methods optimizing speciﬁc metrics. Rather, generic methods were used and the outputs post-ﬁtted to the target metrics by cross-validation or through the ensembling method.</p>
<p><strong>Engineering</strong> One of the big lessons of the AutoML challenge series is that most methods fail to return results in all cases, not a “good” result, but “any” reasonable result. Reasons for failure include “out of time” and “out of memory” or various other failures (e.g., numerical instabilities). We are still very far from having “basic models” that run on all datasets. One of the strengths of auto-sklearn is to ignore those models that fail and generally ﬁnd at least one that returns a result.</p>
<p><strong>Parallelism</strong> The computers made available had several cores, so in principle, the participants could make use of parallelism. One common strategy was just to rely on numerical libraries that internally use such parallelism automatically. The <em>aad_freiburg</em> team used the different cores to launch in parallel model search for different datasets (since each round included ﬁve datasets). These different uses of <span id="_bookmark832" class="anchor"></span>computational resources are visible in the learning curves (see the online appendix).</p>
<p>212 I. Guyon et al.</p>
<p><strong>10.6</strong> <strong>Discussion</strong></p>
</blockquote>
<p>We brieﬂy summarize the main questions we asked ourselves and the main ﬁndings:</p>
<blockquote>
<p>1. <strong>Was</strong> <strong>the</strong> <strong>provided</strong> <strong>time</strong> <strong>budget</strong> <strong>sufﬁcient</strong> <strong>to</strong> <strong>complete</strong> <strong>the</strong> <strong>tasks</strong> <strong>of</strong> <strong>the</strong> <strong>challenge?</strong> We drew learning curves as a function of time for the winning solution of aad_freiburg (auto-sklearn, see the online appendix). This revealed that for most datasets, performances still improved well beyond the time limit imposed by the organizers. Although for about half the datasets the improvement is modest (no more that 20% of the score obtained at the end of the imposed time limit), for some datasets the improvement was very large (more than 2× the original score). The improvements are usually gradual, but sudden performance improvements occur. For instance, for Wallis, the score doubled suddenly at 3 × the time limit imposed in the challenge. As also noted by the authors of the auto- sklearn package [<a href="#_bookmark741">25</a>], it has a slow start but in the long run gets performances close to the best method.</p>
<p>2. <strong>Are</strong> <strong>there</strong> <strong>tasks</strong> <strong>that</strong> <strong>were</strong> <strong>signiﬁcantly</strong> <strong>more</strong> <strong>difﬁcult</strong> <strong>than</strong> <strong>others</strong> <strong>for</strong> <strong>the</strong> <strong>participants?</strong> Yes, there was a very wide range of difﬁculties for the tasks as revealed by the dispersion of the participants in terms of average (median) and variability (third quartile) of their scores. Madeline, a synthetic dataset featuring a very non-linear task, was very difﬁcult for many participants. Other difﬁculties that caused failures to return a solution included large memory requirements (particularly for methods that attempted to convert sparse matrices to full matrices), and short time budgets for datasets with large number of training examples and/or features or with many classes or labels.</p>
<p>3. <strong>Are</strong> <strong>there</strong> <strong>meta-features</strong> <strong>of</strong> <strong>datasets</strong> <strong>and</strong> <strong>methods</strong> <strong>providing</strong> <strong>useful</strong> <strong>insight</strong> <strong>to</strong> <strong>recommend</strong> <strong>certain</strong> <strong>methods</strong> <strong>for</strong> <strong>certain</strong> <strong>types</strong> <strong>of</strong> <strong>datasets?</strong> The <em>aad_freiburg</em> team used a subset of 53 meta-features (a superset of the simple statistics provided with the challenge datasets) to measure similarity between datasets. This allowed them to conduct hyper-parameter search more effectively by initializing the search with settings identical to those selected for similar datasets previously processed (a form of meta-learning). Our own analysis revealed that it is very difﬁcult to predict the predictors’ performances from the meta- features, but it is possible to predict relatively accurately which “basic method” will perform best. With LDA, we could visualize how datasets recoup in two dimensions and show a clean separation between datasets “preferring” Naive Bayes, linear SGD, or KNN, or RF. This deserves further investigation.</p>
<p>4. <strong>Does</strong> <strong>hyper-parameter</strong> <strong>optimization</strong> <strong>really</strong> <strong>improve</strong> <strong>performance</strong> <strong>over</strong> <strong>using</strong> <strong>default</strong> <strong>values?</strong> The comparison we conducted reveals that optimizing hyper- parameters rather than choosing default values for a set of four basic predictive models (K-nearest neighbors, Random Forests, linear SGD, and Naive Bayes) is generally beneﬁcial. In the majority of cases (but not always), hyper-parameter optimization (hyper-opt) results in better performances than default values.</p>
<p>10 Analysis of the AutoML Challenge Series 2015–2018 213</p>
<p>Hyper-opt sometimes fails because of time or memory limitations, which gives room for improvement.</p>
<p>5. <strong>How</strong> <strong>do</strong> <strong>winner’s</strong> <strong>solutions</strong> <strong>compare</strong> <strong>with</strong> <strong>basic</strong> <strong>scikit-learn</strong> <strong>models?</strong> They compare favorably. For example, the results of basic models whose parameters have been optimized do not yield generally as good results as running auto- sklearn. However, a basic model with default HP sometimes outperforms this same model tuned by auto-sklearn.</p>
<p><strong>10.7</strong> <strong>Conclusion</strong></p>
<p>We have analyzed the results of several rounds of AutoML challenges.</p>
<p>Our design of the ﬁrst AutoML challenge (2015/2016) was satisfactory in many respects. In particular, we attracted a large number of participants (over 600), attained results that are statistically signiﬁcant, and advanced the state of the art to automate machine learning. Publicly available libraries have emerged as a result of this endeavor, including auto-sklearn.</p>
</blockquote>
<p>In particular, we designed a benchmark with a large number of diverse datasets, with large enough test sets to separate top-ranking participants. It is difﬁcult to anticipate the size of the test sets needed, because the error bars depend on the performances attained by the participants, so we are pleased that we made reasonable guesses. Our simple rule-of-thumb “N = 50/E” where N is the number of test samples and E the error rate of the smallest class seems to be widely applicable. We made sure that the datasets were neither too easy nor too hard. This is important to be able to separate participants. To quantify this, we introduced the notion of “intrinsic difﬁculty” and “modeling difﬁculty” . Intrinsic difﬁculty can be quantiﬁed by the performance of the best method (as a surrogate for the best attainable performance, i.e., the Bayes rate for classiﬁcation problems). Modeling difﬁculty can be quantiﬁed by the spread in performance between methods. Our best problems have relatively low “intrinsic difﬁculty” and high “modeling difﬁculty” . However, the diversity of the 30 datasets of our ﬁrst 2015/2016 challenge is both a feature and a curse: it allows us to test the robustness of software across a variety of situations, but it makes meta-learning very difﬁcult, if not impossible. Consequently, external meta-learning data must be used if meta-learning is to be explored. This was the strategy adopted by the AAD Freiburg team, which used the OpenML data for meta training. Likewise, we attached different metrics to each dataset. This contributed to making the tasks more realistic and more difﬁcult, but also made meta-learning harder. In the second 2018 challenge, we diminished the variety of datasets and used a single metric.</p>
<blockquote>
<p>With respect to task design, we learned that the devil is in the details. The challenge participants solve exactly the task proposed to the point that their solution may not be adaptable to seemingly similar scenarios. In the case of the AutoML challenge, we pondered whether the metric of the challenge should be the area under the learning curve or one point on the learning curve (the performance obtained after</p>
<p>214 I. Guyon et al.</p>
</blockquote>
<p>a ﬁxed maximum computational time elapsed). We ended up favoring the second solution for practical reasons. Examining after the challenge the learning curves of some participants, it is quite clear that the two problems are radically different, particularly with respect to strategies mitigating “exploration” and “exploitation” . This prompted us to think about the differences between “ﬁxed time” learning (the participants know in advance the time limit and are judged only on the solution delivered at the end of that time) and “any time learning” (the participants can be stopped at any time and asked to return a solution). Both scenarios are useful: the ﬁrst one is practical when models must be delivered continuously at a rapid pace, e.g. for marketing applications; the second one is practical in environments when computational resources are unreliable and interruption may be expected (e.g. people working remotely via an unreliable connection). This will inﬂuence the design of future challenges.</p>
<p>The two versions of AutoML challenge we have run differ in the difﬁculty of transfer learning. In the 2015/2016 challenge, round 0 introduced a sample of all types of data and difﬁculties (types of targets, sparse data or not, missing data or not, categorical variables of not, more examples than features or not). Then each round ramped up difﬁculty. The datasets of round 0 were relatively easy. Then at each round, the code of the participants was blind-tested on data that were one notch harder than in the previous round. Hence transfer was quite hard. In the 2018 challenge, we had 2 phases, each with 5 datasets of similar difﬁculty and the datasets of the ﬁrst phase were each matched with one corresponding dataset on a similar task. As a result, transfer was made simpler.</p>
<p>Concerning the starting kit and baseline methods, we provided code that ended up being the basis of the solution of the majority of participants (with notable exceptions from industry such as Intel and Orange who used their own “in house” packages). Thus, we can question whether the software provided biased the approaches taken. Indeed, all participants used some form of ensemble learning, similarly to the strategy used in the starting kit. However, it can be argued that this is a “natural” strategy for this problem. But, in general, the question of providing enough starting material to the participants without biasing the challenge in a particular direction remains a delicate issue.</p>
<p>From the point of view of challenge protocol design, we learned that it is difﬁcult to keep teams focused for an extended period of time and go through many challenge phases. We attained a large number of participants (over 600) over the whole course of the AutoML challenge, which lasted over a year (2015/2016) and was punctuated by several events (such as hackathons). However, it may be preferable to organize yearly events punctuated by workshops. This is a natural way of balancing competition and cooperation since workshops are a place of exchange. Participants are naturally rewarded by the recognition they gain via the system of scientiﬁc publications. As a conﬁrmation of this conjecture, the second instance of the AutoML challenge (2017/2018) lasting only 4 months attracted nearly 300 participants.</p>
<blockquote>
<p>One important novelty of our challenge design was code submission. Having the code of the participants executed on the same platform under rigorously similar conditions is a great step towards fairness and reproducibility, as well as ensuring the</p>
<p>10 Analysis of the AutoML Challenge Series 2015–2018 215</p>
</blockquote>
<p>viability of solution from the computational point of view. We required the winners to release their code under an open source licence to win their prizes. This was good enough an incentive to obtain several software publications as the “product” of the challenges we organized. In our second challenge (AutoML 2018), we used Docker. Distributing Docker images makes it possible for anyone downloading the code of the participants to easily reproduce the results without stumbling over installation problems due to inconsistencies in computer environments and libraries. Still the hardware may be different and we ﬁnd that, in post-challenge evaluations, changing computers may yield signiﬁcant differences in results. Hopefully, with the proliferation of affordable cloud computing, this will become less of an issue.</p>
<blockquote>
<p>The AutoML challenge series is only beginning. Several new avenues are under study. For instance, we are preparing the NIPS 2018 Life Long Machine Learning challenge in which participants will be exposed to data whose distribution slowly drifts over time. We are also looking at a challenge of automated machine learning where we will focus on transfer from similar domains.</p>
</blockquote>
<p><strong>Acknowledgements</strong> Microsoft supported the organization of this challenge and donated the prizes and cloud computing time on Azure. This project received additional support from the Laboratoire d’Informatique Fondamentale (LIF, UMR CNRS 7279) of the University of Aix Marseille, France, via the LabeX Archimede program, the Laboratoire de Recheche en Informa- tique of Paris Sud University, and INRIA-Saclay as part of the TIMCO project, as well as the support from the Paris-Saclay Center for Data Science (CDS). Additional computer resources were provided generously by J. Buhmann, ETH Zürich. This work has been partially supported by the Spanish project TIN2016-74946-P (MINECO/FEDER, UE) and CERCA Programme/Generalitat de Catalunya. The datasets released were selected among 72 datasets that were donated (or formatted using data publicly available) by the co-authors and by: Y. Aphinyanaphongs, O. Chapelle, Z. Iftikhar Malhi, V. Lemaire, C.-J. Lin, M. Madani, G. Stolovitzky, H.-J. Thiesen, and I. Tsamardinos. Many people provided feedback to early designs of the protocol and/or tested the challenge platform, including: K. Bennett, C. Capponi, G. Cawley, R. Caruana, G. Dror, T. K. Ho, B. Kégl, H. Larochelle, V. Lemaire, C.-J. Lin, V. Ponce López, N. Macia, S. Mercer, F. Popescu, D. Silver, S. Treguer, and I. Tsamardinos. The software developers who contributed to the implementation of the Codalab platform and the sample code include E. Camichael, I. Chaabane, I. Judson, C. Poulain, P. Liang, A. Pesah, L. Romaszko, X. Baro Solé, E. Watson, F. Zhingri, M. Zyskowski. Some initial analyses of the challenge results were performed by I. Chaabane, J. Lloyd, N. Macia, and A. Thakur were incorporated in this paper. Katharina Eggensperger, Syed Mohsin Ali and Matthias Feurer helped with the organization of the Beat AutoSKLearn challenge. Matthias Feurer also contributed to the simulations of running auto-sklearn on 2015– 2016 challenge datasets.</p>
<blockquote>
<p><span id="_bookmark736" class="anchor"></span><strong>Bibliography</strong></p>
<p>1. Alamdari, A.R.S.A., Guyon, I.: Quick start guide for CLOP. Tech. rep., Graz University of <span id="_bookmark786" class="anchor"></span>Technology and Clopinet (May 2006)</p>
<p>2. Andrieu, C., Freitas, N.D., Doucet, A.: Sequential MCMC for Bayesian model selection. In: IEEE Signal Processing Workshop on Higher-Order Statistics. pp. 130– 134 (1999)</p>
<p><span id="_bookmark797" class="anchor"></span>3. Assunção, F., Lourenço, N., Machado, P., Ribeiro, B.: Denser: Deep evolutionary network structured representation. arXiv preprint arXiv:1801.01563 (2018)</p>
</blockquote>
<p>216 I. Guyon et al.</p>
<blockquote>
<p><span id="_bookmark795" class="anchor"></span>4. Baker, B., Gupta, O., Naik, N., Raskar, R.: Designing neural network architectures using <span id="_bookmark804" class="anchor"></span>reinforcement learning. arXiv preprint arXiv:1611.02167 (2016)</p>
<p>5. Bardenet, R., Brendel, M., Kégl, B., Sebag, M.: Collaborative hyperparameter tuning. In: 30th International Conference on Machine Learning. vol. 28, pp. 199–207. JMLR Workshop and <span id="_bookmark769" class="anchor"></span>Conference Proceedings (May 2013)</p>
<p>6. Bengio, Y., Courville, A., Vincent, P.: Representation learning: A review and new perspectives. IEEE Transactions on Pattern Analysis and Machine Intelligence 35(8), 1798– 1828 (2013)</p>
<p><span id="_bookmark759" class="anchor"></span>7. Bennett, K.P., Kunapuli, G., Jing Hu, J.S.P.: Bilevel optimization and machine learning. In: Computational Intelligence: Research Frontiers, Lecture Notes in Computer Science, vol. <span id="_bookmark775" class="anchor"></span>5050, pp. 25–47. Springer (2008)</p>
<p>8. Bergstra, J., Bengio, Y.: Random search for hyper-parameter optimization. Journal of Machine <span id="_bookmark789" class="anchor"></span>Learning Research 13(Feb), 281–305 (2012)</p>
<p>9. Bergstra, J., Yamins, D., Cox, D.D.: Making a science of model search: Hyperparameter opti- mization in hundreds of dimensions for vision architectures. In: 30th International Conference <span id="_bookmark790" class="anchor"></span>on Machine Learning. vol. 28, pp. 115– 123 (2013)</p>
<p>10. Bergstra, J.S., Bardenet, R., Bengio, Y., Kégl, B.: Algorithms for hyper-parameter optimiza- tion. In: Advances in Neural Information Processing Systems. pp. 2546–2554 (2011)</p>
<p><span id="_bookmark802" class="anchor"></span>11. Blum, A.L., Langley, P.: Selection of relevant features and examples in machine learning. <span id="_bookmark820" class="anchor"></span>Artiﬁcial Intelligence 97(1–2), 273–324 (December 1997)</p>
<p>12. Boullé, M.: Compression-based averaging of selective naive bayes classiﬁers. Journal of Machine Learning Research 8, 1659– 1685 (2007), <a href="http://dl.acm.org/citation.cfm?id=1314554" class="uri">http://dl.acm.org/citation.cfm?id=1314554</a></p>
<p><span id="_bookmark821" class="anchor"></span>13. Boullé, M.: A parameter-free classiﬁcation method for large scale learning. Journal of Machine Learning Research 10, 1367– 1385 (2009), <a href="https://doi.org/10.1145/1577069.1755829" class="uri">https://doi.org/10.1145/1577069.1755829</a></p>
<p><span id="_bookmark827" class="anchor"></span>14. Brazdil, P., Carrier, C.G., Soares, C., Vilalta, R.: Metalearning: Applications to data mining. <span id="_bookmark763" class="anchor"></span>Springer Science &amp; Business Media (2008)</p>
<p><span id="_bookmark764" class="anchor"></span>15. Breiman, L.: Random forests. Machine Learning 45(1), 5–32 (2001)</p>
<p>16. Caruana, R., Niculescu-Mizil, A., Crew, G., Ksikes, A.: Ensemble selection from libraries of models. In: 21st International Conference on Machine Learning. pp. 18– . ACM (2004)</p>
<p><span id="_bookmark778" class="anchor"></span>17. Cawley, G.C., Talbot, N.L.C.: Preventing over-ﬁtting during model selection via Bayesian regularisation of the hyper-parameters. Journal of Machine Learning Research 8, 841–861 <span id="_bookmark760" class="anchor"></span>(April 2007)</p>
<p>18. Colson, B., Marcotte, P., Savard, G.: An overview of bilevel programming. Annals of <span id="_bookmark761" class="anchor"></span>Operations Research 153, 235–256 (2007)</p>
<p>19. Dempe, S.: Foundations of bilevel programming. Kluwer Academic Publishers (2002)</p>
</blockquote>
<p><span id="_bookmark773" class="anchor"></span>20. Dietterich, T.G.: Approximate statistical test for comparing supervised classiﬁcation learning <span id="_bookmark767" class="anchor"></span>algorithms. Neural Computation 10(7), 1895– 1923 (1998)</p>
<p>21. Duda, R.O., Hart, P.E., Stork, D.G.: Pattern Classiﬁcation. Wiley, 2nd edn. (2001)</p>
<p><span id="_bookmark800" class="anchor"></span>22. Efron, B.: Estimating the error rate of a prediction rule: Improvement on cross-validation. Journal of the American Statistical Association 78(382), 316–331 (1983)</p>
<p><span id="_bookmark791" class="anchor"></span>23. Eggensperger, K., Feurer, M., Hutter, F., Bergstra, J., Snoek, J., Hoos, H., Leyton-Brown, K.: Towards an empirical foundation for assessing bayesian optimization of hyperparameters. In: NIPS workshop on Bayesian Optimization in Theory and Practice (2013)</p>
<p>24. Escalante, H.J., Montes, M., Sucar, L.E.: Particle swarm model selection. Journal of Machine <span id="_bookmark756" class="anchor"><span id="_bookmark741" class="anchor"></span></span>Learning Research 10, 405–440 (2009)</p>
<p>25. Feurer, M., Klein, A., Eggensperger, K., Springenberg, J., Blum, M., Hutter, F.: Efﬁcient and robust automated machine learning. In: Proceedings of the Neural Information Processing Systems, pp. 2962–2970 (2015), <a href="https://github.com/automl/auto-sklearn" class="uri">https://github.com/automl/auto-sklearn</a></p>
<p>26. Feurer, M., Klein, A., Eggensperger, K., Springenberg, J., Blum, M., Hutter, F.: Methods for improving bayesian optimization for automl. In: Proceedings of the International Conference on Machine Learning 2015, Workshop on Automatic Machine Learning (2015)</p>
<p>27. Feurer, M., Springenberg, J., Hutter, F.: Initializing bayesian hyperparameter optimization via meta-learning. In: Proceedings of the AAAI Conference on Artiﬁcial Intelligence. pp. 1128– 1135 (2015)</p>
<blockquote>
<p>10 Analysis of the AutoML Challenge Series 2015–2018 217</p>
<p><span id="_bookmark742" class="anchor"></span>28. Feurer, M., Eggensperger, K., Falkner, S., Lindauer, M., Hutter, F.: Practical automated machine learning for the automl challenge 2018. In: International Workshop on Automatic Machine Learning at ICML (2018), <a href="https://sites.google.com/site/automl2018icml/" class="uri">https://sites.google.com/site/automl2018icml/</a></p>
<p>29. Friedman, J.H.: Greedy function approximation: A gradient boosting machine. The Annals of <span id="_bookmark765" class="anchor"><span id="_bookmark754" class="anchor"></span></span>Statistics 29(5), 1189– 1232 (2001)</p>
<p>30. Ghahramani, Z.: Unsupervised learning. In: Advanced Lectures on Machine Learning. Lecture Notes in Computer Science, vol. 3176, pp. 72– 112. Springer Berlin Heidelberg (2004)</p>
<p>31. Guyon, I.: Challenges in Machine Learning book series. Microtome (2011–2016), <a href="http://www.mtome.com/Publications/CiML/ciml.html">http://www</a>. <span id="_bookmark747" class="anchor"><span id="_bookmark732" class="anchor"></span></span><a href="http://www.mtome.com/Publications/CiML/ciml.html">mtome.com/Publications/CiML/ciml.html</a></p>
<p>32. Guyon, I., Bennett, K., Cawley, G., Escalante, H.J., Escalera, S., Ho, T.K., Macià, N., Ray, B., Saeed, M., Statnikov, A., Viegas, E.: AutoML challenge 2015: Design and ﬁrst results. In: Proc. of AutoML 2015@ICML (2015), <a href="https://drive.google.com/file/d/0BzRGLkqgrI-qWkpzcGw4bFpBMUk/view">https://drive.google.com/ﬁle/d/0BzRGLkqgrI-</a> <span id="_bookmark745" class="anchor"></span><a href="https://drive.google.com/file/d/0BzRGLkqgrI-qWkpzcGw4bFpBMUk/view">qWkpzcGw4bFpBMUk/view</a></p>
<p>33. Guyon, I., Bennett, K., Cawley, G., Escalante, H.J., Escalera, S., Ho, T.K., Macià, N., Ray, B., Saeed, M., Statnikov, A., Viegas, E.: Design of the 2015 ChaLearn AutoML challenge. In: International Joint Conference on Neural Networks (2015), <a href="http://www.causality.inf.ethz.ch/AutoML/automl_ijcnn15.pdf">http://www.causality.inf.ethz.ch/</a> <span id="_bookmark748" class="anchor"></span><a href="http://www.causality.inf.ethz.ch/AutoML/automl_ijcnn15.pdf">AutoML/automl_ijcnn15.pdf</a></p>
<p>34. Guyon, I., Chaabane, I., Escalante, H.J., Escalera, S., Jajetic, D., Lloyd, J.R., Macía, N., Ray, B., Romaszko, L., Sebag, M., Statnikov, A., Treguer, S., Vie- gas, E.: A brief review of the ChaLearn AutoML challenge. In: Proc. of AutoML 2016@ICML (2016), <a href="https://docs.google.com/a/chalearn.org/viewer?a=v&amp;pid=sites&amp;srcid=Y2hhbGVhcm4ub3JnfGF1dG9tbHxneDoyYThjZjhhNzRjMzI3MTg4">https://docs.google.com/a/chalearn.org/viewer?a=v&amp;pid=sites&amp;srcid=</a> <span id="_bookmark830" class="anchor"></span><a href="https://docs.google.com/a/chalearn.org/viewer?a=v&amp;pid=sites&amp;srcid=Y2hhbGVhcm4ub3JnfGF1dG9tbHxneDoyYThjZjhhNzRjMzI3MTg4">Y2hhbGVhcm4ub3JnfGF1dG9tbHxneDoyYThjZjhhNzRjMzI3MTg4</a></p>
<p>35. Guyon, I., Alamdari, A.R.S.A., Dror, G., Buhmann, J.: Performance prediction challenge. In: <span id="_bookmark750" class="anchor"></span>the International Joint Conference on Neural Networks. pp. 1649– 1656 (2006)</p>
<p>36. Guyon, I., Bennett, K., Cawley, G., Escalante, H.J., Escalera, S., Ho, T.K., Ray, B., Saeed, M., <span id="_bookmark735" class="anchor"></span>Statnikov, A., Viegas, E.: Automl challenge 2015: Design and ﬁrst results (2015)</p>
<p>37. Guyon, I., Cawley, G., Dror, G.: Hands-On Pattern Recognition: Challenges in Machine <span id="_bookmark777" class="anchor"></span>Learning, Volume 1. Microtome Publishing, USA (2011)</p>
<p>38. Guyon, I., Gunn, S., Nikravesh, M., Zadeh, L. (eds.): Feature extraction, foundations and applications. Studies in Fuzziness and Soft Computing, Physica-Verlag, Springer (2006)</p>
<p><span id="_bookmark780" class="anchor"></span>39. Hastie, T., Rosset, S., Tibshirani, R., Zhu, J.: The entire regularization path for the support vector machine. Journal of Machine Learning Research 5, 1391– 1415 (2004)</p>
</blockquote>
<p><span id="_bookmark768" class="anchor"></span>40. Hastie, T., Tibshirani, R., Friedman, J.: The elements of statistical learning: Data mining, <span id="_bookmark792" class="anchor"></span>inference, and prediction. Springer, 2nd edn. (2001)</p>
<p>41. Hutter, F., Hoos, H.H., Leyton-Brown, K.: Sequential model-based optimization for general algorithm conﬁguration. In: Proceedings of the conference on Learning and Intelligent <span id="_bookmark770" class="anchor"></span>OptimizatioN (LION 5) (2011)</p>
<p>42. Ioannidis, J.P.A.: Why most published research ﬁndings are false. PLoS Medicine 2(8), e124 <span id="_bookmark772" class="anchor"></span>(August 2005)</p>
<p>43. Jordan, M.I.: On statistics, computation and scalability. Bernoulli 19(4), 1378– 1390 (Septem- <span id="_bookmark779" class="anchor"></span>ber 2013)</p>
<p>44. Keerthi, S.S., Sindhwani, V., Chapelle, O.: An efﬁcient method for gradient-based adaptation of hyperparameters in SVM models. In: Advances in Neural Information Processing Systems</p>
<blockquote>
<p><span id="_bookmark793" class="anchor"></span>(2007)</p>
</blockquote>
<p>45. Klein, A., Falkner, S., Bartels, S., Hennig, P., Hutter, F.: Fast bayesian hyperparameter optimization on large datasets. In: Electronic Journal of Statistics. vol. 11 (2017)</p>
<p>46. Kohavi, R., John, G.H.: Wrappers for feature selection. Artiﬁcial Intelligence 97(1–2), 273– <span id="_bookmark803" class="anchor"><span id="_bookmark771" class="anchor"></span></span>324 (December 1997)</p>
<p>47. Langford, J.: Clever methods of overﬁtting (2005), blog post at<a href="http://hunch.net/?p=22" class="uri">http://hunch.net/?p=22</a></p>
<blockquote>
<p>218 I. Guyon et al.</p>
</blockquote>
<p>48. Lloyd, J.: Freeze Thaw Ensemble Construction. <a href="https://github.com/jamesrobertlloyd/automl-phase-2">https://github.com/jamesrobertlloyd/automl-</a> <span id="_bookmark831" class="anchor"><span id="_bookmark784" class="anchor"></span></span><a href="https://github.com/jamesrobertlloyd/automl-phase-2">phase-2</a> (2016)</p>
<p>49. Momma, M., Bennett, K.P.: A pattern search method for model selection of support vector regression. In: In Proceedings of the SIAM International Conference on Data Mining. SIAM</p>
<blockquote>
<p><span id="_bookmark776" class="anchor"></span>(2002)</p>
<p>50. Moore, G., Bergeron, C., Bennett, K.P.: Model selection for primal SVM. Machine Learning <span id="_bookmark805" class="anchor"></span>85(1–2), 175–208 (October 2011)</p>
<p>51. Moore, G.M., Bergeron, C., Bennett, K.P.: Nonsmooth bilevel programming for hyperparam- eter selection. In: IEEE International Conference on Data Mining Workshops. pp. 374–381</p>
<p><span id="_bookmark829" class="anchor"></span>(2009)</p>
<p>52. Niculescu-Mizil, A., Perlich, C., Swirszcz, G., Sindhwani, V., Liu, Y., Melville, P., Wang, D., Xiao, J., Hu, J., Singh, M., et al.: Winning the kdd cup orange challenge with ensemble selection. In: Proceedings of the 2009 International Conference on KDD-Cup 2009-Volume 7. <span id="_bookmark782" class="anchor"></span>pp. 23–34. JMLR. org (2009)</p>
<p>53. Opper, M., Winther, O.: Gaussian processes and SVM: Mean ﬁeld results and leave-one-out, pp. 43–65. MIT (10 2000), massachusetts Institute of Technology Press (MIT Press) Available <span id="_bookmark781" class="anchor"></span>on Google Books</p>
<p>54. Park, M.Y., Hastie, T.: L1-regularization path algorithm for generalized linear models. Journal of the Royal Statistical Society: Series B (Statistical Methodology) 69(4), 659–677 (2007)</p>
<p><span id="_bookmark739" class="anchor"></span>55. Pedregosa, F., Varoquaux, G., Gramfort, A., Michel, V., Thirion, B., Grisel, O., Blondel, M., Prettenhofer, P., Weiss, R., Dubourg, V., Vanderplas, J., Passos, A., Cournapeau, D., Brucher, M., Perrot, M., Duchesnay, E.: Scikit-learn: Machine learning in Python. Journal of Machine <span id="_bookmark799" class="anchor"></span>Learning Research 12, 2825–2830 (2011)</p>
<p>56. Pham, H., Guan, M.Y., Zoph, B., Le, Q.V., Dean, J.: Efﬁcient neural architecture search via <span id="_bookmark798" class="anchor"></span>parameter sharing. arXiv preprint arXiv:1802.03268 (2018)</p>
<p>57. Real, E., Moore, S., Selle, A., Saxena, S., Suematsu, Y.L., Le, Q., Kurakin, A.: Large-scale evolution of image classiﬁers. arXiv preprint arXiv:1703.01041 (2017)</p>
<p>58. Ricci, F., Rokach, L., Shapira, B., Kantor, P.B. (eds.): Recommender Systems Handbook. <span id="_bookmark753" class="anchor"><span id="_bookmark755" class="anchor"></span></span>Springer (2011)</p>
<p>59. Schölkopf, B., Smola, A.J.: Learning with Kernels: Support Vector Machines, Regularization, <span id="_bookmark787" class="anchor"></span>Optimization, and Beyond. MIT Press (2001)</p>
<p>60. Snoek, J., Larochelle, H., Adams, R.P.: Practical Bayesian optimization of machine learning algorithms. In: Advances in Neural Information Processing Systems 25, pp. 2951–2959 (2012)</p>
<p><span id="_bookmark785" class="anchor"></span>61. Statnikov, A., Wang, L., Aliferis, C.F.: A comprehensive comparison of random forests and support vector machines for microarray-based cancer classiﬁcation. BMC Bioinformatics 9(1)</p>
<p><span id="_bookmark757" class="anchor"></span>(2008)</p>
<p>62. Sun, Q., Pfahringer, B., Mayo, M.: Full model selection in the space of data mining operators. In: Genetic and Evolutionary Computation Conference. pp. 1503– 1504 (2012)</p>
<p><span id="_bookmark788" class="anchor"></span>63. Swersky, K., Snoek, J., Adams, R.P.: Multi-task Bayesian optimization. In: Advances in Neural Information Processing Systems 26. pp. 2004–2012 (2013)</p>
<p>64. Swersky, K., Snoek, J., Adams, R.P.: Freeze-thaw bayesian optimization. arXiv preprint <span id="_bookmark794" class="anchor"><span id="_bookmark758" class="anchor"></span></span>arXiv:1406.3896 (2014)</p>
<p>65. Thornton, C., Hutter, F., Hoos, H.H., Leyton-Brown, K.: Auto-weka: Automated selection and hyper-parameter optimization of classiﬁcation algorithms. CoRR abs/1208.3719 (2012)</p>
<p><span id="_bookmark766" class="anchor"></span>66. Thornton, C., Hutter, F., Hoos, H.H., Leyton-Brown, K.: Auto-weka: Combined selection and hyperparameter optimization of classiﬁcation algorithms. In: 19th ACM SIGKDD Interna- tional Conference on Knowledge Discovery and Data Mining. pp. 847–855. ACM (2013)</p>
<p><span id="_bookmark822" class="anchor"></span>67. Vanschoren, J., Van Rijn, J.N., Bischl, B., Torgo, L.: Openml: networked science in machine learning. ACM SIGKDD Explorations Newsletter 15(2), 49–60 (2014)</p>
<p>10 Analysis of the AutoML Challenge Series 2015–2018 219</p>
<p>68. Vapnik, V., Chapelle, O.: Bounds on error expectation for support vector machines. Neural <span id="_bookmark737" class="anchor"><span id="_bookmark783" class="anchor"></span></span>computation 12(9), 2013–2036 (2000)</p>
<p>69. Weston, J., Elisseeff, A., BakIr, G., Sinz, F.: Spider (2007), <a href="http://mloss.org/software/view/29/" class="uri">http://mloss.org/software/view/29/</a></p>
<p>70. Zoph, B., Le, Q.V.: Neural architecture search with reinforcement learning. arXiv preprint <span id="_bookmark796" class="anchor"></span>arXiv:1611.01578 (2016)</p>
<p><strong>Open</strong> <strong>Access</strong> This chapter is licensed under the terms of the Creative Commons Attribution 4.0 International License <a href="http://creativecommons.org/licenses/by/4.0/">(http://creativecommons.org/licenses/by/4.0/</a>), which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence and indicate if changes were made.</p>
<p>The images or other third party material in this chapter are included in the chapter’s Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the chapter’s Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder.</p>
</blockquote>
<p><img src="./automlgithubpagesimages//media/image564.png" width="75" height="26" /></p>
</body>
</html>
